@incollection{2000,
  title = {6–7 – {{Definite Integrals}} of {{Special Functions}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {625--850},
  doi = {10.1016/B978-012294757-5/50012-X},
  abstract = {This chapter discusses the definite integrals of special functions including elliptic integrals and functions, the exponential integral function and functions generated by it, the probability integral, the gamma function and functions generated by it, Bessel functions and the functions generated by them. It also describes Mathieu functions, associated Legendre functions, orthogonal polynomials, hypergeometric functions, confluent hypergeometric functions, parabolic cylinder functions, and Meijer's and MacRobert's functions.},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\6QM4SNH8\\Unknown - 2000 - 6–7 – Definite Integrals of Special Functions.pdf}
}

@incollection{2000a,
  title = {10 – {{Vector Field Theory}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {1039--1048},
  doi = {10.1016/B978-012294757-5/50014-3},
  abstract = {This chapter discusses products of vectors and presents the properties of scalar product and vector product, followed by the differentiation of vectors. It also discusses the operators like grad, div, and curl. In addition, solenoidal fields, orthogonal curvilinear coordinates, and vector integral theorems are briefed. Vector integral theorems include Gauss's divergence theorem, Green's theorems, Green's reciprocal theorem, Green's representation theorem, Green's theorem of the arithmetic mean, Poisson's integral in three dimensions, Poisson's integral in two dimensions, Stokes' theorem, and Planar case of Stokes' theorem.},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\UBW7UXX6\\Unknown - 2000 - 10 – Vector Field Theory.pdf}
}

@incollection{2000b,
  title = {11 – {{Algebraic Inequalities}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {1049--1052},
  doi = {10.1016/B978-012294757-5/50015-5},
  abstract = {This chapter discusses algebraic inequalities involving real numbers and complex numbers, followed by inequalities for sets of complex numbers. The algebraic inequalities involving real numbers include Lagrange's identity, Cauchy–Schwarz–Buniakowsky inequality, Minkowski's inequality, Hölder's inequality, Chebyshev's inequality, Arithmetic–geometric inequality, Carleman's inequality, and an inequality involving absolute values. Discussion on inequalities for sets of complex numbers covers complex Cauchy–Schwarz–Buniakowsky inequality, Complex Minkowski inequality, and complex Hölder inequality,},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\NBN9H9EV\\Unknown - 2000 - 11 – Algebraic Inequalities.pdf}
}

@incollection{2000c,
  title = {13 – {{Matrices}} and related results},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {1059--1064},
  doi = {10.1016/B978-012294757-5/50017-9},
  abstract = {This chapter discusses special matrices, quadratic forms, differentiation of matrices, and the matrix exponential. Special matrices include diagonal matrix, identity matrix and null matrix, reducible and irreducible matrices, equivalent matrices, transpose of a matrix, adjoint matrix, inverse matrix, trace of a matrix, symmetric matrix, skew-symmetric matrix, triangular matrices, orthogonal matrices, Hermitian matrix, Unitary matrix, Nilpotent matrix, and Idempotent matrix. Under quadratic forms Sylvester's law of inertia is discussed with its rank, signature, and positive definite and semidefinite quadratic form. In addition, the basic properties of matrix exponential are explained.},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\THP2AHBV\\Unknown - 2000 - 13 – Matrices and related results.pdf}
}

@incollection{2000d,
  title = {14 – {{Determinants}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {1065--1070},
  doi = {10.1016/B978-012294757-5/50018-0},
  abstract = {This chapter presents the expansion of second- and third-order determinants and its basic properties, followed by minors and cofactors of a determinant. It also discusses Laplace expansion of a determinant, Jacobi's theorem, Hadamard's theorem, Hadamard's inequality, Cramer's rule, Vandermonde's determinant (alternant), circulants, Jacobian determinant, Hessian determinants, Wronskian determinants, and Gram–Kowalewski theorem on linear dependence.},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\MEKYWHG9\\Unknown - 2000 - 14 – Determinants.pdf}
}

@incollection{2000e,
  title = {16 – {{Ordinary}} differential equations},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {1083--1097},
  doi = {10.1016/B978-012294757-5/50020-9},
  abstract = {This chapter presents results relating to the solution of ordinary differential equations and discusses fundamental inequalities and the related results. It also discusses first-order systems and presents some special types of elementary differential equations such as variables separable, exact differential equations, and homogeneous differential equations. First-order equations include solution of such equations, the Cauchy problem for the differential equation, and Lipschitz continuity of a function. In addition, second-order equations are also explained, which includes adjoint and self-adjoint equations, Abel's identity, Lagrange identity, and Riccati equation, followed by oscillation and non-oscillation theorems for second-order equations. Equations whose solutions possess an infinite number of zeros in the interval (0,∞) are said to have oscillatory solutions, whereas a real solution is said to be non-oscillatory in the wide sense in (0, ∞) if there exists a finite number “c” such that the solution has no zeros in (c, ∞).},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\ZQVRHP4G\\Unknown - 2000 - 16 – Ordinary differential equations.pdf}
}

@incollection{2000f,
  title = {17 – {{Fourier}}, {{Laplace}}, and {{Mellin Transforms}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {1099--1125},
  doi = {10.1016/B978-012294757-5/50021-0},
  abstract = {This chapter presents integral transforms under which Laplace transform, Fourier transform, Fourier sine and cosine transforms, and Mellin transform are discussed, followed by their basic properties. In addition, a table of Laplace transform pairs, Fourier transform pairs, Fourier transform pairs for spherically symmetric functions, and Mellin cosine transforms is also illustrated. The Fourier transform is also called the exponential or complex Fourier transform of the function f(x) and denoted by F(ξ). The Fourier sine and cosine transforms of the function f(x) are denoted by Fs (ξ) and Fc (ξ) respectively.},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Z5ED33HZ\\Unknown - 2000 - 17 – Fourier, Laplace, and Mellin Transforms.pdf}
}

@incollection{2000g,
  title = {18 – {{The}} z-transform},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {1127--1132},
  doi = {10.1016/B978-012294757-5/50022-2},
  abstract = {This chapter discusses z-transform and its two forms—bilateral and unilateral z-transforms. The z-transform converts a numerical sequence x[n] into a function of the complex variable z and it takes two different forms. The bilateral or two-sided z-transform, denoted in this chapter by Zb \{x[n]\}, is used mainly in signal and image processing, while the unilateral or one-sided z-transform, denoted by Zu \{x[n]\}, is used mainly in the analysis of discrete time systems and the solution of linear difference equations.},
  isbn = {978-0-12-294757-5}
}

@incollection{2000h,
  title = {Index of {{Functions}} and {{Constants}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {1143--1151},
  doi = {10.1016/B978-012294757-5/50024-6},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\KYJWH33I\\Unknown - 2000 - Index of Functions and Constants.pdf}
}

@incollection{2000i,
  title = {5 – {{Indefinite Integrals}} of {{Special Functions}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {615--624},
  doi = {10.1016/B978-012294757-5/50011-8},
  abstract = {This chapter discusses elliptic integrals and functions, the exponential integral function, the sine integral and the cosine integral, the probability integral and Fresnel integrals, and Bessel functions. In elliptic integrals and functions, complete elliptic integrals, Jacobian elliptic functions, and Weierstrass elliptic functions are discussed.},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\2RLLZET9\\Unknown - 2000 - 5 – Indefinite Integrals of Special Functions.pdf}
}

@incollection{2000j,
  title = {8–9 – {{Special Functions}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {851--1038},
  doi = {10.1016/B978-012294757-5/50013-1},
  abstract = {This chapter discusses elliptic integrals and functions, the exponential integral function and functions generated by them, Euler's integrals of the first and second kinds and the functions generated by them, Bessel functions and functions associated with them, along with a series of Bessel functions. It also describes Mathieu functions, associated Legendre functions, orthogonal polynomials, hypergeometric functions, confluent hypergeometric functions, Meijer's G-function, MacRobert's E-function, Riemann's zeta functions and the functions Φ and ξ, Bernoulli numbers and polynomials, and Euler numbers polynomials. The Euler numbers are integers and the Euler numbers of odd index are equal to zero; the signs of two adjacent numbers of even indices are opposite.},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\7L56F57T\\Unknown - 2000 - 8–9 – Special Functions.pdf}
}

@incollection{2000k,
  title = {15 – {{Norms}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {1071--1081},
  doi = {10.1016/B978-012294757-5/50019-2},
  abstract = {This chapter discusses vector norms, matrix norms, spectral radius of a square matrix, inequalities involving eigenvalues of matrices, inequalities for the characteristic polynomial, named theorems on eigenvalues, and variational principles. Primarily, it describes the general properties and principal of norms. The first group of inequalities relating to the eigenvalues λ and satisfying P(λ)=0 are unnamed, whereas the second group of inequalities are named theorems that apply to the explicit form of the characteristic polynomial P(λ). The named inequalities that are discussed include Parodi's theorem, Corollary of Brauer's theorem, Ballieu's theorem, and Routh–Hurwitz theorem. In the theorems involving eigenvalue inequalities, the elements “aij” of matrix A enter directly, and not in the form of the coefficients of the characteristic polynomial. These include Schur's inequalities, Sturmian separation theorem, Poincare's separation theorem, Gerschgorin's theorem, Brauer's theorem, Perron's theorem, Frobenius theorem, Perron–Frobenius theorem, Wielandt's theorem, Ostrowski's theorem, and first and second theorem due to Lyapunov.},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\8DMH8WSK\\Unknown - 2000 - 15 – Norms.pdf}
}

@incollection{2000l,
  title = {12 – {{Integral Inequalities}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {1053--1058},
  doi = {10.1016/B978-012294757-5/50016-7},
  abstract = {This chapter presents mean value theorems and discusses differentiation of definite integral containing a parameter, integral inequalities, convexity and Jensen's inequality, Fourier series and the related inequalities including Riemann-Lebesgue lemma, Dirichlet lemma, Parseval's theorem for trigonometric Fourier series, and Bessel's inequality for generalized Fourier series.},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Z2PC6P3T\\Unknown - 2000 - 12 – Integral Inequalities.pdf}
}

@incollection{2000m,
  title = {Index of {{Concepts}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {1153--1163},
  doi = {10.1016/B978-012294757-5/50025-8},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\LDJ2FN8L\\Unknown - 2000 - Index of Concepts.pdf}
}

@incollection{2000n,
  title = {The {{Order}} of {{Presentation}} of the {{Formulas}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {xxvii-xxix},
  doi = {10.1016/B978-012294757-5/50002-7},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\332H46U5\\Unknown - 2000 - The Order of Presentation of the Formulas.pdf}
}

@incollection{2000o,
  title = {Acknowledgments},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {xxiii-xxv},
  doi = {10.1016/B978-012294757-5/50001-5},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\HFPSFKXS\\Unknown - 2000 - Acknowledgments.pdf}
}

@incollection{2000p,
  title = {Notation},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {xliii-xlv},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-012294757-5/50005-2},
  url = {http://linkinghub.elsevier.com/retrieve/pii/B9780122947575500052},
  urldate = {2018-03-22},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\DT7AVI7L\\Unknown - 2000 - Notation.pdf}
}

@incollection{2000q,
  title = {Use of the {{Tables}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {xxxi-xxxviii},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-012294757-5/50003-9},
  url = {http://linkinghub.elsevier.com/retrieve/pii/B9780122947575500039},
  urldate = {2018-03-22},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\2SQK9BFF\\Unknown - 2000 - Use of the Tables.pdf}
}

@incollection{2000r,
  title = {0 – {{Introduction}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {1--23},
  doi = {10.1016/B978-012294757-5/50007-6},
  abstract = {This chapter introduces finite sums, numerical series and infinite products, functional series, and formulas from differential calculus. Under finite sums, following topics are discussed: progressions, sums of powers of natural numbers, sums of reciprocals of natural numbers, sums of products of reciprocals of natural numbers, and sums of the binomial coefficients. In addition, several examples of numerical series and infinite products are also presented. Functional series is defined and theorems are given, followed by brief description on power series, Fourier series, and asymptotic series. Formulas for differential calculus include differentiation of a definite integral with respect to a parameter, the nthderivative of a product (Leibniz's rule), and the nth derivative of a composite function.},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\6JZJUMWI\\Unknown - 2000 - 0 – Introduction.pdf}
}

@incollection{2000s,
  title = {Index of {{Special Functions}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {xxxix-xlii},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-012294757-5/50004-0},
  url = {http://linkinghub.elsevier.com/retrieve/pii/B9780122947575500040},
  urldate = {2018-03-22},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\6NXPFVCL\\Unknown - 2000 - Index of Special Functions.pdf}
}

@incollection{2000t,
  title = {Elementary {{Functions}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {25--60},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-012294757-5/50008-8},
  url = {http://linkinghub.elsevier.com/retrieve/pii/B9780122947575500088},
  urldate = {2018-03-22},
  abstract = {This chapter discusses elementary functions including power of binomials, exponential function, trigonometric and hyperbolic functions, logarithm, and inverse trigonometric and hyperbolic functions. Power of binomials includes power series and series of rational fractions. In exponential function series representation is given, followed by functional relations and series of exponentials. An introduction to trigonometric and hyperbolic function is provided with its basic functional relations and special series, along with a series representation of logarithm. In addition, the chapter also discusses the principal values of the inverse trigonometric functions defined by the inequalities and the relationship between the inverse and the direct trigonometric functions are described, followed by the relationship among the inverse trigonometric functions, the inverse hyperbolic functions, and the logarithm.},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\CV52B4PR\\Unknown - 2000 - Elementary Functions.pdf}
}

@incollection{2000u,
  title = {Note on the {{Bibliographic References}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  doi = {10.1016/B978-012294757-5/50006-4},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\HK6XI44I\\Unknown - 2000 - Note on the Bibliographic References.pdf}
}

@incollection{2000v,
  title = {2 – {{Indefinite Integrals}} of {{Elementary Functions}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  date = {2000},
  pages = {61--241},
  doi = {10.1016/B978-012294757-5/50009-X},
  abstract = {This chapter provides an introduction to indefinite integrals of elementary functions followed by its forms. Elementary functions include rational functions, algebraic functions, exponential function, hyperbolic function, trigonometric functions, logarithms and inverse-hyperbolic functions, and inverse trigonometric functions. When certain functions are integrated, the logarithm of the absolute value is obtained. In such formulas, the absolute-value bars in the argument of the logarithm are omitted for simplicity in writing. In certain cases, it is important to give the complete form of the primitive function. Such primitive functions, written in the form of definite integrals, are given. Closely related to these formulas are formulas in which the limits of integration and the integrand depend on the same parameter. A number of formulas lose their meaning for certain values of the constants (parameters) or for certain relationships among these constants. These values of the constants and the relationships among them are for the most part completely clear from the very structure of the right hand member of the formula. Therefore, throughout the chapter, remarks to this effect are omitted. The constant of integration in all the formulas of this chapter is also omitted. Therefore, the equality sign (=) means that the functions on the left and right of this symbol differ by a constant.},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\WXPF28II\\Unknown - 2000 - 2 – Indefinite Integrals of Elementary Functions.pdf}
}

@report{2015,
  title = {Robust optimization in {{Raystation}}},
  date = {2015},
  institution = {{Raysearch Laboratories}},
  location = {{Stockholm, Sweden}},
  abstract = {To enable the creation of robust plans for cases where conventional margins do not work, RayStation implements a robust optimization method that explicitly takes into account the effects of possible errors. The optimization then strives for plans that are robust against these effects. The basis of this method is minimax optimization, in which the optimization functions that have been selected to be robust are considered under the worst case scenario [1]. The worst case scenario is the realization of uncertainty under which a robust function attains its highest value. If several func-tions are selected to be robust, their weighted sum in the worst case scenario is considered. Minimax optimization of n functions f1,…,fn, which are all required to be robust over the scenarios enumerated by the set S, and which have nonnegative importance weights w1,…,wn, can be formulated as an optimization problem on the form (1) where X is the set of feasible variables (e.g., MLC leaf positions and segment weights for IMRT or spot weights for IMPT), and d(x;s) is the dose distribution as a function of the variables x and the scenario s. Functions applied only to the nominal scenario can also be added to the objective. Moreover, nominal and robust constraints can be used in combination with formulation (1).},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\YKPAKUZB\\Unknown - 2015 - Robust optimization in Raystation.pdf}
}

@article{Abramowitz1971,
  title = {Bibliographic references used in preparation of text ({{See}} the introduction for an explanation of the letters preceding each bibliographic reference.)},
  author = {Abramowitz, As and Adams, Ad and Byrd, BY},
  date = {1971},
  journaltitle = {Z. CL Coddington, E. A. and Levinson, N. Methods of Mathematical Physics},
  volume = {2},
  publisher = {{Springer Verlag McGraw Hill Macmillan McGraw-Hill Springer Verlag Springer-Verlag McGraw Hill DW Dwight Macmillan Macmillan}},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\4TXR2HHJ\\Abramowitz, Adams, Byrd - 1971 - Bibliographic references used in preparation of text (See the introduction for an explanation of the le.pdf}
}

@book{Abramowitz1972,
  title = {Handbook of {{Mathemtical Functions With Formulas}}, {{Graphs}}, and {{Mathematical Tables}}},
  editor = {Abramowitz, Milton and Stegun, Irene A},
  date = {1972},
  edition = {10},
  location = {{Dover, New York}}
}

@article{Acar2011,
  title = {A scalable optimization approach for fitting canonical tensor decompositions},
  author = {Acar, Evrim and Dunlavy, Daniel M. and Kolda, Tamara G.},
  date = {2011},
  journaltitle = {Journal of Chemometrics},
  volume = {25},
  number = {2},
  pages = {67--86},
  issn = {08869383},
  doi = {10.1002/cem.1335},
  abstract = {Tensor decompositions are higher-order analogues of matrix decompositions and have proven to be powerful tools for data analysis. In particular, we are interested in the canonical tensor decomposition, otherwise known as CANDECOMP/PARAFAC (CP), which expresses a tensor as the sum of component rank-one tensors and is used in a multitude of applications such as chemometrics, signal processing, neuroscience, and web analysis. The task of computing CP, however, can be difficult. The typical approach is based on alternating least squares (ALS) optimization, but it is not accurate in the case of overfactoring. High accuracy can be obtained by using nonlinear least squares (NLS) methods; the disadvantage is that NLS methods are much slower than ALS. In this paper, we propose the use of gradient-based optimization methods. We discuss the mathematical calculation of the derivatives and show that they can be computed efficiently, at the same cost as one iteration of ALS. Computational experiments demonstrate that the gradient-based optimization methods are more accurate than ALS and faster than NLS in terms of total computation time.},
  isbn = {9781479999880},
  keywords = {CANDECOMP,Optimization,PARAFAC,Tensor decomposition,Tensor factorization},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\N9XYWAEW\\Acar, Dunlavy, Kolda - 2011 - A scalable optimization approach for fitting canonical tensor decompositions.pdf}
}

@article{Acar2011a,
  title = {Scalable tensor factorizations for incomplete data},
  author = {Acar, Evrim and Dunlavy, Daniel M and Kolda, Tamara G and Mørup, Morten},
  date = {2011-03},
  journaltitle = {Chemometrics and Intelligent Laboratory Systems},
  volume = {106},
  number = {1},
  pages = {41--56},
  issn = {01697439},
  doi = {10.1016/j.chemolab.2010.08.004},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0169743910001437},
  urldate = {2018-03-29},
  abstract = {a b s t r a c t The problem of incomplete data – i.e., data with missing or unknown values – in multi-way arrays is ubiquitous in biomedical signal processing, network traffic analysis, bibliometrics, social network analysis, chemometrics, computer vision, communication networks, etc. We consider the problem of how to factorize data sets with missing values with the goal of capturing the underlying latent structure of the data and possibly reconstructing missing values (i.e., tensor completion). We focus on one of the most well-known tensor factorizations that captures multi-linear structure, CANDECOMP/PARAFAC (CP). In the presence of missing data, CP can be formulated as a weighted least squares problem that models only the known entries. We develop an algorithm called CP-WOPT (CP Weighted OPTimization) that uses a first-order optimization approach to solve the weighted least squares problem. Based on extensive numerical experiments, our algorithm is shown to successfully factorize tensors with noise and up to 99\% missing data. A unique aspect of our approach is that it scales to sparse large-scale data, e.g., 1000 × 1000 × 1000 with five million known entries (0.5\% dense). We further demonstrate the usefulness of CP-WOPT on two real-world applications: a novel EEG (electroencephalogram) application where missing data is frequently encountered due to disconnections of electrodes and the problem of modeling computer network traffic where data may be absent due to the expense of the data collection process.},
  keywords = {CANDECOMP,Incomplete data,Missing data,Optimization,PARAFAC,Tensor factorization},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\CLXLFIJM\\Acar et al. - 2011 - Scalable tensor factorizations for incomplete data.pdf}
}

@article{Achlioptas2007,
  title = {Fast computation of low-rank matrix approximations},
  author = {Achlioptas, Dimitris and Mcsherry, Frank},
  date = {2007},
  journaltitle = {Journal of the ACM},
  volume = {54},
  number = {2},
  pages = {9-es},
  issn = {00045411},
  doi = {10.1145/1219092.1219097},
  abstract = {Given a matrix A, it is often desirable to find a good approximation to A that has low rank. We introduce a simple technique for accelerating the computation of such approximations when A has strong spectral features, that is, when the singular values of interest are significantly greater than those of a random matrix with size and entries similar to A. Our technique amounts to independently sampling and/or quantizing the entries of A, thus speeding up computation by reducing the number of nonzero entries and/or the length of their representation. Our analysis is based on observing that the acts of sampling and quantization can be viewed as adding a random matrix N to A, whose entries are independent random variables with zero-mean and bounded variance. Since, with high probability, N has very weak spectral features, we can prove that the effect of sampling and quantization nearly vanishes when a low-rank approximation to A + N is computed. We give high probability bounds on the quality of our approximation both in the Frobenius and the 2-norm.},
  isbn = {00045411 (ISSN)},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\HD36I6QE\\Achlioptas, Mcsherry - 2007 - Fast computation of low-rank matrix approximations.pdf}
}

@article{Agmon1954,
  title = {The {{Relaxation Method}} for {{Linear Inequalities}}},
  author = {Agmon, Shmuel},
  date = {1954},
  journaltitle = {Canadian Journal of Mathematics},
  volume = {6},
  pages = {382--392},
  publisher = {{Cambridge University Press}},
  issn = {0008-414X, 1496-4279},
  doi = {10.4153/CJM-1954-037-2},
  url = {https://www.cambridge.org/core/journals/canadian-journal-of-mathematics/article/relaxation-method-for-linear-inequalities/7C0393A9DDB5EBB9FA5F1E78C591D820},
  urldate = {2021-12-16},
  abstract = {In various numerical problems one is confronted with the task of solving a system of linear inequalities:             (1.1)                                      (i = 1, … ,m)             assuming, of course, that the above system is consistent. Sometimes one has, in addition, to minimize a given linear form l(x). Thus, in linear programming one obtains a problem of the latter type.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\LCQRXPYE\\Agmon - 1954 - The Relaxation Method for Linear Inequalities.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\HBT8639G\\7C0393A9DDB5EBB9FA5F1E78C591D820.html}
}

@article{Ahmad2016,
  title = {Evaluation of a commercial {{MRI Linac}} based {{Monte Carlo}} dose calculation algorithm with geant 4},
  author = {Ahmad, Syed Bilal and Sarfehnia, Arman and Paudel, Moti Raj and Kim, Anthony and Hissoiny, Sami and Sahgal, Arjun and Keller, Brian},
  date = {2016},
  journaltitle = {Medical Physics},
  volume = {43},
  number = {2},
  pages = {894--907},
  issn = {2473-4209},
  doi = {10.1118/1.4939808},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1118/1.4939808},
  urldate = {2022-08-11},
  abstract = {Purpose: This paper provides a comparison between a fast, commercial, in-patient Monte Carlo dose calculation algorithm (GPUMCD) and geant4. It also evaluates the dosimetric impact of the application of an external 1.5 T magnetic field. Methods: A stand-alone version of the Elekta™ GPUMCD algorithm, to be used within the Monaco treatment planning system to model dose for the Elekta™ magnetic resonance imaging (MRI) Linac, was compared against geant4 (v10.1). This was done in the presence or absence of a 1.5 T static magnetic field directed orthogonally to the radiation beam axis. Phantoms with material compositions of water, ICRU lung, ICRU compact-bone, and titanium were used for this purpose. Beams with 2 MeV monoenergetic photons as well as a 7 MV histogrammed spectrum representing the MRI Linac spectrum were emitted from a point source using a nominal source-to-surface distance of 142.5 cm. Field sizes ranged from 1.5 × 1.5 to 10 × 10 cm2. Dose scoring was performed using a 3D grid comprising 1 mm3 voxels. The production thresholds were equivalent for both codes. Results were analyzed based upon a voxel by voxel dose difference between the two codes and also using a volumetric gamma analysis. Results: Comparisons were drawn from central axis depth doses, cross beam profiles, and isodose contours. Both in the presence and absence of a 1.5 T static magnetic field the relative differences in doses scored along the beam central axis were less than 1\% for the homogeneous water phantom and all results matched within a maximum of ±2\% for heterogeneous phantoms. Volumetric gamma analysis indicated that more than 99\% of the examined volume passed gamma criteria of 2\%—2 mm (dose difference and distance to agreement, respectively). These criteria were chosen because the minimum primary statistical uncertainty in dose scoring voxels was 0.5\%. The presence of the magnetic field affects the dose at the interface depending upon the density of the material on either sides of the interface. This effect varies with the field size. For example, at the water-lung interface a 33.94\% increase in dose was observed (relative to the Dmax), by both GPUMCD and geant4 for the field size of 2 × 2 cm2 (compared to no B-field case), which increased to 47.83\% for the field size of 5 × 5 cm2 in the presence of the magnetic field. Similarly, at the lung-water interface, the dose decreased by 19.21\% (relative to Dmax) for a field size of 2 × 2 cm2 and by 30.01\% for 5 × 5 cm2 field size. For more complex combinations of materials the dose deposition also becomes more complex. Conclusions: The GPUMCD algorithm showed good agreement against geant4 both in the presence and absence of a 1.5 T external magnetic field. The application of 1.5 T magnetic field significantly alters the dose at the interfaces by either increasing or decreasing the dose depending upon the density of the material on either side of the interfaces.},
  langid = {english},
  keywords = {Algorithms,biological effects of fields,Biological material,biomedical MRI,Cancer,Clinical applications,Dose-volume analysis,dosimetry,Dosimetry,Dosimetry/exposure assessment,e.g. blood,e.g. magnetic resonance imaging,evaluation using geant 4,Field size,GPUMCD,Haemocytometers,Involving electronic emr or nuclear nmr magnetic resonance,linear accelerators,Linear accelerators,Lungs,Magnetic fields,Magnetic resonance imaging,Medical treatment planning,Monte Carlo algorithms,Monte Carlo dose calculation,Monte Carlo methods,MRI Linac,phantoms,Photons,Scintigraphy,urine},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1118/1.4939808},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\KRA7AMF9\\Ahmad et al. - 2016 - Evaluation of a commercial MRI Linac based Monte C.pdf}
}

@report{Ahn2003,
  title = {Standard {{Errors}} of {{Mean}}, {{Variance}}, and {{Standard Deviation Estimators}}},
  author = {Ahn, Sangtae and Fessler, Jeffrey A.},
  date = {2003},
  url = {https://web.eecs.umich.edu/~fessler/papers/files/tr/stderr.pdf},
  urldate = {2016-10-07},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\BJNZ55NG\\Ahn, Fessler - 2003 - Standard Errors of Mean, Variance, and Standard Deviation Estimators.pdf}
}

@inproceedings{Alber2000,
  title = {Hyperion — {{An}} integrated {{IMRT}} planning tool},
  booktitle = {The {{Use}} of {{Computers}} in {{Radiation Therapy}}},
  author = {Alber, M. and Birkner, M. and Laub, W. and Nüsslin, F.},
  editor = {Schlegel, Wolfgang and Bortfeld, Thomas},
  date = {2000},
  pages = {46--48},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-59758-9_17},
  abstract = {The IMRT planning process poses problems beyond conventional planning, and as yet not all confounding factors have been fully understood or countermeasures devised. It may thus be argued that the most prominent feature of IMRT software is its capacity for development.},
  isbn = {978-3-642-59758-9},
  langid = {english}
}

@article{Alber2002,
  title = {On the degeneracy of the {{IMRT}} optimization problem},
  author = {Alber, M. and Meedt, G. and Nüsslin, F. and Reemtsen, R.},
  date = {2002},
  journaltitle = {Medical Physics},
  volume = {29},
  number = {11},
  pages = {2584},
  issn = {00942405},
  doi = {10.1118/1.1500402},
  url = {http://link.aip.org/link/MPHYA6/v29/i11/p2584/s1&Agg=doi},
  urldate = {2014-01-25},
  keywords = {imrt,optimization},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\KBDQVU8C\\Alber et al. - 2002 - On the degeneracy of the IMRT optimization problem.pdf}
}

@article{Alber2007,
  title = {Intensity modulated radiotherapy treatment planning by use of a barrier-penalty multiplier method},
  author = {Alber, M. and Reemtsen, R.},
  date = {2007-06},
  journaltitle = {Optimization Methods and Software},
  shortjournal = {Optimization Methods and Software},
  volume = {22},
  number = {3},
  pages = {391--411},
  issn = {1055-6788, 1029-4937},
  doi = {10.1080/10556780600604940},
  url = {http://www.tandfonline.com/doi/abs/10.1080/10556780600604940},
  urldate = {2020-09-24},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\RW8TTSBQ\\Alber und Reemtsen - 2007 - Intensity modulated radiotherapy treatment plannin.pdf}
}

@article{Albertini2010,
  title = {The influence of the optimization starting conditions on the robustness of intensity-modulated proton therapy plans.},
  author = {Albertini, F and Hug, E B and Lomax, Antony John},
  date = {2010},
  journaltitle = {Physics in medicine and biology},
  volume = {55},
  number = {10},
  eprint = {20427853},
  eprinttype = {pmid},
  pages = {2863--78},
  issn = {1361-6560},
  doi = {10.1088/0031-9155/55/10/005},
  abstract = {In this paper the influence of varying the starting conditions on intensity-modulated proton therapy (IMPT) plans has been studied. In particular IMPT plans have been optimized based on four different starting conditions of initial beamlet fluences: (a) all beamlets with an initial constant weight, delivering a gradient from the proximal to the distal edge of the target (forward wedge approach); (b) beamlet weights reduced from the distal to the proximal aspect of the target such as to deliver a flat 'spread-out-Bragg-peak' (SOBP approach); (c) beamlet weights calculated to deliver a gradient from the distal (maximal dose) to the proximal edge (inverse wedge); (d) beamlet weights set universally to zero except the most distal one, for each given lateral direction (i.e. distal-edge-tracking, DET). An analysis of robustness to range errors has been performed by recalculating plans, assuming a systematic 3\% error in CT values. Results showed that IMPT plans optimized with the forward wedge approach were very sensitive to range errors, since organs-at-risk (OAR) were spared by patching single-field lateral and distal fall-offs, the last ones being strongly sensitive to range errors. In addition a plan robust to range errors can be achieved by starting the optimization process in the case of low-dose constraints to OAR, with the initial flat SOBP approach, and with either the DET or the inverse wedge approaches, in the case of stringent dose-volume constraints to OAR. 'Starting condition-based optimization' as proposed here can therefore provide a tool to transparently 'steer' the optimization outcome to solutions more robust to uncertainties.},
  isbn = {1361-6560 (Electronic) 0031-9155 (Linking)},
  keywords = {Chondrosarcoma,Chondrosarcoma: radiotherapy,Computer-Assisted,Computer-Assisted: methods,Female,Humans,Intensity-Modulated,Intensity-Modulated: methods,Male,Prostatic Neoplasms,Prostatic Neoplasms: radiotherapy,Protons,Protons: therapeutic use,Radiotherapy,Radiotherapy Dosage,Radiotherapy Planning,Thoracic Neoplasms,Thoracic Neoplasms: radiotherapy,Uncertainty,Uterine Cervical Neoplasms,Uterine Cervical Neoplasms: radiotherapy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\FUAYIDM7\\Albertini, Hug, Lomax - 2010 - The influence of the optimization starting conditions on the robustness of intensity-modulated proton the.pdf}
}

@article{Albertini2011,
  title = {Is it necessary to plan with safety margins for actively scanned proton therapy?},
  author = {Albertini, F and Hug, E B and Lomax, Antony John},
  date = {2011-07-21},
  journaltitle = {Physics in Medicine and Biology},
  volume = {56},
  number = {14},
  eprint = {21709340},
  eprinttype = {pmid},
  pages = {4399--4413},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/56/14/011},
  url = {http://stacks.iop.org/0031-9155/56/i=14/a=011?key=crossref.79bc965f9231438e4653528dcc301b14},
  urldate = {2016-07-29},
  abstract = {In radiation therapy, a plan is robust if the calculated and the delivered dose are in agreement, even in the case of different uncertainties. The current practice is to use safety margins, expanding the clinical target volume sufficiently enough to account for treatment uncertainties. This, however, might not be ideal for proton therapy and in particular when using intensity modulated proton therapy (IMPT) plans as degradation in the dose conformity could also be found in the middle of the target resulting from misalignments of highly in-field dose gradients. Single field uniform dose (SFUD) and IMPT plans have been calculated for different anatomical sites and the need for margins has been assessed by analyzing plan robustness to set-up and range uncertainties. We found that the use of safety margins is a good way to improve plan robustness for SFUD and IMPT plans with low in-field dose gradients but not necessarily for highly modulated IMPT plans for which only a marginal improvement in plan robustness could be detected through the definition of a planning target volume. (Some figures in this article are in colour only in the electronic version)},
  isbn = {0031-9155},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\I5UNBWKG\\Albertini, Hug, Lomax - 2011 - Is it necessary to plan with safety margins for actively scanned proton therapy.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\M9SMDQ5Y\\Albertini, Hug, Lomax - 2011 - Is it necessary to plan with safety margins for actively scanned proton therapy(2).pdf;C\:\\Users\\Niklas\\Zotero\\storage\\XUEN5H4F\\Albertini, Hug, Lomax - 2011 - Is it necessary to plan with safety margins for actively scanned proton therapy(3).pdf}
}

@inproceedings{Altschuler1984,
  title = {Feasibility solutions in radiation therapy treatment planning},
  booktitle = {Proceedings of the {{Eighth International Conference}} on the {{Use}} of {{Computers}} in {{Radiation Therapy}}},
  author = {Altschuler, Martin D. and Censor, Yair},
  date = {1984},
  pages = {220--224},
  publisher = {{IEEE Computer Society Press}},
  location = {{Silver Spring, Maryland, USA}},
  url = {http://math.haifa.ac.il/yair/24-RTTP-IEEE84.pdf}
}

@incollection{Altschuler1985,
  title = {Teletherapy treatment planning with physician requirements included in the calculation: {{I}}. {{Concepts}} and methodology},
  booktitle = {Optimization of {{Cancer Radiotherapy}}},
  author = {Altschuler, Martin D. and Powlis, William D. and Censor, Yair},
  editor = {Paliwal, Bhudatt R. and Herbert, Donald E. and Orton, Colin G.},
  date = {1985},
  pages = {443--452},
  publisher = {{American Institute of Physics}},
  location = {{New York}}
}

@article{Arbea2010,
  title = {Intensity-modulated radiation therapy ({{IMRT}}) vs. {{3D}} conformal radiotherapy ({{3DCRT}}) in locally advanced rectal cancer ({{LARC}}): dosimetric comparison and clinical implications.},
  author = {Arbea, Leire and Ramos, Luis Isaac and Martínez-Monge, Rafael and Moreno, Marta and Aristu, Javier},
  date = {2010-01},
  journaltitle = {Radiation oncology (London, England)},
  volume = {5},
  eprint = {20187944},
  eprinttype = {pmid},
  pages = {17},
  issn = {1748-717X},
  doi = {10.1186/1748-717X-5-17},
  url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2845593&tool=pmcentrez&rendertype=abstract},
  urldate = {2013-06-24},
  abstract = {To compare target dose distribution, comformality, normal tissue avoidance, and irradiated body volume (IBV) in 3DCRT using classic anatomical landmarks (c3DCRT), 3DCRT fitting the PTV (f3DCRT), and intensity-modulated radiation therapy (IMRT) in patients with locally advanced rectal cancer (LARC).},
  keywords = {Computer-Assisted,Computer-Assisted: methods,Conformal,Conformal: methods,Humans,Intensity-Modulated,Intensity-Modulated: methods,Radiometry,Radiotherapy,Radiotherapy Planning,Rectal Neoplasms,Rectal Neoplasms: radiotherapy,Rectum,Rectum: radiation effects,Urinary Bladder,Urinary Bladder: radiation effects},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\LFZBP2C3\\Arbea et al. - 2010 - Intensity-modulated radiation therapy (IMRT) vs. 3D conformal radiotherapy (3DCRT) in locally advanced rectal canc.pdf}
}

@article{Arellano-Valle2008,
  title = {On the exact distribution of the maximum of absolutely continuous dependent random variables},
  author = {Arellano-Valle, Reinaldo B. and Genton, Marc G.},
  date = {2008-01},
  journaltitle = {Statistics \& Probability Letters},
  volume = {78},
  number = {1},
  pages = {27--35},
  issn = {01677152},
  doi = {10.1016/j.spl.2007.04.021},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0167715207001678},
  abstract = {We derive the exact probability density function of the maximum of arbitrary absolutely continuous dependent random variables and of absolutely continuous exchangeable random variables. We show this density is related to the family of fundamental skew distributions. In particular, we examine the case where the random variables have an elliptically contoured distribution. We study some particular examples based on the multivariate normal and multivariate Student t distributions, and discuss numerical computation issues. We illustrate our results on a genetic selection problem and on an autoregressive time series model of order one. © 2007 Elsevier B.V. All rights reserved.},
  keywords = {Elliptically contoured,Exchangeable,Fundamental skew distribution,Kurtosis,Maximum,Skewness,Time series},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\V4BGRQHU\\Arellano-Valle, Genton - 2008 - On the exact distribution of the maximum of absolutely continuous dependent random variables.pdf}
}

@article{Astaburuaga2019,
  title = {Incorporation of {{Dosimetric Gradients}} and {{Parotid Gland Migration Into Xerostomia Prediction}}},
  author = {Astaburuaga, Rosario and Gabryś, Hubert S. and Sánchez-Nieto, Beatriz and Floca, Ralf O. and Klüter, Sebastian and Schubert, Kai and Hauswald, Henrik and Bangert, Mark},
  date = {2019},
  journaltitle = {Frontiers in Oncology},
  shortjournal = {Front. Oncol.},
  volume = {9},
  publisher = {{Frontiers}},
  issn = {2234-943X},
  doi = {10.3389/fonc.2019.00697},
  url = {https://www.frontiersin.org/articles/10.3389/fonc.2019.00697/full},
  urldate = {2020-11-12},
  abstract = {Purpose: Due to the sharp gradients of intensity-modulated radiotherapy (IMRT) dose distributions, treatment uncertainties may induce substantial deviations from the planned dose during irradiation. Here, we investigate if the planned mean dose to parotid glands in combination with the dose gradient and information about anatomical changes during the treatment improves xerostomia prediction in head and neck cancer patients. Material and methods: 88 patients were retrospectively analyzed. Three features of the contralateral parotid gland were studied in terms of their association with the outcome, \textbackslash textit\{i.e.\}, grade \$\textbackslash geq\$ 2 (G2+) xerostomia between 6 months and 2 years after radiotherapy (RT): planned mean dose (MD), average lateral dose gradient (GRADX), and parotid gland migration towards medial (PGM). PGM was estimated using daily megavoltage computed tomography (MVCT) images. Three logistic regression models where analyzed: based on 1) MD only, 2) MD and GRADX, and 3) MD, GRADX, and PGM. Additionally, the cohort was stratified based on the median value of GRADX, and a univariate analysis was performed to study the association of the MD with the outcome for patients in low- and high-GRADX domains. Results: The planned MD failed to recognize G2+ xerostomia patients (AUC=0.57). By adding the information of GRADX (second model), the model performance increased to AUC=0.72. The addition of PGM (third model) led to further improvement in the recognition of the outcome (AUC = 0.79). Remarkably, xerostomia patients in the low-GRADX domain were successfully identified (AUC = 0.88) by the MD alone. Conclusions: Our results indicate that GRADX and PGM, which together serve as a proxy of dosimetric changes, provide valuable information for xerostomia prediction.},
  langid = {english},
  keywords = {Anatomical change,Dosimetric changes,head and neck cancer,Intensity-modulated radiotherapy (IMRT),MVCT (megavoltage CT),Normal Tissue Complication Probability (NTCP),Xerostomia},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\YXMR8C2A\\Astaburuaga et al. - 2019 - Incorporation of Dosimetric Gradients and Parotid .pdf}
}

@article{Atun2015,
  title = {Expanding global access to radiotherapy},
  author = {Atun, Rifat and Jaffray, David A. and Barton, Michael B. and Bray, Freddie and Baumann, Michael and Vikram, Bhadrasain and Hanna, Timothy P. and Knaul, Felicia M. and Lievens, Yolande and Lui, Tracey Y. M. and Milosevic, Michael and O'Sullivan, Brian and Rodin, Danielle L. and Rosenblatt, Eduardo and Dyk, Jacob Van and Yap, Mei Ling and Zubizarreta, Eduardo and Gospodarowicz, Mary},
  date = {2015-09-01},
  journaltitle = {The Lancet Oncology},
  shortjournal = {The Lancet Oncology},
  volume = {16},
  number = {10},
  eprint = {26419354},
  eprinttype = {pmid},
  pages = {1153--1186},
  publisher = {{Elsevier}},
  issn = {1470-2045, 1474-5488},
  doi = {10.1016/S1470-2045(15)00222-3},
  url = {https://www.thelancet.com/journals/lanonc/article/PIIS1470-2045(15)00222-3/abstract},
  urldate = {2020-07-06},
  abstract = {{$<$}h2{$>$}Summary{$<$}/h2{$><$}p{$>$}Radiotherapy is a critical and inseparable component of comprehensive cancer treatment and care. For many of the most common cancers in low-income and middle-income countries, radiotherapy is essential for effective treatment. In high-income countries, radiotherapy is used in more than half of all cases of cancer to cure localised disease, palliate symptoms, and control disease in incurable cancers. Yet, in planning and building treatment capacity for cancer, radiotherapy is frequently the last resource to be considered. Consequently, worldwide access to radiotherapy is unacceptably low. We present a new body of evidence that quantifies the worldwide coverage of radiotherapy services by country. We show the shortfall in access to radiotherapy by country and globally for 2015–35 based on current and projected need, and show substantial health and economic benefits to investing in radiotherapy. The cost of scaling up radiotherapy in the nominal model in 2015–35 is US\$26·6 billion in low-income countries, \$62·6 billion in lower-middle-income countries, and \$94·8 billion in upper-middle-income countries, which amounts to \$184·0 billion across all low-income and middle-income countries. In the efficiency model the costs were lower: \$14·1 billion in low-income, \$33·3 billion in lower-middle-income, and \$49·4 billion in upper-middle-income countries—a total of \$96·8 billion. Scale-up of radiotherapy capacity in 2015–35 from current levels could lead to saving of 26·9 million life-years in low-income and middle-income countries over the lifetime of the patients who received treatment. The economic benefits of investment in radiotherapy are very substantial. Using the nominal cost model could produce a net benefit of \$278·1 billion in 2015–35 (\$265·2 million in low-income countries, \$38·5 billion in lower-middle-income countries, and \$239·3 billion in upper-middle-income countries). Investment in the efficiency model would produce in the same period an even greater total benefit of \$365·4 billion (\$12·8 billion in low-income countries, \$67·7 billion in lower-middle-income countries, and \$284·7 billion in upper-middle-income countries). The returns, by the human-capital approach, are projected to be less with the nominal cost model, amounting to \$16·9 billion in 2015–35 (–\$14·9 billion in low-income countries; –\$18·7 billion in lower-middle-income countries, and \$50·5 billion in upper-middle-income countries). The returns with the efficiency model were projected to be greater, however, amounting to \$104·2 billion (–\$2·4 billion in low-income countries, \$10·7 billion in lower-middle-income countries, and \$95·9 billion in upper-middle-income countries). Our results provide compelling evidence that investment in radiotherapy not only enables treatment of large numbers of cancer cases to save lives, but also brings positive economic benefits.{$<$}/p{$>$}},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\KYYYAZKK\\fulltext.html}
}

@misc{Bachert2012,
  title = {Lecture: {{Medical Physics II}}},
  author = {Bachert, Peter},
  date = {2012}
}

@article{Bader2008,
  title = {Efficient {{MATLAB Computations}} with {{Sparse}} and {{Factored Tensors}}},
  author = {Bader, Brett W and Kolda, Tamara G},
  date = {2008-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  volume = {30},
  number = {1},
  pages = {205--231},
  issn = {1064-8275},
  doi = {10.1137/060676489},
  url = {http://epubs.siam.org/doi/10.1137/060676489},
  urldate = {2018-03-29},
  abstract = {In this paper, the term tensor refers simply to a multidimensional or N -way array, and we consider how specially structured tensors allow for efficient storage and computation. First, we study sparse tensors, which have the property that the vast majority of the elements are zero. We propose storing sparse tensors using coordinate format and describe the computational efficiency of this scheme for various mathematical operations, including those typical to tensor decomposition algorithms. Second, we study factored tensors, which have the property that they can be assembled from more basic components. We consider two specific types: A Tucker tensor can be expressed as the product of a core tensor (which itself may be dense, sparse, or factored) and a matrix along each mode, and a Kruskal tensor can be expressed as the sum of rank-1 tensors. We are interested in the case where the storage of the components is less than the storage of the full tensor, and we demonstrate that many elementary operations can be computed using only the components. All of the efficiencies described in this paper are implemented in the Tensor Toolbox for MATLAB.},
  keywords = {65F50,68P05,MATLAB classes,multilinear algebraic computations,parallel factors (PARAFAC) model,sparse multidimensional arrays,tensor decom-positions,Tucker model},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\9VBZMI8N\\Bader, Kolda - 2008 - Efficient MATLAB Computations with Sparse and Factored Tensors.pdf}
}

@article{Bahn2020,
  title = {Late {{Contrast Enhancing Brain Lesions}} in {{Proton-Treated Patients With Low-Grade Glioma}}: {{Clinical Evidence}} for {{Increased Periventricular Sensitivity}} and {{Variable RBE}}},
  shorttitle = {Late {{Contrast Enhancing Brain Lesions}} in {{Proton-Treated Patients With Low-Grade Glioma}}},
  author = {Bahn, Emanuel and Bauer, Julia and Harrabi, Semi and Herfarth, Klaus and Debus, Jürgen and Alber, Markus},
  date = {2020-07-01},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {107},
  number = {3},
  pages = {571--578},
  issn = {0360-3016},
  doi = {10.1016/j.ijrobp.2020.03.013},
  url = {https://www.sciencedirect.com/science/article/pii/S0360301620309366},
  urldate = {2022-12-13},
  abstract = {Purpose Late radiation-induced contrast-enhancing brain lesions (CEBLs) on magnetic resonance imaging (MRI) after proton therapy of brain tumors have been observed to occur frequently in regions of high linear energy transfer (LET) and in proximity to the ventricular system. We analyzed 110 patients with low-grade glioma treated with proton therapy to determine whether the risk for CEBLs is increased in proximity to the ventricular system and if there is a relationship between relative biological effectiveness (RBE) and LET. Methods and Materials We contoured CEBLs identified on follow-up T1-MRI scans and computed dose and dose-averaged LET (LETd) distributions for all patients using the Monte Carlo method. We then performed cross-validated voxel-level logistic regression to predict local risks for image change and to extract model parameters, such as the RBE. From the voxel-level model, we derived a model for patient-level risk prediction based on the treatment plan. Results Of 110 patients, 23 exhibited 1 or several CEBLs on follow-up MRI scans. The voxel-level logistic model has an accuracy as follows: area under the curve of 0.94 and Brier score of 2.6 × 10-5. Model predictions are a 3-fold increased risk in the 4 mm region around the ventricular system and an LETd-dependent RBE of, for example, 1.20 for LETd = 2 keV/μm and 1.50 for LETd = 5 keV/μm. The patient-level risk model has an accuracy as follows: area under the curve of 0.78 and Brier score of 0.13. Conclusions Our findings present clinical evidence for an increased risk in ventricular proximity and for a proton RBE that increases significantly with increasing LET. We present a voxel-level model that accurately predicts the localization of late MRI contrast change and extrapolate a patient-level model that allows treatment plan–based risk prediction.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\27WZJU6L\\Bahn et al. - 2020 - Late Contrast Enhancing Brain Lesions in Proton-Tr.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\M794HFBE\\S0360301620309366.html}
}

@article{Bai2019,
  title = {Robust optimization to reduce the impact of biological effect variation from physical uncertainties in intensity-modulated proton therapy},
  author = {Bai, Xuemin and Lim, Gino and Wieser, Hans-Peter and Bangert, Mark and Grosshans, David and Mohan, Radhe and Cao, Wenhua},
  date = {2019-01},
  journaltitle = {Physics in Medicine \& Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {64},
  number = {2},
  pages = {025004},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/aaf5e9},
  url = {https://doi.org/10.1088/1361-6560/aaf5e9},
  urldate = {2021-12-15},
  abstract = {Robust optimization (RO) methods are applied to intensity-modulated proton therapy (IMPT) treatment plans to ensure their robustness in the face of treatment delivery uncertainties, such as proton range and patient setup errors. However, the impact of those uncertainties on the biological effect of protons has not been specifically considered. In this study, we added biological effect-based objectives into a conventional RO cost function for IMPT optimization to minimize the variation in biological effect. One brain tumor case, one prostate tumor case and one head \& neck tumor case were selected for this study. Three plans were generated for each case using three different optimization approaches: planning target volume (PTV)-based optimization, conventional RO, and RO incorporating biological effect (BioRO). In BioRO, the variation in biological effect caused by IMPT delivery uncertainties was minimized for voxels in both target volumes and critical structures, in addition to a conventional voxel-based worst-case RO objective function. The biological effect was approximated by the product of dose-averaged linear energy transfer (LET) and physical dose. All plans were normalized to give the same target dose coverage, assuming a constant relative biological effectiveness (RBE) of 1.1. Dose, biological effect, and their uncertainties were evaluated and compared among the three optimization approaches for each patient case. Compared with PTV-based plans, RO plans achieved more robust target dose coverage and reduced biological effect hot spots in critical structures near the target. Moreover, with their sustained robust dose distributions, BioRO plans not only reduced variations in biological effect in target and normal tissues but also further reduced biological effect hot spots in critical structures compared with RO plans. Our findings indicate that IMPT could benefit from the use of conventional RO, which would reduce the biological effect in normal tissues and produce more robust dose distributions than those of PTV-based optimization. More importantly, this study provides a proof of concept that incorporating biological effect uncertainty gap into conventional RO would not only control the IMPT plan robustness in terms of physical dose and biological effect but also achieve further reduction of biological effect in normal tissues.},
  langid = {english}
}

@article{Ballas2006,
  title = {Radiation therapy facilities in the {{United States}}},
  author = {Ballas, Leslie K. and Elkin, Elena B. and Schrag, Deborah and Minsky, Bruce D. and Bach, Peter B.},
  date = {2006-11-15},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {Int J Radiat Oncol},
  volume = {66},
  number = {4},
  pages = {1204--1211},
  issn = {0360-3016},
  doi = {10.1016/j.ijrobp.2006.06.035},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301606011084},
  urldate = {2019-10-27},
  abstract = {Purpose: About half of all cancer patients in the United States receive radiation therapy as a part of their cancer treatment. Little is known, however, about the facilities that currently deliver external beam radiation. Our goal was to construct a comprehensive database of all radiation therapy facilities in the United States that can be used for future health services research in radiation oncology. Methods and Materials: From each state’s health department we obtained a list of all facilities that have a linear accelerator or provide radiation therapy. We merged these state lists with information from the American Hospital Association (AHA), as well as 2 organizations that audit the accuracy of radiation machines: the Radiologic Physics Center (RPC) and the Radiation Dosimetry Services (RDS). The comprehensive database included all unique facilities listed in 1 or more of the 4 sources. Results: We identified 2,246 radiation therapy facilities operating in the United States as of 2004–2005. Of these, 448 (20\%) facilities were identified through state health department records alone and were not listed in any other data source. Conclusions: Determining the location of the 2,246 radiation facilities in the United States is a first step in providing important information to radiation oncologists and policymakers concerned with access to radiation therapy services, the distribution of health care resources, and the quality of cancer care.},
  langid = {english},
  keywords = {Access to care,Database,Facility location,Radiation therapy,Resource distribution},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\344HSMRV\\Ballas et al. - 2006 - Radiation therapy facilities in the United States.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\LU8HAQM5\\S0360301606011084.html}
}

@article{Balter2007,
  title = {Imaging and alignment for image-guided radiation therapy.},
  author = {Balter, James M and Kessler, Marc L},
  date = {2007},
  journaltitle = {J Clin Oncol},
  volume = {25},
  number = {8},
  pages = {931--937},
  doi = {10.1200/JCO.2006.09.7998},
  url = {http://dx.doi.org/10.1200/JCO.2006.09.7998},
  abstract = {Image-guided radiation therapy is an exciting new area that focuses heavily on the potential benefit of advanced imaging and image registration to improve precision, thus limiting morbidity and potentially allowing for safe delivery of increased dose. This review explores the issues surrounding the use of imaging and image registration for treatment planning and verification, with emphasis on the underlying patient model and alignment algorithms.},
  keywords = {Computer-Assisted,Humans,Image Processing,Magnetic Resonance Imaging,methods,Neoplasms,Positron-Emission Tomog,radiography/radiotherapy,Radiotherapy,Tomography,X-Ray Computed}
}

@article{Bangert2012,
  title = {Characterizing the combinatorial beam angle selection problem},
  author = {Bangert, Mark and Ziegenhein, Peter and Oelfke, Uwe},
  date = {2012-10},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {57},
  number = {20},
  pages = {6707--6723},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/57/20/6707},
  url = {https://doi.org/10.1088%2F0031-9155%2F57%2F20%2F6707},
  urldate = {2019-10-27},
  abstract = {The beam angle selection (BAS) problem in intensity-modulated radiation therapy is often interpreted as a combinatorial optimization problem, i.e. finding the best combination of η beams in a discrete set of candidate beams. It is well established that the combinatorial BAS problem may be solved efficiently with metaheuristics such as simulated annealing or genetic algorithms. However, the underlying parameters of the optimization process, such as the inclusion of non-coplanar candidate beams, the angular resolution in the space of candidate beams, and the number of evaluated beam ensembles as well as the relative performance of different metaheuristics have not yet been systematically investigated. We study these open questions in a meta-analysis of four strategies for combinatorial optimization in order to provide a reference for future research related to the BAS problem in intensity-modulated radiation therapy treatment planning. We introduce a high-performance inverse planning engine for BAS. It performs a full fluence optimization for ≈3600 treatment plans per hour while handling up to 50 GB of dose influence data (≈1400 candidate beams). For three head and neck patients, we compare the relative performance of a genetic, a cross-entropy, a simulated annealing and a naive iterative algorithm. The selection of ensembles with 5, 7, 9 and 11 beams considering either only coplanar or all feasible candidate beams is studied for an angular resolution of 5°, 10°, 15° and 20° in the space of candidate beams. The impact of different convergence criteria is investigated in comparison to a fixed termination after the evaluation of 10 000 beam ensembles. In total, our simulations comprise a full fluence optimization for about 3000 000 treatment plans. All four combinatorial BAS strategies yield significant improvements of the objective function value and of the corresponding dose distributions compared to standard beam configurations with equi-spaced coplanar beams. The genetic and the cross-entropy algorithms showed faster convergence in the very beginning of the optimization but the simulated annealing algorithm eventually arrived at almost the same objective function values. These three strategies typically yield clinically equivalent treatment plans. The iterative algorithm showed the worst convergence properties. The choice of the termination criterion had a stronger influence on the performance of the simulated annealing algorithm than on the performance of the genetic and the cross-entropy algorithms. We advocate to terminate the optimization process after the evaluation of 1000 beam combinations without objective function decrease. For our simulations, this resulted in an average deviation of the objective function from the reference value after 10 000 evaluated beam ensembles of 0.5\% for all metaheuristics. On average, there was only a minor improvement when increasing the angular resolution in the space of candidate beam angles from 20° to 5°. However, we observed significant improvements when considering non-coplanar candidate beams for challenging head and neck cases.},
  langid = {english},
  keywords = {matRadGrant}
}

@article{Bangert2013,
  title = {Analytical probabilistic modeling for radiation therapy treatment planning.},
  author = {Bangert, Mark and Hennig, Philipp and Oelfke, Uwe},
  date = {2013},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {58},
  number = {16},
  eprint = {23877218},
  eprinttype = {pmid},
  pages = {5401--5419},
  issn = {1361-6560},
  doi = {10.1088/0031-9155/58/16/5401},
  abstract = {This paper introduces the concept of analytical probabilistic modeling (APM) to quantify uncertainties in quality indicators of radiation therapy treatment plans. Assuming Gaussian probability densities over the input parameters of the treatment plan quality indicators, APM enables the calculation of the moments of the induced probability density over the treatment plan quality indicators by analytical integration. This paper focuses on analytical probabilistic dose calculation algorithms and the implications of APM regarding treatment planning. We derive closed-form expressions for the expectation value and the (co)variance of (1) intensity-modulated photon and proton dose distributions based on a pencil beam algorithm and (2) the standard quadratic objective function used in inverse planning. Complex correlation models of high dimensional uncertain input parameters and the different nature of random and systematic uncertainties in fractionated radiation therapy are explicitly incorporated into APM. APM variance calculations on phantom data sets show that the correlation assumptions and the difference of random and systematic uncertainties of the input parameters have a crucial impact on the uncertainty of the resulting dose. The derivations regarding the quadratic objective function show that APM has the potential to enable robust planning at almost the same computational cost like conventional inverse planning after a single probabilistic dose calculation. Beneficial applications of APM in the context of radiation therapy treatment planning are feasible.},
  keywords = {Humans,matRadGrant,Models; Statistical,Photons,Protons,Protons: therapeutic use,Radiotherapy Dosage,Radiotherapy Planning; Computer-Assisted,Radiotherapy Planning; Computer-Assisted: methods,Uncertainty},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\8HVA8WEK\\Bangert, Hennig, Oelfke - 2013 - Analytical probabilistic modeling for radiation therapy treatment planning.pdf}
}

@article{Bangert2013a,
  title = {Comparison of beam angle selection strategies for intracranial {{IMRT}}},
  author = {Bangert, Mark and Ziegenhein, Peter and Oelfke, Uwe},
  date = {2013},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {40},
  number = {1},
  pages = {011716},
  issn = {2473-4209},
  doi = {10.1118/1.4771932},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.4771932},
  urldate = {2019-10-27},
  abstract = {Purpose: Various strategies to select beneficial beam ensembles for intensity-modulated radiation therapy (IMRT) have been suggested over the years. These beam angle selection (BAS) strategies are usually evaluated against reference configurations applying equispaced coplanar beams but they are not compared to one another. Here, the authors present a meta analysis of four BAS strategies that incorporates fluence optimization (FO) into BAS by combinatorial optimization (CO) and one BAS strategy that decouples FO from BAS, i.e., spherical cluster analysis (SCA). The underlying parameters of the BAS process are investigated and the dosimetric benefits of the BAS strategies are quantified. Methods: For three intracranial lesions in proximity to organs at risk (OARs) the authors compare treatment plans applying equispaced coplanar beam ensembles with treatment plans using five different BAS strategies, i.e., four CO techniques and SCA, to establish coplanar and noncoplanar beam ensembles. Treatment plans applying 5, 7, 9, and 11 beams are investigated. For the CO strategies the authors perform BAS runs with a 5°, 10°, 15°, and 20° angular resolution, which corresponds to a minimum of 18 coplanar and a maximum of 1400 noncoplanar candidate beams. In total 272 treatment plans with different BAS settings are generated for every patient. The quality of the treatment plans is compared based on the protection of OARs yet integral dose, target homogeneity, and target conformity are also considered. Results: It is possible to reduce the average mean and maximum doses in OARs by more than 4 Gy (1 Gy) with optimized noncoplanar (coplanar) beam ensembles found with BAS by CO or SCA. For BAS including FO by CO, the individual algorithm used and the angular resolution in the space of candidate beams does not have a crucial impact on the quality of the resulting treatment plans. All CO algorithms yield similar target conformity and slightly improved target homogeneity in comparison to equispaced coplanar setups. Furthermore, optimized coplanar (noncoplanar) beam ensembles enabled more than a 6\% (5\%) reduction of the integral dose. For SCA, however, integral dose was increased and target conformity was decreased in comparison to equispaced coplanar setups—especially for a small number of beams. Conclusion: Both BAS strategies incorporating FO by CO and independent BAS strategies excluding FO provide dose savings in OARs for optimized coplanar and especially noncoplanar beam ensembles; they should not be neglected in the clinic.},
  langid = {english},
  keywords = {Anatomy,Annealing,beam angle optimization,brain,Cancer,Cluster analysis,Computer hardware,Data sets,dosimetry,Dosimetry,high performance computing,Intensity modulated radiation therapy,intensity-modulated radiation therapy,matRadGrant,Medical treatment planning,optimisation,radiation therapy,Radiation therapy,Spatial resolution,treatment planning,Treatment strategy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\46KYVPTM\\1.html}
}

@inproceedings{Bangert2014,
  title = {Analytical probabilistic proton dose calculation and range uncertainties},
  booktitle = {Journal of {{Physics}}: {{Conference Series}}},
  author = {Bangert, M and Hennig, P and Oelfke, U},
  date = {2014-03-24},
  volume = {489},
  number = {1},
  pages = {012002},
  publisher = {{IOP Publishing}},
  issn = {1742-6588},
  doi = {10.1088/1742-6596/489/1/012002},
  url = {http://stacks.iop.org/1742-6596/489/i=1/a=012002?key=crossref.cb4394216892932d5b2cb4e2b8b42d3a},
  urldate = {2018-03-06},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\FRSTESHZ\\Bangert, Hennig, Oelfke - 2014 - Analytical probabilistic proton dose calculation and range uncertainties.pdf}
}

@inproceedings{Bangert2019,
  title = {{{SP-0469}}: {{Mitigation}} of range uncertainties with probabilistic {{IMPT}} optimization},
  shorttitle = {Mitigation of range uncertainties with probabilistic {{IMPT}} optimization},
  booktitle = {Radiotherapy and {{Oncology}}},
  author = {Bangert, Mark and Wahl, Niklas and Wieser, Hans-Peter},
  date = {2019-04-01},
  volume = {133},
  pages = {S241},
  location = {{Milan}},
  doi = {10.1016/S0167-8140(19)30889-8},
  url = {https://www.thegreenjournal.com/article/S0167-8140(19)30889-8/abstract},
  urldate = {2019-09-18},
  eventtitle = {{{ESTRO}}},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\8SDBUC7Q\\Bangert et al. - 2019 - SP-0469 Mitigation of range uncertainties with pro.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\F6RWBE4K\\Bangert et al. - 2019 - SP-0469 Mitigation of range uncertainties with pro.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\KHZL7DMM\\abstract.html;C\:\\Users\\Niklas\\Zotero\\storage\\UFWBCK42\\fulltext.html}
}

@online{Bangert2020,
  title = {Developing {{matRad}}, an {{Open-Source Dose Calculation}} and {{Optimization Toolkit}} for {{Radiation Therapy Planning}}},
  author = {Bangert, Mark and Jäkel, Oliver and Wahl, Niklas and Wieser, Hans-Peter},
  date = {2020},
  url = {https://www.mathworks.com/company/newsletters/articles/developing-matrad-an-open-source-dose-calculation-and-optimization-toolkit-for-radiation-therapy-planning.html},
  urldate = {2020-12-12},
  abstract = {DKFZ researchers developed a MATLAB toolkit that spans the entire treatment planning workflow, from setting treatment parameters and optimizing the plan to visualizing and evaluating the results.},
  langid = {english},
  organization = {{MathWorks Techincal Articles and Newsletters}},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\ZN9USI9K\\developing-matrad-an-open-source-dose-calculation-and-optimization-toolkit-for-radiation-therap.html}
}

@article{Barateau2020,
  title = {Comparison of {{CBCT}}‐based dose calculation methods in head and neck cancer radiotherapy: from {{Hounsfield}} unit to density calibration curve to deep learning},
  shorttitle = {Comparison of {{CBCT}}‐based dose calculation methods in head and neck cancer radiotherapy},
  author = {Barateau, Anaïs and De Crevoisier, Renaud and Largent, Axel and Mylona, Eugenia and Perichon, Nicolas and Castelli, Joël and Chajon, Enrique and Acosta, Oscar and Simon, Antoine and Nunes, Jean‐Claude and Lafond, Caroline},
  date = {2020-10},
  journaltitle = {Medical Physics},
  shortjournal = {Med. Phys.},
  volume = {47},
  number = {10},
  pages = {4683--4693},
  issn = {0094-2405, 2473-4209},
  doi = {10.1002/mp.14387},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/mp.14387},
  urldate = {2022-08-15},
  abstract = {Purpose: Anatomical variations occur during head and neck (H\&N) radiotherapy treatment. kV cone-beam computed tomography (CBCT) images can be used for daily dose monitoring to assess dose variations owing to anatomic changes. Deep learning methods (DLMs) have recently been proposed to generate pseudo-CT (pCT) from CBCT to perform dose calculation. This study aims to evaluate the accuracy of a DLM and to compare this method with three existing methods of dose calculation from CBCT in H\&N cancer radiotherapy. Methods: Forty-four patients received VMAT for H\&N cancer (70-63-56 Gy). For each patient, reference CT (Bigbore, Philips) and CBCT images (XVI, Elekta) were acquired. The DLM was based on a generative adversarial network. The three compared methods were: (a) a method using a density to Hounsfield Unit (HU) relation from phantom CBCT image (HU-D curve method), (b) a water–airbone density assignment method (DAM), and iii) a method using deformable image registration (DIR). The imaging endpoints were the mean absolute error (MAE) and mean error (ME) of HU from pCT and reference CT (CTref). The dosimetric endpoints were dose discrepancies and 3D gamma analyses (local, 2\%/2 mm, 30\% dose threshold). Dose discrepancies were defined as the mean absolute differences between DVHs calculated from the CTref and pCT of each method. Results: In the entire body, the MAEs and MEs of the DLM, HU-D curve method, DAM, and DIR method were 82.4 and 17.1 HU, 266.6 and 208.9 HU, 113.2 and 14.2 HU, and 95.5 and −36.6 HU, respectively. The MAE obtained using the DLM differed significantly from those of other methods (Wilcoxon, P ≤ 0.05). The DLM dose discrepancies were 7 Æ 8 cGy (maximum = 44 cGy) for the ipsilateral parotid gland Dmean and 5 Æ 6 cGy (max = 26 cGy) for the contralateral parotid gland mean dose (Dmean). For the parotid gland Dmean, no significant dose difference was observed between the DLM and other methods. The mean 3D gamma pass rate Æ standard deviation was 98.1 Æ 1.2\%, 91.0 Æ 5.3\%, 97.9 Æ 1.6\%, and 98.8 Æ 0.7\% for the DLM, HU-D method, DAM, and DIR method, respectively. The gamma pass rates and mean gamma results of the HU-D curve method, DAM, and DIR method differed significantly from those of the DLM. The mean calculation time to generate one pCT was 30 sec for the deep learning and DIR methods. Conclusions: For H\&N radiotherapy, DIR method and DLM appears as the most appealing CBCTbased dose calculation methods among the four methods in terms of dose accuracy as well as calculation time. Using the DIR method or DLM with CBCT images enables dose monitoring in the parotid glands during the treatment course and may be used to trigger replanning. © 2020 American Association of Physicists in Medicine [https://doi.org/10.1002/mp.14387]},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\43QT89TP\\Barateau et al. - 2020 - Comparison of CBCT‐based dose calculation methods .pdf}
}

@article{Barendsen1982,
  ids = {Barendsen1982a},
  title = {Dose fractionation, dose rate and iso-effect relationships for normal tissue responses},
  author = {Barendsen, G. W.},
  date = {1982},
  journaltitle = {International Journal of Radiation Oncology, Biology, Physics},
  volume = {8},
  number = {11},
  eprint = {6759484},
  eprinttype = {pmid},
  pages = {1981--1997},
  issn = {03603016},
  doi = {10.1016/0360-3016(82)90459-X},
  abstract = {An analysis is,,presented of responses of a variety of normal tissues in animals to fractionated irradiations. It is shown that the influence of fractionation can be described on the basis of a simple formula relating the effectiveness for induction of cellular effects to the dose per fraction: F(D) = 1D + a2D2. The ratio a1 a2 is derived as an essential parameter for, the description of fractionation effects. It is concluded that the values of a1 a2 for responses of various tissues range widely from 2 to 10 Gy. On the basis of the review of radiobiological data, a formalism is developed for the analysis and prediction of iso-effect relations for tissue tolerance, which can be used as an alternative to the nominal standard dose (NSD) formula of Ellis and its derived equations. An essential characteristic of the formalism is that three groups of tissue responses are distinguished which can be described with respect to fractionation effects by average values of al a2 = 10; 5 and 2.5 Gy, respectively. These groups comprise a l: a.o. skin and intestine; 2: connective tissue; 3:a.o. lung and vascular system. Dose rate effects can be described by a similar formalism. For the calculation of equivalent total doses to be applied in clinical treatments, a concept denoted Extrapolated Tolerance Dose (ETD) of Extrapolated Response Dose (ERD) is introduced. ETD is the tolerance dose for an infinite number of very small fractions. This concept is shown to be useful for the summation of different fractionated schedules and of low dose rate treatments. A number of examples is presented illustrating similarities and differences in comparison with calculations based on the NSD formula. An important feature of the described formalism is that it is directly based on radiobiological insights and it provides a more logical concept to account for the diversity of tissue responses than the assumption of different exponents of N and T in the NSD formula. ?? 1982.},
  isbn = {0360-3016},
  keywords = {Dose fractionation,Tissue responses,Tolerance},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\P7W8XVWH\\Barendsen - 1982 - Dose fractionation, dose rate and iso-effect relat.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\WCBTZMZA\\Barendsen - 1982 - Dose fractionation, dose rate and iso-effect relationships for normal tissue responses.pdf}
}

@article{Bargetz2018,
  title = {Convergence properties of dynamic string-averaging projection methods in the presence of perturbations},
  author = {Bargetz, Christian and Reich, Simeon and Zalas, Rafał},
  date = {2018-01},
  journaltitle = {Numerical Algorithms},
  shortjournal = {Numer Algor},
  volume = {77},
  number = {1},
  pages = {185--209},
  issn = {1017-1398, 1572-9265},
  doi = {10.1007/s11075-017-0310-4},
  url = {http://link.springer.com/10.1007/s11075-017-0310-4},
  urldate = {2021-11-30},
  abstract = {Assuming that the absence of perturbations guarantees weak or strong convergence to a common fixed point, we study the behavior of perturbed products of an infinite family of nonexpansive operators. Our main result indicates that the convergence rate of unperturbed products is essentially preserved in the presence of perturbations. This, in particular, applies to the linear convergence rate of dynamic string-averaging projection methods, which we establish here as well. Moreover, we show how this result can be applied to the superiorization methodology.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Y2M9AUDB\\Bargetz et al. - 2018 - Convergence properties of dynamic string-averaging.pdf}
}

@misc{Barkmann2022,
  title = {Superiorization as a novel strategy for linearly constrained inverse radiotherapy treatment planning},
  author = {Barkmann, Florian and Censor, Yair and Wahl, Niklas},
  date = {2022-07-26},
  number = {arXiv:2207.13187},
  eprint = {2207.13187},
  eprinttype = {arxiv},
  primaryclass = {physics},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2207.13187},
  url = {http://arxiv.org/abs/2207.13187},
  urldate = {2022-07-28},
  abstract = {We apply the superiorization methodology to the intensity-modulated radiation therapy (IMRT) treatment planning problem. In superiorization, linear voxel dose inequality constraints are the fundamental modeling tool within which a feasibility-seeking projection algorithm will seek a feasible point. This algorithm is then perturbed with gradient descent steps to reduce a nonlinear objective function. Within the open-source inverse planning toolkit matRad, we implement a prototypical algorithmic framework for superiorization using the well-established Agmon, Motzkin, and Schoenberg (AMS) feasibility-seeking projection algorithm and common nonlinear dose optimization objective functions. Based on this prototype, we apply superiorization to intensity-modulated radiation therapy treatment planning and compare its performance with feasibility-seeking and nonlinear constrained optimization. For these comparisons, we use the TG119 water phantom and a head-and-neck patient of the CORT dataset. Bare feasibility-seeking with AMS confirms previous studies, showing it can find solutions that are nearly equivalent to those found by the established piece-wise least-squares optimization approach. The superiorization prototype solved the linearly constrained planning problem with similar performance to that of a general-purpose nonlinear constrained optimizer while showing smooth convergence in both constraint proximity and objective function reduction. Superiorization is a useful alternative to constrained optimization in radiotherapy inverse treatment planning. Future extensions with other approaches to feasibility-seeking, e.g., with dose-volume constraints and more sophisticated perturbations, may unlock its full potential for high-performant inverse treatment planning.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Optimization and Control,Physics - Medical Physics},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\S2SWVAR4\\Barkmann et al. - 2022 - Superiorization as a novel strategy for linearly c.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\3JU9K2R6\\2207.html}
}

@article{Battistoni2016,
  title = {The {{FLUKA Code}}: {{An Accurate Simulation Tool}} for {{Particle Therapy}}},
  shorttitle = {The {{FLUKA Code}}},
  author = {Battistoni, Giuseppe and Bauer, Julia and Boehlen, Till T. and Cerutti, Francesco and Chin, Mary P. W. and Dos Santos Augusto, Ricardo and Ferrari, Alfredo and Ortega, Pablo G. and Kozłowska, Wioletta and Magro, Giuseppe and Mairani, Andrea and Parodi, Katia and Sala, Paola R. and Schoofs, Philippe and Tessonnier, Thomas and Vlachoudis, Vasilis},
  date = {2016},
  journaltitle = {Frontiers in Oncology},
  volume = {6},
  issn = {2234-943X},
  url = {https://www.frontiersin.org/article/10.3389/fonc.2016.00116},
  urldate = {2022-05-17},
  abstract = {Monte Carlo (MC) codes are increasingly spreading in the hadrontherapy community due to their detailed description of radiation transport and interaction with matter. The suitability of a MC code for application to hadrontherapy demands accurate and reliable physical models capable of handling all components of the expected radiation field. This becomes extremely important for correctly performing not only physical but also biologically based dose calculations, especially in cases where ions heavier than protons are involved. In addition, accurate prediction of emerging secondary radiation is of utmost importance in innovative areas of research aiming at in vivo treatment verification. This contribution will address the recent developments of the FLUKA MC code and its practical applications in this field. Refinements of the FLUKA nuclear models in the therapeutic energy interval lead to an improved description of the mixed radiation field as shown in the presented benchmarks against experimental data with both 4He and 12C ion beams. Accurate description of ionization energy losses and of particle scattering and interactions lead to the excellent agreement of calculated depth–dose profiles with those measured at leading European hadron therapy centers, both with proton and ion beams. In order to support the application of FLUKA in hospital-based environments, Flair, the FLUKA graphical interface, has been enhanced with the capability of translating CT DICOM images into voxel-based computational phantoms in a fast and well-structured way. The interface is capable of importing also radiotherapy treatment data described in DICOM RT standard. In addition, the interface is equipped with an intuitive PET scanner geometry generator and automatic recording of coincidence events. Clinically, similar cases will be presented both in terms of absorbed dose and biological dose calculations describing the various available features.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\YKJFZKQI\\Battistoni et al. - 2016 - The FLUKA Code An Accurate Simulation Tool for Pa.pdf}
}

@article{Bauer2013,
  title = {Implementation and initial clinical experience of offline {{PET}}/{{CT-based}} verification of scanned carbon ion treatment},
  author = {Bauer, Julia and Unholtz, Daniel and Sommerer, Florian and Kurz, Christopher and Haberer, Thomas and Herfarth, Klaus and Welzel, Thomas and Combs, Stephanie E. and Debus, Jürgen and Parodi, Katia},
  date = {2013-05-01},
  journaltitle = {Radiotherapy and Oncology},
  shortjournal = {Radiotherapy and Oncology},
  volume = {107},
  number = {2},
  pages = {218--226},
  issn = {0167-8140},
  doi = {10.1016/j.radonc.2013.02.018},
  url = {http://www.sciencedirect.com/science/article/pii/S0167814013001606},
  urldate = {2020-04-03},
  abstract = {Background and purpose We report on the implementation of offline PET/CT-based treatment verification at the Heidelberg Ion Beam Therapy Centre (HIT) and present first clinical cases for post-activation measurements after scanned carbon ion irradiation. Key ingredient of this in-vivo treatment verification is the comparison of irradiation-induced patient activation measured by a PET scanner with a prediction simulated by means of Monte Carlo techniques. Material and methods At HIT, a commercial full-ring PET/CT scanner has been installed in close vicinity to the treatment rooms. After selected irradiation fractions, the patient either walks to the scanner for acquisition of the activation data or is transported using a shuttle system. The expected activity distribution is obtained from the production of β+-active isotopes simulated by the FLUKA code on the basis of the patient-specific treatment plan, post-processed considering the time course of the respective treatment fraction, the estimated biological washout of the induced activity and a simplified model of the imaging process. Results We present four patients with different indications of head, head/neck, liver and pelvic tumours. A clear correlation between the measured PET signal and the simulated activity pattern is observed for all patients, thus supporting a proper treatment delivery. In the case of a pelvic tumour patient it was possible to detect minor treatment delivery inaccuracies. Conclusions The initial clinical experience proves the feasibility of the implemented strategy for offline confirmation of scanned carbon ion irradiation and therefore constitutes a first step towards a comprehensive PET/CT-based treatment verification in the clinical routine at HIT.},
  langid = {english},
  keywords = {Carbon ion treatment,Monte Carlo simulations,Offline PET,Treatment monitoring},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\I45ZXVYL\\Bauer et al. - 2013 - Implementation and initial clinical experience of .pdf;C\:\\Users\\Niklas\\Zotero\\storage\\MVJ3B7UC\\S0167814013001606.html}
}

@article{Baumann2017,
  title = {An efficient method to predict and include {{Bragg}} curve degradation due to lung-equivalent materials in {{Monte Carlo}} codes by applying a density modulation},
  author = {Baumann, Kilian-Simon and Witt, Matthias and Weber, Uli and Engenhart-Cabillic, Rita and Zink, Klemens},
  date = {2017-04},
  journaltitle = {Physics in Medicine \& Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {62},
  number = {10},
  pages = {3997},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/aa641f},
  url = {https://dx.doi.org/10.1088/1361-6560/aa641f},
  urldate = {2022-11-29},
  abstract = {Sub-millimetre-sized heterogeneities such as lung parenchyma cause Bragg peak degradation which can lead to an underdose of the tumor and an overdose of healthy tissue when not accounted for in treatment planning. Since commonly used treatment-planning CTs do not resolve the fine structure of lungs, this degradation can hardly be considered. We present a mathematical model capable of predicting and describing Bragg peak degradation due to a lung-equivalent geometry consisting of sub-millimetre voxels filled with either lung tissue or air. The material characteristic ‘modulation power’ is introduced to quantify the Bragg peak degradation. A strategy was developed to transfer the modulating effects of such fine structures to rougher structures such as 2 mm thick CT voxels, which is the resolution of typically used CTs. This is done by using the modulation power to derive a density distribution applicable to these voxels. By replacing the previously used sub-millimetre voxels by 2 mm thick voxels filled with lung tissue and modulating the lung tissue’s density in each voxel individually, we were able to reproduce the Bragg peak degradation. Hence a solution is found to include Bragg curve degradation due to lung-equivalent materials in Monte Carlo-based treatment-planning systems.},
  langid = {english}
}

@article{Bauschke1996,
  title = {On {{Projection Algorithms}} for {{Solving Convex Feasibility Problems}}},
  author = {Bauschke, Heinz H. and Borwein, Jonathan M.},
  date = {1996-09-01},
  journaltitle = {SIAM Review},
  shortjournal = {SIAM Rev.},
  volume = {38},
  number = {3},
  pages = {367--426},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1445},
  doi = {10.1137/S0036144593251710},
  url = {https://epubs.siam.org/doi/abs/10.1137/S0036144593251710},
  urldate = {2021-11-30},
  abstract = {Due to their extraordinary utility and broad applicability in many areas of classical mathematics and modern physical sciences (most notably, computerized tomography), algorithms for solving convex feasibility problems continue to receive great attention. To unify, generalize, and review some of these algorithms, a very broad and flexible framework is investigated. Several crucial new concepts which allow a systematic discussion of questions on behaviour in general Hilbert spaces and on the quality of convergence are brought out. Numerous examples are given.},
  keywords = {47H09,49M45,65-02,65J05,90C25,angle between two subspaces,averaged mapping,Cimmino’s method,computerized tomography,convex feasibility problem,convex function,convex inequalities,convex programming,convex set,Fejer monotone sequence,firmly nonexpansive mapping,Hilbert space,image recovery,iterative method,Kaczmarz’s method,linear convergence,linear feasibility problem,linear inequalities,nonexpansive mapping,orthogonal projection,projection algorithm,projection method,Slater point,subdifferential,subgradient,subgradient algorithm,successive projections},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\IR7CX8AC\\Bauschke und Borwein - 1996 - On Projection Algorithms for Solving Convex Feasib.pdf}
}

@article{Bauschke2013,
  title = {Projection {{Methods}}: {{Swiss Army Knives}} for {{Solving Feasibility}} and {{Best Approximation Problems}} with {{Halfspaces}}},
  shorttitle = {Projection {{Methods}}},
  author = {Bauschke, Heinz H. and Koch, Valentin R.},
  date = {2013},
  doi = {10.1090/conm/636/12726},
  abstract = {We model a problem motivated by road design as a feasibility problem. Projections onto theconstraint setsare obtained, and projectionmethodsfor solving the feasibility problem are studied. We present results of numerical experiments which demonstrate the efficacy of projection methods even for challenging nonconvex problems.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\HMQ3DCPZ\\Bauschke und Koch - 2013 - Projection Methods Swiss Army Knives for Solving .pdf}
}

@book{Bazaraa2006,
  title = {Nonlinear {{Programming}}: {{Theory}} and {{Algorithms}}},
  shorttitle = {Nonlinear {{Programming}}},
  author = {Bazaraa, Mokhtar S. and Sherali, Hanif D. and Shetty, C. M.},
  date = {2006-06-13},
  edition = {3},
  publisher = {{Wiley-Interscience}},
  location = {{Hoboken, N.J}},
  isbn = {978-0-471-48600-8},
  langid = {english},
  pagetotal = {872}
}

@article{Bedford2019,
  title = {Calculation of absorbed dose in radiotherapy by solution of the linear {{Boltzmann}} transport equations},
  author = {Bedford, James L.},
  date = {2019-01},
  journaltitle = {Physics in Medicine \& Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {64},
  number = {2},
  pages = {02TR01},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/aaf0e2},
  url = {https://dx.doi.org/10.1088/1361-6560/aaf0e2},
  urldate = {2022-12-07},
  abstract = {Over the last decade, dose calculations which solve the linear Boltzmann transport equations have been introduced into clinical practice and are now in widespread use. However, knowledge in the radiotherapy community concerning the details of their function is limited. This review gives a general description of the linear Boltzmann transport equations as applied to calculation of absorbed dose in clinical radiotherapy. The aim is to elucidate the principles of the method, rather than to describe a particular implementation. The literature on the performance of typical algorithms is then reviewed, in many cases with reference to Monte Carlo simulations. The review is completed with an overview of the emerging applications in the important area of MR-guided radiotherapy.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\EJGHFTL6\\Bedford - 2019 - Calculation of absorbed dose in radiotherapy by so.pdf}
}

@article{Bednyakov2014,
  title = {On the {{Molière}} theory of multiple scattering of charged particles (1947–1948) and its critique in subsequent years},
  author = {Bednyakov, A. A.},
  date = {2014-09-14},
  journaltitle = {Physics of Particles and Nuclei},
  volume = {45},
  number = {5},
  pages = {991--999},
  publisher = {{Pleiades Publishing}},
  issn = {1063-7796},
  doi = {10.1134/S1063779614050037},
  url = {http://link.springer.com/10.1134/S1063779614050037},
  urldate = {2018-04-16},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\7578JH5J\\Bednyakov - 2014 - On the Molière theory of multiple scattering of charged particles (1947–1948) and its critique in subsequent years.pdf}
}

@article{Bellinzona2015,
  title = {On the parametrization of lateral dose profiles in proton radiation therapy},
  author = {Bellinzona, V.E. and Ciocca, M. and Embriaco, A. and Fontana, A. and Mairani, A. and Mori, M. and Parodi, K.},
  date = {2015-07-01},
  journaltitle = {Physica Medica},
  volume = {31},
  number = {5},
  pages = {484--492},
  publisher = {{Elsevier}},
  issn = {11201797},
  doi = {10.1016/j.ejmp.2015.05.004},
  url = {https://www.sciencedirect.com/science/article/pii/S1120179715001143},
  urldate = {2018-04-25},
  abstract = {PURPOSE The accurate evaluation of the lateral dose profile is an important issue in the field of proton radiation therapy. The beam spread, due to Multiple Coulomb Scattering (MCS), is described by the Molière's theory. To take into account also the contribution of nuclear interactions, modern Treatment Planning Systems (TPSs) generally approximate the dose profiles by a sum of Gaussian functions. In this paper we have compared different parametrizations for the lateral dose profile of protons in water for therapeutical energies: the goal is to improve the performances of the actual treatment planning. METHODS We have simulated typical dose profiles at the CNAO (Centro Nazionale di Adroterapia Oncologica) beamline with the FLUKA code and validated them with data taken at CNAO considering different energies and depths. We then performed best fits of the lateral dose profiles for different functions using ROOT and MINUIT. RESULTS The accuracy of the best fits was analyzed by evaluating the reduced χ2, the number of free parameters of the functions and the calculation time. The best results were obtained with the triple Gaussian and double Gaussian Lorentz–Cauchy functions which have 6 parameters, but good results were also obtained with the so called Gauss–Rutherford function which has only 4 parameters. CONCLUSIONS The comparison of the studied functions with accurate and validated Monte Carlo calculations and with experimental data from CNAO lead us to propose an original parametrization, the Gauss–Rutherford function, to describe the lateral dose profiles of proton beams.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\YQBQU6SK\\Bellinzona et al. - 2015 - On the parametrization of lateral dose profiles in proton radiation therapy.pdf}
}

@article{Bellinzona2016,
  title = {A model for the accurate computation of the lateral scattering of protons in water},
  author = {Bellinzona, E V and Ciocca, M and Embriaco, A and Ferrari, A and Fontana, A and Mairani, A and Parodi, K and Rotondi, A and Sala, P and Tessonnier, T},
  date = {2016-02-21},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {61},
  number = {4},
  pages = {N102-117},
  issn = {0031-9155, 1361-6560},
  doi = {10.1088/0031-9155/61/4/N102},
  url = {https://iopscience.iop.org/article/10.1088/0031-9155/61/4/N102},
  urldate = {2020-05-28},
  abstract = {A pencil beam model for the calculation of the lateral scattering in water of protons for any therapeutic energy and depth is presented. It is based on the full Molière theory, taking into account the energy loss and the effects of mixtures and compounds. Concerning the electromagnetic part, the model has no free parameters and is in very good agreement with the FLUKA Monte Carlo (MC) code. The effects of the nuclear interactions are parametrized with a two-parameter tail function, adjusted on MC data calculated with FLUKA. The model, after the convolution with the beam and the detector response, is in agreement with recent proton data in water from HIT. The model gives results with the same accuracy of the MC codes based on Molière theory, with a much shorter computing time.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\EGUKXNL6\\Bellinzona et al. - 2016 - A model for the accurate computation of the latera.pdf}
}

@book{Bellman1961,
  title = {Adaptive control processes: a guided tour},
  author = {Bellman, Richard E},
  date = {1961},
  edition = {1},
  publisher = {{Princeton University Press}},
  abstract = {The aim of this work is to present a unified approach to the modern field of control theory and to provide a technique for making problems involving deterministic, stochastic, and adaptive processes of both linear and nonlinear type amenable to machine solution. Mr. Bellman has used the theory of dynamic programming to formulate, analyze, and prepare these processes for numerical treatment by digital computers. The unique concept of the book is that of a single problem stretching from recognition and formulation to analytic treatment and computational solution. Due to the emphasis upon ideas and concepts, this book is equally suited for the pure and applied mathematician, and for control engineers in all fields. Originally published in 1961. The Princeton Legacy Library uses the latest print-on-demand technology to again make available previously out-of-print books from the distinguished backlist of Princeton University Press. These paperback editions preserve the original texts of these important books while presenting them in durable paperback editions. The goal of the Princeton Legacy Library is to vastly increase access to the rich scholarly heritage found in the thousands of books published by Princeton University Press since its founding in 1905. Frontmatter -- PREFACE -- CONTENTS -- INTRODUCTION -- CHAPTER I. FEEDBACK CONTROL AND THE CALCULUS OF VARIATIONS -- CHAPTER II. DYNAMICAL SYSTEMS AND TRANSFORMATIONS -- CHAPTER III. MULTISTAGE DECISION PROCESSES AND DYNAMIC PROGRAMMING -- CHAPTER IV. DYNAMIC PROGRAMMING AND THE CALCULUS OF VARIATIONS -- CHAPTER V. COMPUTATIONAL ASPECTS OF DYNAMIC PROGRAMMING -- CHAPTER VI. THE LAGRANGE MULTIPLIER -- CHAPTER VII. TWO-POINT BOUNDARY VALUE PROBLEMS -- CHAPTER VIII. SEQUENTIAL MACHINES AND THE SYNTHESIS OF LOGICAL SYSTEMS -- CHAPTER IX. UNCERTAINTY AND RANDOM PROCESSES -- CHAPTER X. STOCHASTIC CONTROL PROCESSES -- CHAPTER XI. MARKOVIAN DECISION PROCESSES -- CHAPTER XII. QUASILINEARIZATION -- CHAPTER XIII. STOCHASTIC LEARNING MODELS -- CHAPTER XIV. THE THEORY OF GAMES AND PURSUIT PROCESSES -- CHAPTER XV. ADAPTIVE PROCESSES -- CHAPTER XVI. ADAPTIVE CONTROL PROCESSES -- CHAPTER XVII. SOME ASPECTS OF COMMUNICATION THEORY -- CHAPTER XVIII. SUCCESSIVE APPROXIMATIONS -- INDEX -- Backmatter.},
  isbn = {978-1-4008-7466-8}
}

@article{Below2007,
  title = {Documenting {{Drought-Related Disasters}}: {{A Global Reassessment}}},
  author = {Below, R. and Grover-Kopec, E. and Dilley, M.},
  date = {2007-09-01},
  journaltitle = {The Journal of Environment \& Development},
  volume = {16},
  number = {3},
  pages = {328--344},
  publisher = {{SAGE Publications}},
  issn = {1070-4965},
  doi = {10.1177/1070496507306222},
  url = {http://jed.sagepub.com/cgi/doi/10.1177/1070496507306222},
  urldate = {2016-08-10},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\HTPJ7NGU\\Below, Grover-Kopec, Dilley - 2007 - Documenting Drought-Related Disasters A Global Reassessment.pdf}
}

@article{Benaroya2005,
  title = {Probability {{Models}} in {{Engineering}} and {{Science}}},
  author = {Benaroya, Haym and Mi Han, Seon},
  date = {2005},
  journaltitle = {Mechanical Engineering},
  volume = {48},
  number = {4},
  eprint = {13901341},
  eprinttype = {pmid},
  pages = {740},
  issn = {0040-1706},
  doi = {10.1198/tech.2006.s441},
  abstract = {1. Introduction -- 2. Events and probability -- 3. Random variable models -- 4. Functions of random variables -- 5. Random processes -- 6. Single-degree-of-freedom dynamics -- 7. Multidegree-of-freedom vibration -- 8. Continuous system vibration -- 9. Reliability -- 10. Nonlinear dynamic models -- 11. Nonstationary models -- 12. The Monte Carlo method -- 13. Fluid-induced vibration.},
  isbn = {0-8247-2315-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\A9KEQYXC\\Benaroya, Mi Han - 2005 - Probability Models in Engineering and Science.pdf}
}

@unpublished{Bennan2020,
  title = {Joint {{Optimization}} of {{Photon-Carbon}} ion treatments for {{Glioblastoma}}},
  author = {Bennan, Amit Ben Antony and Unkelbach, Jan and Wahl, Niklas and Salome, Patrick and Bangert, Mark},
  date = {2020},
  location = {{Journal article preprint, available upon request}}
}

@article{Bennan2021,
  title = {Joint optimization of photon – carbon ion treatments for {{Glioblastoma}}},
  author = {Bennan, Amit Ben Antony and Unkelbach, Jan and Wahl, Niklas and Salome, Patrick and Bangert, Mark},
  date = {2021-05-28},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {IJROBP},
  volume = {111},
  number = {2},
  pages = {559--572},
  issn = {0360-3016},
  doi = {10.1016/j.ijrobp.2021.05.126},
  url = {https://www.sciencedirect.com/science/article/pii/S0360301621006684},
  urldate = {2021-06-30},
  abstract = {Purpose: Carbon ions are radiobiologically more effective than photons and are beneficial for treating radioresistant gross tumour volumes (GTV). However, due to a reduced fractionation effect, they may be disadvantageous for treating infiltrative tumours, where healthy tissue inside the clinical target volume (CTV) must be protected through fractionation. This work addresses the question: what is the ideal combined photon-carbon ion fluence distribution for treating infiltrative tumours given a specific fraction allocation between photons and carbon ions? Methods: We present a method to simultaneously optimize sequentially delivered intensity modulated photon (IMRT) and carbon ion (CIRT) treatments based on cumulative biological effect, incorporating both the variable RBE of carbon ions and the fractionation effect within the linear quadratic model. The method is demonstrated for six Glioblastoma patients in comparison to current clinical standard of independently optimized CIRT - IMRT plans. Results: Compared to the reference plan, joint optimization strategies yield inhomogeneous photon and carbon ion dose distributions that cumulatively deliver a homogeneous biological effect distribution. In the optimal distributions, the dose to CTV is mostly delivered by photons while carbon ions are restricted to the GTV with variations depending on tumour size and location. Improvements in conformity of high dose regions are reflected by a mean EQD2 reduction of 3.29 ± 1.22 Gy in a dose fall-off margin around the CTV. Carbon ions may deliver higher doses to the center of the GTV, while photon contributions are increased at interfaces with CTV and critical structures. This results in a mean EQD2 reduction of 8.3 ± 2.28 Gy, where the brainstem abuts the target volumes. Conclusions: We have developed a biophysical model to optimize combined photon-carbon ion treatments. For six glioblastoma patient cases, we show that our approach results in a more targeted application of carbon ions that (1) reduces dose in normal tissues within the target volume which can only be protected through fractionation (2) boosts central target volume regions in order to reduce integral dose. Joint optimization of IMRT - CIRT treatments enable the exploration of a new spectrum of plans that can better address physical and radiobiological treatment planning challenges.},
  langid = {english},
  selected = {true},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\SBHRK75R\\S0360301621006684.html}
}

@article{Bernatowicz2013,
  title = {Comparative study of layered and volumetric rescanning for different scanning speeds of proton beam in liver patients},
  author = {Bernatowicz, K. and Lomax, A. J. and Knopf, A.},
  date = {2013-10},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {58},
  number = {22},
  pages = {7905--7920},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/58/22/7905},
  url = {https://doi.org/10.1088%2F0031-9155%2F58%2F22%2F7905},
  urldate = {2020-03-25},
  abstract = {In recent years, particle therapy has become a widely accepted form of cancer treatment and technological advances in beam delivery technology (i.e. pencil beam scanning (PBS)) have enabled the application of highly conformal dose distributions to static targets. Current research focuses on the possibilities for the treatment of mobile targets with these techniques. Of different motion mitigation methods being investigated, rescanning is perhaps the easiest to apply clinically. In general however, different PBS delivery systems exhibit a different temporal parameter space between delivery and target motions, due to the system specific beam position adjustment times (BPATs). Depending on these BPATs, dosimetric effects appearing during irradiation of moving targets vary significantly. In this work, volumetric and layered rescanning were compared for four different scenarios—a combination of fast and slow BPATs laterally (4 ms and 10 ms) and in depth (80 ms and 1 s); and nine different treatment plan arrangements for two clinical liver cases. 4D dose calculations were performed assuming regular, sinusoidal rigid motion as a worst-case motion scenario to model interplay effects. Calculations were sampled over three different starting phases resulting in a total of 432 dose distributions. It was found that layered rescanning is the method of choice for slow scanning systems, both in terms of dose homogeneity (D5–95 values are lower by up to 16\% with layered rescanning) and in the estimated treatment delivery times (reduction of up to 300 s with layered rescanning). Analysis of dose homogeneity showed that layered rescanning leads to a smoother decrease in dose inhomogeneity as a function of the number of rescans than volumetric rescanning, which shows larger fluctuations. However, layered rescanning appears to be more sensitive to the starting phase. When analyzing the performance of both approaches and different scanning speeds as a function of delivery time, layered rescanning appears to be the only viable approach for slow energy changing systems, even approaching the performance of fast energy changing systems, as long as lateral scanning speeds are kept high. Similar results were found for multiple field plans and when analyzing different field directions.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\SI686IUR\\Bernatowicz et al. - 2013 - Comparative study of layered and volumetric rescan.pdf}
}

@article{Bernatowicz2016,
  title = {Four-{{Dimensional Dose Reconstruction}} for {{Scanned Proton Therapy Using Liver 4DCT-MRI}}},
  author = {Bernatowicz, Kinga and Peroni, Marta and Perrin, Rosalind and Weber, Damien C. and Lomax, Antony},
  date = {2016-05},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {95},
  number = {1},
  pages = {216--223},
  issn = {03603016},
  doi = {10.1016/j.ijrobp.2016.02.050},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0360301616001930},
  urldate = {2020-03-20},
  abstract = {Purpose: Four-dimensional computed tomography-magnetic resonance imaging (4DCT-MRI) is an image-processing technique for simulating many 4DCT data sets from a static reference CT and motions extracted from 4DMRI studies performed using either volunteers or patients. In this work, different motion extraction approaches were tested using 6 liver cases, and a detailed comparison between 4DCT-MRI and 4DCT was performed. Methods and Materials: 4DCT-MRI has been generated using 2 approaches. The first approach used motion extracted from 4DMRI as being “most similar” to that of 4DCT from the same patient (subject-specific), and the second approach used the most similar motion obtained from a motion library derived from 4DMRI liver studies of 13 healthy volunteers (population-based). The resulting 4DCT-MRI and 4DCTs were compared using scanned proton 4D dose calculations (4DDC). Results: Dosimetric analysis showed that 93\% Æ 8\% of points inside the clinical target volume (CTV) agreed between 4DCT and subject-specific 4DCT-MRI (gamma analysis: 3\%/3 mm). The population-based approach however showed lower dosimetric agreement with only 79\% Æ 14\% points in the CTV reaching the 3\%/3 mm criteria. Conclusions: 4D CT-MRI extends the capabilities of motion modeling for dose calculations by accounting for realistic and variable motion patterns, which can be directly employed in clinical research studies. We have found that the subject-specific liver modeling appears more accurate than the population-based approach. The former is particularly interesting for clinical applications, such as improved target delineation},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Y6JWRLNU\\Bernatowicz et al. - 2016 - Four-Dimensional Dose Reconstruction for Scanned P.pdf}
}

@inproceedings{Bert2009,
  title = {Motion management in scanned particle therapy: beam gating \& tracking},
  shorttitle = {Motion management in scanned particle therapy},
  booktitle = {World {{Congress}} on {{Medical Physics}} and {{Biomedical Engineering}}, {{September}} 7 - 12, 2009, {{Munich}}, {{Germany}}},
  author = {Bert, C. and Gemmel, A. and Saito, N. and Chaudhri, N. and Lüchtenborg, R. and Durante, M. and Rietzel, E.},
  editor = {Dössel, Olaf and Schlegel, Wolfgang C.},
  date = {2009},
  series = {{{IFMBE Proceedings}}},
  pages = {345--348},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-03474-9_97},
  abstract = {Treatment of intra-fractionally moving targets with scanned ion beams requires motion mitigation techniques due to interplay effects. We implemented Gating (paused irradiation) and Beam Tracking (position adaptive irradiation) at GSI and performed experimental studies to validate both techniques. Gating requires mitigation of interplay effects within the gating window. An increased overlap, e.g. larger beam spots at constant spacing of rasterpoints was successfully tested. At 5 mm gating windows and 1 mm spacing, 10 mm FWHM beam spot sizes are required. Beam Tracking accuracy was studied in comparison to stationary irradiations with an ionization chamber array. Within the target volume deviations of 0.3 ± 1.5 \% were measured. Clinical implementation at the Heidelberg Ion Beam therapy (HIT) will start with Gating. The mid-term goal is Beam Tracking because treatment planning studies for lung tumors showed that Tracking results in a reduced dose to the ipsilateral lung in comparison to Gating.},
  isbn = {978-3-642-03474-9},
  langid = {english},
  keywords = {ion beam,organ motion,radiotherapy,scanning}
}

@article{Bert2011,
  title = {Motion in radiotherapy: particle therapy},
  shorttitle = {Motion in radiotherapy},
  author = {Bert, C. and Durante, M.},
  date = {2011-07},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {56},
  number = {16},
  pages = {R113--R144},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/56/16/R01},
  url = {https://doi.org/10.1088%2F0031-9155%2F56%2F16%2Fr01},
  urldate = {2020-03-23},
  abstract = {Charged particle beam radiotherapy requires dedicated measures to compensate for the dosimetric influence of inter- and intra-fractional target motion. Independent of the delivery technique, these measures have to incorporate the strong influence of the radiological depth on the delivered dose. For scanned beam delivery, interference effects of target motion and scanned beam can further cause under-dosage of the clinical target volume despite using margins. Within the scope of this review, published data with respect to motion management in scattered as well as scanned beam treatment delivery will be summarized. Based on a section covering the dosimetric impact of organ motion, motion management during treatment planning, patient positioning, treatment delivery and treatment validation will be summarized. For scattered beam delivery, the concepts and data are often based on clinical usage since treatment of moving tumors has been performed for several years. In the field of scanned beam delivery, the report focuses on the results of research on countermeasures of the interference effect. Clinical application of these techniques can be expected in the near future.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\W6MRZ27B\\Bert und Durante - 2011 - Motion in radiotherapy particle therapy.pdf}
}

@article{Berthelsen2007,
  title = {What's new in target volume definition for radiologists in {{ICRU Report}} 71? {{How}} can the {{ICRU}} volume definitions be integrated in clinical practice?},
  author = {Berthelsen, Anne Kiil and Dobbs, Jane and Kjellén, Elisabeth and Landberg, Torsten and Möller, Torgil R and Nilsson, Per and Specht, Lena and Wambersie, André},
  date = {2007-01},
  journaltitle = {Cancer imaging : the official publication of the International Cancer Imaging Society},
  volume = {7},
  eprint = {17594916},
  eprinttype = {pmid},
  pages = {104--16},
  issn = {1470-7330},
  doi = {10.1102/1470-7330.2007.0013},
  url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1906985&tool=pmcentrez&rendertype=abstract},
  urldate = {2014-01-15},
  abstract = {The optimal definition of the size, shape and location of gross tumour volume is one of the most important steps in the planning of radiation therapy, and necessitates a proper understanding of the procedure from both the oncologic radiologist and the radiation oncologist. This overview reports on the different terms and concepts that have been recommended in the ICRU Reports for this purpose; the latest Report 71 focuses on both previously given recommendations, and especially on electron beam therapy. This paper also highlights some of the problems that are encountered in the use of the International Commission on Radiation Units and Measurements (ICRU) recommendations in clinical practice, and at the interface between the radiation oncologist and the diagnostic oncologist.},
  keywords = {Brachytherapy,Brachytherapy: standards,Brachytherapy: trends,Dose-Response Relationship; Radiation,Forecasting,Humans,International Cooperation,Interprofessional Relations,Radiation Injuries,Radiation Injuries: prevention & control,Radiation Oncology,Radiation Oncology: standards,Radiology; Interventional,Radiology; Interventional: standards,Radiology; Interventional: trends,Radiotherapy Dosage,Radiotherapy Planning; Computer-Assisted,Radiotherapy Planning; Computer-Assisted: standard,Radiotherapy Planning; Computer-Assisted: trends,Sensitivity and Specificity},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\I64U2ITI\\Berthelsen et al. - 2007 - What's new in target volume definition for radiologists in ICRU Report 71 How can the ICRU volume definitions.pdf}
}

@article{Bertin2006,
  title = {Generalised extreme value statistics and sum of correlated variables},
  author = {Bertin, Eric and Clusel, Maxime},
  date = {2006},
  journaltitle = {Journal of Physics A: Mathematical and Theoretical},
  volume = {39},
  pages = {7607},
  url = {https://hal.archives-ouvertes.fr/hal-00016701/document},
  urldate = {2018-03-22},
  abstract = {We show that generalised extreme value statistics –the statistics of the k th largest value among a large set of random variables– can be mapped onto a problem of random sums. This allows us to identify classes of non-identical and (generally) correlated random variables with a sum distributed according to one of the three (k-dependent) asymptotic distributions of extreme value statistics, namely the Gumbel, Fréchet and Weibull distributions. These classes, as well as the limit distributions, are naturally extended to real values of k, thus providing a clear interpretation to the onset of Gumbel distributions with non-integer index k in the statistics of global observables. This is one of the very few known generalisations of the central limit theorem to non-independent random variables. Finally, in the context of a simple physical model, we relate the index k to the ratio of the correlation length to the system size, which remains finite in strongly correlated systems. PACS numbers: 02.50.-r (Probability theory, stochastic processes, and statistics); 05.40.-a (Fluctuation phenomena, random processes, noise, and Brownian motion);},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\L47ZP5CS\\Bertin, Clusel - 2006 - Generalised extreme value statistics and sum of correlated variables.pdf}
}

@article{Bethe1930,
  title = {Zur {{Theorie}} des {{Durchgangs}} schneller {{Korpuskularstrahlen}} durch {{Materie}}},
  author = {Bethe, H.},
  date = {1930},
  journaltitle = {Annalen der Physik},
  volume = {397},
  number = {3},
  pages = {325--400},
  publisher = {{Wiley-Blackwell}},
  issn = {00033804},
  doi = {10.1002/andp.19303970303},
  url = {http://doi.wiley.com/10.1002/andp.19303970303},
  urldate = {2018-03-29},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\VZ9A5VQ4\\Bethe - 1930 - Zur Theorie des Durchgangs schneller Korpuskularstrahlen durch Materie.pdf}
}

@article{Bloch1933,
  title = {Zur {{Bremsung}} rasch bewegter {{Teilchen}} beim {{Durchgang}} durch {{Materie}}},
  author = {Bloch, F.},
  date = {1933},
  journaltitle = {Annalen der Physik},
  volume = {408},
  number = {3},
  pages = {285--320},
  publisher = {{Wiley-Blackwell}},
  issn = {00033804},
  doi = {10.1002/andp.19334080303},
  url = {http://doi.wiley.com/10.1002/andp.19334080303},
  urldate = {2018-03-29},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\YRFY5BK6\\Bloch - 1933 - Zur Bremsung rasch bewegter Teilchen beim Durchgang durch Materie.pdf}
}

@article{Bohoslavsky2013,
  title = {Probabilistic objective functions for margin-less {{IMRT}} planning},
  author = {Bohoslavsky, Román and Witte, Marnix G and Janssen, Tomas M and family=Herk, given=Marcel, prefix=van, useprefix=true},
  date = {2013},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {58},
  number = {11},
  eprint = {23640114},
  eprinttype = {pmid},
  pages = {3563--3580},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/58/11/3563},
  url = {http://stacks.iop.org/0031-9155/58/i=11/a=3563?key=crossref.79938efd7333300ef1b285f9f13502c7},
  abstract = {We present a method to implement probabilistic treatment planning of intensity-modulated radiation therapy using custom software plugins in a commercial treatment planning system. Our method avoids the definition of safety-margins by directly including the effect of geometrical uncertainties during optimization when objective functions are evaluated. Because the shape of the resulting dose distribution implicitly defines the robustness of the plan, the optimizer has much more flexibility than with a margin-based approach. We expect that this added flexibility helps to automatically strike a better balance between target coverage and dose reduction for surrounding healthy tissue, especially for cases where the planning target volume overlaps organs at risk. Prostate cancer treatment planning was chosen to develop our method, including a novel technique to include rotational uncertainties. Based on population statistics, translations and rotations are simulated independently following a marker-based IGRT correction strategy. The effects of random and systematic errors are incorporated by first blurring and then shifting the dose distribution with respect to the clinical target volume. For simplicity and efficiency, dose-shift invariance and a rigid-body approximation are assumed. Three prostate cases were replanned using our probabilistic objective functions. To compare clinical and probabilistic plans, an evaluation tool was used that explicitly incorporates geometric uncertainties using Monte-Carlo methods. The new plans achieved similar or better dose distributions than the original clinical plans in terms of expected target coverage and rectum wall sparing. Plan optimization times were only about a factor of two higher than in the original clinical system. In conclusion, we have developed a practical planning tool that enables margin-less probability-based treatment planning with acceptable planning times, achieving the first system that is feasible for clinical implementation.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\U5IJRHV6\\Bohoslavsky et al. - 2013 - Probabilistic objective functions for margin-less IMRT planning.pdf}
}

@article{Bol2012a,
  title = {Fast online {{Monte Carlo-based IMRT}} planning for the {{MRI}} linear accelerator.},
  author = {Bol, G H and Hissoiny, S and Lagendijk, J J W and Raaymakers, B W},
  date = {2012-03-07},
  journaltitle = {Physics in medicine and biology},
  volume = {57},
  number = {5},
  eprint = {22349450},
  eprinttype = {pmid},
  pages = {1375--1385},
  publisher = {{IOP Publishing}},
  issn = {1361-6560},
  doi = {10.1088/0031-9155/57/5/1375},
  url = {http://dx.doi.org/10.1088/0031-9155/57/5/1375},
  urldate = {2013-12-12},
  abstract = {The MRI accelerator, a combination of a 6 MV linear accelerator with a 1.5 T MRI, facilitates continuous patient anatomy updates regarding translations, rotations and deformations of targets and organs at risk. Accounting for these demands high speed, online intensity-modulated radiotherapy (IMRT) re-optimization. In this paper, a fast IMRT optimization system is described which combines a GPU-based Monte Carlo dose calculation engine for online beamlet generation and a fast inverse dose optimization algorithm. Tightly conformal IMRT plans are generated for four phantom cases and two clinical cases (cervix and kidney) in the presence of the magnetic fields of 0 and 1.5 T. We show that for the presented cases the beamlet generation and optimization routines are fast enough for online IMRT planning. Furthermore, there is no influence of the magnetic field on plan quality and complexity, and equal optimization constraints at 0 and 1.5 T lead to almost identical dose distributions.},
  langid = {english},
  keywords = {Cervix Uteri,Cervix Uteri: pathology,Computer-Assisted,Computer-Assisted: methods,Female,Humans,Imaging,Intensity-Modulated,Intensity-Modulated: methods,Kidney,Kidney: pathology,Magnetic Fields,Magnetic Resonance Im,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Male,methods,Monte Carlo Method,Particle Accel,Particle Accelerators,pathology,Phantoms,Radiation Dosage,Radiotherapy,Radiotherapy Planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\HEFY2492\\Bol et al. - 2012 - Fast online Monte Carlo-based IMRT planning for the MRI linear accelerator.pdf}
}

@misc{Bol2013,
  title = {Private {{Communication}}},
  author = {Bol, G H},
  date = {2013}
}

@article{Borgefors1986,
  title = {Distance transformations in digital images},
  author = {Borgefors, Gunilla},
  date = {1986-06},
  journaltitle = {Computer Vision, Graphics, and Image Processing},
  volume = {34},
  number = {3},
  pages = {344--371},
  issn = {0734189X},
  doi = {10.1016/S0734-189X(86)80047-0},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0734189X86800470},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Y3I3ZFZZ\\Borgefors - 1986 - Distance transformations in digital images.pdf}
}

@article{Borgefors1996,
  title = {On {{Digital Distance Transforms}} in {{Three Dimensions}}},
  author = {Borgefors, Gunilla},
  date = {1996-11},
  journaltitle = {Computer Vision and Image Understanding},
  volume = {64},
  number = {3},
  pages = {368--376},
  issn = {10773142},
  doi = {10.1006/cviu.1996.0065},
  url = {http://www.sciencedirect.com/science/article/pii/S107731429690065X},
  urldate = {2014-08-11},
  abstract = {Digital distance transforms in 3D have been considered for more than 10 years. However, not all of the complexities involved have been unravelled. In this paper the complete geometry and equations for 3D transforms based on a 3 × 3 × 3 neighborhood of local distances are given. A new type of valid distance transforms (DTs) have been discovered. The optimal solutions are computed, where optimality is defined as minimizing the maximum difference from the true Euclidean distance, thus making the DTs as direction independent as possible. The well-known 〈3, 4, 5〉 DT is confirmed as the most practical weighted DT, where the distance is set to 3 between neighbors sharing an area, 4 between neighbors sharing an edge, and 5 between neighbors sharing a point.}
}

@article{Bortfeld1990,
  title = {Methods of image reconstruction from projections applied to conformation radiotherapy},
  author = {Bortfeld, Th and Bürkelbach, J. and Boesecke, R. and Schlegel, W.},
  date = {1990-10},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {35},
  number = {10},
  pages = {1423--1434},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/35/10/007},
  url = {https://doi.org/10.1088/0031-9155/35/10/007},
  urldate = {2021-12-01},
  abstract = {The problem of optimizing the dose distribution for conformation radiotherapy with intensity modulated external beams is similar to the problem of reconstructing a 3D image from its 2D projections. In this paper we analyse the relationship between these problems. We show that the main image reconstruction methods, namely filtered backprojection and iterative reconstruction, can be directly applied to conformation therapy. We examine the features of each of these methods with regard to this new application and we present first theoretical results.},
  langid = {english}
}

@article{Bortfeld1993,
  ids = {Bortfeld1993a},
  title = {Decomposition of pencil beam kernels for fast dose calculations in three-dimensional treatment planning},
  author = {Bortfeld, Thomas and Schlegel, Wolfgang and Rhein, Bernhard},
  date = {1993},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {20},
  number = {2},
  pages = {311--318},
  issn = {NA},
  doi = {10.1118/1.597070},
  abstract = {A method for the calculation of three-dimensional dose distributions for high-energy photon beams is presented. The main features are (i) the calculation is fast enough to allow interactive three-dimensional treatment planning, and (ii) irregularly shaped or compensated fields, which are required to fit three-dimensional dose distributions to target volumes, are adequately taken into consideration. The method is based on the pencil beam convolution technique and shares its features concerning accuracy. A considerable gain in speed is achieved by decomposing the pencil beam kernel into three separated terms, thus reducing the required number of two-dimensional convolutions. The convolutions are performed in the frequency domain via the fast Hartley transform. Using these techniques, the calculation time for the convolutions is only about 8 s on a DEC VAX station 3100. This is one-fourth to one-third of the calculation time for the ray tracing through the three-dimensional CT data set, which has to be performed in any case. Results of the calculation are compared with measurements in a homogeneous phantom for 15 MV photons. Two irregular fields shaped with a multileaf collimator are considered. The deviations between measured and calculated absolute dose values are smaller than ±2\%. © 1993, American Association of Physicists in Medicine. All rights reserved.},
  keywords = {87.53.10.b,ALGORITHMS,convolution,CONVOLUTION,decomposition,dose calculation,Dosimetry/exposure assessment,Hartley,KERNELS,Medical treatment planning,Multileaf collimators,pencil beam kernel,Photons,RADIOTHERAPY,Ray tracing,SPATIAL DOSE DISTRIBUTIONS,THREE−DIMENSIONAL CALCULATIONS,transform,Treatment strategy,X−RAY DOSIMETRY},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\HYJEFJYG\\Bortfeld, Schlegel, Rhein - 1993 - Decomposition of pencil beam kernels for fast dose calculations in three-dimensional treatment planni.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\GM4LAAU8\\1.html}
}

@article{Bortfeld1997,
  title = {An analytical approximation of the {{Bragg}} curve for therapeutic proton beams},
  author = {Bortfeld, Thomas},
  date = {1997-12},
  journaltitle = {Medical Physics},
  volume = {24},
  number = {12},
  eprint = {9434986},
  eprinttype = {pmid},
  pages = {2024--2033},
  publisher = {{Wiley}},
  issn = {00942405},
  doi = {10.1118/1.598116},
  abstract = {The knowledge of proton depth-dose curves, or "Bragg curves," is a fundamental prerequisite for dose calculations in radiotherapy planning, among other applications. In various cases it is desirable to have an analytical representation of the Bragg curve, rather than using measured or numerically calculated data. This work provides an analytical approximation of the Bragg curve in closed form. The underlying model is valid for proton energies between about 10 and 200 MeV. Its main four constituents are: (i) a power-law relationship describing the range-energy dependency; (ii) a linear model for the fluence reduction due to nonelastic nuclear interactions, assuming local deposition of a fraction of the released energy; (iii) a Gaussian approximation of the range straggling distribution; and (iv) a representation of the energy spectrum of poly-energetic beams by a Gaussian with a linear "tail." Based on these assumptions the Bragg curve can be described in closed form using a simple combination of Gaussians and parabolic cylinder functions. The resulting expression can be fitted to measurements within the measurement error. Very good agreement is also found with numerically calculated Bragg curves.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\D8ZW6H76\\Bortfeld - 1997 - An analytical approximation of the Bragg curve for therapeutic proton beams.pdf}
}

@article{Bortfeld2004,
  title = {Effects of motion on the total dose distribution},
  author = {Bortfeld, Thomas and Jiang, Steve B and Rietzel, Eike},
  date = {2004-01},
  journaltitle = {Seminars in Radiation Oncology},
  volume = {14},
  number = {1},
  pages = {41--51},
  issn = {10534296},
  doi = {10.1053/j.semradonc.2003.10.011},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S1053429603000924},
  urldate = {2016-10-11},
  abstract = {The success of highly target-conformal treatments such as intensity-modulated radiotherapy (IMRT) can be compromised by motion of the inner organs and random patient setup errors. This article gives an overview of different studies that looked at the effect of organ motion and setup errors on radiation therapy dose distributions, both from a qualitative and quantitative point of view. The qualitative findings are generally applicable (ie, case independent). It is found that motion always leads to a blurring of the dose distribution. In addition, there are so-called interplay effects if the treatment delivery involves moving parts, such as multileaf collimators. After a large number of fractions, the interplay effects lead to a normal distribution of the dose value around the average blurred value. Thirdly, organ motion can also cause a spatial deformation of the dose distribution. Quantitatively it has been found that both deformation and interplay effects appear to be small (in the order of 1\%–2\%) in many typical clinical cases. The dominant effect is the blurring of the dose distribution, which is, in essence, independent of the treatment technique, and is not more pronounced in IMRT than in more conventional treatment techniques. However, because in IMRT there is a tendency to reduce or compromise target margins, the blurring has potentially a bigger effect on the outcome of IMRT, unless precision dose delivery techniques (such as gated or motion-synchronized beams) are used. An alternative to the use of margins is to do the planning based on blurred dose distributions.}
}

@article{Bortfeld2006,
  title = {{{IMRT}}: a review and preview.},
  author = {Bortfeld, Thomas},
  date = {2006-07-07},
  journaltitle = {Physics in medicine and biology},
  shortjournal = {Phys Med Biol},
  volume = {51},
  number = {13},
  eprint = {16790913},
  eprinttype = {pmid},
  pages = {R363-79},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/51/13/R21},
  abstract = {The very first cornerstone paper on intensity-modulated radiation therapy (IMRT) was published in Physics in Medicine and Biology, and many seminal IMRT works have since appeared in this journal. Today IMRT is a widely used clinical treatment modality in many countries. This contribution to the 50th anniversary issue reviews the physical, mathematical, and technological milestones that have facilitated the clinical implementation and success of IMRT. In particular, the basic concepts and developments of both IMRT treatment planning ('inverse planning') and the delivery of cone-beam IMRT with a multileaf collimator from a fixed number of static beam directions are discussed. An outlook into the future of IMRT concludes the paper.},
  keywords = {Animals,Biotechnology,Biotechnology: instrumentation,Biotechnology: methods,Biotechnology: trends,Equipment Design,Forecasting,Humans,Neoplasms,Neoplasms: radiotherapy,Radiometry,Radiometry: instrumentation,Radiometry: methods,Radiometry: trends,Radiotherapy Dosage,Radiotherapy Planning; Computer-Assisted,Radiotherapy Planning; Computer-Assisted: methods,Radiotherapy Planning; Computer-Assisted: trends,Radiotherapy; Conformal,Radiotherapy; Conformal: instrumentation,Radiotherapy; Conformal: methods,Radiotherapy; Conformal: trends},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\6D9LGJ2W\\Bortfeld - 2006 - IMRT a review and preview.pdf}
}

@incollection{Bortfeld2006a,
  title = {Optimization of {{Treatment Plans}}, {{Inverse Planning}}},
  booktitle = {New {{Technologies}} in {{Radiation Oncology}}},
  author = {Bortfeld, Thomas and Thieke, Christian},
  editor = {Schlegel, Wolfgang and Bortfeld, Thomas and Grosu, Anca-Ligia},
  date = {2006},
  series = {Medical {{Radiology}}},
  pages = {207--220},
  publisher = {{Springer-Verlag}},
  location = {{Berlin/Heidelberg}},
  doi = {10.1007/3-540-29999-8_17},
  url = {http://link.springer.com/10.1007/3-540-29999-8_17},
  urldate = {2020-09-11},
  isbn = {978-3-540-00321-2},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\5I983HJD\\Bortfeld und Thieke - 2006 - Optimization of Treatment Plans, Inverse Planning.pdf}
}

@article{Bortfeld2008,
  title = {Robust {{Management}} of {{Motion Uncertainty}} in {{Intensity-Modulated Radiation Therapy}}},
  author = {Bortfeld, T. and Chan, T. C. Y. and Trofimov, a. and Tsitsiklis, J. N.},
  date = {2008},
  journaltitle = {Operations Research},
  volume = {56},
  number = {6},
  pages = {1461--1473},
  issn = {0030-364X},
  doi = {10.1287/opre.1070.0484},
  abstract = {Radiation therapy is subject to uncertainties that need to be accounted for when determining a suitable treatment plan for a cancer patient. For lung and liver tumors, the presence of breathing motion during treatment is a challenge to the effective and reliable delivery of the radiation. In this paper, we build a model of motion uncertainty using probability density functions that describe breathing motion, and provide a robust formulation of the problem of optimizing intensity-modulated radiation therapy. We populate our model with real patient data and measure the robustness of the resulting solutions on a clinical lung example. Our robust framework generalizes current mathematical programming formulations that account for motion, and gives insight into the trade-off between sparing the healthy tissues and ensuring that the tumor receives sufficient dose. For comparison, we also compute solutions to a nominal (no uncertainty) and margin (worst-case) formulation. In our experiments, we found that the nominal solution typically underdosed the tumor in the unacceptable range of 6\% to 11\%, whereas the robust solution underdosed by only 1\% to 2\% in the worst case. In addition, the robust solution reduced the total dose delivered to the main organ-at-risk (the left lung) by roughly 11\% on average, as compared to the margin solution.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\KSFYITYY\\Bortfeld et al. - 2008 - Robust Management of Motion Uncertainty in Intensity-Modulated Radiation Therapy.pdf}
}

@article{Bostel2019,
  title = {Dosimetric {{Impact}} of {{Interfractional Variations}} in {{Prostate Cancer Radiotherapy}}—{{Implications}} for {{Imaging Frequency}} and {{Treatment Adaptation}}},
  author = {Bostel, Tilman and Sachpazidis, Ilias and Splinter, Mona and Bougatf, Nina and Fechter, Tobias and Zamboglou, Constantinos and Jäkel, Oliver and Huber, Peter E. and Baltas, Dimos and Debus, Jürgen and Nicolay, Nils H.},
  date = {2019},
  journaltitle = {Frontiers in Oncology},
  volume = {9},
  pages = {940},
  issn = {2234-943X},
  doi = {10.3389/fonc.2019.00940},
  url = {https://www.frontiersin.org/article/10.3389/fonc.2019.00940},
  urldate = {2021-09-01},
  abstract = {Background and purpose: To analyze deviations of the applied from the planned doses on a voxel-by-voxel basis for definitive prostate cancer radiotherapy depending on anatomic variations and imaging frequency.Materials and methods: Daily in-room CT imaging was performed in treatment position for 10 patients with prostate cancer undergoing intensity-modulated radiotherapy (340 fraction CTs). Applied fraction doses were recalculated on daily images, and voxel-wise dose accumulation was performed using a deformable registration algorithm. For weekly imaging, weekly position correction vectors were derived and used to rigidly register daily scans of that week to the planning CT scan prior to dose accumulation. Applied and prescribed doses were compared in dependence of the imaging frequency, and derived TCP and NTCP values were calculated.Results: Daily CT-based repositioning resulted in non-significant deviations of all analyzed dose-volume, conformity and uniformity parameters to the CTV, bladder and rectum irrespective of anatomic changes. Derived average TCP values were comparable, and NTCP values for the applied doses to the bladder and rectum did not significantly deviate from the planned values. For weekly imaging, the applied D2 to the CTV, rectum and bladder significantly varied from the planned doses, and the CTV conformity index and D98 decreased. While TCP values were comparable, the NTCP for the bladder erroneously appeared reduced for weekly repositioning.Conclusions: Based on daily diagnostic quality CT imaging and voxel-wise dose accumulation, we demonstrated for the first time that daily, but not weekly imaging resulted in only negligible deviations of the applied from the planned doses for prostate intensity-modulated radiotherapy. Therefore, weekly imaging may not be adequately reliable for adaptive treatment delivery techniques for prostate. This work will contribute to devising adaptive re-planning strategies for prostate radiotherapy.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\477TSZRE\\Bostel et al. - 2019 - Dosimetric Impact of Interfractional Variations in.pdf}
}

@article{Bourhis2019,
  title = {Treatment of a first patient with {{FLASH-radiotherapy}}},
  author = {Bourhis, Jean and Sozzi, Wendy Jeanneret and Jorge, Patrik Gonçalves and Gaide, Olivier and Bailat, Claude and Duclos, Fréderic and Patin, David and Ozsahin, Mahmut and Bochud, François and Germond, Jean-François and Moeckli, Raphaël and Vozenin, Marie-Catherine},
  date = {2019-10},
  journaltitle = {Radiotherapy and Oncology},
  shortjournal = {Radiotherapy and Oncology},
  volume = {139},
  pages = {18--22},
  issn = {01678140},
  doi = {10.1016/j.radonc.2019.06.019},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167814019329597},
  urldate = {2020-05-07},
  abstract = {Background: When compared to conventional radiotherapy (RT) in pre-clinical studies, FLASH-RT was shown to reproducibly spare normal tissues, while preserving the anti-tumor activity. This marked increase of the differential effect between normal tissues and tumors prompted its clinical translation. In this context, we present here the treatment of a first patient with FLASH-RT. Material \& methods: A 75-year-old patient presented with a multiresistant CD30+ T-cell cutaneous lymphoma disseminated throughout the whole skin surface. Localized skin RT has been previously used over 110 times for various ulcerative and/or painful cutaneous lesions progressing despite systemic treatments. However, the tolerance of these RT was generally poor, and it was hypothesized that FLASH-RT could offer an equivalent tumor control probability, while being less toxic for the skin. This treatment was given to a 3.5-cm diameter skin tumor with a 5.6-MeV linac specifically designed for FLASH-RT. The prescribed dose to the PTV was 15 Gy, in 90 ms. Redundant dosimetric measurements were performed with GafChromic films and alanine, to check the consistency between the prescribed and the delivered doses. Results: At 3 weeks, i.e. at the peak of the reactions, a grade 1 epithelitis (CTCAE v 5.0) along with a transient grade 1 oedema (CTCAE v5.0) in soft tissues surrounding the tumor were observed. Clinical examination was consistent with the optical coherence tomography showing no decrease of the thickness of the epidermis and no disruption at the basal membrane with limited increase of the vascularization. In parallel, the tumor response was rapid, complete, and durable with a short follow-up of 5 months. These observations, both on normal skin and on the tumor, were promising and prompt to further clinical evaluation of FLASH-RT. Conclusion: This first FLASH-RT treatment was feasible and safe with a favorable outcome both on normal skin and the tumor. Ó 2019 Published by Elsevier B.V. Radiotherapy and Oncology 139 (2019) 18–22},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\J5CZ2DQ3\\Bourhis et al. - 2019 - Treatment of a first patient with FLASH-radiothera.pdf}
}

@article{Bradley2015,
  title = {Standard-dose versus high-dose conformal radiotherapy with concurrent and consolidation carboplatin plus paclitaxel with or without cetuximab for patients with stage {{IIIA}} or {{IIIB}} non-small-cell lung cancer ({{RTOG}} 0617): a randomised, two-by-two factorial phase 3 study},
  shorttitle = {Standard-dose versus high-dose conformal radiotherapy with concurrent and consolidation carboplatin plus paclitaxel with or without cetuximab for patients with stage {{IIIA}} or {{IIIB}} non-small-cell lung cancer ({{RTOG}} 0617)},
  author = {Bradley, Jeffrey D. and Paulus, Rebecca and Komaki, Ritsuko and Masters, Gregory and Blumenschein, George and Schild, Steven and Bogart, Jeffrey and Hu, Chen and Forster, Kenneth and Magliocco, Anthony and Kavadi, Vivek and Garces, Yolanda I. and Narayan, Samir and Iyengar, Puneeth and Robinson, Cliff and Wynn, Raymond B. and Koprowski, Christopher and Meng, Joanne and Beitler, Jonathan and Gaur, Rakesh and Curran, Walter and Choy, Hak},
  date = {2015-02-01},
  journaltitle = {The Lancet Oncology},
  shortjournal = {The Lancet Oncology},
  volume = {16},
  number = {2},
  eprint = {25601342},
  eprinttype = {pmid},
  pages = {187--199},
  publisher = {{Elsevier}},
  issn = {1470-2045, 1474-5488},
  doi = {10.1016/S1470-2045(14)71207-0},
  url = {https://www.thelancet.com/journals/lanonc/article/PIIS1470-2045(14)71207-0/abstract},
  urldate = {2020-03-23},
  abstract = {{$<$}h2{$>$}Summary{$<$}/h2{$><$}h3{$>$}Background{$<$}/h3{$><$}p{$>$}We aimed to compare overall survival after standard-dose versus high-dose conformal radiotherapy with concurrent chemotherapy and the addition of cetuximab to concurrent chemoradiation for patients with inoperable stage III non-small-cell lung cancer.{$<$}/p{$><$}h3{$>$}Methods{$<$}/h3{$><$}p{$>$}In this open-label randomised, two-by-two factorial phase 3 study in 185 institutions in the USA and Canada, we enrolled patients (aged ≥18 years) with unresectable stage III non-small-cell lung cancer, a Zubrod performance status of 0–1, adequate pulmonary function, and no evidence of supraclavicular or contralateral hilar adenopathy. We randomly assigned (1:1:1:1) patients to receive either 60 Gy (standard dose), 74 Gy (high dose), 60 Gy plus cetuximab, or 74 Gy plus cetuximab. All patients also received concurrent chemotherapy with 45 mg/m\textsuperscript{2} paclitaxel and carboplatin once a week (AUC 2); 2 weeks after chemoradiation, two cycles of consolidation chemotherapy separated by 3 weeks were given consisting of paclitaxel (200 mg/m\textsuperscript{2}) and carboplatin (AUC 6). Randomisation was done with permuted block randomisation methods, stratified by radiotherapy technique, Zubrod performance status, use of PET during staging, and histology; treatment group assignments were not masked. Radiation dose was prescribed to the planning target volume and was given in 2 Gy daily fractions with either intensity-modulated radiation therapy or three-dimensional conformal radiation therapy. The use of four-dimensional CT and image-guided radiation therapy were encouraged but not necessary. For patients assigned to receive cetuximab, 400 mg/m\textsuperscript{2} cetuximab was given on day 1 followed by weekly doses of 250 mg/m\textsuperscript{2}, and was continued through consolidation therapy. The primary endpoint was overall survival. All analyses were done by modified intention-to-treat. The study is registered with ClinicalTrials.gov, number NCT00533949.{$<$}/p{$><$}h3{$>$}Findings{$<$}/h3{$><$}p{$>$}Between Nov 27, 2007, and Nov 22, 2011, 166 patients were randomly assigned to receive standard-dose chemoradiotherapy, 121 to high-dose chemoradiotherapy, 147 to standard-dose chemoradiotherapy and cetuximab, and 110 to high-dose chemoradiotherapy and cetuximab. Median follow-up for the radiotherapy comparison was 22·9 months (IQR 27·5–33·3). Median overall survival was 28·7 months (95\% CI 24·1–36·9) for patients who received standard-dose radiotherapy and 20·3 months (17·7–25·0) for those who received high-dose radiotherapy (hazard ratio [HR] 1·38, 95\% CI 1·09–1·76; p=0·004). Median follow-up for the cetuximab comparison was 21·3 months (IQR 23·5–29·8). Median overall survival in patients who received cetuximab was 25·0 months (95\% CI 20·2–30·5) compared with 24·0 months (19·8–28·6) in those who did not (HR 1·07, 95\% CI 0·84–1·35; p=0·29). Both the radiation-dose and cetuximab results crossed protocol-specified futility boundaries. We recorded no statistical differences in grade 3 or worse toxic effects between radiotherapy groups. By contrast, the use of cetuximab was associated with a higher rate of grade 3 or worse toxic effects (205 [86\%] of 237 \emph{vs} 160 [70\%] of 228 patients; p{$<$}0·0001). There were more treatment-related deaths in the high-dose chemoradiotherapy and cetuximab groups (radiotherapy comparison: eight \emph{vs} three patients; cetuximab comparison: ten \emph{vs} five patients). There were no differences in severe pulmonary events between treatment groups. Severe oesophagitis was more common in patients who received high-dose chemoradiotherapy than in those who received standard-dose treatment (43 [21\%] of 207 patients \emph{vs} 16 [7\%] of 217 patients; p{$<$}0·0001).{$<$}/p{$><$}h3{$>$}Interpretation{$<$}/h3{$><$}p{$>$}74 Gy radiation given in 2 Gy fractions with concurrent chemotherapy was not better than 60 Gy plus concurrent chemotherapy for patients with stage III non-small-cell lung cancer, and might be potentially harmful. Addition of cetuximab to concurrent chemoradiation and consolidation treatment provided no benefit in overall survival for these patients.{$<$}/p{$><$}h3{$>$}Funding{$<$}/h3{$><$}p{$>$}National Cancer Institute and Bristol-Myers Squibb.{$<$}/p{$>$}},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\J5QJ6GS2\\Bradley et al. - 2015 - Standard-dose versus high-dose conformal radiother.pdf}
}

@article{Brahme1982,
  title = {Solution of an integral equation encountered in rotation therapy},
  author = {Brahme, A. and Roos, J.-E. and Lax, I.},
  date = {1982-10},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {27},
  number = {10},
  pages = {1221--1229},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/27/10/002},
  url = {https://doi.org/10.1088/0031-9155/27/10/002},
  urldate = {2021-11-30},
  abstract = {An integral equation relating the lateral absorbed dose profile of a photon beam to the resultant absorbed dose distribution during single-turn rotating-beam therapy has been set up and solved for the case of a cylindrical phantom with the axis of rotation coinciding with the axis of symmetry of the cylinder. In the first approximation the results obtained are also valid when the axis of rotation is somewhat off-centred, even in a phantom that deviates from circular symmetry, provided the rotation is performed in both clockwise and counter clockwise directions. The calculated dose profiles indicate that improved dose uniformity can be achieved using a new type of non-linear wedge-shaped filter, which can easily be designed using the derived general analytic solution to the integral equation.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\YIGDGNFG\\Brahme et al. - 1982 - Solution of an integral equation encountered in ro.pdf}
}

@article{Bray2018,
  title = {Global cancer statistics 2018: {{GLOBOCAN}} estimates of incidence and mortality worldwide for 36 cancers in 185 countries},
  shorttitle = {Global cancer statistics 2018},
  author = {Bray, Freddie and Ferlay, Jacques and Soerjomataram, Isabelle and Siegel, Rebecca L. and Torre, Lindsey A. and Jemal, Ahmedin},
  date = {2018-11},
  journaltitle = {CA: A Cancer Journal for Clinicians},
  shortjournal = {CA-Cancer J Clin},
  volume = {68},
  number = {6},
  pages = {394--424},
  issn = {00079235},
  doi = {10.3322/caac.21492},
  url = {http://doi.wiley.com/10.3322/caac.21492},
  urldate = {2019-11-05},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\3Z7Z9LQ5\\Bray et al. - 2018 - Global cancer statistics 2018 GLOBOCAN estimates .pdf}
}

@article{Breedveld2007,
  title = {A novel approach to multi-criteria inverse planning for {{IMRT}}.},
  author = {Breedveld, Sebastiaan and Storchi, Pascal R M and Keijzer, Marleen and Heemink, Arnold W and Heijmen, Ben J M},
  date = {2007-10-21},
  journaltitle = {Physics in medicine and biology},
  volume = {52},
  number = {20},
  eprint = {17921588},
  eprinttype = {pmid},
  pages = {6339--53},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/52/20/016},
  abstract = {Treatment plan optimization is a multi-criteria process. Optimizing solely on one objective or on a sum of a priori weighted objectives may result in inferior treatment plans. Manually adjusting weights or constraints in a trial and error procedure is time consuming. In this paper we introduce a novel multi-criteria optimization approach to automatically optimize treatment constraints (dose-volume and maximum-dose). The algorithm tries to meet these constraints as well as possible, but in the case of conflicts it relaxes lower priority constraints so that higher priority constraints can be met. Afterwards, all constraints are tightened, starting with the highest priority constraints. Applied constraint priority lists can be used as class solutions for patients with similar tumour types. The presented algorithm does iteratively apply an underlying algorithm for beam profile optimization, based on a quadratic objective function with voxel-dependent importance factors. These voxel-dependent importance factors are automatically adjusted to reduce dose-volume and maximum-dose constraint violations.},
  keywords = {Algorithms,Body Burden,Computer Simulation,Humans,Models; Biological,Radiometry,Radiometry: methods,Radiotherapy Dosage,Radiotherapy Planning; Computer-Assisted,Radiotherapy Planning; Computer-Assisted: methods,Radiotherapy; Conformal,Radiotherapy; Conformal: methods,Relative Biological Effectiveness},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\JTEZS4BR\\Breedveld et al. - 2007 - A novel approach to multi-criteria inverse planning for IMRT.pdf}
}

@article{Breedveld2009,
  title = {Equivalence of multi-criteria methods},
  shorttitle = {Phys {{Med Biol}}},
  author = {Breedveld, Sebastiaan and Storchi, Pascal R M and Heijmen, Ben J M},
  date = {2009-12-07},
  journaltitle = {Physics in Medicine \& Biology},
  volume = {54},
  number = {23},
  pages = {7199--7209},
  doi = {10.1088/0031-9155/54/23/011},
  abstract = {Several methods can be used to achieve multi-criteria optimization of radiation therapy treatment planning, which strive for Pareto-optimality. The property of the solution being Pareto optimal is desired, because it guarantees that no criteria can be improved without deteriorating another criteria. The most widely used methods are the weighted-sum method, in which the different treatment objectives are weighted, and constrained optimization methods, in which treatment goals are set and the algorithm has to find the best plan fulfilling these goals. The constrained method used in this paper, the 2p c (2-phase -constraint) method is based on the -constraint method, which generates Pareto-optimal solutions. Both approaches are uniquely related to each other. In this paper, we will show that it is possible to switch from the constrained method to the weighted-sum method by using the Lagrange multipliers from the constrained optimization problem, and vice versa by setting the appropriate constraints. In general, the theory presented in this paper can be useful in cases where a new situation is slightly different from the original situation, e.g. in online treatment planning, with deformations of the volumes of interest, or in automated treatment planning, where changes to the automated plan have to be made. An example of the latter is given where the planner is not satisfied with the result from the constrained method and wishes to decrease the dose in a structure. By using the Lagrange multipliers, a weighted-sum optimization problem is constructed, which generates a Paretooptimal solution in the neighbourhood of the original plan, but fulfills the new treatment objectives.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\T9AHL9JA\\Breedveld et al. - Equivalence of multi-criteria methods.pdf}
}

@article{Breedveld2012,
  title = {{{iCycle}}: {{Integrated}}, multicriterial beam angle, and profile optimization for generation of coplanar and noncoplanar {{IMRT}} plans},
  shorttitle = {{{iCycle}}},
  author = {Breedveld, Sebastiaan and Storchi, Pascal R. M. and Voet, Peter W. J. and Heijmen, Ben J. M.},
  date = {2012},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {39},
  number = {2},
  pages = {951--963},
  issn = {2473-4209},
  doi = {10.1118/1.3676689},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.3676689},
  urldate = {2019-10-25},
  abstract = {Purpose: To introduce iCycle, a novel algorithm for integrated, multicriterial optimization of beam angles, and intensity modulated radiotherapy (IMRT) profiles. Methods: A multicriterial plan optimization with iCycle is based on a prescription calledwish-list, containing hard constraints and objectives with ascribed priorities. Priorities are ordinal parameters used for relative importance ranking of the objectives. The higher an objective priority is, the higher the probability that the corresponding objective will be met. Beam directions are selected from an input set of candidate directions. Input sets can be restricted, e.g., to allow only generation of coplanar plans, or to avoid collisions between patient/couch and the gantry in a noncoplanar setup. Obtaining clinically feasible calculation times was an important design criterium for development of iCycle. This could be realized by sequentially adding beams to the treatment plan in an iterative procedure. Each iteration loop starts with selection of the optimal direction to be added. Then, a Pareto-optimal IMRT plan is generated for the (fixed) beam setup that includes all so far selected directions, using a previously published algorithm for multicriterial optimization of fluence profiles for a fixed beam arrangement Breedveld et al. [Phys. Med. Biol. 54, 7199–7209 (2009)]. To select the next direction, each not yet selected candidate direction is temporarily added to the plan and an optimization problem, derived from the Lagrangian obtained from the just performed optimization for establishing the Pareto-optimal plan, is solved. For each patient, a single one-beam, two-beam, three-beam, etc. Pareto-optimal plan is generated until addition of beams does no longer result in significant plan quality improvement. Plan generation with iCycle is fully automated. Results: Performance and characteristics of iCycle are demonstrated by generating plans for a maxillary sinus case, a cervical cancer patient, and a liver patient treated with SBRT. Plans generated with beam angle optimization did better meet the clinical goals than equiangular or manually selected configurations. For the maxillary sinus and liver cases, significant improvements for noncoplanar setups were seen. The cervix case showed that also in IMRT with coplanar setups, beam angle optimization with iCycle may improve plan quality. Computation times for coplanar plans were around 1–2 h and for noncoplanar plans 4–7 h, depending on the number of beams and the complexity of the site. Conclusions: Integrated beam angle and profile optimization with iCycle may result in significant improvements in treatment plan quality. Due to automation, the plan generation workload is minimal. Clinical application has started.},
  langid = {english},
  keywords = {Anatomy,cancer,Cancer,Computer simulation,Dosimetry,including brachytherapy,Intensity modulated radiation therapy,intensity modulation,iterative methods,Lagrangian mechanics,liver,Liver,Numerical approximation and analysis,optimisation,optimization,Optimization,probability,Probability theory,radiation therapy,Radiation therapy,Therapeutic applications,Tissues,treatment planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\8XH2DJ5E\\Breedveld et al. - 2012 - iCycle Integrated, multicriterial beam angle, and.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\3ZUCARBH\\1.html}
}

@article{Breedveld2017,
  title = {An interior-point implementation developed and tuned for radiation therapy treatment planning},
  author = {Breedveld, Sebastiaan and family=Berg, given=Bas, prefix=van den, useprefix=true and Heijmen, Ben},
  date = {2017-11},
  journaltitle = {Computational Optimization and Applications},
  shortjournal = {Comput Optim Appl},
  volume = {68},
  number = {2},
  pages = {209--242},
  issn = {0926-6003, 1573-2894},
  doi = {10.1007/s10589-017-9919-4},
  url = {http://link.springer.com/10.1007/s10589-017-9919-4},
  urldate = {2020-09-11},
  abstract = {While interior-point methods share the same fundamentals, the implementation determines the actual performance. In order to attain the highest efficiency, different applications may require differently tuned implementations. In this paper we describe an implementation specifically designed for optimisation in radiation therapy. These problems are large-scale nonlinear (and sometimes nonconvex) constrained optimisation problems, consisting of both sparse and dense data. Several applicationspecific properties are exploited to enhance efficiency. Permuting, tiling and mixed precision arithmetic allow the algorithm to optimally process the mixed dense and sparse data matrices (making this step 2.2 times faster, and overall runtime reduction of 55\%) and scalability (16 threads resulted in a speed-up factor of 9.8 compared to singlethreaded performance, against a speed-up factor of 7.7 for the less optimised implementation). Predefined cost-functions are hard-coded and the computationally expensive second derivatives are written in canonical form, and combined if multiple cost-functions are defined for the same clinical structure. The derivatives are then computed using a scaled matrix–matrix product. A cheap initialisation strategy based on the background knowledge reduces the number of iterations by 11\%. We also propose a novel combined Mehrotra–Gondzio approach. The algorithm is extensively tested on a dataset consisting of 120 patients, distributed over 6 tumour sites/approaches. This test dataset is made publicly available.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\EJWIE5LE\\Breedveld et al. - 2017 - An interior-point implementation developed and tun.pdf}
}

@article{Breedveld2017a,
  title = {Data for {{TROTS}} – {{The Radiotherapy Optimisation Test Set}}},
  author = {Breedveld, Sebastiaan and Heijmen, Ben},
  date = {2017-06},
  journaltitle = {Data in Brief},
  shortjournal = {Data in Brief},
  volume = {12},
  pages = {143--149},
  issn = {23523409},
  doi = {10.1016/j.dib.2017.03.037},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2352340917301130},
  urldate = {2022-02-18},
  abstract = {The Radiotherapy Optimisation Test Set (TROTS) is an extensive set of problems originating from radiotherapy (radiation therapy) treatment planning. This dataset is created for 2 purposes: (1) to supply a large-scale dense dataset to measure performance and quality of mathematical solvers, and (2) to supply a dataset to investigate the multi-criteria optimisation and decision-making nature of the radiotherapy problem. The dataset contains 120 problems (patients), divided over 6 different treatment protocols/ tumour types. Each problem contains numerical data, a configuration for the optimisation problem, and data required to visualise and interpret the results. The data is stored as HDF5 compatible Matlab files, and includes scripts to work with the dataset.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\HE3XXDQE\\Breedveld und Heijmen - 2017 - Data for TROTS – The Radiotherapy Optimisation Tes.pdf}
}

@article{Brooke2020,
  title = {Dynamic string-averaging {{CQ-methods}} for the split feasibility problem with percentage violation constraints arising in radiation therapy treatment planning},
  author = {Brooke, Mark and Censor, Yair and Gibali, Aviv},
  date = {2020},
  journaltitle = {International Transactions in Operational Research},
  issn = {1475-3995},
  doi = {10.1111/itor.12929},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/itor.12929},
  urldate = {2021-11-30},
  abstract = {We study a feasibility-seeking problem with percentage violation constraints (PVCs). These are additional constraints that are appended to an existing family of constraints, which single out certain subsets of the existing constraints and declare that up to a specified fraction of the number of constraints in each subset is allowed to be violated by up to a specified percentage of the existing bounds. Our motivation to investigate problems with PVCs comes from the field of radiation therapy treatment planning (RTTP) wherein the fully discretized inverse planning problem is formulated as a split feasibility problem and the PVCs give rise to nonconvex constraints. Following the CQ algorithm of Byrne (2002, Inverse Problems, Vol. 18, pp. 441–53), we develop a string-averaging CQ-method that uses only projections onto the individual sets that are half-spaces represented by linear inequalities. The question of extending our theoretical results to the nonconvex sets case is still open. We describe how our results apply to RTTP and provide a numerical example.},
  langid = {english},
  keywords = {common fixed points,CQ-algorithm,cutter operator,dose-volume constraints,percentage violation constraints,radiation therapy treatment planning,split feasibility,string-averaging},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/itor.12929},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\MRSGF28P\\Brooke et al. - Dynamic string-averaging CQ-methods for the split .pdf;C\:\\Users\\Niklas\\Zotero\\storage\\RNQKAM6Y\\itor.html}
}

@article{Buettner2012,
  title = {Novel approaches to improve the therapeutic index of head and neck radiotherapy: {{An}} analysis of data from the {{PARSPORT}} randomised phase {{III}} trial},
  shorttitle = {Novel approaches to improve the therapeutic index of head and neck radiotherapy},
  author = {Buettner, Florian and Miah, Aisha B. and Gulliford, Sarah L. and Hall, Emma and Harrington, Kevin J. and Webb, Steve and Partridge, Mike and Nutting, Christopher M.},
  date = {2012-04},
  journaltitle = {Radiotherapy and Oncology},
  shortjournal = {Radiotherapy and Oncology},
  volume = {103},
  number = {1},
  pages = {82--87},
  issn = {01678140},
  doi = {10.1016/j.radonc.2012.02.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167814012000667},
  urldate = {2021-08-03},
  abstract = {Purpose: Subjective xerostomia is a common side-effect following radiotherapy for the treatment of head-and-neck cancer. Standard mean dose models previously used to model xerostomia only that partially predict the occurrence of xerostomia. Studies in animal models have suggested that there are regional variations in the radiosensitivity of the parotid glands. In this work we tested the hypothesis that this is also true for the human parotid gland. Methods: We present novel dose–response models explicitly taking the spatial distribution of the radiation dose into account. We considered dose to the submandibular gland and other clinical factors and used a variable-selection algorithm to select the best dose–response model. This methodology was applied to 63 head and neck cancer patients and validated using two independent patient cohorts of 19 and 29 patients, respectively. Results: The predictive accuracy of dose–response models improved significantly when including regional variations of radiosensitivity of the parotid glands compared to standard mean-dose models (p = 0.001, t-test). Beneficial dose-pattern analysis demonstrated the importance of minimising dose to the lateral and cranial component of the human parotid gland in order to avoid xerostomia. Furthermore we found an evidence that surgical removal of the sub-mandibular gland significantly increases the risk of radiation-induced xerostomia. Conclusion: Dose–response models which take the shape of the dose-distribution into account predicted xerostomia significantly better than standard mean-dose models. Our novel model could be used to rank potential treatment plans more reliably according to their therapeutic index and may be useful to generate better treatment plans.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\8AUYVWXE\\Buettner et al. - 2012 - Novel approaches to improve the therapeutic index .pdf}
}

@article{Bungartz2004,
  ids = {Gertsner2008},
  title = {Sparse grids},
  author = {Bungartz, Hans\_Joachim and Griebel, Michael},
  date = {2004},
  journaltitle = {Acta Numerica},
  volume = {13},
  pages = {147--270},
  issn = {09624929},
  doi = {10.1017/S0962492904000182},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\BMLR3DPK\\Bungartz, Griebel - 2004 - Sparse grids.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\TJCSK3WP\\Gertsner, Griebel - 2008 - Sparse grids (Quantitative Finance).pdf}
}

@article{Burigo2019,
  title = {Simultaneous optimization of {{RBE-weighted}} dose and nanometric ionization distributions in treatment planning with carbon ions},
  author = {Burigo, Lucas N. and Ramos-Méndez, José and Bangert, Mark and Schulte, Reinhard W. and Faddegon, Bruce},
  date = {2019-01},
  journaltitle = {Physics in Medicine \& Biology},
  shortjournal = {Phys Med Biol},
  volume = {64},
  number = {1},
  pages = {015015},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/aaf400},
  url = {https://doi.org/10.1088%2F1361-6560%2Faaf400},
  urldate = {2019-10-25},
  abstract = {Inverse treatment planning in intensity modulated particle therapy (IMPT) with scanned carbon–ion beams is currently based on the optimization of RBE-weighted dose to satisfy requirements of target coverage and limited toxicity to organs-at-risk (OARs) and healthy tissues. There are many feasible IMPT plans that meet these requirements, which allows the introduction of further criteria to narrow the selection of a biologically optimal treatment plan. We propose a novel treatment planning strategy based on the simultaneous optimization of RBE-weighted dose and nanometric ionization details (ID) as a new physical characteristic of the delivered plan beyond LET. In particular, we focus on the distribution of large ionization clusters (more than 3 ionizations) to enhance the biological effect across the target volume while minimizing biological effect in normal tissues. Carbon–ion treatment plans for different patient geometries and beam configurations generated with the simultaneous optimization strategy were compared against reference plans obtained with RBE-weighted dose optimization alone. Quality indicators, inhomogeneity index and planning volume histograms of RBE-weighted dose and large ionization clusters were used to evaluate the treatment plans. We show that with simultaneous optimization, ID distributions can be optimized in carbon–ion radiotherapy without compromising the RBE-weighted dose distributions. This strategy can potentially be used to account for optimization of endpoints closely related to radiation quality to achieve better tumor control and reduce risks of complications.},
  langid = {english},
  keywords = {matRadGrant},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\QYB6FN4W\\Burigo et al. - 2019 - Simultaneous optimization of RBE-weighted dose and.pdf}
}

@article{Burnet2004,
  title = {Defining the tumour and target volumes for radiotherapy.},
  author = {Burnet, Neil G and Thomas, Simon J and Burton, Kate E and Jefferies, Sarah J},
  date = {2004-01},
  journaltitle = {Cancer imaging : the official publication of the International Cancer Imaging Society},
  volume = {4},
  number = {2},
  eprint = {18250025},
  eprinttype = {pmid},
  pages = {153--61},
  issn = {1470-7330},
  doi = {10.1102/1470-7330.2004.0054},
  url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1434601&tool=pmcentrez&rendertype=abstract},
  urldate = {2014-01-15},
  abstract = {Radiotherapy is a localised treatment. The definition of tumour and target volumes for radiotherapy is vital to its successful execution. This requires the best possible characterisation of the location and extent of tumour. Diagnostic imaging, including help and advice from diagnostic specialists, is therefore essential for radiotherapy planning. There are three main volumes in radiotherapy planning. The first is the position and extent of gross tumour, i.e. what can be seen, palpated or imaged; this is known as the gross tumour volume (GTV). Developments in imaging have contributed to the definition of the GTV. The second volume contains the GTV, plus a margin for sub-clinical disease spread which therefore cannot be fully imaged; this is known as the clinical target volume (CTV). It is the most difficult because it cannot be accurately defined for an individual patient, but future developments in imaging, especially towards the molecular level, should allow more specific delineation of the CTV. The CTV is important because this volume must be adequately treated to achieve cure. The third volume, the planning target volume (PTV), allows for uncertainties in planning or treatment delivery. It is a geometric concept designed to ensure that the radiotherapy dose is actually delivered to the CTV. Radiotherapy planning must always consider critical normal tissue structures, known as organs at risk (ORs). In some specific circumstances, it is necessary to add a margin analogous to the PTV margin around an OR to ensure that the organ cannot receive a higher-than-safe dose; this gives a planning organ at risk volume. This applies to an organ such as the spinal cord, where damage to a small amount of normal tissue would produce a severe clinical manifestation. The concepts of GTV, CTV and PTV have been enormously helpful in developing modern radiotherapy. Attention to detail in radiotherapy planning is vital, and does affect outcomes: 'the devil is in the detail'. Radiotherapy planning is also dependent on high quality imaging, and the better the imaging the better will be the outcomes from radiotherapy.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\JHSMTKVD\\Burnet et al. - 2004 - Defining the tumour and target volumes for radiotherapy.pdf}
}

@article{Carlsson2006,
  title = {Iterative regularization in intensity-modulated radiation therapy optimization},
  author = {Carlsson, Fredrik and Forsgren, Anders},
  date = {2006},
  journaltitle = {Medical Physics},
  volume = {33},
  number = {1},
  pages = {225--234},
  issn = {2473-4209},
  doi = {10.1118/1.2148918},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1118/1.2148918},
  urldate = {2022-01-11},
  abstract = {A common way to solve intensity-modulated radiation therapy (IMRT) optimization problems is to use a beamlet-based approach. The approach is usually employed in a three-step manner: first a beamlet-weight optimization problem is solved, then the fluence profiles are converted into step-and-shoot segments, and finally postoptimization of the segment weights is performed. A drawback of beamlet-based approaches is that beamlet-weight optimization problems are ill-conditioned and have to be regularized in order to produce smooth fluence profiles that are suitable for conversion. The purpose of this paper is twofold: first, to explain the suitability of solving beamlet-based IMRT problems by a BFGS quasi-Newton sequential quadratic programming method with diagonal initial Hessian estimate, and second, to empirically show that beamlet-weight optimization problems should be solved in relatively few iterations when using this optimization method. The explanation of the suitability is based on viewing the optimization method as an iterative regularization method. In iterative regularization, the optimization problem is solved approximately by iterating long enough to obtain a solution close to the optimal one, but terminating before too much noise occurs. Iterative regularization requires an optimization method that initially proceeds in smooth directions and makes rapid initial progress. Solving ten beamlet-based IMRT problems with dose-volume objectives and bounds on the beamlet-weights, we find that the considered optimization method fulfills the requirements for performing iterative regularization. After segment-weight optimization, the treatments obtained using 35 beamlet-weight iterations outperform the treatments obtained using 100 beamlet-weight iterations, both in terms of objective value and of target uniformity. We conclude that iterating too long may in fact deteriorate the quality of the deliverable plan.},
  langid = {english},
  keywords = {conjugate gradient method,conjugate gradient methods,Eigenvalues,Hessian matrices,Image reconstruction,Intensity modulated radiation therapy,intensity modulation,intensity-modulated radiation therapy,Iteration theory,iterative methods,iterative regularization,Matrix theory,Medical treatment planning,Newton method,Numerical optimization,Numerical solutions,optimisation,Optimization,quadratic programming,quasi-Newton method,radiation therapy,regularization,Singular values,Solution processes,Treatment strategy,Variational methods},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1118/1.2148918},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\8ML3GJBW\\1.html}
}

@book{Casella2002,
  title = {Statistical {{Inference}}},
  author = {Casella, George and Berger, Roger L},
  date = {2002},
  edition = {2},
  publisher = {{Duxbury}},
  location = {{Pacific Grove, CA}},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\PKR3Y877\\Casella, Berger - 2002 - Statistical Inference.pdf}
}

@article{Casiraghi2013a,
  title = {Advantages and limitations of the 'worst case scenario' approach in {{IMPT}} treatment planning.},
  author = {Casiraghi, M and Albertini, F and Lomax, Antony John},
  date = {2013-03-07},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {58},
  number = {5},
  eprint = {23391569},
  eprinttype = {pmid},
  pages = {1323--1339},
  publisher = {{IOP Publishing}},
  issn = {1361-6560},
  doi = {10.1088/0031-9155/58/5/1323},
  abstract = {The 'worst case scenario' (also known as the minimax approach in optimization terms) is a common approach to model the effect of delivery uncertainties in proton treatment planning. Using the 'dose-error-bar distribution' previously reported by our group as an example, we have investigated in more detail one of the underlying assumptions of this method. That is, the dose distributions calculated for a limited number of worst case patient positioning scenarios (i.e. limited number of shifts sampled on a spherical surface) represent the worst dose distributions that can occur during the patient treatment under setup uncertainties. By uniformly sampling patient shifts from anywhere within a spherical error-space, a number of treatment scenarios have been simulated and dose deviations from the nominal dose distribution have been computed. The dose errors from these simulations (comprehensive approach) have then been compared to the dose-error-bar approach previously reported (surface approximation) using both point-by-point and dose- and error-volume-histogram analysis (DVH/EVHs). This comparison has been performed for two different clinical cases treated using intensity modulated proton therapy (IMPT): a skull-base and a spinal-axis tumor. Point-by-point evaluation shows that the surface approximation leads to a correct estimation (95\% accuracy) of the potential dose errors for the 96\% and 85\% of the irradiated voxels, for the two investigated cases respectively. We also found that the voxels for which the surface approximation fails are generally localized close to sharp soft tissue-bone interfaces and air cavities. Moreover, analysis of EVHs and DVHs for the two cases shows that the percentage of voxels of a given volume of interest potentially affected by a certain maximum dose error is correctly estimated using the surface approximation and that this approach also accurately predicts the upper and lower bounds of the DVH curves that can occur under positioning uncertainties. In conclusion, the assumption that the larger the patient shift the worse the dose error does not always hold on a point-by-point basis. Nevertheless, when performing a volumetric analysis, a limited set of worst case error scenarios correctly represents the worst quality of the plan in presence of setup errors. As a consequence of these results, we believe that the worst case scenario approach can be used in the IMPT planning procedure for estimating plan robustness provided that the possible limitations of this approach are known.},
  keywords = {Computer-Assisted,Computer-Assisted: methods,Humans,Intensity-Modulated,Intensity-Modulated: methods,Proton Therapy,Proton Therapy: methods,Radiotherapy,Radiotherapy Planning,Skull Base Neoplasms,Skull Base Neoplasms: pathology,Skull Base Neoplasms: radiotherapy,Spinal Neoplasms,Spinal Neoplasms: pathology,Spinal Neoplasms: radiotherapy,Tumor Burden,Tumor Burden: radiation effects},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\QM6FD4D3\\Casiraghi, Albertini, Lomax - 2013 - Advantages and limitations of the 'worst case scenario' approach in IMPT treatment planning.pdf}
}

@article{Cassioli2012,
  title = {Aperture shape optimization for {{IMRT}} treatment planning},
  author = {Cassioli, A. and Unkelbach, J.},
  date = {2012-12},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {58},
  number = {2},
  pages = {301--318},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/58/2/301},
  url = {https://doi.org/10.1088%2F0031-9155%2F58%2F2%2F301},
  urldate = {2019-10-27},
  abstract = {We propose an algorithm for aperture shape optimization (ASO) for step and shoot delivery of intensity-modulated radiotherapy. The method is an approach to direct aperture optimization (DAO) that exploits gradient information to locally optimize the positions of the leafs of a multileaf collimator. Based on the dose-influence matrix, the dose distribution is locally approximated as a linear function of the leaf positions. Since this approximation is valid only in a small interval around the current leaf positions, we use a trust-region-like method to optimize the leaf positions: in one iteration, the leaf motion is confined to the beamlets where the leaf edges are currently positioned. This yields a well-behaved optimization problem for the leaf positions and the aperture weights, which can be solved efficiently. If, in one iteration, a leaf is moved to the edge of a beamlet, the leaf motion can be confined to the neighboring beamlet in the next iteration. This allows for large leaf position changes over the course of the algorithm. In this paper, the ASO algorithm is embedded into a column-generation approach to DAO. After a new aperture is added to the treatment plan, we use the ASO algorithm to simultaneously optimize aperture weights and leaf positions for the new set of apertures. We present results for a paraspinal tumor case, a prostate case and a head and neck case. The computational results indicate that, using this approach, treatment plans close to the ideal fluence map optimization solution can be obtained.},
  langid = {english}
}

@book{Cegielski2012,
  title = {Iterative {{Methods}} for {{Fixed Point Problems}} in {{Hilbert Spaces}}},
  author = {Cegielski, Andrzej},
  date = {2012-09-13},
  publisher = {{Springer}},
  location = {{New York}},
  isbn = {978-3-642-30900-7},
  langid = {english},
  pagetotal = {316}
}

@inproceedings{Censor1987,
  title = {On the fully discretized model for the inverse problem of radiation therapy treatment planning},
  booktitle = {Proceedings of the thirteenth annual northeast bioengineering conference},
  author = {Censor, Yair and Powlis, William D. and Altschuler, Martin D.},
  date = {1987},
  volume = {1},
  pages = {211--214},
  publisher = {{Institute of Electrical and Electronics Engineers}},
  location = {{New York, NY, USA}}
}

@article{Censor1988,
  title = {A computational solution of the inverse problem in radiation-therapy treatment planning},
  author = {Censor, Yair and Altschuler, Martin D. and Powlis, William D.},
  date = {1988-01-01},
  journaltitle = {Applied Mathematics and Computation},
  shortjournal = {Applied Mathematics and Computation},
  volume = {25},
  number = {1},
  pages = {57--87},
  issn = {0096-3003},
  doi = {10.1016/0096-3003(88)90064-1},
  url = {http://www.sciencedirect.com/science/article/pii/0096300388900641},
  urldate = {2020-09-11},
  abstract = {Radiation therapy concerns the delivery of the proper dose of radiation to a tumor volume without causing irreparable damage to healthy tissue and critical organs. The forward problem refers to calculating the dose distribution that would be delivered to a measured patient cross-section when the radiation field generated by the beam sources is specified. The inverse problem refers to calculating the radiation field that will provide a specified dose distribution in the patient. The forward and inverse problems of radiation-therapy treatment planning are first formulated in their continuous versions, and the point is made that, in this field of application, the inverse problem calls for the inversion of an operator for which no analytic closed-form mathematical representation exists. To attack the inverse problem under such circumstances, a discretized model is set up in which both patient section and radiation field are finely discretized. This leads to a linear feasibility problem, which is solved by a relaxation method. The paper includes full details of this new approach, with discussion of technical aspects such as dose apportionment, software development, and experimental results. Consequences and limitations as well as a precise comparison with other methodologies are also discussed.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\2CG9YSI9\\0096300388900641.html}
}

@article{Censor1988a,
  title = {On the use of {{Cimmino}}'s simultaneous projections method for computing a solution of the inverse problem in radiation therapy treatment planning},
  author = {Censor, Y. and Altschuler, M. D. and Powlis, W. D.},
  date = {1988-08},
  journaltitle = {Inverse Problems},
  shortjournal = {Inverse Problems},
  volume = {4},
  number = {3},
  pages = {607--623},
  publisher = {{IOP Publishing}},
  issn = {0266-5611},
  doi = {10.1088/0266-5611/4/3/006},
  url = {https://doi.org/10.1088/0266-5611/4/3/006},
  urldate = {2021-11-30},
  abstract = {In radiation therapy one is confronted with the task of formulating a treatment plan which delivers a specified dose to a tumour but avoids irreparable damage to surrounding uninvolved structures. Radiation therapy treatment planning (RTTP) involves an inverse and a forward problem. The inverse problem is to devise a treatment plan, i.e. a radiation beam configuration and beam weighting, which provides a specified dose distribution to the delineated region. The forward problem is to calculate the dose distribution within the patient that results from the weighted radiation beam configuration. Since no analytic closed-form mathematical formulation of the forward operator exists, the inverse problem actually calls for computerised inversion of data. This inversion is achieved by constructing a fully discretised model that leads to a system of linear inequalities. These inequalities are solved either by a row-action method or a block-Cimmino algorithm which allows the assignment of weights within each block of inequalities.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\RXLIX9IG\\Censor et al. - 1988 - On the use of Cimmino's simultaneous projections m.pdf}
}

@book{Censor1998,
  title = {Parallel {{Optimization}}: {{Theory}}, {{Algorithms}}, and {{Applications}}},
  shorttitle = {Parallel {{Optimization}}},
  author = {Censor, Yair and Zenios, Stavros A.},
  date = {1998},
  series = {Numerical {{Mathematics}} and {{Scientific Computation}}},
  publisher = {{Oxford University Press}},
  location = {{New York, NY, USA}},
  isbn = {978-0-19-510062-4}
}

@incollection{Censor1999,
  title = {Mathematical {{Aspects}} of {{Radiation Therapy Treatment Planning}}: {{Continuous Inversion Versus Full Discretization}} and {{Optimization Versus Feasibility}}},
  shorttitle = {Mathematical {{Aspects}} of {{Radiation Therapy Treatment Planning}}},
  booktitle = {Computational {{Radiology}} and {{Imaging}}: {{Therapy}} and {{Diagnostics}}},
  author = {Censor, Yair},
  editor = {Börgers, Christoph and Natterer, Frank},
  date = {1999},
  series = {The {{IMA Volumes}} in {{Mathematics}} and its {{Applications}}},
  pages = {101--112},
  publisher = {{Springer}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4612-1550-9_6},
  url = {https://doi.org/10.1007/978-1-4612-1550-9_6},
  urldate = {2021-11-30},
  abstract = {A mathematical formulation of the radiation therapy problem consists of a pair of forward and inverse problems. The inverse problem is to determine external radiation beams, along with their locations, profiles, and intensities, that will provide a given dose distribution within the irradiated object. We discuss the inverse problem in its fully discretized formulation.},
  isbn = {978-1-4612-1550-9},
  langid = {english}
}

@incollection{Censor2003,
  title = {Mathematical {{Optimization For The Inverse Problem Of Intensity-Modulated Radiation Therapy}}},
  booktitle = {Intensity-{{Modulated Radiation Therapy}}: {{The State}} of {{The Art}}},
  author = {Censor, Yair},
  editor = {Palta, Jatinder R. and Mackie, Thomas R.},
  date = {2003},
  series = {American {{Association}} of {{Physicists}} in {{Medicine}}},
  number = {Medical Physics Monograph No. 29},
  pages = {25--49},
  publisher = {{Medical Physics Publishing}},
  location = {{Madison, Wisconsin, USA}},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\NM7764C2\\Censor - Mathematical Optimization For The Inverse Problem .pdf}
}

@article{Censor2006,
  title = {A unified approach for inversion problems in intensity-modulated radiation therapy},
  author = {Censor, Yair and Bortfeld, Thomas and Martin, Benjamin and Trofimov, Alexei},
  date = {2006-04},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {51},
  number = {10},
  pages = {2353--2365},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/51/10/001},
  url = {https://doi.org/10.1088/0031-9155/51/10/001},
  urldate = {2021-11-30},
  abstract = {We propose and study a unified model for handling dose constraints (physical dose, equivalent uniform dose (EUD), etc) and radiation source constraints in a single mathematical framework based on the split feasibility problem. The model does not impose on the constraints an exogenous objective (merit) function. The optimization algorithm minimizes a weighted proximity function that measures the sum of the squares of the distances to the constraint sets. This guarantees convergence to a feasible solution point if the split feasibility problem is consistent (i.e., has a solution), or, otherwise, convergence to a solution that minimally violates the physical dose constraints and EUD constraints. We present computational results that demonstrate the validity of the model and the power of the proposed algorithmic scheme.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\75SQAC39\\Censor et al. - 2006 - A unified approach for inversion problems in inten.pdf}
}

@article{Censor2010,
  title = {Perturbation {{Resilience}} and {{Superiorization}} of {{Iterative Algorithms}}},
  author = {Censor, Y and Davidi, R and Herman, G T},
  date = {2010-06-01},
  journaltitle = {Inverse problems},
  shortjournal = {Inverse Probl},
  volume = {26},
  number = {6},
  eprint = {20613969},
  eprinttype = {pmid},
  pages = {65008},
  issn = {0266-5611},
  doi = {10.1088/0266-5611/26/6/065008},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2897099/},
  urldate = {2021-12-01},
  abstract = {Iterative algorithms aimed at solving some problems are discussed. For certain problems, such as finding a common point in the intersection of a finite number of convex sets, there often exist iterative algorithms that impose very little demand on computer resources. For other problems, such as finding that point in the intersection at which the value of a given function is optimal, algorithms tend to need more computer memory and longer execution time. A methodology is presented whose aim is to produce automatically for an iterative algorithm of the first kind a “superiorized version” of it that retains its computational efficiency but nevertheless goes a long way towards solving an optimization problem. This is possible to do if the original algorithm is “perturbation resilient,” which is shown to be the case for various projection algorithms for solving the consistent convex feasibility problem. The superiorized versions of such algorithms use perturbations that steer the process in the direction of a superior feasible point, which is not necessarily optimal, with respect to the given function. After presenting these intuitive ideas in a precise mathematical form, they are illustrated in image reconstruction from projections for two different projection algorithms superiorized for the function whose value is the total variation of the image.},
  pmcid = {PMC2897099},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\PWPJ49P4\\Censor et al. - 2010 - Perturbation Resilience and Superiorization of Ite.pdf}
}

@article{Censor2012,
  title = {From analytic inversion to contemporary {{IMRT}} optimization: {{Radiation}} therapy planning revisited from a mathematical perspective},
  shorttitle = {From analytic inversion to contemporary {{IMRT}} optimization},
  author = {Censor, Yair and Unkelbach, Jan},
  date = {2012-04-01},
  journaltitle = {Physica Medica},
  shortjournal = {Physica Medica},
  volume = {28},
  number = {2},
  pages = {109--118},
  issn = {1120-1797},
  doi = {10.1016/j.ejmp.2011.04.002},
  url = {https://www.sciencedirect.com/science/article/pii/S1120179711000287},
  urldate = {2021-11-30},
  abstract = {In this paper we look at the development of radiation therapy treatment planning from a mathematical point of view. Historically, planning for Intensity-Modulated Radiation Therapy (IMRT) has been considered as an inverse problem. We discuss first the two fundamental approaches that have been investigated to solve this inverse problem: Continuous analytic inversion techniques on one hand, and fully-discretized algebraic methods on the other hand. In the second part of the paper, we review another fundamental question which has been subject to debate from the beginning of IMRT until the present day: The rotation therapy approach versus fixed angle IMRT. This builds a bridge from historic work on IMRT planning to contemporary research in the context of Intensity-Modulated Arc Therapy (IMAT).},
  langid = {english},
  keywords = {Algebraic inverse planning,IMRT,Inverse problem,Radiation therapy treatment planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\FBUMRDFE\\Censor und Unkelbach - 2012 - From analytic inversion to contemporary IMRT optim.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\M4J3GKC2\\S1120179711000287.html}
}

@article{Censor2012a,
  title = {On the effectiveness of projection methods for convex feasibility problems with linear inequality constraints},
  author = {Censor, Yair and Chen, Wei and Combettes, Patrick L. and Davidi, Ran and Herman, Gabor T.},
  date = {2012-04-01},
  journaltitle = {Computational Optimization and Applications},
  shortjournal = {Comput Optim Appl},
  volume = {51},
  number = {3},
  pages = {1065--1088},
  issn = {1573-2894},
  doi = {10.1007/s10589-011-9401-7},
  url = {https://doi.org/10.1007/s10589-011-9401-7},
  urldate = {2021-11-30},
  abstract = {The effectiveness of projection methods for solving systems of linear inequalities is investigated. It is shown that they often have a computational advantage over alternatives that have been proposed for solving the same problem and that this makes them successful in many real-world applications. This is supported by experimental evidence provided in this paper on problems of various sizes (up to tens of thousands of unknowns satisfying up to hundreds of thousands of constraints) and by a discussion of the demonstrated efficacy of projection methods in numerous scientific publications and commercial patents (dealing with problems that can have over a billion unknowns and a similar number of constraints).},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\AL5X5D7R\\Censor et al. - 2012 - On the effectiveness of projection methods for con.pdf}
}

@article{Censor2012b,
  title = {On the effectiveness of projection methods for convex feasibility problems with linear inequality constraints},
  author = {Censor, Yair and Chen, Wei and Combettes, Patrick L. and Davidi, Ran and Herman, Gabor T.},
  date = {2012-04-01},
  journaltitle = {Computational Optimization and Applications},
  shortjournal = {Comput Optim Appl},
  volume = {51},
  number = {3},
  pages = {1065--1088},
  issn = {1573-2894},
  doi = {10.1007/s10589-011-9401-7},
  url = {https://doi.org/10.1007/s10589-011-9401-7},
  urldate = {2021-12-01},
  abstract = {The effectiveness of projection methods for solving systems of linear inequalities is investigated. It is shown that they often have a computational advantage over alternatives that have been proposed for solving the same problem and that this makes them successful in many real-world applications. This is supported by experimental evidence provided in this paper on problems of various sizes (up to tens of thousands of unknowns satisfying up to hundreds of thousands of constraints) and by a discussion of the demonstrated efficacy of projection methods in numerous scientific publications and commercial patents (dealing with problems that can have over a billion unknowns and a similar number of constraints).},
  langid = {english}
}

@article{Censor2013,
  title = {Convergence and perturbation resilience of dynamic string-averaging projection methods},
  author = {Censor, Yair and Zaslavski, Alexander J.},
  date = {2013-01-01},
  journaltitle = {Computational Optimization and Applications},
  shortjournal = {Comput Optim Appl},
  volume = {54},
  number = {1},
  pages = {65--76},
  issn = {1573-2894},
  doi = {10.1007/s10589-012-9491-x},
  url = {https://doi.org/10.1007/s10589-012-9491-x},
  urldate = {2021-11-30},
  abstract = {We consider the convex feasibility problem (CFP) in Hilbert space and concentrate on the study of string-averaging projection (SAP) methods for the CFP, analyzing their convergence and their perturbation resilience. In the past, SAP methods were formulated with a single predetermined set of strings and a single predetermined set of weights. Here we extend the scope of the family of SAP methods to allow iteration-index-dependent variable strings and weights and term such methods dynamic string-averaging projection (DSAP) methods. The bounded perturbation resilience of DSAP methods is relevant and important for their possible use in the framework of the recently developed superiorization heuristic methodology for constrained minimization problems.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\TGYJ5BM6\\Censor und Zaslavski - 2013 - Convergence and perturbation resilience of dynamic.pdf}
}

@article{Censor2014,
  title = {Projected {{Subgradient Minimization Versus Superiorization}}},
  author = {Censor, Yair and Davidi, Ran and Herman, Gabor T. and Schulte, Reinhard W. and Tetruashvili, Luba},
  date = {2014-03-01},
  journaltitle = {Journal of Optimization Theory and Applications},
  shortjournal = {J Optim Theory Appl},
  volume = {160},
  number = {3},
  pages = {730--747},
  issn = {1573-2878},
  doi = {10.1007/s10957-013-0408-3},
  url = {https://doi.org/10.1007/s10957-013-0408-3},
  urldate = {2021-12-01},
  abstract = {The projected subgradient method for constrained minimization repeatedly interlaces subgradient steps for the objective function with projections onto the feasible region, which is the intersection of closed and convex constraints sets, to regain feasibility. The latter poses a computational difficulty, and, therefore, the projected subgradient method is applicable only when the feasible region is “simple to project onto.” In contrast to this, in the superiorization methodology a feasibility-seeking algorithm leads the overall process, and objective function steps are interlaced into it. This makes a difference because the feasibility-seeking algorithm employs projections onto the individual constraints sets and not onto the entire feasible region.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\8UJV69Y6\\Censor et al. - 2014 - Projected Subgradient Minimization Versus Superior.pdf}
}

@article{Censor2014a,
  title = {String-averaging projected subgradient methods for constrained minimization},
  author = {Censor, Yair and Zaslavski, Alexander J.},
  date = {2014-05-04},
  journaltitle = {Optimization Methods and Software},
  volume = {29},
  number = {3},
  pages = {658--670},
  publisher = {{Taylor \& Francis}},
  issn = {1055-6788},
  doi = {10.1080/10556788.2013.841693},
  url = {https://doi.org/10.1080/10556788.2013.841693},
  urldate = {2021-12-01},
  abstract = {We consider constrained minimization problems and propose to replace the projection onto the entire feasible region, required in the projected subgradient method, by projections onto the individual sets whose intersection forms the entire feasible region. Specifically, we propose to perform such projections onto the individual sets in an algorithmic regime of a feasibility-seeking iterative projection method. For this purpose we use the recently developed family of dynamic string-averaging projection methods wherein iteration-index-dependent variable strings and variable weights are permitted. This gives rise to an algorithmic scheme that generalizes, from the algorithmic structural point of view, earlier work of Helou Neto and De Pierro, of Nedić, of Nurminski, and of Ram et al.},
  keywords = {65K10,90C25,fixed point,Hilbert space,metric projection,non-expansive operator,projected subgradient minimization,string-averaging projection methods,variable strings,variable weights},
  annotation = {\_eprint: https://doi.org/10.1080/10556788.2013.841693},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\MDXD29WM\\Censor und Zaslavski - 2014 - String-averaging projected subgradient methods for.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\UFBFN85I\\10556788.2013.html}
}

@article{Censor2015,
  title = {Weak and Strong Superiorization: Between Feasibility-Seeking and Minimization},
  shorttitle = {Weak and Strong Superiorization},
  author = {Censor, Yair},
  date = {2015-11-01},
  journaltitle = {Analele Universitatii "Ovidius" Constanta - Seria Matematica},
  volume = {23},
  number = {3},
  pages = {41--54},
  doi = {10.1515/auom-2015-0046},
  url = {https://sciendo.com/de/article/10.1515/auom-2015-0046},
  urldate = {2021-12-01},
  abstract = {We review the superiorization methodology, which can be thought of, in some cases, as lying between feasibility-seeking and constrained minimization. It is not quite trying to solve the full edged constrained minimization problem; rather, the task is to find a feasible point which is superior (with respect to an objective function value) to one returned by a feasibility-seeking only algorithm. We distinguish between two research directions in the superiorization methodology that nourish from the same general principle: Weak superiorization and strong superiorization and clarify their nature.},
  langid = {ngerman},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\KF7YILKI\\Censor - 2015 - Weak and Strong Superiorization Between Feasibili.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\YUFHGVE7\\auom-2015-0046.html}
}

@article{Censor2015a,
  title = {Projection methods: an annotated bibliography of books and reviews},
  shorttitle = {Projection methods},
  author = {Censor, Yair and Cegielski, Andrzej},
  date = {2015-11-02},
  journaltitle = {Optimization},
  volume = {64},
  number = {11},
  pages = {2343--2358},
  publisher = {{Taylor \& Francis}},
  issn = {0233-1934},
  doi = {10.1080/02331934.2014.957701},
  url = {https://doi.org/10.1080/02331934.2014.957701},
  urldate = {2021-12-01},
  abstract = {Projections onto sets are used in a wide variety of methods in optimization theory but not every method that uses projections really belongs to the class of projection methods as we mean it here. Here, projection methods are iterative algorithms that use projections onto sets while relying on the general principle that when a family of (usually closed and convex) sets is present, then projections (or approximate projections) onto the given individual sets are easier to perform than projections onto other sets (intersections, image sets under some transformation, etc.) that are derived from the given family of individual sets. Projection methods employ projections (or approximate projections) onto convex sets in various ways. They may use different kinds of projections and, sometimes, even use different projections within the same algorithm. They serve to solve a variety of problems which are either of the feasibility or the optimization types. They have different algorithmic structures, of which some are particularly suitable for parallel computing, and they demonstrate nice convergence properties and/or good initial behavioural patterns. This class of algorithms has witnessed great progress in recent years and its member algorithms have been applied with success to many scientific, technological and mathematical problems. This annotated bibliography includes books and review papers on, or related to, projection methods that we know about, use and like. If you know of books or review papers that should be added to this list please contact us.},
  keywords = {65K10,90C25,annotated bibliography,Cimmino,convex feasibility,fixed points,Kaczmarz,projection methods,row-action methods,variational inequalities,von Neumann},
  annotation = {\_eprint: https://doi.org/10.1080/02331934.2014.957701},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\TQIG5KUL\\Censor und Cegielski - 2015 - Projection methods an annotated bibliography of b.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\7N3JJNZ8\\02331934.2014.html}
}

@article{Censor2017,
  title = {Can {{Linear Superiorization Be Useful}} for {{Linear Optimization Problems}}?},
  author = {Censor, Yair},
  date = {2017},
  journaltitle = {Inverse Problems},
  shortjournal = {Inverse Probl},
  volume = {33},
  number = {4},
  eprint = {29335660},
  eprinttype = {pmid},
  pages = {044006},
  issn = {0266-5611},
  doi = {10.1088/1361-6420/33/4/044006},
  abstract = {Linear superiorization considers linear programming problems but instead of attempting to solve them with linear optimization methods it employs perturbation resilient feasibility-seeking algorithms and steers them toward reduced (not necessarily minimal) target function values. The two questions that we set out to explore experimentally are (i) Does linear superiorization provide a feasible point whose linear target function value is lower than that obtained by running the same feasibility-seeking algorithm without superiorization under identical conditions? and (ii) How does linear superiorization fare in comparison with the Simplex method for solving linear programming problems? Based on our computational experiments presented here, the answers to these two questions are: "yes" and "very well", respectively.},
  langid = {english},
  pmcid = {PMC5766045},
  keywords = {Agmon-Motzkin-Schoenberg algorithm,algorithmic operator,bounded perturbation resilience,feasibility-seeking,linear feasibility problem,linear inequalities,linear programming,linear superiorization,Simplex algorithm,Superiorization},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\M6JY5NFB\\Censor - 2017 - Can Linear Superiorization Be Useful for Linear Op.pdf}
}

@unpublished{Censor2018,
  title = {Algorithms and {{Convergence Results}} of {{Projection Methods}} for {{Inconsistent Feasibility Problems}}: {{A Review}}},
  shorttitle = {Algorithms and {{Convergence Results}} of {{Projection Methods}} for {{Inconsistent Feasibility Problems}}},
  author = {Censor, Yair and Zaknoon, Maroun},
  date = {2018-04-26},
  eprint = {1802.07529},
  eprinttype = {arxiv},
  primaryclass = {math},
  url = {http://arxiv.org/abs/1802.07529},
  urldate = {2021-11-30},
  abstract = {The convex feasibility problem (CFP) is to find a feasible point in the intersection of finitely many convex and closed sets. If the intersection is empty then the CFP is inconsistent and a feasible point does not exist. However, algorithmic research of inconsistent CFPs exists and is mainly focused on two directions. One is oriented toward defining other solution concepts that will apply, such as proximity function minimization wherein a proximity function measures in some way the total violation of all constraints. The second direction investigates the behavior of algorithms that are designed to solve a consistent CFP when applied to inconsistent problems. This direction is fueled by situations wherein one lacks a priori information about the consistency or inconsistency of the CFP or does not wish to invest computational resources to get hold of such knowledge prior to running his algorithm. In this paper we bring under one roof and telegraphically review some recent works on inconsistent CFPs.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Optimization and Control},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\8XW2X657\\Censor und Zaknoon - 2018 - Algorithms and Convergence Results of Projection M.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\WX9K3825\\1802.html}
}

@article{Censor2021,
  title = {Developments in {{Mathematical Algorithms}} and {{Computational Tools}} for {{Proton CT}} and {{Particle Therapy Treatment Planning}}},
  author = {Censor, Yair and Schubert, Keith E. and Schulte, Reinhard W.},
  date = {2021},
  journaltitle = {IEEE Transactions on Radiation and Plasma Medical Sciences},
  pages = {1--1},
  issn = {2469-7303},
  doi = {10.1109/TRPMS.2021.3107322},
  abstract = {We summarize recent results and ongoing activities in mathematical algorithms and computer science methods related to proton computed tomography (pCT) and intensity-modulated particle therapy (IMPT) treatment planning. Proton therapy necessitates a high level of delivery accuracy to exploit the selective targeting imparted by the Bragg peak. For this purpose, pCT utilizes the proton beam itself to create images. The technique works by sending a low-intensity beam of protons through the patient and measuring the position, direction, and energy loss of each exiting proton. The pCT technique allows reconstruction of the volumetric distribution of the relative stopping power (RSP) of the patient tissues for use in treatment planning and pre-treatment range verification. We have investigated new ways to make the reconstruction both efficient and accurate. Better accuracy of RSP also enables more robust inverse approaches to IMPT. For IMPT, we developed a framework for performing intensity-modulation of the proton pencil beams. We expect that these developments will lead to additional project work in the years to come, which requires a regular exchange between experts in the fields of mathematics, computer science, and medical physics. We have initiated such an exchange by organizing annual workshops on pCT and IMPT algorithm and technology developments. This report is, admittedly, tilted toward our interdisciplinary work and methods. We offer a comprehensive overview of results, problems, and challenges in pCT and IMPT with the aim of making other scientists wanting to tackle such issues and to strengthen their interdisciplinary collaboration by bringing together cutting-edge know-how from medicine, computer science, physics, and mathematics to bear on medical physics problems at hand.},
  eventtitle = {{{IEEE Transactions}} on {{Radiation}} and {{Plasma Medical Sciences}}},
  keywords = {blob basis functions,data partitioning,digital phantoms,Image reconstruction,intensity-modulated therapy,Inverse problems,Medical treatment,Monte Carlo simulation,motion-adapted reconstruction.,Perturbation methods,Planning,Plasmas,proton computed tomography,proton therapy,Protons,superiorization},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\F3JQIGBZ\\Censor et al. - 2021 - Developments in Mathematical Algorithms and Comput.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\K86QCWPJ\\9521582.html}
}

@article{Cervino2011,
  title = {{{MRI-guided}} tumor tracking in lung cancer radiotherapy.},
  author = {Cervino, Laura I and Du, Jiang and Jiang, Steve B},
  date = {2011-07},
  journaltitle = {Phys Med Biol},
  volume = {56},
  number = {13},
  pages = {3773--3785},
  doi = {10.1088/0031-9155/56/13/003},
  url = {http://dx.doi.org/10.1088/0031-9155/56/13/003},
  abstract = {Precise tracking of lung tumor motion during treatment delivery still represents a challenge in radiation therapy. Prototypes of MRI-linac hybrid systems are being created which have the potential of ionization-free real-time imaging of the tumor. This study evaluates the performance of lung tumor tracking algorithms in cine-MRI sagittal images from five healthy volunteers. Visible vascular structures were used as targets. Volunteers performed several series of regular and irregular breathing. Two tracking algorithms were implemented and evaluated: a template matching (TM) algorithm in combination with surrogate tracking using the diaphragm (surrogate was used when the maximum correlation between the template and the image in the search window was less than specified), and an artificial neural network (ANN) model based on the principal components of a region of interest that encompasses the target motion. The mean tracking error ? and the error at 95\% confidence level e(95) were evaluated for each model. The ANN model led to ? = 1.5 mm and e(95) = 4.2 mm, while TM led to ? = 0.6 mm and e(95) = 1.0 mm. An extra series was considered separately to evaluate the benefit of using surrogate tracking in combination with TM when target out-of-plane motion occurs. For this series, the mean error was 7.2 mm using only TM and 1.7 mm when the surrogate was used in combination with TM. Results show that, as opposed to tracking with other imaging modalities, ANN does not perform well in MR-guided tracking. TM, however, leads to highly accurate tracking. Out-of-plane motion could be addressed by surrogate tracking using the diaphragm, which can be easily identified in the images.},
  keywords = {Algorithms; Diaphragm; Fluoroscopy; Humans; Lung N,Computer-Assisted,diagnosis/physiopathology/radiotherapy; Magnetic,methods; Time Factors}
}

@article{Chan2001,
  title = {The {{Digital TV Filter}} and {{Nonlinear Denoising}}},
  author = {Chan, Tony F and Osher, Stanley and Shen, Jianhong},
  date = {2001},
  journaltitle = {IEEE TRANSACTIONS ON IMAGE PROCESSING},
  volume = {10},
  number = {2},
  pages = {231--241},
  abstract = {—Motivated by the classical TV (total variation) restoration model, we propose a new nonlinear filter—the digital TV filter for denoising and enhancing digital images, or more generally, data living on graphs. The digital TV filter is a data dependent lowpass filter, capable of denoising data without blurring jumps or edges. In iterations, it solves a global total variational (or 1) optimization problem, which differs from most statistical filters. Applications are given in the denoising of one-dimensional (1-D) signals, two-dimensional (2-D) data with irregular structures, gray scale and color images, and nonflat image features such as chromaticity.},
  keywords = {color images,data-dependent,de-noising,digital filters,edge-enhancement,graph,Index Terms—Chromaticity,median filters,nonlinear,restoration,total variation (TV)},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\2YL55ZDR\\Chan, Osher, Shen - 2001 - The Digital TV Filter and Nonlinear Denoising.pdf}
}

@article{Chan2006,
  title = {A robust approach to {{IMRT}} optimization.},
  author = {Chan, Timothy C Y and Bortfeld, Thomas and Tsitsiklis, John N},
  date = {2006},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {51},
  number = {10},
  eprint = {16675870},
  eprinttype = {pmid},
  pages = {2567--2583},
  issn = {00942405},
  doi = {10.1118/1.2240982},
  abstract = {Managing uncertainty is a major challenge in radiation therapy treatment planning, including uncertainty induced by intrafraction motion, which is particularly important for tumours in the thorax and abdomen. Common methods to account for motion are to introduce a margin or to convolve the static dose distribution with a motion probability density function. Unlike previous work in this area, our development does not assume that the patient breathes according to a fixed distribution, nor is the patient required to breathe the same way throughout the treatment. Despite this generality, we create a robust optimization framework starting from the convolution method that is robust to fluctuations in breathing motion, yet spares healthy tissue better than a margin solution. We describe how to generate the data for our model using breathing motion data and we test our model on a computer phantom using data from real patients. In our numerical results, the robust solution delivers approximately 38\% less dose to the healthy tissue than the margin solution, while providing the same level of protection against breathing uncertainty.},
  isbn = {0031-9155 (Print) 0031-9155 (Linking)},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\6MPDC7P5\\Chan, Bortfeld, Tsitsiklis - 2006 - A robust approach to IMRT optimization.pdf}
}

@article{Chan2013,
  title = {Adaptive and robust radiation therapy optimization for lung cancer},
  author = {Chan, Timothy C Y and Mišić, Velibor V.},
  date = {2013},
  journaltitle = {European Journal of Operational Research},
  volume = {231},
  number = {3},
  pages = {745--756},
  issn = {03772217},
  doi = {10.1016/j.ejor.2013.06.003},
  abstract = {A previous approach to robust intensity-modulated radiation therapy (IMRT) treatment planning for moving tumors in the lung involves solving a single planning problem before the start of treatment and using the resulting solution in all of the subsequent treatment sessions. In this paper, we develop an adaptive robust optimization approach to IMRT treatment planning for lung cancer, where information gathered in prior treatment sessions is used to update the uncertainty set and guide the reoptimization of the treatment for the next session. Such an approach allows for the estimate of the uncertain effect to improve as the treatment goes on and represents a generalization of existing robust optimization and adaptive radiation therapy methodologies. Our method is computationally tractable, as it involves solving a sequence of linear optimization problems. We present computational results for a lung cancer patient case and show that using our adaptive robust method, it is possible to attain an improvement over the traditional robust approach in both tumor coverage and organ sparing simultaneously. We also prove that under certain conditions our adaptive robust method is asymptotically optimal, which provides insight into the performance observed in our computational study. The essence of our method - solving a sequence of single-stage robust optimization problems, with the uncertainty set updated each time - can potentially be applied to other problems that involve multi-stage decisions to be made under uncertainty. © 2013 Elsevier B.V. All rights reserved.},
  keywords = {Adaptive radiation therapy,Intensity-modulated radiation therapy,Linear programming,OR in health services,Robust optimization},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\UWVPQTVM\\Chan, Mišić - 2013 - Adaptive and robust radiation therapy optimization for lung cancer.pdf}
}

@article{Chen2010,
  title = {A fast optimization algorithm for multicriteria intensity modulated proton therapy planning: {{Fast}} multicriteria {{IMPT}} planning},
  shorttitle = {A fast optimization algorithm for multicriteria intensity modulated proton therapy planning},
  author = {Chen, Wei and Craft, David and Madden, Thomas M. and Zhang, Kewu and Kooy, Hanne M. and Herman, Gabor T.},
  date = {2010-08-26},
  journaltitle = {Medical Physics},
  shortjournal = {Med. Phys.},
  volume = {37},
  number = {9},
  pages = {4938--4945},
  issn = {00942405},
  doi = {10.1118/1.3481566},
  url = {http://doi.wiley.com/10.1118/1.3481566},
  urldate = {2020-06-09},
  abstract = {Purpose: To describe a fast projection algorithm for optimizing intensity modulated proton therapy ͑IMPT͒ plans and to describe and demonstrate the use of this algorithm in multicriteria IMPT planning. Methods: The authors develop a projection-based solver for a class of convex optimization problems and apply it to IMPT treatment planning. The speed of the solver permits its use in multicriteria optimization, where several optimizations are performed which span the space of possible treatment plans. The authors describe a plan database generation procedure which is customized to the requirements of the solver. The optimality precision of the solver can be specified by the user. Results: The authors apply the algorithm to three clinical cases: A pancreas case, an esophagus case, and a tumor along the rib cage case. Detailed analysis of the pancreas case shows that the algorithm is orders of magnitude faster than industry-standard general purpose algorithms ͑MOSEK’s interior point optimizer, primal simplex optimizer, and dual simplex optimizer͒. Additionally, the projection solver has almost no memory overhead. Conclusions: The speed and guaranteed accuracy of the algorithm make it suitable for use in multicriteria treatment planning, which requires the computation of several diverse treatment plans. Additionally, given the low memory overhead of the algorithm, the method can be extended to include multiple geometric instances and proton range possibilities, for robust optimization. © 2010 American Association of Physicists in Medicine. ͓DOI: 10.1118/1.3481566͔},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\DEU67BYJ\\Chen et al. - 2010 - A fast optimization algorithm for multicriteria in.pdf}
}

@article{Chen2012,
  title = {Including robustness in multi-criteria optimization for intensity-modulated proton therapy},
  author = {Chen, Wei and Unkelbach, Jan and Trofimov, Alexei and Madden, Thomas and Kooy, Hanne and Bortfeld, Thomas and Craft, David},
  date = {2012},
  journaltitle = {Physics in Medicine and Biology},
  volume = {57},
  eprint = {22222720},
  eprinttype = {pmid},
  pages = {591--608},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/57/3/591},
  abstract = {We present a method to include robustness in a multi-criteria optimization (MCO) framework for intensity-modulated proton therapy (IMPT). The approach allows one to simultaneously explore the trade-off between different objectives as well as the trade-off between robustness and nominal plan quality. In MCO, a database of plans each emphasizing different treatment planning objectives, is pre-computed to approximate the Pareto surface. An IMPT treatment plan that strikes the best balance between the different objectives can be selected by navigating on the Pareto surface. In our approach, robustness is integrated into MCO by adding robustified objectives and constraints to the MCO problem. Uncertainties (or errors) of the robust problem are modeled by pre-calculated dose-influence matrices for a nominal scenario and a number of pre-defined error scenarios (shifted patient positions, proton beam undershoot and overshoot). Objectives and constraints can be defined for the nominal scenario, thus characterizing nominal plan quality. A robustified objective represents the worst objective function value that can be realized for any of the error scenarios and thus provides a measure of plan robustness. The optimization method is based on a linear projection solver and is capable of handling large problem sizes resulting from a fine dose grid resolution, many scenarios, and a large number of proton pencil beams. A base-of-skull case is used to demonstrate the robust optimization method. It is demonstrated that the robust optimization method reduces the sensitivity of the treatment plan to setup and range errors to a degree that is not achieved by a safety margin approach. A chordoma case is analyzed in more detail to demonstrate the involved trade-offs between target underdose and brainstem sparing as well as robustness and nominal plan quality. The latter illustrates the advantage of MCO in the context of robust planning. For all cases examined, the robust optimization for each Pareto optimal plan takes less than 5 min on a standard computer, making a computationally friendly interface possible to the planner. In conclusion, the uncertainty pertinent to the IMPT procedure can be reduced during treatment planning by optimizing plans that emphasize different treatment objectives, including robustness, and then interactively seeking for a most-preferred one from the solution Pareto surface.},
  archiveprefix = {arXiv},
  isbn = {1361-6560 (Electronic)\textbackslash r0031-9155 (Linking)},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\JKTKEAQH\\Chen et al. - 2012 - Including robustness in multi-criteria optimization for intensity-modulated proton therapy.pdf}
}

@article{Chen2014,
  title = {Selection and order statistics from correlated normal random variables},
  author = {Chen, E Jack},
  date = {2014-12-11},
  journaltitle = {Discrete Event Dynamic Systems},
  volume = {24},
  number = {4},
  pages = {659--668},
  issn = {0924-6703},
  doi = {10.1007/s10626-013-0180-4},
  url = {http://link.springer.com/10.1007/s10626-013-0180-4},
  urldate = {2018-04-29},
  abstract = {This paper investigates order statistics from correlated normal random variables and its application, namely, ranking and selection. We propose a new approach to estimate the percentage points (quantiles) of the correlated normal distributions. The new approach is flexible and can be used to estimate the critical constants for the problem at hand, even when the correlations are unknown or unequal. An experimental performance evaluation demonstrates the validity and efficiency of the procedures.},
  keywords = {Order statistics,Ranking and selection ·,Simulation ·},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\JC4GHII3\\Chen - 2014 - Selection and order statistics from correlated normal random variables.pdf}
}

@article{Chen2019,
  title = {Early stage non-small cell lung cancer treated with pencil beam scanning particle therapy: retrospective analysis of early results on safety and efficacy},
  shorttitle = {Early stage non-small cell lung cancer treated with pencil beam scanning particle therapy},
  author = {Chen, Jian and Lu, Jiade J. and Ma, Ningyi and Zhao, Jingfang and Chen, Chang and Fan, Min and Jiang, Guoliang and Mao, Jingfang},
  date = {2019-01-25},
  journaltitle = {Radiation Oncology},
  shortjournal = {Radiation Oncology},
  volume = {14},
  number = {1},
  pages = {16},
  issn = {1748-717X},
  doi = {10.1186/s13014-019-1216-1},
  url = {https://doi.org/10.1186/s13014-019-1216-1},
  urldate = {2020-04-03},
  abstract = {To evaluate the safety and efficacy of particle therapy (PT) using pencil beam scanning (PBS) technique for early stage non-small cell lung cancer (NSCLC).},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\DKKKDB6A\\Chen et al. - 2019 - Early stage non-small cell lung cancer treated wit.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\W9N3M3KG\\s13014-019-1216-1.html}
}

@article{Cho2000,
  title = {Hardware-sensitive optimization for intensity modulated radiotherapy},
  author = {Cho, Paul S. and Marks, Robert J.},
  date = {2000-01},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {45},
  number = {2},
  pages = {429--440},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/45/2/312},
  url = {https://doi.org/10.1088/0031-9155/45/2/312},
  urldate = {2021-11-30},
  abstract = {The multileaf collimator (MLC) hardware constraints are usually neglected in the process of intensity-modulated beam optimization. Consequently, it is not always possible to deliver planned beam modulation using dynamic MLC. Beam optimization is significantly diminished if the results must be approximated due to limitations imposed by the delivery device. To overcome this problem, an inverse beam optimization method which incorporates the hardware constraints has been developed. The hardware constraints, including the leaf velocity, the dose rate and the minimum required gap between opposing and adjacent leaves, were considered. An iterative search for feasible modulation was conducted alternately in the dosimetric space and the MLC position-time space. The optimization algorithm was designed for a unidirectional leaf trajectory and a constant dose rate. A scheme to reduce tongue-and-groove underdosage during optimization was also implemented. Comparisons were made between the solutions produced by this method and conventional optimization disregarding the hardware restrictions. The beam profiles generated by the conventional method were modified to satisfy the hardware specifications. The results indicate that inclusion of MLC constraints during optimization can improve the degree of conformity that is deliverable.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\KUECMN6M\\Cho und Marks - 2000 - Hardware-sensitive optimization for intensity modu.pdf}
}

@article{Choi2002,
  title = {The generalized equivalent uniform dose function as a basis for intensity-modulated treatment planning},
  author = {Choi, Beong and Deasy, Joseph O},
  date = {2002-10-21},
  journaltitle = {Physics in Medicine and Biology},
  volume = {47},
  number = {20},
  pages = {3579--3589},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/47/20/302},
  url = {http://stacks.iop.org/0031-9155/47/i=20/a=302?key=crossref.ddd30481b73c6c64876551eeeca4bfad},
  urldate = {2018-04-07}
}

@article{Christiansen2018,
  title = {Continuous aperture dose calculation and optimization for volumetric modulated arc therapy},
  author = {Christiansen, Eric and Heath, Emily and Xu, Tong},
  date = {2018-10},
  journaltitle = {Physics in Medicine \& Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {63},
  number = {21},
  pages = {21NT01},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/aae65e},
  url = {https://doi.org/10.1088%2F1361-6560%2Faae65e},
  urldate = {2019-09-25},
  abstract = {Although VMAT delivery features continuous gantry rotation and leaf motion, dose calculation is often performed under the dual assumption of discrete apertures changing instantaneously from one discrete angle to the next. In this work, the validity of these two approximations is determined, as well as their impact on the quality of optimized plans. Further, an accurate method of fluence calculation is derived which does not use the discrete aperture approximation, but instead calculates the fluence as the multi-leaf collimator leaves sweep from one position to another. This continuous aperture fluence calculation is integrated in the VMAT optimization process using the open-source treatment planning system matRad. The three-step approach of VMAT optimization is used: fluence map optimization followed by leaf sequencing and direct aperture optimization, with variable leaf speed, gantry rotation speed, and MU rate. The benefit of the continuous aperture VMAT method over the discrete aperture method is determined by comparing the plan quality of discrete aperture and continuous aperture optimized plans, when the former is recalculated using the continuous aperture fluence calculation. Discrete aperture VMAT plans calculated at 4° spacing result in significant dose errors (10\%–35\%, depending on the anatomical site) as compared to the reference dose (continuous aperture fluence calculation at 0.5° spacing). These errors are greatly reduced (to 0.8\%–2\%) when the continuous aperture fluence calculation method was used at the same 4° spacing, implying that the dose error is primarily due to the discrete aperture approximation. Whereas all dose objectives were met by the discrete aperture VMAT optimized plan, many of them failed when the dose was recalculated with the continuous aperture fluence calculation. All objectives were met once again when the plan was optimized with the new continuous aperture VMAT optimization. Further, using only half of the beam angles, the continuous aperture VMAT optimization can achieve the same degree of accuracy with only 40\% of the computing time as compared with the standard discrete aperture VMAT.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\FSFQ52S8\\Christiansen et al. - 2018 - Continuous aperture dose calculation and optimizat.pdf}
}

@article{Chu2005,
  title = {Robust optimization for intensity modulated radiation therapy treatment planning under uncertainty},
  author = {Chu, Millie and Zinchenko, Yuriy and Henderson, Shane G and Sharpe, Michael B},
  date = {2005-12-07},
  journaltitle = {Physics in Medicine and Biology},
  volume = {50},
  number = {23},
  eprint = {16306645},
  eprinttype = {pmid},
  pages = {5463--77},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/50/23/003},
  url = {http://stacks.iop.org/0031-9155/50/i=23/a=003?key=crossref.30133b90fdff9a1f21059f4edae85bd9},
  urldate = {2016-07-25},
  abstract = {The recent development of intensity modulated radiation therapy (IMRT) allows the dose distribution to be tailored to match the tumour's shape and position, avoiding damage to healthy tissue to a greater extent than previously possible. Traditional treatment plans assume that the target structure remains in a fixed location throughout treatment. However, many studies have shown that because of organ motion, inconsistencies in patient positioning over the weeks of treatment, etc, the tumour location is not stationary. We present a probabilistic model for the IMRT inverse problem and show that it is identical to using robust optimization techniques, under certain assumptions. For a sample prostate case, our computational results show that this method is computationally feasible and promising-compared to traditional methods, our model has the potential to find treatment plans that are more adept at sparing healthy tissue while maintaining the prescribed dose to the target.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\PAGQIBKQ\\Chu et al. - 2005 - Robust optimization for intensity modulated radiation therapy treatment planning under uncertainty(2).pdf;C\:\\Users\\Niklas\\Zotero\\storage\\UMNJMQMD\\Chu et al. - 2005 - Robust optimization for intensity modulated radiation therapy treatment planning under uncertainty.pdf}
}

@inproceedings{Cisternas2015,
  title = {{{matRad}} - a multi-modality open source {{3D}} treatment planning toolkit},
  booktitle = {World {{Congress}} on {{Medical Physics}} and {{Biomedical Engineering}}, {{June}} 7-12, 2015, {{Toronto}}, {{Canada}}},
  author = {Cisternas, E. and Mairani, A. and Ziegenhein, P. and Jäkel, O. and Bangert, M.},
  editor = {Jaffray, David A.},
  date = {2015},
  series = {{{IFMBE Proceedings}}},
  pages = {1608--1611},
  publisher = {{Springer International Publishing}},
  abstract = {We present matRad, an open source software for three-dimensional radiation treatment planning of intensitymodulated photon, proton, and carbon ion therapy. matRad is developed for educational and research purposes; it is entirely written in MATLAB. A first beta release is available for download. The toolkit features a highly modular design with a set of individual functions modeling the entire treatment planning workflow based on a segmented patient CT. All algorithms, e.g. for ray tracing, photon/proton/carbon dose calculation, fluence optimization, and multileaf collimator sequencing, follow well-established approaches and operate on clinically adequate voxel and bixel resolution. Patient data as well as base data for all required computations is included in matRad. We achieve computation times of 60-100s (60-400s) for realistic patient cases including photon (particle) dose calculation and fluence optimization. Memory consumption ranges between 0.2GB and 2.2GB. Dose distributions of a treatment planning study for a phantom and prostate patient case considering multiple radiation modalities are shown. Both the computational and dosimetric results encourage a future use of matRad in an educational and scientific setting.},
  isbn = {978-3-319-19387-8},
  langid = {english},
  keywords = {matRadGrantOther,open source software,particle therapy,Radiation therapy,treatment planning}
}

@article{Clark1961,
  title = {The {{Greatest}} of a {{Finite Set}} of {{Random Variables}}},
  author = {Clark, Charles E.},
  date = {1961-04},
  journaltitle = {Operations Research},
  volume = {9},
  number = {2},
  eprint = {20543249},
  eprinttype = {pmid},
  pages = {145--162},
  issn = {0030-364X},
  doi = {10.1287/opre.9.2.145},
  url = {http://pubsonline.informs.org/doi/abs/10.1287/opre.9.2.145},
  abstract = {The variables \textbackslash xi\_1,\textbackslash ldots,\textbackslash xi\_n have a joint normal distribution. We are concerned with the calculation or approximation of max(\textbackslash xi\_1,\textbackslash ldots,\textbackslash xi\_n). Current analyses and tables handle the case in which the tj are independently distributed with common expected values and common variances. This paper presents formulas and tables for the most general case with n=2. When n{$>$}2, the problem becomes cumbersome. This paper presents formulas and tables that permit approximations to the moments in case n{$>$}2. The moments are approximated by iteration of a three-parameter computation or, alternatively, through successive use of a three-parameter table, which is given. Recent applications of the theory are described.},
  archiveprefix = {arXiv},
  isbn = {0191-2615},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\3WD7C854\\Clark - 1961 - The Greatest of a Finite Set of Random Variables.pdf}
}

@book{Coles2001,
  title = {An {{Introduction}} to {{Statistical Modeling}} of {{Extreme Values}}},
  author = {Coles, Stuart},
  date = {2001},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {{Springer London}},
  location = {{London}},
  doi = {10.1007/978-1-4471-3675-0},
  url = {http://link.springer.com/10.1007/978-1-4471-3675-0},
  urldate = {2018-04-05},
  abstract = {1. Introduction -- 2. Basics of Statistical Modeling -- 3. Classical Extreme Value Theory and Models -- 4. Threshold Models -- 5. Extremes of Dependent Sequences -- 6. Extremes of Non-stationary Sequences -- 7. A Point Process Characterization of Extremes -- 8. Multivariate Extremes -- 9. Further Topics.},
  isbn = {978-1-84996-874-4},
  pagetotal = {208}
}

@article{Combs2010,
  title = {Randomized phase {{II}} study evaluating a carbon ion boost applied after combined radiochemotherapy with temozolomide versus a proton boost after radiochemotherapy with temozolomide in patients with primary glioblastoma: {{The CLEOPATRA Trial}}},
  shorttitle = {Randomized phase {{II}} study evaluating a carbon ion boost applied after combined radiochemotherapy with temozolomide versus a proton boost after radiochemotherapy with temozolomide in patients with primary glioblastoma},
  author = {Combs, Stephanie E and Kieser, Meinhard and Rieken, Stefan and Habermehl, Daniel and Jäkel, Oliver and Haberer, Thomas and Nikoghosyan, Anna and Haselmann, Renate and Unterberg, Andreas and Wick, Wolfgang and Debus, Jürgen},
  date = {2010-12},
  journaltitle = {BMC Cancer},
  shortjournal = {BMC Cancer},
  volume = {10},
  number = {1},
  pages = {478},
  issn = {1471-2407},
  doi = {10.1186/1471-2407-10-478},
  url = {http://bmccancer.biomedcentral.com/articles/10.1186/1471-2407-10-478},
  urldate = {2020-11-20},
  abstract = {Background: Treatment standard for patients with primary glioblastoma (GBM) is combined radiochemotherapy with temozolomide (TMZ). Radiation is delivered up to a total dose of 60 Gy using photons. Using this treatment regimen, overall survival could be extended significantly however, median overall survival is still only about 15 months. Carbon ions offer physical and biological advantages. Due to their inverted dose profile and the high local dose deposition within the Bragg peak precise dose application and sparing of normal tissue is possible. Moreover, in comparison to photons, carbon ions offer an increase relative biological effectiveness (RBE), which can be calculated between 2 and 5 depending on the GBM cell line as well as the endpoint analyzed. Protons, however, offer an RBE which is comparable to photons. First Japanese Data on the evaluation of carbon ion radiation therapy showed promising results in a small and heterogeneous patient collective. Methods/Design: In the current Phase II-CLEOPATRA-Study a carbon ion boost will be compared to a proton boost applied to the macroscopic tumor after surgery at primary diagnosis in patients with GBM applied after standard radiochemotherapy with TMZ up to 50 Gy. In the experimental arm, a carbon ion boost will be applied to the macroscopic tumor up to a total dose of 18 Gy E in 6 fractions at a single dose of 3 Gy E. In the standard arm, a proton boost will be applied up to a total dose 10 Gy E in 5 single fractions of 2 Gy E.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\6RXXME7G\\Combs et al. - 2010 - Randomized phase II study evaluating a carbon ion .pdf}
}

@article{Combs2012,
  title = {Treatment of pediatric patients and young adults with particle therapy at the {{Heidelberg Ion Therapy Center}} ({{HIT}}): establishment of workflow and initial clinical data},
  author = {Combs, Stephanie E and Kessel, Kerstin A and Herfarth, Klaus and Jensen, Alexandra and Oertel, Susanne and Blattmann, Claudia and Ecker, Swantje and Hoess, Angelika and Martin, Eike and Witt, Olaf and Jäkel, Oliver and Kulozik, Andreas E and Debus, Jürgen},
  date = {2012},
  journaltitle = {Radiation Oncology},
  volume = {7},
  number = {1},
  eprint = {23072718},
  eprinttype = {pmid},
  pages = {170},
  issn = {1748-717X},
  doi = {10.1186/1748-717X-7-170},
  url = {http://ro-journal.biomedcentral.com/articles/10.1186/1748-717X-7-170},
  abstract = {BACKGROUND: To report on establishment of workflow and clinical results of particle therapy at the Heidelberg Ion Therapy Center.\textbackslash n\textbackslash nMATERIALS AND METHODS: We treated 36 pediatric patients (aged 21 or younger) with particle therapy at HIT. Median age was 12 years (range 2-21 years), five patients (14\%) were younger than 5 years of age. Indications included pilocytic astrocytoma, parameningeal and orbital rhabdomyosarcoma, skull base and cervical chordoma, osteosarcoma and adenoid-cystic carcinoma (ACC), as well as one patient with an angiofibroma of the nasopharynx. For the treatment of small children, an anesthesia unit at HIT was established in cooperation with the Department of Anesthesiology.\textbackslash n\textbackslash nRESULTS: Treatment concepts depended on tumor type, staging, age of the patient, as well as availability of specific study protocols. In all patients, particle radiotherapy was well tolerated and no interruptions due to toxicity had to be undertaken. During follow-up, only mild toxicites were observed. Only one patient died of tumor progression: Carbon ion radiotherapy was performed as an individual treatment approach in a child with a skull base recurrence of the previously irradiated rhabdomyosarcoma. Besides this patient, tumor recurrence was observed in two additional patients.\textbackslash n\textbackslash nCONCLUSION: Clinical protocols have been generated to evaluate the real potential of particle therapy, also with respect to carbon ions in distinct pediatric patient populations. The strong cooperation between the pediatric department and the department of radiation oncology enable an interdisciplinary treatment and stream-lined workflow and acceptance of the treatment for the patients and their parents.},
  isbn = {1748-717x},
  keywords = {carbon ion radiotherapy,children,proton radiation},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\XADQGPWW\\Combs et al. - 2012 - Treatment of pediatric patients and young adults with particle therapy at the Heidelberg Ion Therapy Center (HIT).pdf}
}

@book{Cook2013,
  title = {{{CUDA}} programming: a developer's guide to parallel computing with {{GPUs}}},
  author = {Cook, Shane},
  date = {2013},
  publisher = {{Morgan Kaufmann}},
  location = {{Waltham, MA}},
  isbn = {978-0-12-415933-4},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\LPU5JFHE\\Cook - 2013 - CUDA programming a developer's guide to parallel computing with GPUs.pdf}
}

@article{Cormack1987,
  title = {A problem in rotation therapy with {{X Rays}}},
  author = {Cormack, A. M.},
  date = {1987-04-01},
  journaltitle = {International Journal of Radiation Oncology, Biology, Physics},
  shortjournal = {International Journal of Radiation Oncology, Biology, Physics},
  volume = {13},
  number = {4},
  eprint = {3558053},
  eprinttype = {pmid},
  pages = {623--630},
  publisher = {{Elsevier}},
  issn = {0360-3016},
  doi = {10.1016/0360-3016(87)90082-4},
  url = {https://www.redjournal.org/article/0360-3016(87)90082-4/abstract},
  urldate = {2021-12-01},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}p{$>$}The radiation field required to produce a dose distribution in rotation therapy may, in a certain approximation, be calculated using an integral equation, that is, the solution of the equation predicts the intensities needed to produce the dose distribution. The nature of this approximation is discussed and is shown to be connected with a Radon-type problem for circles through the origin provided the beam can be continuously modified during the rotation. The lowest order approximation provides a vivid geometrical way of looking at treatment planning which may be useful in novel situations and which will persist, to some extent, in higher-order approximations. Questions of scattering, and of the extension of the problem to a full three dimensional treatment are discussed.{$<$}/p{$>$}},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\RAXEBCZ7\\pdf.html}
}

@article{Cormode2009,
  title = {Probabilistic {{Histograms}} for {{Probabilistic Data}}},
  author = {Cormode, Graham and Mcgregor, Andrew and {Antonios Deligiannakis}},
  date = {2009},
  journaltitle = {Proceedings of the VLDB Endowment},
  volume = {2},
  number = {1},
  pages = {526--537},
  issn = {2150-8097},
  abstract = {There is a growing realization that modern database management systems (DBMSs) must be able to manage data that contains un- certainties that are represented in the form of probabilistic rela- tions. Consequently, the design of each core DBMS component must be revisited in the presence of uncertain and probabilistic in- formation. In this paper, we study how to build histogram syn- opses for probabilistic relations, for the purposes of enabling both DBMS-internal decisions (such as indexing and query planning), and (possibly, user-facing) approximate query processing tools. In contrast to initial work in this area, our probabilistic histograms retain the key possible-worlds semantics of probabilistic data, al- lowing for more accurate, yet concise, representation of the un- certainty characteristics of data and query results. We present a variety of techniques for building optimal probabilistic histograms, each one tuned to a different choice of approximation-error metric. We show that these can be incorporated into a general Dynamic Programming (DP) framework, which generalizes that used for ex- isting histogram constructions. The end result is a histogram where each “bucket” is approximately represented by a compact proba- bility distribution function (PDF), which can be used as the basis for query planning and approximate query answering. We present novel, polynomial-time algorithms to find optimal probabilistic his- tograms for a variety of PDF-error metrics (including variation dis- tance, sum squared error, max error and EMD1). Our experimental study shows that our probabilistic histogram synopses can accu- rately capture the key statistical properties of uncertain data, while being much more compact to store and work with than the original uncertain relations.},
  isbn = {0000000000000},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\PR354KVX\\Cormode, Mcgregor, Antonios Deligiannakis - 2009 - Probabilistic Histograms for Probabilistic Data.pdf}
}

@article{Cotrutz2002,
  title = {Using voxel-dependent importance factors for interactive {{DVH-based}} dose optimization},
  author = {Cotrutz, Cristian and Xing, Lei},
  date = {2002-05-21},
  journaltitle = {Physics in Medicine and Biology},
  volume = {47},
  number = {10},
  pages = {1659--1669},
  issn = {00319155},
  doi = {10.1088/0031-9155/47/10/304},
  url = {http://stacks.iop.org/0031-9155/47/i=10/a=304},
  urldate = {2014-08-07},
  abstract = {Intensity modulated radiation therapy (IMRT) inverse planning is usually performed by pre-selecting  parameters such as beam modality, beam configuration and importance factors and then optimizing the  fluence profiles or beamlet weights. In reality, the IMRT dose optimization problem may be  ill-conditioned and there may not be a physical solution to account for the chosen parameters and  constraints. Planner intervention is often required to conduct a multiple trial-and-error process  where several parameters are sequentially varied until an acceptable compromise is achieved. The  resulting solution reflects a balance between the conflicting requirements of the target and the  sensitive structures. A major problem of the conventional inverse planning formalism is that there  exists no effective mechanism for a planner to fine-tune the dose distribution on a local level or  to differentially modify the dose–volume histograms (DVHs) of the involved structures. In this paper  we introduce a new inverse planning scheme with voxel-dependent importance factors and demonstrate  that it provides us with an effective link between the system parameters and the dosimetric  behaviour at a local level. The planning proceeds in two steps. After a conventional trial-and-error  inverse planning procedure is completed, we identify the dose interval at which the fractional  volume on the DVH curve needs to be changed. The voxels that receive dose in the selected range are  then located and their voxel-dependent importance factors are adjusted accordingly. The fine-tuning  of the DVHs is iterative in nature and, using widely available computer graphic software tools, the  process can be made graphically interactive. The new IMRT planning scheme is applied to two test  cases and the results indicate that our control over the differential shapes of the DVHs of the  involved structures is greatly enhanced. Thus the technique may have significant practical  implications in facilitating the IMRT treatment planning process.}
}

@article{Cotrutz2003,
  title = {{{IMRT}} dose shaping with regionally variable penalty scheme},
  author = {Cotrutz, Cristian and Xing, Lei},
  date = {2003},
  journaltitle = {Medical Physics},
  volume = {30},
  number = {4},
  pages = {544},
  issn = {00942405},
  doi = {10.1118/1.1556610},
  url = {http://link.aip.org/link/MPHYA6/v30/i4/p544/s1},
  urldate = {2014-02-02},
  keywords = {dose optimization,importance factors,imrt,inverse planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\5C5IWDEH\\Cotrutz, Xing - 2003 - IMRT dose shaping with regionally variable penalty scheme.pdf}
}

@article{Craft2005,
  title = {Exploration of tradeoffs in intensity-modulated radiotherapy},
  author = {Craft, David and Halabi, Tarek and Bortfeld, Thomas},
  date = {2005-12-21},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {50},
  number = {24},
  eprint = {16333160},
  eprinttype = {pmid},
  pages = {5857--5868},
  issn = {0031-9155, 1361-6560},
  doi = {10.1088/0031-9155/50/24/007},
  url = {https://iopscience.iop.org/article/10.1088/0031-9155/50/24/007},
  urldate = {2020-12-07},
  abstract = {The purpose of this study is to calculate Pareto surfaces in multi-criteria radiation treatment planning and to analyse the dependency of the Pareto surfaces on the objective functions used for the volumes of interest. We develop a linear approach that allows us to calculate truly Pareto optimal treatment plans, and we apply it to explore the tradeoff between tumour dose homogeneity and critical structure sparing. We show that for two phantom and two clinical cases, a smooth (as opposed to kinked) Pareto tradeoff curve exists. We find that in the paraspinal cases the Pareto surface is invariant to the response function used on the spinal cord: whether the mean cord dose or the maximum cord dose is used, the Pareto plan database is similar. This is not true for the lung studies, where the choice of objective function on the healthy lung tissue influences the resulting Pareto surface greatly. We conclude that in the special case when the tumour wraps around the organ at risk, e.g. prostate cases and paraspinal cases, the Pareto surface will be largely invariant to the objective function used to model the organ at risk.},
  langid = {english},
  keywords = {Humans,Lung Neoplasms,Lung Neoplasms: radiotherapy,Phantoms; Imaging,Radiotherapy; Intensity-Modulated},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\HNKF82CN\\Craft et al. - 2005 - Exploration of tradeoffs in intensity-modulated ra.pdf}
}

@article{Craft2006,
  title = {Approximating convex {{Pareto}} surfaces in multiobjective radiotherapy planning},
  author = {Craft, David L and Halabi, Tarek F and Shih, Helen A and Bortfeld, Thomas R},
  date = {2006},
  journaltitle = {Medical Physics},
  volume = {33},
  number = {9},
  pages = {10},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\R3RB9RFT\\Craft et al. - 2006 - Approximating convex Pareto surfaces in multiobjec.pdf}
}

@article{Craft2007,
  title = {An approach for practical multiobjective {{IMRT}} treatment planning.},
  author = {Craft, David and Halabi, Tarek and Shih, Helen A and Bortfeld, Thomas},
  date = {2007-12-01},
  journaltitle = {International journal of radiation oncology, biology, physics},
  volume = {69},
  number = {5},
  eprint = {17920782},
  eprinttype = {pmid},
  pages = {1600--7},
  issn = {0360-3016},
  doi = {10.1016/j.ijrobp.2007.08.019},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301607037650},
  urldate = {2015-07-29},
  abstract = {PURPOSE: To introduce and demonstrate a practical multiobjective treatment planning procedure for intensity-modulated radiation therapy (IMRT) planning. METHODS AND MATERIALS: The creation of a database of Pareto optimal treatment plans proceeds in two steps. The first step solves an optimization problem that finds a single treatment plan which is close to a set of clinical aspirations. This plan provides an example of what is feasible, and is then used to determine mutually satisfiable hard constraints for the subsequent generation of the plan database. All optimizations are done using linear programming. RESULTS: The two-step procedure is applied to a brain, a prostate, and a lung case. The plan databases created allow for the selection of a final treatment plan based on the observed tradeoffs between the various organs involved. CONCLUSIONS: The proposed method reduces the human iteration time common in IMRT treatment planning. Additionally, the database of plans, when properly viewed, allows the decision maker to make an informed final plan selection.},
  keywords = {Aged,Algorithms,Brain Neoplasms,Brain Neoplasms: radiotherapy,Carcinoma; Non-Small-Cell Lung,Carcinoma; Non-Small-Cell Lung: radiotherapy,Databases; Factual,Female,Hemangiopericytoma,Hemangiopericytoma: radiotherapy,Humans,Lung Neoplasms,Lung Neoplasms: radiotherapy,Male,Middle Aged,Prostatic Neoplasms,Prostatic Neoplasms: radiotherapy,Radiotherapy Dosage,Radiotherapy Planning; Computer-Assisted,Radiotherapy Planning; Computer-Assisted: methods,Radiotherapy; Adjuvant,Radiotherapy; Adjuvant: methods,Radiotherapy; Intensity-Modulated,Radiotherapy; Intensity-Modulated: methods}
}

@article{Craft2014,
  title = {Shared data for intensity modulated radiation therapy ({{IMRT}}) optimization research: the {{CORT}} dataset},
  shorttitle = {Shared data for intensity modulated radiation therapy ({{IMRT}}) optimization research},
  author = {Craft, David and Bangert, Mark and Long, Troy and Papp, Dávid and Unkelbach, Jan},
  date = {2014-12-01},
  journaltitle = {GigaScience},
  shortjournal = {Gigascience},
  volume = {3},
  number = {1},
  doi = {10.1186/2047-217X-3-37},
  url = {https://academic.oup.com/gigascience/article/3/1/2047-217X-3-37/2682969},
  urldate = {2019-10-27},
  abstract = {AbstractBackground:.  We provide common datasets (which we call the CORT dataset: common optimization for radiation therapy) that researchers can use when devel},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\FPWZUPM6\\Craft et al. - 2014 - Shared data for intensity modulated radiation ther.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\CLYG5AR3\\2682969.html}
}

@article{Cressie1986,
  title = {The moment generating function has its moments},
  author = {Cressie, Noel and Borkent, Marinus and Gupta, R P},
  date = {1986-01-01},
  journaltitle = {Journal of Statistical Planning and Inference},
  volume = {13},
  pages = {337--344},
  publisher = {{North-Holland}},
  issn = {03783758},
  doi = {10.1016/0378-3758(86)90143-6},
  abstract = {Traditionally, the moment generating function of a random variable X, is used to generate (positive integer) moments of X. However, moments of quite general transformations of X can be obtained by judicious differentiations and weighted integration of the moment generating function. The particular case of Xγ, −∞{$<$}γ{$<$}∞, is treated in detail, and applications are given.},
  keywords = {AMS Subject Classification,Fractional calculus,Method of moments,Primary 60E05,Real moments,Secondary 62E99 Key words and phrases}
}

@article{Crijns2011,
  title = {Towards {{MRI-guided}} linear accelerator control: gating on an {{MRI}} accelerator.},
  author = {Crijns, S P M and Kok, J G M and Lagendijk, J J W and Raaymakers, B W},
  date = {2011-08},
  journaltitle = {Phys Med Biol},
  volume = {56},
  number = {15},
  pages = {4815--4825},
  doi = {10.1088/0031-9155/56/15/012},
  url = {http://dx.doi.org/10.1088/0031-9155/56/15/012},
  abstract = {To boost the possibilities of image guidance in radiotherapy by providing images with superior soft-tissue contrast during treatment, we pursue diagnostic quality MRI functionality integrated with a linear accelerator. Large respiration-induced semi-periodic target excursions hamper treatment of cancer of the abdominal organs. Methods to compensate},
  keywords = {Acceleration; Humans; Magnetic Resonance Imaging,Computer-Assisted,instrumentation/methods; Movement; Radiotherapy,instrumentation/methods; Time Factors}
}

@unpublished{CutandaHenriquez2007,
  ids = {Henriquez2008},
  title = {A novel method for the evaluation of uncertainty in dose volume histogram computation},
  author = {Cutanda Henriquez, Francisco and Vargas Castrillon, Silvia},
  date = {2007},
  eprint = {18313532},
  eprinttype = {pmid},
  pages = {17},
  abstract = {Dose volume histograms are a useful tool in state-of-the-art radiotherapy planning, and it is essential to be aware of their limitations. Dose distributions computed by treatment planning systems are affected by several sources of uncertainty such as algorithm limitations, measurement uncertainty in the data used to model the beam and residual differences between measured and computed dose, once the model is optimized. In order to take into account the effect of uncertainty, a probabilistic approach is proposed and a new kind of histogram, a dose-expected volume histogram, is introduced. The expected value of the volume in the region of interest receiving an absorbed dose equal or greater than a certain value is found using the probability distribution of the dose at each point. A rectangular probability distribution is assumed for this point dose, and a relationship is given for practical computations. This method is applied to a set of dose volume histograms for different regions of interest for 6 brain patients, 8 lung patients, 8 pelvis patients and 6 prostate patients planned for IMRT. These results show how dose computation uncertainty has effects on PTV coverage and, to a lesser extent, in dose to organs at risk. This method allows to quantify these effects.},
  archiveprefix = {arXiv},
  keywords = {Dose distribution,Dose uncertainty,Dose-volume histogram,Probability distribution,Treatment planning system},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\NDWH8FX6\\Henríquez, Castrillón - 2008 - A Novel Method for the Evaluation of Uncertainty in Dose-Volume Histogram Computation.pdf}
}

@inproceedings{daCostaFerreira2019,
  title = {Incorporating the {{Local Biological Effect}} of {{Dose Per Fraction}} in {{IMRT Inverse Optimization}}},
  booktitle = {World {{Congress}} on {{Medical Physics}} and {{Biomedical Engineering}} 2018},
  author = {family=Costa Ferreira, given=Brígida, prefix=da, useprefix=true and Mavroidis, Panayiotis and Dias, Joana and Rocha, Humberto},
  editor = {Lhotska, Lenka and Sukupova, Lucie and Lacković, Igor and Ibbott, Geoffrey S.},
  date = {2019},
  pages = {413--416},
  publisher = {{Springer Singapore}},
  location = {{Singapore}},
  abstract = {In intensity modulated radiation therapy (IMRT), the dose in each voxel of the organs at risk (OAR) can be strongly reduced compared to conformal radiation therapy (RT). Due to the sensitivity of late side-effects to fraction size, a smaller dose per fraction in the normal tissues represent an increased tolerance to RT. This expected reduction in biological effect may then be used as an additional degree of freedom during IMRT optimization. In this study, the comparison between plans optimized with and without a voxel-based fractionation correction was made. Four patients diagnosed with a head and neck (HN), a breast, a lung or a prostate tumor were used as test cases. Voxel-based fractionation corrections were incorporated into the optimization algorithm by converting the dose in each normal tissue voxel to EQD2 (equivalent dose delivered at 2~Gy per fraction). The maximum gain in the probability of tumor control (PB), due to the incorporation of the correction for fractionation in each voxel, was 1.3\% with a 0.1\% increase in the probability of complications (PI) for the HN tumor case. However, in plan optimization and evaluation, when tolerance doses were compared with the respective planned EQD2 (calculated from the 3-dimensional dose distribution), PB increased by 19.3\% in the HN, 12.5\% in the lung, 6.2\% in the breast and 2.7\% in the prostate tumor case, respectively. The corresponding increases in PI were 2.3\%, 6.2\%, 1.0\% and 0.7\%, respectively. Incorporating voxel-based fractionation corrections in plan optimization is important to be able to show the clinical quality of a given plan against established tolerance constraints. To properly compare different plans, their dose distributions should be converted to a common fractionation scheme (e.g. 2~Gy per fraction) for which the doses have been associated with clinical outcomes.},
  isbn = {978-981-10-9023-3}
}

@article{Dagum1998,
  title = {{{OpenMP}}: an industry standard {{API}} for shared-memory programming},
  author = {Dagum, Leonardo and Menon, Ramesh},
  date = {1998},
  journaltitle = {IEEE Computational Science and Engineering},
  volume = {5},
  number = {1},
  pages = {46--55},
  publisher = {{IEEE Computer Society Press}},
  issn = {10709924},
  doi = {10.1109/99.660313},
  url = {http://ieeexplore.ieee.org/document/660313/},
  urldate = {2016-11-22}
}

@article{Daly-Schveitzer2011,
  title = {Intensity-modulated radiation therapy ({{IMRT}}): toward a new standard for radiation therapy of head and neck cancer?},
  author = {Daly-Schveitzer, N and Juliéron, M and Tao, Y Gan and Moussier, A and Bourhis, J},
  date = {2011-11},
  journaltitle = {European annals of otorhinolaryngology, head and neck diseases},
  volume = {128},
  number = {5},
  eprint = {21798842},
  eprinttype = {pmid},
  pages = {241--7},
  issn = {1879-7296},
  doi = {10.1016/j.anorl.2011.04.001},
  url = {http://www.sciencedirect.com/science/article/pii/S1879729611000731},
  urldate = {2014-02-27},
  abstract = {Intensity-modulated radiation therapy (IMRT) is an evolution of 3D conformal radiation therapy, which is the current standard radiation therapy technique in head-and-neck cancer. Modulating the radiation intensity of each beam by dynamic interposition of the computer-assisted collimator leaves yields dose distributions that are particularly well adapted to head-and-neck tumor volumes. It is thus possible to predetermine dose per element: i.e., the minimum effective dose to be delivered to tumor areas, and the maximum to be safely delivered to organs at risk. The technique thereby enables complex tumoral targets to be optimally covered, while sparing healthy tissue, and salivary glands in particular. In addition, the technique allows dose-escalation, with a higher dose per session delivered to the macroscopic tumor than to other irradiated areas. The first results of ongoing randomized trials confirmed those of earlier comparative studies, showing marked improvement in side effects, including post-radiation xerostomia. Although the positive impact of this technique on tumor control remains to be proven, salivary function conservation currently makes IMRT the standard treatment in most head-and-neck cancer.},
  keywords = {Head and Neck Neoplasms,Head and Neck Neoplasms: radiotherapy,Humans,Radiotherapy Dosage,Radiotherapy Planning; Computer-Assisted,Radiotherapy; Adjuvant,Radiotherapy; Intensity-Modulated},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\GJEJQ4LJ\\Daly-Schveitzer et al. - 2011 - Intensity-modulated radiation therapy (IMRT) toward a new standard for radiation therapy of head and nec.pdf}
}

@article{Davidi2009,
  title = {Perturbation-resilient block-iterative projection methods with application to image reconstruction from projections},
  author = {Davidi, R. and Herman, G.T. and Censor, Y.},
  date = {2009-07-01},
  journaltitle = {International transactions in operational research : a journal of The International Federation of Operational Research Societies},
  shortjournal = {Int Trans Oper Res},
  volume = {16},
  number = {4},
  eprint = {23271857},
  eprinttype = {pmid},
  pages = {505--524},
  issn = {0969-6016},
  doi = {10.1111/j.1475-3995.2009.00695.x},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3529939/},
  urldate = {2021-11-30},
  abstract = {A block-iterative projection algorithm for solving the consistent convex feasibility problem in a finite-dimensional Euclidean space that is resilient to bounded and summable perturbations (in the sense that convergence to a feasible point is retained even if such perturbations are introduced in each iterative step of the algorithm) is proposed. This resilience can be used to steer the iterative process towards a feasible point that is superior in the sense of some functional on the points in the Euclidean space having a small value. The potential usefulness of this is illustrated in image reconstruction from projections, using both total variation and negative entropy as the functional.},
  pmcid = {PMC3529939},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\4T9ZHHQJ\\Davidi et al. - 2009 - Perturbation-resilient block-iterative projection .pdf}
}

@incollection{Davidi2015,
  title = {Feasibility-{{Seeking}} and {{Superiorization Algorithms Applied}} to {{Inverse Treatment Planning}} in {{Radiation Therapy}}},
  booktitle = {Contemporary {{Mathematics}}},
  author = {Davidi, Ran and Censor, Yair and Schulte, Reinhard and Geneser, Sarah and Xing, Lei},
  editor = {Reich, Simeon and Zaslavski, Alexander},
  date = {2015},
  volume = {636},
  pages = {83--92},
  publisher = {{American Mathematical Society}},
  location = {{Providence, Rhode Island}},
  doi = {10.1090/conm/636/12729},
  url = {http://www.ams.org/conm/636},
  urldate = {2020-09-11},
  abstract = {We apply the recently proposed superiorization methodology (SM) to the inverse planning problem in radiation therapy. The inverse planning problem is represented here as a constrained minimization problem of the total variation (TV) of the intensity vector over a large system of linear twosided inequalities. The SM can be viewed conceptually as lying between feasibility-seeking for the constraints and full-fledged constrained minimization of the objective function subject to these constraints. It is based on the discovery that many feasibility-seeking algorithms (of the projection methods variety) are perturbation-resilient, and can be proactively steered toward a feasible solution of the constraints with a reduced, thus superiorized, but not necessarily minimal, objective function value.},
  isbn = {978-1-4704-1480-1},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\AWF448LR\\Davidi et al. - 2015 - Feasibility-Seeking and Superiorization Algorithms.pdf}
}

@article{Davis,
  title = {Can {{CT}} scan protocols used for radiotherapy treatment planning be adjusted to optimize image quality and patient dose? {{A}} systematic review},
  shorttitle = {Can {{CT}} scan protocols used for radiotherapy treatment planning be adjusted to optimize image quality and patient dose?},
  author = {Davis, Anne T and Palmer, Antony L and Nisbet, Andrew},
  journaltitle = {The British Journal of Radiology},
  shortjournal = {Br J Radiol},
  volume = {90},
  number = {1076},
  eprint = {28452568},
  eprinttype = {pmid},
  pages = {20160406},
  issn = {0007-1285},
  doi = {10.1259/bjr.20160406},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5603945/},
  urldate = {2022-11-30},
  abstract = {This article reviews publications related to the use of CT scans for radiotherapy treatment planning, specifically the impact of scan protocol changes on CT number and treatment planning dosimetry and on CT image quality. A search on PubMed and EMBASE and a subsequent review of references yielded 53 relevant articles. CT scan parameters significantly affect image quality. Some will also affect Hounsfield unit (HU) values, though this is not comprehensively reported on. Changes in tube kilovoltage and, on some scanners, field of view and reconstruction algorithms have been found to produce notable HU changes. The degree of HU change which can be tolerated without changing planning dose by {$>$}1\% depends on the body region and size, planning algorithms, treatment beam energy and type of plan. A change in soft-tissue HU value has a greater impact than changes in HU for bone and air. The use of anthropomorphic phantoms is recommended when assessing HU changes. There is limited published work on CT scan protocol optimization in radiotherapy. Publications suggest that HU tolerances of ±20\,HU for soft tissue and of ±50\,HU for the lung and bone would restrict dose changes in the treatment plan to {$<$}1\%. Literature related to the use of CT images in radiotherapy planning has been reviewed to establish the acceptable level of HU change and the impact on image quality of scan protocol adjustment. Conclusions have been presented and further work identified.},
  pmcid = {PMC5603945},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\7KT3ILXB\\Davis et al. - Can CT scan protocols used for radiotherapy treatm.pdf}
}

@article{Deasy2003,
  title = {{{CERR}}: {{A}} computational environment for radiotherapy research},
  shorttitle = {{{CERR}}},
  author = {Deasy, Joseph O. and Blanco, Angel I. and Clark, Vanessa H.},
  date = {2003},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {30},
  number = {5},
  pages = {979--985},
  issn = {2473-4209},
  doi = {10.1118/1.1568978},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.1568978},
  urldate = {2019-09-02},
  abstract = {A software environment is described, called the computational environment for radiotherapy research (CERR, pronounced “sir”). CERR partially addresses four broad needs in treatment planning research: (a) it provides a convenient and powerful software environment to develop and prototype treatment planning concepts, (b) it serves as a software integration environment to combine treatment planning software written in multiple languages (MATLAB, FORTRAN, C/C++, JAVA, etc.), together with treatment plan information (computed tomography scans, outlined structures, dose distributions, digital films, etc.), (c) it provides the ability to extract treatment plans from disparate planning systems using the widely available AAPM/RTOG archiving mechanism, and (d) it provides a convenient and powerful tool for sharing and reproducing treatment planning research results. The functional components currently being distributed, including source code, include: (1) an import program which converts the widely available AAPM/RTOG treatment planning format into a MATLAB cell-array data object, facilitating manipulation; (2) viewers which display axial, coronal, and sagittal computed tomography images, structure contours, digital films, and isodose lines or dose colorwash, (3) a suite of contouring tools to edit and/or create anatomical structures, (4) dose–volume and dose–surface histogram calculation and display tools, and (5) various predefined commands. CERR allows the user to retrieve any AAPM/RTOG key word information about the treatment plan archive. The code is relatively self-describing, because it relies on MATLAB structure field name definitions based on the AAPM/RTOG standard. New structure field names can be added dynamically or permanently. New components of arbitrary data type can be stored and accessed without disturbing system operation. CERR has been applied to aid research in dose–volume-outcome modeling, Monte Carlo dose calculation, and treatment planning optimization. In summary, CERR provides a powerful, convenient, and common framework which allows researchers to use common patient data sets, and compare and share research results.},
  langid = {english},
  keywords = {AAPM format,Archives,Cell processes,cellular biophysics,Computed radiography,Computed tomography,computer software,Computer software,computerised tomography,Dosimetry,Information integration,MATLAB,medical computing,Medical imaging,Medical treatment planning,radiation protection,radiation therapy,Radiation therapy,Researchers,RTOG format,Thin film structure,treatment planning,Treatment strategy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\TPDUWHN6\\1.html}
}

@article{Deasy2010,
  title = {Radiotherapy dose-volume effects on salivary gland function.},
  author = {Deasy, Joseph O and Moiseenko, Vitali and Marks, Lawrence and Chao, K S Clifford and Nam, Jiho and Eisbruch, Avraham},
  date = {2010-03-01},
  journaltitle = {International journal of radiation oncology, biology, physics},
  volume = {76},
  eprint = {20171519},
  eprinttype = {pmid},
  pages = {S58-63},
  issn = {1879-355X},
  doi = {10.1016/j.ijrobp.2009.06.090},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301609032891},
  urldate = {2014-02-23},
  abstract = {Publications relating parotid dose-volume characteristics to radiotherapy-induced salivary toxicity were reviewed. Late salivary dysfunction has been correlated to the mean parotid gland dose, with recovery occurring with time. Severe xerostomia (defined as long-term salivary function of {$<$}25\% of baseline) is usually avoided if at least one parotid gland is spared to a mean dose of less than approximately 20 Gy or if both glands are spared to less than approximately 25 Gy (mean dose). For complex, partial-volume RT patterns (e.g., intensity-modulated radiotherapy), each parotid mean dose should be kept as low as possible, consistent with the desired clinical target volume coverage. A lower parotid mean dose usually results in better function. Submandibular gland sparing also significantly decreases the risk of xerostomia. The currently available predictive models are imprecise, and additional study is required to identify more accurate models of xerostomia risk.},
  issue = {3 Suppl},
  keywords = {Humans,Models; Biological,Parotid Gland,Parotid Gland: physiopathology,Parotid Gland: radiation effects,Radiation Injuries,Radiation Injuries: complications,Radiotherapy,Radiotherapy Dosage,Radiotherapy: adverse effects,Submandibular Gland,Submandibular Gland: radiation effects,Xerostomia,Xerostomia: etiology,Xerostomia: prevention & control},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\CHJ3QJBP\\Deasy et al. - 2010 - Radiotherapy dose-volume effects on salivary gland function.pdf}
}

@article{DelGuerra1997,
  title = {{{PET}} dosimetry in proton radiotherapy: a {{Monte Carlo}} study},
  shorttitle = {{{PET}} dosimetry in proton radiotherapy},
  author = {Del Guerra, A. and Di Domenico, G. and Mukhopadhayay, D.},
  date = {1997-10-01},
  journaltitle = {Applied Radiation and Isotopes},
  shortjournal = {Applied Radiation and Isotopes},
  volume = {48},
  number = {10},
  pages = {1617--1624},
  issn = {0969-8043},
  doi = {10.1016/S0969-8043(97)00162-0},
  url = {http://www.sciencedirect.com/science/article/pii/S0969804397001620},
  urldate = {2020-04-03},
  abstract = {We have used a Monte Carlo program to evaluate the applicability of positron emission tomography to in vivo dosimetry for proton radiotherapy. The transport program PTRAN was utilized to estimate the distribution of positron emitter nuclei produced by proton nuclear inelastic interactions in tissue. A comparison of Monte Carlo results with experimental data available in the literature shows that PET can be a useful tool in proton radiotherapy especially for in vivo Bragg peak localization.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\5VHBZ9TQ\\Del Guerra et al. - 1997 - PET dosimetry in proton radiotherapy a Monte Carl.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\E8D64FC6\\S0969804397001620.html}
}

@article{Demirhan2011a,
  title = {On a multivariate log-gamma distribution and the use of the distribution in the {{Bayesian}} analysis},
  author = {Demirhan, Haydar and Hamurkaroglu, Canan},
  date = {2011-03-01},
  journaltitle = {Journal of Statistical Planning and Inference},
  volume = {141},
  number = {3},
  pages = {1141--1152},
  publisher = {{North-Holland}},
  issn = {03783758},
  doi = {10.1016/j.jspi.2010.09.015},
  url = {https://www.sciencedirect.com/science/article/pii/S037837581000426X?via=ihub},
  urldate = {2018-04-03},
  abstract = {In this article, we propose a new generalized multivariate log-gamma distribution. We consider the usage of the proposed multivariate distribution as the prior distribution in the Bayesian analysis. The generalized multivariate log-gamma distribution allows for the inclusion of prior knowledge on correlations between model parameters when likelihood is not in the form of a normal distribution. Use of the proposed distribution in the Bayesian analysis of log-linear models is also discussed.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\YQ5UPIFC\\Demirhan, Hamurkaroglu - 2011 - On a multivariate log-gamma distribution and the use of the distribution in the Bayesian analysis.pdf}
}

@article{DeRuysscher2015,
  title = {Tumour {{Movement}} in {{Proton Therapy}}: {{Solutions}} and {{Remaining Questions}}: {{A Review}}},
  shorttitle = {Tumour {{Movement}} in {{Proton Therapy}}},
  author = {De Ruysscher, Dirk and Sterpin, Edmond and Haustermans, Karin and Depuydt, Tom},
  date = {2015-06-29},
  journaltitle = {Cancers},
  shortjournal = {Cancers},
  volume = {7},
  number = {3},
  pages = {1143--1153},
  issn = {2072-6694},
  doi = {10.3390/cancers7030829},
  url = {http://www.mdpi.com/2072-6694/7/3/0829},
  urldate = {2020-03-23},
  abstract = {Movement of tumours, mostly by respiration, has been a major problem for treating lung cancer, liver tumours and other locations in the abdomen and thorax. Organ motion is indeed one component of geometrical uncertainties that includes delineation and target definition uncertainties, microscopic disease and setup errors. At present, minimising motion seems to be the easiest to implement in clinical practice. If combined with adaptive approaches to correct for gradual anatomical variations, it may be a practical strategy. Other approaches such as repainting and tracking could increase the accuracy of proton therapy delivery, but advanced 4D solutions are needed. Moreover, there is a need to perform clinical studies to investigate which approach is the best in a given clinical situation. The good news is that existing and emerging technology and treatment planning systems as will without doubt lead in the forthcoming future to practical solutions to tackle intra-fraction motion in proton therapy. These developments may also improve motion management in photon therapy as well.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\AQLAVFAV\\De Ruysscher et al. - 2015 - Tumour Movement in Proton Therapy Solutions and R.pdf}
}

@thesis{Desplanques2015,
  type = {phdthesis},
  title = {{{AN OPEN SOURCE SOFTWARE FOR PROTON TREATMENT PLANNING}}},
  author = {Desplanques, Maxime},
  date = {2015},
  institution = {{Politecnico di Milano}},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\5LE9BTE7\\Desplanques - 2015 - AN OPEN SOURCE SOFTWARE FOR PROTON TREATMENT PLANNING.pdf}
}

@article{Doerner2017,
  title = {Technical {{Note}}: {{Parallel}} implementation of the {{EGSnrc Monte Carlo}} simulation of ionizing radiation transport using {{OpenMP}}},
  author = {Doerner, Edgardo and Caprile, Paola},
  date = {2017-12-01},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {44},
  number = {12},
  pages = {6672--6677},
  issn = {2473-4209},
  doi = {10.1002/mp.12642},
  url = {https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.12642},
  urldate = {2019-09-18},
  abstract = {Purpose To present the implementation of a new option for parallel processing of the EGSnrc Monte Carlo system using the OpenMP API, as an alternative to the provided method based on the use of a ba...},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\QB2DY2YJ\\mp.html}
}

@article{Doerner2018,
  title = {Technical {{Note}}: {{An}} hybrid parallel implementation for {{EGSnrc Monte Carlo}} user codes},
  author = {Doerner, Edgardo and Caprile, Paola},
  date = {2018},
  journaltitle = {Medical Physics},
  volume = {45},
  number = {8},
  pages = {3969--3973},
  issn = {2473-4209},
  doi = {10.1002/mp.13033},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.13033},
  urldate = {2019-09-18},
  abstract = {Purpose The purpose of this study was to present a parallel solution for the EGSnrc Monte Carlo code system combining MPI and OpenMP programming models as an alternative to the provided implementation, based on the use of a batch-queueing system (BQS). Methods Relying on a previous implementation based on OpenMP by E. Doerner and P. Caprile [Med. Phys. 44, 6672 (2017)], this work incorporates MPI features to efficiently distribute the simulation on current high-performance computing (HPC) systems. These features are introduced through properly defined macros, which are enabled depending on the compilation flags given by the user. The presented solution was benchmarked using the DOSXYZnrc code for a 6 MV clinical photon beam impinging on an homogeneous water phantom. Results The platform validation against the serial run results confirmed that the introduction of new features does not modify the final dose distribution. The performance tests indicated that the new implementation was able to handle efficiently the workload distribution among the computing units available. Using all the resources available, the hybrid simulation was 10\% faster than the MPI only solution and 30\% faster than the BQS implementation. Conclusions The hybrid method presented is a viable solution to parallelize MC simulations using the EGSnrc codes in distributed computing systems in an simple and efficient way, taking advantage of the available resources and giving the user the possibility of choosing between different parallelization schemes (only OpenMP/MPI or a combination of both).},
  langid = {english},
  keywords = {distributed computing,Monte Carlo methods,MPI,multicore systems,OpenMP,particle transport simulation},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\NFJKBTF2\\mp.html}
}

@report{Doucet2010,
  title = {A {{Note}} on {{Efficient Conditional Simulation}} of {{Gaussian Distributions}}},
  author = {Doucet, Arnaud},
  date = {2010},
  institution = {{University of British Columbia}},
  location = {{Vancouver}},
  abstract = {Consider a multivariate Gaussian random vector which can be partitioned into observed and unobserved components.We review a technique proposed almost twenty years ago in the astrophysics literature to sample from the posterior Gaussian distribution of the unobserved components given the observed components [6]. This technique can be computationally cheaper than the standard approach which requires computing the Cholesky decomposition of the posterior covariance matrix. This useful method does not appear to be widely known and has been rediscovered independently in various publications.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\4F7VVXN9\\Doucet - 2010 - A Note on Efficient Conditional Simulation of Gaussian Distributions.pdf}
}

@incollection{Dreher2018,
  title = {Clinical {{Rationale}} and {{Indications}} for {{Particle Therapy}}},
  booktitle = {Progress in {{Tumor Research}}},
  author = {Dreher, Constantin and Combs, Stephanie E.},
  editor = {Guckenberger, M. and Combs, S.E. and Zips, D.},
  date = {2018},
  volume = {44},
  pages = {89--104},
  publisher = {{S. Karger AG}},
  doi = {10.1159/000486997},
  url = {https://www.karger.com/Article/FullText/486997},
  urldate = {2022-05-30},
  abstract = {Particle therapy is characterized by distinct physical properties leading to a reduction of integral dose compared to photons. While protons have an almost comparable biological effect, carbon ions and other heavier charged particles offer an increased relative biological effectiveness. The potential clinical benefit has been pointed out by several groups. Most likely, for protons, children have the largest margin of benefit since their normal tissue is very sensitive to radiation, and curative treatments lead to extremely long-term survivors having a lot of scope for long-term side effects. Many clinical studies, mostly of a retrospective nature, have shown promising results for various tumor types being treated with proton and heavy ion radiotherapy. Further clinical trials are needed in order to evaluate the opportunities of ion beam therapy and its prognostic influence on the general outcome, and many studies are currently recruiting patients. The aim here is to summarize current knowledge, possible clinical rationales, and indications for ion beam therapy.},
  isbn = {978-3-318-06361-5 978-3-318-06362-2},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Q7AILNB6\\Dreher und Combs - 2018 - Clinical Rationale and Indications for Particle Th.pdf}
}

@misc{Dummy,
  title = {Dummy {{Reference}}},
  author = {{Citation\_Needed}},
  date = {0001}
}

@article{Dursun2019,
  title = {A column generation heuristic for {{VMAT}} planning with adaptive {{CVaR}} constraints},
  author = {Dursun, Pınar and Taşkın, Z Caner and Altınel, İ Kuban and Bilge, Hatice and Kesen, Nazmiye Dönmez and Okutan, Murat and Oral, Ethem Nezih},
  date = {2019-10-21},
  journaltitle = {Physics in Medicine \& Biology},
  shortjournal = {Phys Med Biol},
  volume = {64},
  number = {20},
  pages = {205024},
  issn = {1361-6560},
  doi = {10.1088/1361-6560/ab416e},
  url = {https://iopscience.iop.org/article/10.1088/1361-6560/ab416e},
  urldate = {2019-10-30},
  abstract = {In this study we develop an efficient computational procedure that generates medically acceptable treatment plans for volumetric modulated arc therapy with constant gantry speed. Our proposed method is a column generation heuristic based on a mixed integer linear programming model, where the objective function contains minimization of total monitor unit of the treatment plan and dosevolume requirements are included as conditional value-at-risk constraints. Our heuristic generates a full treatment arc for the restricted master problem and calibrates the right hand side parameters of the conditional value-at-risk constraints in the first phase. In the second phase, this initial solution is improved by performing column generation. This is a fully automated procedure and produces treatment plans in a single call without any human intervention. We evaluate its performance on real prostate cancer data by comparing the quality of the generated plans with those obtained by a widely used commercial treatment planning system. Our analysis shows that the results are promising, and the generated plans satisfy the prescription restrictions and require 22\% fewer monitor units on average compared to the ones obtained using Eclipse.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\8EN3S6AQ\\Dursun et al. - 2019 - A column generation heuristic for VMAT planning wi.pdf}
}

@book{Dvorak2018,
  title = {Clinical Radiotherapy Physics with MATLAB: A Problem-Solving Approach},
  shorttitle = {Clinical Radiotherapy Physics with MATLAB},
  author = {Dvorak, Pavel},
  date = {2018-06-12},
  edition = {1},
  publisher = {{Taylor \& Francis Inc}},
  location = {{Boca Raton}},
  abstract = {The first MATLAB® programming book written specifically for clinical radiotherapy medical physicists and medical physics trainees, this much-needed book teaches users how to create their own clinical applications using MATLAB®, as a complement to commercial software particularly when the latter does not cover specific local clinical needs. Chapters explore key radiotherapy areas such as handling volumes, 3D dose calculation, comparing dose distributions, reconstructing treatment plans and their summations, and automated tests for machine quality assurance. Readers will learn to independently analyse and process images, doses, structures, and other radiotherapy clinical data to deal with standard and non-standard situations in radiotherapy. This book will also significantly improve understanding of areas such as data nature, information content, DICOM RT standard, and data flow. It will be an invaluable reference for students of medical physics, in addition to clinical radiotherapy physicists and researchers working in radiotherapy.Features:Includes real clinical medical physics applications derived from actual clinical problemsProvides commented MATLAB® scripts working with sample data and/or own data matching input requirementsPromotes critical thinking and practical problem solving skills},
  isbn = {978-1-4987-5499-6},
  langid = {Englisch},
  pagetotal = {244}
}

@misc{Edmonton,
  title = {Official {{Project Website}}},
  author = {Edmonton, C C I},
  url = {http://www.mp.med.ualberta.ca/linac-mr/}
}

@article{Elsasser2010,
  title = {Quantification of the {{Relative Biological Effectiveness}} for {{Ion Beam Radiotherapy}}: {{Direct Experimental Comparison}} of {{Proton}} and {{Carbon Ion Beams}} and a {{Novel Approach}} for {{Treatment Planning}}},
  shorttitle = {Quantification of the {{Relative Biological Effectiveness}} for {{Ion Beam Radiotherapy}}},
  author = {Elsässer, Thilo and Weyrather, Wilma K. and Friedrich, Thomas and Durante, Marco and Iancu, Gheorghe and Krämer, Michael and Kragl, Gabriele and Brons, Stephan and Winter, Marcus and Weber, Klaus-Josef and Scholz, Michael},
  date = {2010-11-15},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {Int J Radiat Oncol},
  volume = {78},
  number = {4},
  pages = {1177--1183},
  issn = {0360-3016},
  doi = {10.1016/j.ijrobp.2010.05.014},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301610006905},
  urldate = {2019-09-17},
  abstract = {Purpose To present the first direct experimental in vitro comparison of the biological effectiveness of range-equivalent protons and carbon ion beams for Chinese hamster ovary cells exposed in a three-dimensional phantom using a pencil beam scanning technique and to compare the experimental data with a novel biophysical model. Methods and Materials Cell survival was measured in the phantom after irradiation with two opposing fields, thus mimicking the typical patient treatment scenario. The novel biophysical model represents a substantial extension of the local effect model, previously used for treatment planning in carbon ion therapy for more than 400 patients, and potentially can be used to predict effectiveness of all ion species relevant for radiotherapy. A key feature of the new approach is the more sophisticated consideration of spatially correlated damage induced by ion irradiation. Results The experimental data obtained for Chinese hamster ovary cells clearly demonstrate that higher cell killing is achieved in the target region with carbon ions as compared with protons when the effects in the entrance channel are comparable. The model predictions demonstrate agreement with these experimental data and with data obtained with helium ions under similar conditions. Good agreement is also achieved with relative biological effectiveness values reported in the literature for other cell lines for monoenergetic proton, helium, and carbon ions. Conclusion Both the experimental data and the new modeling approach are supportive of the advantages of carbon ions as compared with protons for treatment-like field configurations. Because the model predicts the effectiveness for several ion species with similar accuracy, it represents a powerful tool for further optimization and utilization of the potential of ion beams in tumor therapy.},
  keywords = {Biophysical model,Ion beam therapy,Relative biological effectiveness (RBE),Treatment planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\M4WMUS54\\Elsässer et al. - 2010 - Quantification of the Relative Biological Effectiv.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\NIFCBSAW\\S0360301610006905.html}
}

@article{Emami1991,
  title = {Tolerance of normal tissue to therapeutic irradiation},
  author = {Emami, B. and Lyman, J. and Brown, A. and Cola, L. and Goitein, M. and Munzenrider, J.E. and Shank, B. and Solin, L.J. and Wesson, M.},
  date = {1991},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {21},
  number = {1},
  pages = {109--122},
  url = {http://www.sciencedirect.com/science/article/pii/036030169190171Y},
  urldate = {2014-01-23},
  abstract = {The importance of knowledge on tolerance of normal tissue organs to irradiation by radiation oncologists cannot be overemphasized. Unfortunately, current knowledge is less than adequate. With the increasing use of 3-D treatment planning and dose delivery, this issue, particularly volumetric information, will become even more critical. As a part of the NCI contract N01 CM-47316, a task force, chaired by the primary author, was formed and an extensive literature search was carried out to address this issue. In this manuscript we present the updated information on tolerance of normal tissues of concern in the protocols of this contract, based on available data, with a special emphasis on partial volume effects. Due to a lack of precise and comprehensive data base, opinions and experience of the clinicians from four universities involved in the contract have also been contributory. Obviously, this is not and cannot be a comprehensive work, which is beyond the scope of this contract.},
  keywords = {Irradiation,Normal tissue tolerance,Three-dimensional treatment planning,Volume effects},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\U7FG9BMQ\\Emami et al. - 1991 - Tolerance of normal tissue to therapeutic irradiation.pdf}
}

@article{Embriaco2017,
  title = {On the lateral dose profile of 4 {{He}} beams in water},
  author = {Embriaco, A. and Bellinzona, V.E. and Fontana, A. and Rotondi, A.},
  date = {2017-08},
  journaltitle = {Physica Medica},
  shortjournal = {Physica Medica},
  volume = {40},
  pages = {51--58},
  issn = {11201797},
  doi = {10.1016/j.ejmp.2017.07.007},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1120179717302223},
  urldate = {2020-05-28},
  abstract = {Purpose: We investigate the possibility to improve the accuracy of the lateral dose profile for 4He beams with a novel approach, by extending an already validated model for proton beams to heavier ions. Methods: The full Molière theory for the Coulomb multiple scattering is applied to the case of 4He beams, with a complete separation of the electromagnetic and of the nuclear contributions in the calculation of the total dose. The latter is described with only three free parameters. Results: The accuracy of the results compared with Monte Carlo predictions already validated with experimental data is comparable with other studies at low energy, but improves by a factor 2 at high energy. In addition the found solution is more stable with respect to (multi-) Gaussian and other parameterizations. This result makes this method of interest for applications to Treatment Planning Systems (TPS) in ion beam therapy. Conclusions: We propose a model, named MONETa (MOdel of ioN dosE for Therapy for a), for the calculation of the lateral dose of 4He beams in water that allows fast and accurate dose calculations by requiring a small data base of parameters as input.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\UYKC28LV\\Embriaco et al. - 2017 - On the lateral dose profile of 4 He beams in water.pdf}
}

@article{Embriaco2017a,
  title = {An accurate model for the computation of the dose of protons in water},
  author = {Embriaco, A. and Bellinzona, V.E. and Fontana, A. and Rotondi, A.},
  date = {2017-06},
  journaltitle = {Physica Medica},
  shortjournal = {Physica Medica},
  volume = {38},
  pages = {66--75},
  issn = {11201797},
  doi = {10.1016/j.ejmp.2017.05.049},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1120179717301680},
  urldate = {2020-05-28},
  abstract = {Purpose: The accurate and fast calculation of the dose in proton radiation therapy is an essential ingredient for successful treatments. We propose a novel approach with a minimal number of parameters. Methods: The approach is based on the exact calculation of the electromagnetic part of the interaction, namely the Molière theory of the multiple Coulomb scattering for the transversal 1D projection and the Bethe-Bloch formula for the longitudinal stopping power profile, including a gaussian energy straggling. To this e.m. contribution the nuclear proton-nucleus interaction is added with a simple twoparameter model. Then, the non gaussian lateral profile is used to calculate the radial dose distribution with a method that assumes the cylindrical symmetry of the distribution. Results: The results, obtained with a fast C++ based computational code called MONET (MOdel of ioN dosE for Therapy), are in very good agreement with the FLUKA MC code, within a few percent in the worst case. Conclusions: This study provides a new tool for fast dose calculation or verification, possibly for clinical use.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\N9KXLSUQ\\Embriaco et al. - 2017 - An accurate model for the computation of the dose .pdf}
}

@article{Engel2005,
  title = {A new algorithm for optimal multileaf collimator field segmentation},
  author = {Engel, Konrad},
  date = {2005-11-01},
  journaltitle = {Discrete Applied Mathematics},
  shortjournal = {Discrete Appl Math},
  volume = {152},
  number = {1},
  pages = {35--51},
  issn = {0166-218X},
  doi = {10.1016/j.dam.2004.10.007},
  url = {http://www.sciencedirect.com/science/article/pii/S0166218X05001411},
  urldate = {2019-10-27},
  abstract = {We present a new efficient leaf sequencing algorithm for the generation of intensity maps by a nonnegative combination of segments. Intensity maps describe the intensity modulation of beams in radiotherapy. We only study the static case (step and shoot). We exactly optimize the total number of monitor units and heuristically optimize the number of segments. We present a short exact proof for a formula giving the smallest total number of monitor units and describe a class of algorithms yielding this minimal value. A special member of this class provides a solution with a very small number of segments.},
  langid = {english},
  keywords = {IMRT,Intensity modulation,Leaf sequencing,Multileaf collimator,Radiation therapy optimization},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\86RCWNNX\\Engel - 2005 - A new algorithm for optimal multileaf collimator f.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\Y7LC7Y67\\S0166218X05001411.html}
}

@article{Engelsman2005,
  title = {How much margin reduction is possible through gating or breath hold?},
  author = {Engelsman, M. and Sharp, G. C. and Bortfeld, T. and Onimaru, R. and Shirato, H.},
  date = {2005-01},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {50},
  number = {3},
  pages = {477--490},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/50/3/006},
  url = {https://doi.org/10.1088%2F0031-9155%2F50%2F3%2F006},
  urldate = {2020-03-23},
  abstract = {We determined the relationship between intra-fractional breathing motion and safety margins, using daily real-time tumour tracking data of 40 patients (43 tumour locations), treated with radiosurgery at Hokkaido University. We limited our study to the dose-blurring effect of intra-fractional breathing motion, and did not consider differences in positioning accuracy or systematic errors. The additional shift in the prescribed isodose level (e.g. 95\%) was determined by convolving a one-dimensional dose profile, having a dose gradient representing an 8 MV beam through either lung or water, with the probability density function (PDF) of breathing. This additional shift is a measure for the additional margin that should be applied in order to maintain the same probability of tumour control as without intra-fractional breathing. We show that the required safety margin is a nonlinear function of the peak-to-peak breathing motion. Only a small reduction in the shift of isodose curves was observed for breathing motion up to 10 mm. For larger motion, 20 or 30 mm, control of patient breathing during irradiation, using either gating or breath hold, can allow a substantial reduction in safety margins of about 7 or 12 mm depending on the dose gradient prior to blurring. Clinically relevant random setup uncertainties, which also have a blurring effect on the dose distribution, have only a small effect on the margin needed for intra-fractional breathing motion. Because of the one-dimensional nature of our analysis, the resulting margins are mainly applicable in the superior–inferior direction. Most measured breathing PDFs were not consistent with the PDF of a simple parametric curve such as cos4, either because of irregular breathing or base-line shifts. Instead, our analysis shows that breathing motion can be modelled as Gaussian with a standard deviation of about 0.4 times the peak-to-peak breathing motion.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\V53NDK5N\\Engelsman et al. - 2005 - How much margin reduction is possible through gati.pdf}
}

@article{Engelsman2006,
  title = {Four-dimensional proton treatment planning for lung tumors},
  author = {Engelsman, Martijn and Rietzel, Eike and Kooy, Hanne M.},
  date = {2006-04-01},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {64},
  number = {5},
  pages = {1589--1595},
  issn = {0360-3016},
  doi = {10.1016/j.ijrobp.2005.12.026},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301605030956},
  urldate = {2020-03-23},
  abstract = {Purpose: In proton radiotherapy, respiration-induced variations in density lead to changes in radiologic path lengths and will possibly result in geometric misses. We compared different treatment planning strategies for lung tumors that compensate for respiratory motion. Methods and Materials: Particle-specific treatment planning margins were applied to standard helical computed tomography (CT) scans as well as to “representative” CT scans. Margins were incorporated beam specific laterally by aperture widening and longitudinally by compensator smearing. Furthermore, treatment plans using full time-resolved 4D-computed tomography data were generated. Results: Four-dimensional treatment planning guaranteed target coverage throughout a respiratory cycle. Use of a standard helical CT data set resulted in underdosing the target volume to 36\% of the prescribed dose. For CT data representing average target positions, coverage can be expected but not guaranteed. In comparison to this strategy, 4D planning decreased the mean lung dose by up to 16\% and the lung volume receiving 20 Gy (prescribed target dose 72 Gy) by up to 15\%. Conclusion: When the three planning strategies are compared, only 4D proton treatment planning guarantees delivery of the prescribed dose throughout a respiratory cycle. Furthermore, the 4D planning approach results in equal or reduced dose to critical structures; even the ipsilateral lung is spared.},
  langid = {english},
  keywords = {Four-dimensional computed tomography,Lung,Proton,Treatment planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\AB9LK3ZH\\Engelsman et al. - 2006 - Four-dimensional proton treatment planning for lun.pdf}
}

@article{Engelsman2013,
  title = {Physics {{Controversies}} in {{Proton Therapy}}},
  author = {Engelsman, Martijn and Schwarz, Marco and Dong, Lei},
  date = {2013-04-01},
  journaltitle = {Seminars in Radiation Oncology},
  shortjournal = {Seminars in Radiation Oncology},
  series = {Controversies in {{Proton Therapy}}},
  volume = {23},
  number = {2},
  pages = {88--96},
  issn = {1053-4296},
  doi = {10.1016/j.semradonc.2012.11.003},
  url = {http://www.sciencedirect.com/science/article/pii/S1053429612001063},
  urldate = {2020-03-23},
  abstract = {The physical characteristics of proton beams are appealing for cancer therapy. The rapid increase in operational and planned proton therapy facilities may suggest that this technology is a “plug-and-play” valuable addition to the arsenal of the radiation oncologist and medical physicist. In reality, the technology is still evolving, so planning and delivery of proton therapy in patients face many practical challenges. This review article discusses the current status of proton therapy treatment planning and delivery techniques, indicates current limitations in dealing with range uncertainties, and proposes possible developments for proton therapy and supplementary technology to try to realize the actual potential of proton therapy.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\2E9CEVL5\\Engelsman et al. - 2013 - Physics Controversies in Proton Therapy.pdf}
}

@article{Engelsman2013a,
  title = {Physics {{Controversies}} in {{Proton Therapy}}},
  author = {Engelsman, Martijn and Schwarz, Marco and Dong, Lei},
  date = {2013-04-01},
  journaltitle = {Seminars in Radiation Oncology},
  shortjournal = {Seminars in Radiation Oncology},
  series = {Controversies in {{Proton Therapy}}},
  volume = {23},
  number = {2},
  pages = {88--96},
  issn = {1053-4296},
  doi = {10.1016/j.semradonc.2012.11.003},
  url = {https://www.sciencedirect.com/science/article/pii/S1053429612001063},
  urldate = {2022-08-16},
  abstract = {The physical characteristics of proton beams are appealing for cancer therapy. The rapid increase in operational and planned proton therapy facilities may suggest that this technology is a “plug-and-play” valuable addition to the arsenal of the radiation oncologist and medical physicist. In reality, the technology is still evolving, so planning and delivery of proton therapy in patients face many practical challenges. This review article discusses the current status of proton therapy treatment planning and delivery techniques, indicates current limitations in dealing with range uncertainties, and proposes possible developments for proton therapy and supplementary technology to try to realize the actual potential of proton therapy.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\2WRNE2DE\\Engelsman et al. - 2013 - Physics Controversies in Proton Therapy.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\IYDDXHR8\\S1053429612001063.html}
}

@article{Enghardt1992,
  title = {The spatial distribution of positron-emitting nuclei generated by relativistic light ion beams in organic matter},
  author = {Enghardt, W. and Fromm, W. D. and Geissel, H. and Heller, H. and Kraft, G. and Magel, A. and Manfrass, P. and Munzenberg, G. and Nickel, F. and Pawelke, J. and Schardt, D. and Scheidenberger, C. and Sobiella, M.},
  date = {1992-11},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {37},
  number = {11},
  pages = {2127--2131},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/37/11/009},
  url = {https://doi.org/10.1088%2F0031-9155%2F37%2F11%2F009},
  urldate = {2020-04-03},
  abstract = {The range distributions of positron emitters generated during the stopping process of relativistic light ions in organic matter exhibit a pronounced maximum near the range of the primary particles. The shape of this distribution can be qualitatively understood from a simple Monte Carlo approach of the stopping, fragmentation and decay processes. These results offer the possibility of beam monitoring by means of PET techniques during the tumour therapy with a light ion beam. Furthermore, a refinement of this technique may allow the actual dose distribution to be calculated from PET data.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\EMC38KTE\\Enghardt et al. - 1992 - The spatial distribution of positron-emitting nucl.pdf}
}

@article{Ezzell2009,
  title = {{{IMRT}} commissioning: {{Multiple}} institution planning and dosimetry comparisons, a report from {{AAPM Task Group}} 119},
  shorttitle = {{{IMRT}} commissioning},
  author = {Ezzell, Gary A. and Burmeister, Jay W. and Dogan, Nesrin and LoSasso, Thomas J. and Mechalakos, James G. and Mihailidis, Dimitris and Molineu, Andrea and Palta, Jatinder R. and Ramsey, Chester R. and Salter, Bill J. and Shi, Jie and Xia, Ping and Yue, Ning J. and Xiao, Ying},
  date = {2009},
  journaltitle = {Medical Physics},
  volume = {36},
  number = {11},
  pages = {5359--5373},
  issn = {2473-4209},
  doi = {10.1118/1.3238104},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.3238104},
  urldate = {2021-01-21},
  abstract = {AAPM Task Group 119 has produced quantitative confidence limits as baseline expectation values for IMRT commissioning. A set of test cases was developed to assess the overall accuracy of planning and delivery of IMRT treatments. Each test uses contours of targets and avoidance structures drawn within rectangular phantoms. These tests were planned, delivered, measured, and analyzed by nine facilities using a variety of IMRT planning and delivery systems. Each facility had passed the Radiological Physics Center credentialing tests for IMRT. The agreement between the planned and measured doses was determined using ion chamber dosimetry in high and low dose regions, film dosimetry on coronal planes in the phantom with all fields delivered, and planar dosimetry for each field measured perpendicular to the central axis. The planar dose distributions were assessed using gamma criteria of 3\%/3 mm. The mean values and standard deviations were used to develop confidence limits for the test results using the concept . Other facilities can use the test protocol and results as a basis for comparison to this group. Locally derived confidence limits that substantially exceed these baseline values may indicate the need for improved IMRT commissioning.},
  langid = {english},
  keywords = {Calibration,commissioning,Dose-volume analysis,dosimetry,Dosimetry,Error analysis,IMRT,Intensity modulated radiation therapy,Ionization chambers,Medical imaging,Medical treatment planning,Multileaf collimators,phantoms,Physicists,quality assurance,Quality assurance,radiation therapy,Radiation therapy equipment},
  annotation = {\_eprint: https://aapm.onlinelibrary.wiley.com/doi/pdf/10.1118/1.3238104},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\KDMVDMUL\\Ezzell et al. - 2009 - IMRT commissioning Multiple institution planning .pdf;C\:\\Users\\Niklas\\Zotero\\storage\\4CXUZCZ7\\1.html}
}

@article{Ezzell2009a,
  title = {{{IMRT}} commissioning: multiple institution planning and dosimetry comparisons, a report from {{AAPM Task Group}} 119},
  shorttitle = {{{IMRT}} commissioning},
  author = {Ezzell, Gary A. and Burmeister, Jay W. and Dogan, Nesrin and LoSasso, Thomas J. and Mechalakos, James G. and Mihailidis, Dimitris and Molineu, Andrea and Palta, Jatinder R. and Ramsey, Chester R. and Salter, Bill J. and Shi, Jie and Xia, Ping and Yue, Ning J. and Xiao, Ying},
  date = {2009-11},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {36},
  number = {11},
  eprint = {19994544},
  eprinttype = {pmid},
  pages = {5359--5373},
  issn = {0094-2405},
  doi = {10.1118/1.3238104},
  abstract = {AAPM Task Group 119 has produced quantitative confidence limits as baseline expectation values for IMRT commissioning. A set of test cases was developed to assess the overall accuracy of planning and delivery of IMRT treatments. Each test uses contours of targets and avoidance structures drawn within rectangular phantoms. These tests were planned, delivered, measured, and analyzed by nine facilities using a variety of IMRT planning and delivery systems. Each facility had passed the Radiological Physics Center credentialing tests for IMRT. The agreement between the planned and measured doses was determined using ion chamber dosimetry in high and low dose regions, film dosimetry on coronal planes in the phantom with all fields delivered, and planar dosimetry for each field measured perpendicular to the central axis. The planar dose distributions were assessed using gamma criteria of 3\%/3 mm. The mean values and standard deviations were used to develop confidence limits for the test results using the concept confidence limit = /mean/ + 1.96sigma. Other facilities can use the test protocol and results as a basis for comparison to this group. Locally derived confidence limits that substantially exceed these baseline values may indicate the need for improved IMRT commissioning.},
  langid = {english},
  keywords = {Film Dosimetry,Head and Neck Neoplasms,Humans,Male,Phantoms; Imaging,Prostatic Neoplasms,Quality Assurance; Health Care,Radiometry,Radiotherapy Planning; Computer-Assisted,Radiotherapy; Intensity-Modulated},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\EDRE5IYH\\Ezzell et al. - 2009 - IMRT commissioning multiple institution planning .pdf}
}

@article{Fabiano2020,
  title = {Combined proton–photon treatments – {{A}} new approach to proton therapy without a gantry},
  author = {Fabiano, Silvia and Balermpas, Panagiotis and Guckenberger, Matthias and Unkelbach, Jan},
  date = {2020},
  journaltitle = {Radiotherapy and Oncology},
  pages = {7},
  abstract = {Purpose: Although the number of proton therapy centres is growing worldwide, proton therapy is still a limited resource. The primary reasons are gantry size and cost. Therefore, we investigate the potential of a new design for proton therapy, which may facilitate proton treatments in conventional bunkers and allow the widespread use of protons. Materials and methods: The treatment room consists of a standard Linac for IMRT, a motorized couch for treatments in lying position, and a horizontal proton beamline equipped with pencil beam scanning. As proton beams are limited to a coronal plane, treatment plans may be suboptimal for many tumour sites. However, high-quality plans may be realized by combining protons and photons. Treatment planning is performed by simultaneously optimizing IMRT and IMPT plans based on their cumulative physical dose. We demonstrate this concept for three head\&neck cancer cases. Results: Optimal combinations use photons to improve dose conformity while protons reduce the integral dose to normal tissues. In fact, combined treatments improve on single-modality IMRT and fixed beamline IMPT plans for quality-of-life-limiting OARs and retain most of the integral dose reduction in the healthy tissues of the pure IMPT plans. The lower doses that can be obtained with multi-modality treatments reduce the risk for side effects compared to single-modality IMRT plans. Conclusion: Combined proton–photon treatments may play a role in developing a new solution for proton therapy without a gantry. Optimal combinations improve on IMRT plans and reduce the risk of side effects while making protons available to more patients.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\2M459NH3\\Fabiano et al. - 2020 - Combined proton–photon treatments – A new approach.pdf}
}

@article{Fallone2009,
  title = {First {{MR}} images obtained during megavoltage photon irradiation from a prototype integrated linac-{{MR}} system},
  author = {Fallone, B G and Murray, B and Rathee, S and Stanescu, T and Steciw, S and Vidakovic, S and Blosser, E and Tymofichuk, D},
  date = {2009},
  journaltitle = {Medical Physics},
  volume = {36},
  number = {6},
  pages = {2084--2088},
  publisher = {{AAPM}},
  doi = {10.1118/1.3125662},
  url = {http://link.aip.org/link/?MPH/36/2084/1},
  keywords = {biomedical MRI; cancer; linear accelerators; phant}
}

@article{Fan2019,
  title = {Automatic treatment planning based on three-dimensional dose distribution predicted from deep learning technique},
  author = {Fan, Jiawei and Wang, Jiazhou and Chen, Zhi and Hu, Chaosu and Zhang, Zhen and Hu, Weigang},
  date = {2019-01},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {46},
  number = {1},
  pages = {370--381},
  issn = {00942405},
  doi = {10.1002/mp.13271},
  url = {http://doi.wiley.com/10.1002/mp.13271},
  urldate = {2019-10-30},
  abstract = {Purpose: To develop an automated treatment planning strategy for external beam intensity-modulated radiation therapy (IMRT), including a deep learning-based three-dimensional (3D) dose prediction and a dose distribution-based plan generation algorithm. Methods and Materials: A residual neural network-based deep learning model is trained to predict a dose distribution based on patient-specific geometry and prescription dose. A total of 270 headand-neck cancer cases were enrolled in this study, including 195 cases in the training dataset, 25 cases in the validation dataset, and 50 cases in the testing dataset. All patients were treated with IMRT with a variety of different prescription patterns. The model input consists of CT images and contours delineating the organs at risk (OARs) and planning target volumes (PTVs). The algorithm output is trained to predict the dose distribution on the CT image slices. The obtained prediction model is used to predict dose distributions for new patients. Then, an optimization objective function based on these predicted dose distributions is created for automatic plan generation. Results: Our results demonstrate that the deep learning method can predict clinically acceptable dose distributions. There is no statistically significant difference between prediction and real clinical plan for all clinically relevant dose–volume histogram (DVH) indices, except brainstem, right and left lens. However, the predicted plans were still clinically acceptable. The results of plan generation show no statistically significant differences between the automatic generated plan and the predicted plan except PTV70.4, but the difference is only 0.5\% which is still clinically acceptable. Conclusion: This study developed a new automated radiotherapy treatment planning system based on 3D dose prediction and 3D dose distribution-based optimization. It is a promising approach for realizing automated treatment planning in the future. © 2018 American Association of Physicists in Medicine [https://doi.org/10.1002/mp.13271]},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\C3YYTRIZ\\Fan et al. - 2019 - Automatic treatment planning based on three-dimens.pdf}
}

@article{Farrance2012,
  title = {Uncertainty of {{Measurement}}: {{A Review}} of the {{Rules}} for {{Calculating Uncertainty Components}} through {{Functional Relationships}}.},
  author = {Farrance, Ian and Frenkel, Robert},
  date = {2012-05},
  journaltitle = {The Clinical biochemist. Reviews},
  volume = {33},
  number = {2},
  eprint = {22896744},
  eprinttype = {pmid},
  pages = {49--75},
  publisher = {{The Australian Association of Clinical Biochemists}},
  issn = {0159-8090},
  abstract = {The Evaluation of Measurement Data - Guide to the Expression of Uncertainty in Measurement (usually referred to as the GUM) provides general rules for evaluating and expressing uncertainty in measurement. When a measurand, y, is calculated from other measurements through a functional relationship, uncertainties in the input variables will propagate through the calculation to an uncertainty in the output y. The manner in which such uncertainties are propagated through a functional relationship provides much of the mathematical challenge to fully understanding the GUM.The aim of this review is to provide a general overview of the GUM and to show how the calculation of uncertainty in the measurand may be achieved through a functional relationship. That is, starting with the general equation for combining uncertainty components as outlined in the GUM, we show how this general equation can be applied to various functional relationships in order to derive a combined standard uncertainty for the output value of the particular function (the measurand). The GUM equation may be applied to any mathematical form or functional relationship (the starting point for laboratory calculations) and describes the propagation of uncertainty from the input variable(s) to the output value of the function (the end point or outcome of the laboratory calculation). A rule-based approach is suggested with a number of the more common rules tabulated for the routine calculation of measurement uncertainty.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\KIQ7CVV8\\Farrance, Frenkel - 2012 - Uncertainty of Measurement A Review of the Rules for Calculating Uncertainty Components through Functional Re.pdf}
}

@report{Finch2009,
  title = {Incremental calculation of weighted mean and variance},
  author = {Finch, Tony},
  date = {2009},
  institution = {{University of Cambridge Computing Service}},
  abstract = {In these notes I explain how to derive formulae for numerically stable calculation of the mean and standard deviation, which are also suitable for incremental on-line calculation. I then generalize these formulae to weighted means and standard deviations. I unpick the difficulties that arise when generalizing further to normalized weights. Finally I show that the exponentially weighted moving average is a special case of the incremental normalized weighted mean formula, and derive a formula for the exponentially weighted moving standard deviation. 1 Simple mean Straightforward translation of equation 1 into code can suffer from loss of precision because of the difference in magnitude between a sample and the sum of all samples. Equation 4 calculates the mean in a way that is more numerically stable because it avoids accumulating large sums. µ n = 1 n n i=1 x i (1) = 1 n (x n + n−1 i=1 x i) (2) = 1 n (x n + (n − 1)µ n−1) (3) = µ n−1 + 1 n (x n − µ n−1) (4) This formula also provides us with some useful identities. x n − µ n−1 = n(µ n − µ n−1) (5) x n − µ n = n(µ n − µ n−1) − µ n + µ n−1 = (n − 1)(µ n − µ n−1) (6) 2 Simple variance The definition of the standard deviation in equation 7 below requires us to already know the mean, which implies two passes over the data. This isn't feasible for online algorithms that need to produce incremental results after each sample becomes available. Equation 12 solves this problem since it allows us to calculate the standard deviation from two running sums. σ},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\W7C3KCQC\\Finch - 2009 - Incremental calculation of weighted mean and variance.pdf}
}

@article{Fippel2003,
  title = {A virtual photon energy fluence model for {{Monte Carlo}} dose calculation},
  author = {Fippel, Matthias and Haryanto, Freddy and Dohm, Oliver and Nüsslin, Fridtjof and Kriesen, Stephan},
  date = {2003},
  journaltitle = {Medical Physics},
  volume = {30},
  number = {3},
  pages = {301--311},
  issn = {2473-4209},
  doi = {10.1118/1.1543152},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1118/1.1543152},
  urldate = {2022-12-09},
  abstract = {The presented virtual energy fluence (VEF) model of the patient-independent part of the medical linear accelerator heads, consists of two Gaussian-shaped photon sources and one uniform electron source. The planar photon sources are located close to the bremsstrahlung target (primary source) and to the flattening filter (secondary source), respectively. The electron contamination source is located in the plane defining the lower end of the filter. The standard deviations or widths and the relative weights of each source are free parameters. Five other parameters correct for fluence variations, i.e., the horn or central depression effect. If these parameters and the field widths in the X and Y directions are given, the corresponding energy fluence distribution can be calculated analytically and compared to measured dose distributions in air. This provides a method of fitting the free parameters using the measurements for various square and rectangular fields and a fixed number of monitor units. The next step in generating the whole set of base data is to calculate monoenergetic central axis depth dose distributions in water which are used to derive the energy spectrum by deconvolving the measured depth dose curves. This spectrum is also corrected to take the off-axis softening into account. The VEF model is implemented together with geometry modules for the patient specific part of the treatment head (jaws, multileaf collimator) into the XVMC dose calculation engine. The implementation into other Monte Carlo codes is possible based on the information in this paper. Experiments are performed to verify the model by comparing measured and calculated dose distributions and output factors in water. It is demonstrated that open photon beams of linear accelerators from two different vendors are accurately simulated using the VEF model. The commissioning procedure of the VEF model is clinically feasible because it is based on standard measurements in air and water. It is also useful for IMRT applications because a full Monte Carlo simulation of the treatment head would be too time-consuming for many small fields.},
  langid = {english},
  keywords = {Biomedical modeling,bremsstrahlung,dose calculation,dosimetry,Electron sources,Experiment design,Intensity modulated radiation therapy,linear accelerators,Linear accelerators,Medical accelerators,modelling,Monte Carlo,Monte Carlo methods,Multileaf collimators,photon beam modeling,Photons,radiation therapy,Water vapor},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1118/1.1543152},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\BZICIJFJ\\Fippel et al. - 2003 - A virtual photon energy fluence model for Monte Ca.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\UZX7LHKS\\1.html}
}

@article{Fogliata2007,
  title = {On the performances of different {{IMRT}} treatment planning systems for selected paediatric cases},
  author = {Fogliata, Antonella and Nicolini, Giorgia and Alber, Markus and Åsell, Mats and Clivio, Alessandro and Dobler, Barbara and Larsson, Malin and Lohr, Frank and Lorenz, Friedlieb and Muzik, Jan and Polednik, Martin and Vanetti, Eugenio and Wolff, Dirk and Wyttenbach, Rolf and Cozzi, Luca},
  date = {2007},
  journaltitle = {Radiation Oncology},
  shortjournal = {Radiat Oncol},
  volume = {2},
  number = {1},
  pages = {7},
  issn = {1748717X},
  doi = {10.1186/1748-717X-2-7},
  url = {http://ro-journal.biomedcentral.com/articles/10.1186/1748-717X-2-7},
  urldate = {2020-09-11},
  abstract = {Background: To evaluate the performance of seven different TPS (Treatment Planning Systems: Corvus, Eclipse, Hyperion, KonRad, Oncentra Masterplan, Pinnacle and PrecisePLAN) when intensity modulated (IMRT) plans are designed for paediatric tumours. Methods: Datasets (CT images and volumes of interest) of four patients were used to design IMRT plans. The tumour types were: one extraosseous, intrathoracic Ewing Sarcoma; one mediastinal Rhabdomyosarcoma; one metastatic Rhabdomyosarcoma of the anus; one Wilm's tumour of the left kidney with multiple liver metastases. Prescribed doses ranged from 18 to 54.4 Gy. To minimise variability, the same beam geometry and clinical goals were imposed on all systems for every patient. Results were analysed in terms of dose distributions and dose volume histograms. Results: For all patients, IMRT plans lead to acceptable treatments in terms of conformal avoidance since most of the dose objectives for Organs At Risk (OARs) were met, and the Conformity Index (averaged over all TPS and patients) ranged from 1.14 to 1.58 on primary target volumes and from 1.07 to 1.37 on boost volumes. The healthy tissue involvement was measured in terms of several parameters, and the average mean dose ranged from 4.6 to 13.7 Gy. A global scoring method was developed to evaluate plans according to their degree of success in meeting dose objectives (lower scores are better than higher ones). For OARs the range of scores was between 0.75 ± 0.15 (Eclipse) to 0.92 ± 0.18 (Pinnacle3 with physical optimisation). For target volumes, the score ranged from 0.05 ± 0.05 (Pinnacle3 with physical optimisation) to 0.16 ± 0.07 (Corvus). Conclusion: A set of complex paediatric cases presented a variety of individual treatment planning challenges. Despite the large spread of results, inverse planning systems offer promising results for IMRT delivery, hence widening the treatment strategies for this very sensitive class of patients.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\RHUR49KD\\Fogliata et al. - 2007 - [No title found].pdf}
}

@inproceedings{Foka2022,
  title = {Particle therapy masterclass},
  booktitle = {{{EPJ Web}} of {{Conferences}}},
  author = {Foka, Panagiota and Mamaras, Aristeidis and Skrjiel, Damir and Seco, Joao and Graeff, Christian and Pulia, Marco and Wieser, Hans-Peter and Wahl, Niklas},
  date = {2022},
  volume = {258},
  pages = {01002},
  publisher = {{EDP Sciences}},
  location = {{Online}},
  doi = {10.1051/epjconf/202225801002},
  url = {https://www.epj-conferences.org/articles/epjconf/abs/2022/02/epjconf_vconf2021_01002/epjconf_vconf2021_01002.html},
  urldate = {2022-02-11},
  abstract = {The aim of the new Particle Therapy MasterClass (PTMC) was to develop an educational and training environment in which anyone can learn about fundamental and applied research in particle therapy. The PTMC was recently integrated into the International MasterClass 2021 online programme that attracted 1500 students from 37 institutes in 20 countries, worldwide. The PTMC focuses on the topic of cancer treatment, a particularly sensitive and socially relevant topic. The main idea is to (a) provide a basic understanding of cancer radiation therapy, (b) demonstrate that fundamental properties of particle interactions with matter, which are used for detection in physics experiments, are also the basis for treating cancer tumours; and (c) show that the same accelerator technologies are used in both, research laboratories and therapy centres. For the hands-on session, the open-source professional treatment planning software matRad is used, developed for research and training by the German Cancer Research Center – DKFZ. Ultimately, students are shown “what physics has to do with medicine” and what are the various possibilities that physics and STEM studies may open up for job opportunities in fields that are lacking expert personnel.},
  eventtitle = {{{vConf21}}},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\XM6E92E3\\Foka et al. - 2022 - Particle therapy masterclass.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\RV7I4AGA\\epjconf_vconf2021_01002.html}
}

@article{Fotina2012,
  title = {Feasibility of {{CBCT-based}} dose calculation: {{Comparative}} analysis of {{HU}} adjustment techniques},
  shorttitle = {Feasibility of {{CBCT-based}} dose calculation},
  author = {Fotina, Irina and Hopfgartner, Johannes and Stock, Markus and Steininger, Thomas and Lütgendorf-Caucig, Carola and Georg, Dietmar},
  date = {2012-08},
  journaltitle = {Radiotherapy and Oncology},
  shortjournal = {Radiotherapy and Oncology},
  volume = {104},
  number = {2},
  pages = {249--256},
  issn = {01678140},
  doi = {10.1016/j.radonc.2012.06.007},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S016781401200268X},
  urldate = {2022-08-16},
  abstract = {Background and purpose: The aim of this work was to compare the accuracy of different HU adjustments for CBCT-based dose calculation. Methods and materials: Dose calculation was performed on CBCT images of 30 patients. In the first two approaches phantom-based (Pha-CC) and population-based (Pop-CC) conversion curves were used. The third method (WAB) represents override of the structures with standard densities for water, air and bone. In ROI mapping approach all structures were overridden with average HUs from planning CT. All techniques were benchmarked to the Pop-CC and CT-based plans by DVH comparison and c-index analysis. Results: For prostate plans, WAB and ROI mapping compared to Pop-CC showed differences in PTV Dmedian below 2\%. The WAB and Pha-CC methods underestimated the bladder dose in IMRT plans. In lung cases PTV coverage was underestimated by Pha-CC method by 2.3\% and slightly overestimated by the WAB and ROI techniques. The use of the Pha-CC method for head–neck IMRT plans resulted in difference in PTV coverage up to 5\%. Dose calculation with WAB and ROI techniques showed better agreement with pCT than conversion curve-based approaches. Conclusions: Density override techniques provide an accurate alternative to the conversion curve-based methods for dose calculation on CBCT images. Ó 2012 Elsevier Ireland Ltd. All rights reserved. Radiotherapy and Oncology 104 (2012) 249–256},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\E5WQVYDX\\Fotina et al. - 2012 - Feasibility of CBCT-based dose calculation Compar.pdf}
}

@article{Fredriksson2011,
  title = {Minimax optimization for handling range and setup uncertainties in proton therapy},
  author = {Fredriksson, Albin and Forsgren, Anders and Hårdemark, Björn},
  date = {2011},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {38},
  number = {3},
  eprint = {21520880},
  eprinttype = {pmid},
  pages = {1672--1684},
  publisher = {{American Association of Physicists in Medicine}},
  issn = {00942405},
  doi = {10.1118/1.3556559},
  url = {http://scitation.aip.org/content/aapm/journal/medphys/38/3/10.1118/1.3556559},
  urldate = {2016-07-25},
  abstract = {Intensity modulated proton therapy (IMPT) is sensitive to errors, mainly due to high stopping power dependency and steep beam dose gradients. Conventional margins are often insufficient to ensure robustness of treatment plans. In this article, a method is developed that takes the uncertainties into account during the plan optimization.},
  keywords = {impt optimization,minimax optimization,robust planning,uncertainty},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\2XXFM9RS\\Fredriksson et al. - 2011 - Minimax optimization for handling range and setup .pdf}
}

@article{Fredriksson2012,
  title = {A characterization of robust radiation therapy treatment planning methods—from expected value to worst case optimization},
  author = {Fredriksson, Albin},
  date = {2012-07-31},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {39},
  number = {8},
  eprint = {22894442},
  eprinttype = {pmid},
  pages = {5169--5181},
  publisher = {{American Association of Physicists in Medicine}},
  issn = {00942405},
  doi = {10.1118/1.4737113},
  url = {http://scitation.aip.org/content/aapm/journal/medphys/39/8/10.1118/1.4737113},
  urldate = {2017-01-13},
  abstract = {Purpose: To characterize a class of optimization formulations used to handle systematic and random errors in radiation therapy, and to study the differences between the methods within this class. Methods: The class of robust methods that can be formulated as minimax stochastic programs is studied. This class generalizes many previously used methods, ranging between optimization of the expected and the worst case objective value. The robust methods are used to plan intensity-modulated proton therapy (IMPT) treatments for a case subject to systematic setup and range errors, random setup errors with and without uncertain probability distribution, and combinations thereof. As reference, plans resulting from a conventional method that uses a margin to account for errors are shown. Results: For all types of errors, target coverage robustness increased with the conservativeness of the method. For systematic errors, best case organ at risk (OAR) doses increased and worst case doses decreased with the conservativeness. Accounting for random errors of fixed probability distribution resulted in heterogeneous dose. The heterogeneities were reduced when uncertainty in the probability distribution was accounted for. Doing so, the OAR doses decreased with the conservativeness. All robust methods studied resulted in more robust target coverage and lower OAR doses than the conventional method. Conclusions: Accounting for uncertainties is essential to ensure plan quality in complex radiation therapy such as IMPT. The utilization of more information than conventional in the optimization can lead to robust target coverage and low OAR doses. Increased target coverage robustness can be achieved by more conservative methods.},
  keywords = {Anatomy,dosimetry,Dosimetry,Dosimetry/exposure assessment,IMPT,including brachytherapy,Inequalities,Intensity modulated radiation therapy,measurement errors,Medical treatment planning,optimization,Optimization,probability,Probability theory,Proton therapy,radiation therapy,Radiation therapy,Radiation treatment,robust planning,stochastic programming,Therapeutic applications,uncertainty},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Q7J77BM9\\Fredriksson - 2012 - A characterization of robust radiation therapy treatment planning methods—from expected value to worst case optimiz.pdf}
}

@article{Fredriksson2016,
  title = {The scenario-based generalization of radiation therapy margins},
  author = {Fredriksson, Albin and Bokrantz, Rasmus},
  date = {2016-03-07},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {61},
  number = {5},
  eprint = {26895381},
  eprinttype = {pmid},
  pages = {2067--2082},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/61/5/2067},
  url = {http://stacks.iop.org/0031-9155/61/i=5/a=2067?key=crossref.a79f05a7a0b46cfc0673e2002e5c1130},
  urldate = {2016-07-22},
  abstract = {We give a scenario-based treatment plan optimization formulation that is equivalent to planning with geometric margins if the scenario doses are calculated using the static dose cloud approximation. If the scenario doses are instead calculated more accurately, then our formulation provides a novel robust planning method that overcomes many of the difficulties associated with previous scenario-based robust planning methods. In particular, our method protects only against uncertainties that can occur in practice, it gives a sharp dose fall-off outside high dose regions, and it avoids underdosage of the target in 'easy' scenarios. The method shares the benefits of the previous scenario-based robust planning methods over geometric margins for applications where the static dose cloud approximation is inaccurate, such as irradiation with few fields and irradiation with ion beams. These properties are demonstrated on a suite of phantom cases planned for treatment with scanned proton beams subject to systematic setup uncertainty.},
  archiveprefix = {arXiv},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\I6PHEX3B\\Fredriksson, Bokrantz - 2016 - The scenario-based generalization of radiation therapy margins.pdf}
}

@article{Fuchs2017,
  title = {Magnetic field effects on particle beams and their implications for dose calculation in {{MR-guided}} particle therapy},
  author = {Fuchs, Hermann and Moser, Philipp and Gröschl, Martin and Georg, Dietmar},
  date = {2017},
  journaltitle = {Medical Physics},
  volume = {44},
  number = {3},
  pages = {1149--1156},
  issn = {2473-4209},
  doi = {10.1002/mp.12105},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mp.12105},
  urldate = {2022-08-11},
  abstract = {Purpose To investigate and model effects of magnetic fields on proton and carbon ion beams for dose calculation. Methods In a first step, Monte Carlo simulations using Gate 7.1/Geant4.10.0.p03 were performed for proton and carbon ion beams in magnetic fields ranging from 0 to 3 T. Initial particle energies ranged from 60 to 250 MeV (protons) and 120 to 400 MeV/u (carbon ions), respectively. The resulting dose distributions were analyzed focusing on beam deflection, dose deformation, as well as the impact of material heterogeneities. In a second step, a numerical algorithm was developed to calculate the lateral beam position. Using the Runge–Kutta method, an iterative solution of the relativistic Lorentz equation, corrected for the changing particle energy during penetration, was performed. For comparison, a γ-index analysis was utilized, using a criteria of 2\%/2 mm of the local maximum. Results A tilt in the dose distribution within the Bragg peak area was observed, leading to non-negligible dose distribution changes. The magnitude was found to depend on the magnetic field strength as well as on the initial beam energy. Comparison of the 3 T dose distribution with non-B field (nominal) dose distributions, resulted in a γmean (mean value of the γ distribution) of 0.6, with 14.4\% of the values above 1 and γ1\% (1\% of all points have an equal or higher γ value) of 1.8. The presented numerical algorithm calculated the lateral beam offset with maximum errors of less than 2\% with calculation times of less than 5 μs. The impact of tissue interfaces on the proton dose distributions was found to be less than 2\% for a dose voxel size of 1 × 1 × 1 mm3. Conclusion Non-negligible dose deformations at the Bragg peak area were identified for high initial energies and strong magnetic fields. A fast numerical algorithm based on the solution of the energy-corrected relativistic Lorentz equation was able to describe the beam path, taking into account the particle energy, magnetic field, and material.},
  langid = {english},
  keywords = {carbon ion,characterization,ion beam therapy,magnetic field,MR,proton},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mp.12105},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\R7HZT2YE\\Fuchs et al. - 2017 - Magnetic field effects on particle beams and their.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\3GZK8J78\\mp.html}
}

@article{Furukawa2008,
  title = {Delivery verification using {{3D}} dose reconstruction based on fluorescence measurement in a carbon beam scanning irradiation system},
  author = {Furukawa, Takuji and Saotome, Naoya and Inaniwa, Taku and Sato, Shinji and Noda, Koji and Kanai, Tatsuaki},
  date = {2008},
  journaltitle = {Medical Physics},
  volume = {35},
  number = {6},
  pages = {2235--2242},
  issn = {2473-4209},
  doi = {10.1118/1.2911868},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.2911868},
  urldate = {2020-03-20},
  abstract = {The authors have developed a method to reconstruct the 3D dose distribution in a particle beam scanning irradiation system. In this scheme, 3D dose distribution is reconstructed by using the measured images of fluence distribution, which are taken for each iso-energy slice (i.e., the unit of the depth scanning). A fluorescent screen with a CCD camera is used to measure the fluence distribution. This system was installed at the HIMAC experimental port and tested by using carbon ion beams. Since a maximum difference between the reconstructed dose and the ionization chamber measurement was around in the target volume, this system can be useful for quick verification of 3D dose distribution.},
  langid = {english},
  keywords = {3D dose reconstruction,bio-optics,Cameras,cancer,Charge coupled devices,Computed tomography,Deconvolution,dosimetry,Dosimetry/exposure assessment,Flow visualization,fluorescence,fluorescent screen,Image reconstruction,Ionization chambers,Medical image reconstruction,Medical imaging,particle therapy,pencil beam scanning,radiation therapy,Time measurement},
  annotation = {\_eprint: https://aapm.onlinelibrary.wiley.com/doi/pdf/10.1118/1.2911868}
}

@article{Gabrys2018,
  title = {Design and {{Selection}} of {{Machine Learning Methods Using Radiomics}} and {{Dosiomics}} for {{Normal Tissue Complication Probability Modeling}} of {{Xerostomia}}},
  author = {Gabryś, Hubert S. and Buettner, Florian and Sterzing, Florian and Hauswald, Henrik and Bangert, Mark},
  date = {2018-03-05},
  journaltitle = {Frontiers in Oncology},
  volume = {8},
  pages = {35},
  publisher = {{Frontiers}},
  issn = {2234-943X},
  doi = {10.3389/fonc.2018.00035},
  url = {http://journal.frontiersin.org/article/10.3389/fonc.2018.00035/full},
  urldate = {2019-08-05},
  abstract = {Purpose: To investigate whether machine learning with dosiomic, radiomic, and demographic features allows for xerostomia risk assessment more precise than normal tissue complication probability (NTCP) models based on the mean radiation dose to parotid glands. Material and methods: A cohort of 153 head-and-neck cancer patients was used to model xerostomia at 0-6 months (early), 6-15 months (late), 15-24 months (long-term), and at any time (a longitudinal model) after radiotherapy. Predictive power of the features was evaluated by the area under the receiver operating characteristic curve (AUC) of univariate logistic regression models. The multivariate NTCP models were tuned and tested with single and nested cross-validation, respectively. We compared predictive performance of seven classification algorithms, six feature selection methods, and ten data cleaning/class balancing techniques using the Friedman test and the Nemenyi post-hoc analysis. Results: NTCP models based on the parotid mean dose failed to predict xerostomia (AUCs  0.85), dose gradients in the right-left (AUCs {$>$} 0.78), and the anterior-posterior (AUCs {$>$} 0.72) direction. Multivariate models of long-term xerostomia were typically based on the parotid volume, the parotid eccentricity, and the dose-volume histogram (DVH) spread with the generalization AUCs ranging from 0.74 to 0.88. On average, support vector machines and extra-trees were the top performing classifiers, whereas the algorithms based on logistic regression were the best choice for feature selection. We found no advantage in using data cleaning or class balancing methods. Conclusions: We demonstrated that incorporation of organ- and dose-shape descriptors is beneficial for xerostomia prediction in highly conformal radiotherapy treatments. Due to strong reliance on patient-specific, dose-independent factors, our results underscore the need for development of personalized data-driven risk profiles for NTCP models of xerostomia. The facilitated machine learning pipeline is described in detail and can serve as a valuable reference for future work in radiomic and dosiomic NTCP modeling.},
  keywords = {dosiomics,head and neck,IMRT,machine learning,NTCP,Radiomics,Radiotherapy,Xerostomia},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\ZUXJQZ5L\\Gabryś et al. - 2018 - Design and Selection of Machine Learning Methods Using Radiomics and Dosiomics for Normal Tissue Complication Pro.pdf}
}

@article{Gadoue2022,
  title = {A dose–volume constraint ({{DVC}}) projection-based algorithm for {{IMPT}} inverse planning optimization},
  author = {Gadoue, Sherif M. and Toomeh, Dolla and Schultze, Blake E. and Schulte, Reinhard W.},
  date = {2022},
  journaltitle = {Medical Physics},
  issn = {2473-4209},
  doi = {10.1002/mp.15504},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mp.15504},
  urldate = {2022-03-02},
  abstract = {Purpose Provide a projection-based algorithm to solve the class of optimization problems encountered in intensity modulated proton therapy (IMPT). The algorithm can handle percentage dose–volume constraints (DVCs) that are usually found in such problems. Methods To seek a feasible solution, the automatic relaxation method was used to project the spot weight vector onto the interval defined by lower and upper bound target dose constraints. The obtained solution was optimized separately based on the objective of each organ at risk (OAR) in addition to maximizing the minimum target dose using the bisection search method using a stopping criterion of 10 cGy. The combined weight was used in the CQ algorithm to solve the split feasibility problem but with a special projection technique due to the nonconvexity of DVCs. The algorithm was applied to four clinical IMPT cases (meningioma, prostate, tongue, and oropharynx) and compared to the corresponding treatment plans optimized in Eclipse. Results The treatment plans obtained, for the four cases, using the BCQ-ARM algorithm have dosimetric endpoints that are similar to their counterparts generated from Eclipse. The algorithm worked equally well with all cases, including the complex head and neck ones. The stopping criterion of 10 cGy results in making the generated plans slightly less optimal (ε\$\textbackslash epsilon\$–optimal) rather than optimal, but with the advantage of the possibility of generating a database of plans. Conclusions The application of the BCQ-ARM algorithm to different cases of IMPT plans with DVCs was demonstrated. The algorithm is successful in generating plans that are dosimetrically equivalent to their corresponding Eclipse plans. Thus, it is suitable to generate optimized treatment plans in a clinically reasonable time frame.},
  langid = {english},
  keywords = {dose–volume constraints,IMPT,optimization,projection algorithms,proton therapy},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mp.15504},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\GWLT3FEV\\Gadoue et al. - A dose–volume constraint (DVC) projection-based al.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\V9DJTDU9\\mp.html}
}

@software{Galassi2016,
  title = {{{GNU Scientific Library Reference Manual}}},
  author = {Galassi, Mark and Davies, Jim and Theiler, James and Gough, Brian and Jungman, Gerard and Alken, Patrick and Booth, Michael and Rossi, Fabrice},
  date = {2016},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\N3GY9IBD\\Galassi et al. - 2016 - GNU Scientific Library Reference Manual.pdf}
}

@article{Gao2020,
  title = {Simultaneous dose and dose rate optimization ({{SDDRO}}) for {{FLASH}} proton therapy},
  author = {Gao, Hao and Lin, Bowen and Lin, Yuting and Fu, Shujun and Langen, Katja and Liu, Tian and Bradley, Jeffery},
  date = {2020},
  journaltitle = {Medical Physics},
  volume = {47},
  number = {12},
  pages = {6388--6395},
  issn = {2473-4209},
  doi = {10.1002/mp.14531},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.14531},
  urldate = {2021-03-16},
  abstract = {Purpose FLASH radiotherapy (RT) can potentially reduce normal tissue toxicity while preserving tumoricidal effectiveness to improve the therapeutic ratio. The key of FLASH for sparing normal tissues is to irradiate tissues with an ultra-high dose rate (i.e., ≥40 Gy/s), for which proton RT can be used. However, currently available treatment plan optimization method only optimizes the dose distribution and does not directly optimize the dose rate. The contribution of this work to FLASH proton RT is the development of a novel treatment optimization method, that is, simultaneous dose and dose rate optimization (SDDRO), to optimize tissue-receiving dose rate distribution as well as dose distribution. Methods Distinguished from existing methods, SDDRO accounts for dose rate constraint and optimizes dose rate distribution. In terms of mathematical formulation, SDDRO is a constrained optimization problem with dose-volume constraint on dose distribution, minimum dose rate constraint on dose-averaged tissue-receiving dose rates, minimum monitor unit constraint on spot weight, and maximum intensity constraint on beam intensity. In terms of optimization algorithm, SDDRO is solved by iterative convex relaxation and alternating direction method of multipliers. SDDRO algorithms are presented for both scenarios with either constant or variable beam intensity. Results SDDRO was compared with intensity modulated proton therapy (IMPT) (dose optimization alone, and no dose rate optimization) using three lung cases. SDDRO substantially improved the dose rate distribution compared to IMPT, for example, increasing of the region-of-interest (ROI) volume (ROI = CTV\_10mm: the ring sandwiched by 10 mm outer and inner expansion of CTV boundary) receiving at least 40 Gy/s from 30–50\% to at least 98\%, and the lung volume receiving at least 40 Gy/s from 30–40\% to 70–90\%. Moreover, both dose and dose rate distributions from SDDRO were further considerably improved via the combined use of hypofractionation and multiple beams. Conclusions We have developed a joint dose and dose rate optimization method for FLASH proton RT, namely SDDRO, which is first-of-its-kind to the best of our knowledge. The results suggest that (a) SDDRO can substantially improve the FLASH-dose rate coverage (e.g., in terms of dose rate volume histogram) compared to IMPT for the purpose of normal tissue sparing while preserving the dose distribution and (b) the combination of hypofractionation and multiple beams can further considerably improve the SDDRO plan quality in terms of both dose and dose rate distribution.},
  langid = {english},
  keywords = {dose rate optimization,FLASH,IMPT,proton therapy},
  annotation = {\_eprint: https://aapm.onlinelibrary.wiley.com/doi/pdf/10.1002/mp.14531},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\UTJ48GLH\\mp.html}
}

@article{Gao2021,
  title = {Generating synthetic {{CT}} from low-dose cone-beam {{CT}} by using generative adversarial networks for adaptive radiotherapy},
  author = {Gao, Liugang and Xie, Kai and Wu, Xiaojin and Lu, Zhengda and Li, Chunying and Sun, Jiawei and Lin, Tao and Sui, Jianfeng and Ni, Xinye},
  date = {2021-10-14},
  journaltitle = {Radiation Oncology},
  shortjournal = {Radiation Oncology},
  volume = {16},
  number = {1},
  pages = {202},
  issn = {1748-717X},
  doi = {10.1186/s13014-021-01928-w},
  url = {https://doi.org/10.1186/s13014-021-01928-w},
  urldate = {2022-08-16},
  abstract = {To develop high-quality synthetic CT (sCT) generation method from low-dose cone-beam CT (CBCT) images by using attention-guided generative adversarial networks (AGGAN) and apply these images to dose calculations in radiotherapy.},
  keywords = {Adaptive radiotherapy,Attention-guided GAN,Low-dose CBCT,Synthetic CT,Unpaired},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\XQIPAEZ6\\Gao et al. - 2021 - Generating synthetic CT from low-dose cone-beam CT.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\QDXAPH6S\\s13014-021-01928-w.html}
}

@article{Geant4,
  title = {Geant4-a simulation toolkit},
  author = {Agostinelli, S. and Allison, J. and Amako, K. and Apostolakis, J. and Araujo, H. and Arce, P. and Asai, M. and {...}},
  date = {2003},
  journaltitle = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  volume = {506},
  number = {3},
  pages = {250--303},
  doi = {10.1016/S0168-9002(03)01368-8}
}

@article{Gensheimer2010,
  title = {In {{Vivo Proton Beam Range Verification Using Spine MRI Changes}}},
  author = {Gensheimer, Michael F. and Yock, Torunn I. and Liebsch, Norbert J. and Sharp, Gregory C. and Paganetti, Harald and Madan, Neel and Grant, P. Ellen and Bortfeld, Thomas},
  date = {2010-09-01},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {78},
  number = {1},
  pages = {268--275},
  issn = {0360-3016},
  doi = {10.1016/j.ijrobp.2009.11.060},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301609036347},
  urldate = {2020-04-03},
  abstract = {Purpose In proton therapy, uncertainty in the location of the distal dose edge can lead to cautious treatment plans that reduce the dosimetric advantage of protons. After radiation exposure, vertebral bone marrow undergoes fatty replacement that is visible on magnetic resonance imaging (MRI). This presents an exciting opportunity to observe radiation dose distribution in vivo. We used quantitative spine MRI changes to precisely detect the distal dose edge in proton radiation patients. Methods and Materials We registered follow-up T1-weighted MRI images to planning computed tomography scans from 10 patients who received proton spine irradiation. A radiation dose-MRI signal intensity curve was created using the lateral beam penumbra in the sacrum. This curve was then used to measure range errors in the lumbar spine. Results In the lateral penumbra, there was an increase in signal intensity with higher dose throughout the full range of 0–37.5 Gy (RBE). In the distal fall-off region, the beam sometimes appeared to penetrate farther than planned. The mean overshoot in 10 patients was 1.9 mm (95\% confidence interval, 0.8–3.1 mm), on the order of the uncertainties inherent to our range verification method. Conclusions We have demonstrated in vivo proton range verification using posttreatment spine MRI changes. Our analysis suggests the presence of a systematic overshoot of a few millimeters in some proton spine treatments, but the range error does not exceed the uncertainty incorporated into the treatment planning margin. It may be possible to extend our technique to MRI sequences that show early bone marrow changes, enabling adaptive treatment modification.},
  langid = {english},
  keywords = {Bone marrow,Brain neoplasms,Dosimetry,Magnetic resonance imaging,Proton radiotherapy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\J8I2ACTF\\Gensheimer et al. - 2010 - In Vivo Proton Beam Range Verification Using Spine.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\3HWB566K\\S0360301609036347.html}
}

@article{Genz1992,
  title = {Numerical {{Computation}} of {{Multivariate Normal Probabilities}}},
  author = {Genz, Alan},
  date = {1992-06},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {1},
  number = {2},
  pages = {141--149},
  issn = {1061-8600},
  doi = {10.1080/10618600.1992.10477010},
  url = {http://www.tandfonline.com/doi/abs/10.1080/10618600.1992.10477010},
  keywords = {adaptive},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\E448SCLV\\Genz - 1992 - Numerical Computation of Multivariate Normal Probabilities.pdf}
}

@article{Genz2004,
  title = {Numerical computation of rectangular bivariate and trivariate normal and t probabilities},
  author = {Genz, Alan},
  date = {2004-08},
  journaltitle = {Statistics and Computing},
  shortjournal = {Stat Comput},
  volume = {14},
  number = {3},
  pages = {251--260},
  issn = {0960-3174},
  doi = {10.1023/B:STCO.0000035304.20635.31},
  url = {http://link.springer.com/10.1023/B:STCO.0000035304.20635.31},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\RK5WWZWV\\Genz - 2004 - Numerical computation of rectangular bivariate and trivariate normal and t probabilities.pdf}
}

@article{Giebeler2009,
  title = {Dose perturbations from implanted helical gold markers in proton therapy of prostate cancer},
  author = {Giebeler, Annelise and Fontenot, Jonas and Balter, Peter and Ciangaru, George and Zhu, Ronald and Newhauser, Wayne},
  date = {2009},
  journaltitle = {Journal of Applied Clinical Medical Physics},
  volume = {10},
  number = {1},
  pages = {63--70},
  issn = {1526-9914},
  doi = {10.1120/jacmp.v10i1.2875},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1120/jacmp.v10i1.2875},
  urldate = {2020-04-03},
  abstract = {Implanted gold fiducial markers are widely used in radiation therapy to improve targeting accuracy. Recent investigations have revealed that metallic fiducial markers can cause severe perturbations in dose distributions for proton therapy, suggesting smaller markers should be considered. The objective of this study was to estimate the dosimetric impact of small gold markers in patients receiving proton therapy for prostate cancer. Small, medium, and large helical wire markers with lengths of 10 mm and helix diameters of 0.35 mm, 0.75 mm, and 1.15 mm, respectively, were implanted in an anthropomorphic phantom. Radiographic visibility was confirmed using a kilovoltage x-ray imaging system, and dose perturbations were predicted from Monte Carlo simulations and confirmed by measurements. Monte Carlo simulations indicated that size of dose perturbation depended on marker size, orientation, and distance from the beam's end of range. Specifically, the perturbation of proton dose for the lateral-opposed-pair treatment technique was 31\% for large markers and 23\% for medium markers in a typical oblique orientation. Results for perpendicular and parallel orientations were respectively lower and higher. Consequently, these markers are not well suited for use in patients receiving proton therapy for prostate cancer. Dose perturbation was not observed for the small markers, but these markers were deemed too fragile for transrectal implantation in the prostate. PACS number: 87.53.Pb},
  langid = {english},
  keywords = {and heavier particle dosimetry,fiducial markers,neutron,proton},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\5YPXLH3L\\Giebeler et al. - 2009 - Dose perturbations from implanted helical gold mar.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\MBFNUT32\\jacmp.v10i1.html}
}

@article{Giraud2013,
  title = {Respiratory {{Gating}} for {{Radiotherapy}}: {{Main Technical Aspects}} and {{Clinical Benefits}}},
  shorttitle = {Respiratory {{Gating}} for {{Radiotherapy}}},
  author = {Giraud, Philippe and Houle, Annie},
  date = {2013},
  journaltitle = {ISRN Pulmonology},
  shortjournal = {ISRN Pulmonology},
  volume = {2013},
  pages = {1--13},
  issn = {2090-5777},
  doi = {10.1155/2013/519602},
  url = {https://www.hindawi.com/archive/2013/519602/},
  urldate = {2020-03-23},
  abstract = {Respiratory-gated radiotherapy offers a significant potential for improvement in the irradiation of tumor sites affected by respiratory motion such as lung, breast, and liver tumors. An increased conformality of irradiation fields leading to decreased complication rates of organs at risk is expected. Five main strategies are used to reduce respiratory motion effects: integration of respiratory movements into treatment planning, forced shallow breathing with abdominal compression, breath-hold techniques, respiratory gating techniques, and tracking techniques. Measurements of respiratory movements can be performed either in a representative sample of the general population, or directly on the patient before irradiation. Reduction of breathing motion can be achieved by using either abdominal compression, breath-hold techniques, or respiratory gating techniques. Abdominal compression can be used to reduce diaphragmatic excursions. Breath-hold can be achieved with active techniques, in which airflow of the patient is temporarily blocked by a valve, or passive techniques, in which the patient voluntarily breath-holds. Respiratory gating techniques use external devices to predict the phase of the breathing cycle while the patient breathes freely. Another approach is tumor-tracking technique, which consists of a real-time localization of a constantly moving tumor. This work describes these different strategies and gives an overview of the literature.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\EZDTSPHA\\Giraud und Houle - 2013 - Respiratory Gating for Radiotherapy Main Technica.pdf}
}

@article{Goitein1985,
  title = {Calculation of the uncertainty in the dose delivered during radiation therapy},
  author = {Goitein, Michael},
  date = {1985-09-01},
  journaltitle = {Medical physics},
  volume = {12},
  number = {5},
  eprint = {4046996},
  eprinttype = {pmid},
  pages = {608--612},
  publisher = {{American Association of Physicists in Medicine}},
  issn = {00942405},
  doi = {10.1118/1.595762},
  url = {http://doi.wiley.com/10.1118/1.595762},
  urldate = {2016-07-29},
  abstract = {There is, inevitably, uncertainty in our knowledge of the dose at any point within an irradiated patient. A technique is presented for estimating this uncertainty by performing three parallel calculations, one using nominal values and the others extreme values of the parameters upon which the dose depends. Such calculations can be made with almost any algorithm for calculating dose. They result in an estimate, at some specified confidence level which is determined by the data used, of the range of dose likely at any point. Such calculations should help therapists to avert over- or underdosage which might not be evident in conventional calculations of the nominal dose.},
  keywords = {culation of the uncertainty,Dosimetry,DOSIMETRY,Dosimetry/exposure assessment,Drug delivery,during radiation therapy,ERRORS,in the dose delivered,IRRADIATION,RADIATION DOSE DISTRIBUTIONS,Radiation therapy,RADIOTHERAPY,RELIABILITY,Treatment strategy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\W8TNKJ85\\Goitein - 1985 - Calculation of the uncertainty in the dose delivered during radiation therapy.pdf}
}

@article{Goldman2005,
  title = {Feasibility of a fast inverse dose optimization algorithm for {{IMRT}} via matrix inversion without negative beamlet intensities},
  author = {Goldman, S. P. and Chen, J. Z. and Battista, J. J.},
  date = {2005-08-30},
  journaltitle = {Medical Physics},
  volume = {32},
  number = {9},
  pages = {3007},
  publisher = {{American Association of Physicists in Medicine}},
  issn = {00942405},
  doi = {10.1118/1.2030427},
  url = {http://scitation.aip.org/content/aapm/journal/medphys/32/9/10.1118/1.2030427},
  urldate = {2014-01-15},
  abstract = {A fast optimization algorithm is very important for inverse planning of intensity modulated radiation therapy(IMRT), and for adaptive radiotherapy of the future. Conventional numerical search algorithms such as the conjugate gradient search, with positive beam weight constraints, generally require numerous iterations and may produce suboptimal dose results due to trapping in local minima. A direct solution of the inverse problem using conventional quadratic objective functions without positive beam constraints is more efficient but will result in unrealistic negative beam weights. We present here a direct solution of the inverse problem that does not yield unphysical negative beam weights. The objective function for the optimization of a large number of beamlets is reformulated such that the optimization problem is reduced to a linear set of equations. The optimal set of intensities is found through a matrix inversion, and negative beamlet intensities are avoided without the need for externally imposed ad-hoc constraints. The method has been demonstrated with a test phantom and a few clinical radiotherapy cases, using primary dose calculations. We achieve highly conformal primary dose distributions with very rapid optimization times. Typical optimization times for a single anatomical slice (two dimensional) (head and neck) using a LAPACKmatrix inversion routine in a single processor desktop computer, are: 0.03 s for 500 beamlets; 0.28 s for 1000 beamlets; 3.1 s for 2000 beamlets; and 12 s for 3000 beamlets. Clinical implementation will require the additional time of a one-time precomputation of scattered radiation for all beamlets, but will not impact the optimization speed. In conclusion, the new method provides a fast and robust technique to find a global minimum that yields excellent results for the inverse planning of IMRT.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\CU7F7KLD\\Goldman, Chen, Battista - 2005 - Feasibility of a fast inverse dose optimization algorithm for IMRT via matrix inversion without negativ.pdf}
}

@article{Gordon2005,
  title = {Component-{{Averaged Row Projections}}: {{A Robust}}, {{Block-Parallel Scheme}} for {{Sparse Linear Systems}}},
  shorttitle = {Component-{{Averaged Row Projections}}},
  author = {Gordon, Dan and Gordon, Rachel},
  date = {2005-01-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {27},
  number = {3},
  pages = {1092--1117},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/040609458},
  url = {https://epubs.siam.org/doi/abs/10.1137/040609458},
  urldate = {2021-12-01},
  abstract = {A new method for the parallel solution of large sparse linear systems is introduced. It proceeds by dividing the equations into blocks and operating in block-parallel iterative mode; i.e., all the blocks are processed in parallel, and the partial results are "merged" to form the next iterate. The new scheme performs Kaczmarz row projections within the blocks and merges the results by certain component-averaging operations---hence it is called component-averaged row projections, or CARP\textbackslash @. The system matrix can be general, nonsymmetric, and ill-conditioned, and the division into blocks is unrestricted. For partial differential equations (PDEs)\textbackslash @, if the blocks are domain-based, then only variables at the boundaries between domains are averaged, thereby minimizing data transfer between processors. CARP is very robust; its application to test cases of linear systems derived from PDEs shows that it converges in difficult cases where state-of-the-art methods fail. It is also very memory efficient and exhibits an almost linear speedup ratio, with efficiency greater than unity in some cases. A formal proof of convergence is presented: It is shown that the component-averaging operations are equivalent to row projections in a certain superspace, so the convergence properties of CARP are identical to those of Kaczmarz's algorithm in the superspace. CARP and its convergence proof also apply to the consistent convex feasibility problem.},
  keywords = {15A06,65F10,65F50,65N12,65Y05,90C51,block-parallel,component-averaging,convex feasibility problem,domain decomposition,linear equations,parallel processing,partial differential equations,row projections,sparse linear systems,superspace},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\I3HTFMUV\\Gordon und Gordon - 2005 - Component-Averaged Row Projections A Robust, Bloc.pdf}
}

@article{Gordon2009,
  title = {Coverage-based treatment planning: optimizing the {{IMRT PTV}} to meet a {{CTV}} coverage criterion.},
  author = {Gordon, J J and Siebers, J V},
  date = {2009},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {36},
  number = {3},
  eprint = {19378757},
  eprinttype = {pmid},
  pages = {961--973},
  issn = {00942405},
  doi = {10.1118/1.3075772},
  abstract = {This work demonstrates an iterative approach-referred to as coverage-based treatment planning-designed to produce treatment plans that ensure target coverage for a specified percentage of setup errors. In this approach the clinical target volume to planning target volume (CTV-to-PTV) margin is iteratively adjusted until the specified CTV coverage is achieved. The advantage of this approach is that it automatically compensates for the dosimetric margin around the CTV, i.e., the extra margin that is created when the dose distribution extends beyond the PTV. When applied to 27 prostate plans, this approach reduced the average CTV-to-PTV margin from 5 to 2.8 mm. This reduction in PTV size produced a corresponding decrease in the volume of normal tissue receiving high dose. The total volume of tissue receiving {$>$} or =65 Gy was reduced on average by 19.3\% or about 48 cc. Individual reductions varied from 8.7\% to 28.6\%. The volume of bladder receiving {$>$} or =60 Gy was reduced on average by 5.6\% (reductions for individuals varied from 1.7\% to 10.6\%), and the volume of periprostatic rectum receiving {$>$} or =65 Gy was reduced on average by 4.9\% (reductions for individuals varied from 0.9\% to 12.3\%). The iterative method proposed here represents a step toward a probabilistic treatment planning algorithm which can generate dose distributions (i.e., treated volumes) that closely approximate a specified level of coverage in the presence of geometric uncertainties. The general principles of coverage-based treatment planning are applicable to arbitrary treatment sites and delivery techniques. Importantly, observed deviations between coverage implied by specified CTV-to-PTV margins and coverage achieved by a given treatment plan imply a generic need to perform coverage probability analysis on a per-plan basis to ensure that the desired level of coverage is achieved.},
  keywords = {imrt,margins,prostate,radiotherapy,setup errors},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\B66I46NR\\Gordon, Siebers - 2009 - Coverage-based treatment planning optimizing the IMRT PTV to meet a CTV coverage criterion.pdf}
}

@article{Gordon2010,
  title = {Coverage optimized planning: probabilistic treatment planning based on dose coverage histogram criteria.},
  author = {Gordon, J J and Sayah, N and Weiss, E and Siebers, J V},
  date = {2010},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {37},
  number = {2},
  eprint = {20229863},
  eprinttype = {pmid},
  pages = {550--563},
  issn = {00942405},
  doi = {10.1118/1.3273063},
  abstract = {This work (i) proposes a probabilistic treatment planning framework, termed coverage optimized planning (COP), based on dose coverage histogram (DCH) criteria; (ii) describes a concrete proof-of-concept implementation of COP within the PINNACLE treatment planning system; and (iii) for a set of 28 prostate anatomies, compares COP plans generated with this implementation to traditional PTV-based plans generated with planning criteria approximating those in the high dose arm of the Radiation Therapy Oncology Group 0126 protocol. Let Dv denote the dose delivered to fractional volume v of a structure. In conventional intensity modulated radiation therapy planning, Dv has a unique value derived from the static (planned) dose distribution. In the presence of geometric uncertainties (e.g., setup errors) Dv assumes a range of values. The DCH is the complementary cumulative distribution function of D(v+). DCHs are similar to dose volume histograms (DVHs). Whereas a DVH plots volume v versus dose D, a DCH plots coverage probability Q versus D. For a given patient, Q is the probability (i.e., percentage of geometric uncertainties) for which the realized value of Dv exceeds D. PTV-based treatment plans can be converted to COP plans by replacing DVH optimization criteria with corresponding DCH criteria. In this approach, PTVs and planning organ at risk volumes are discarded, and DCH criteria are instead applied directly to clinical target volumes (CTVs) or organs at risk (OARs). Plans are optimized using a similar strategy as for DVH criteria. The specific implementation is described. COP was found to produce better plans than standard PTV-based plans, in the following sense. While target OAR dose tradeoff curves were equivalent to those for PTV-based plans, COP plans were able to exploit slack in OAR doses, i.e., cases where OAR doses were below their optimization limits, to increase target coverage. Specifically, because COP plans were not constrained by a predefined PTV, they were able to provide wider dosimetric margins around the CTV, by pushing OAR doses up to, but not beyond, their optimization limits. COP plans demonstrated improved target coverage when averaged over all 28 prostate anatomies, indicating that the COP approach can provide benefits for many patients. However, the degree to which slack OAR doses can be exploited to increase target coverage will vary according to the individual patient anatomy. The proof-of-concept COP implementation investigated here utilized a probabilistic DCH criteria only for the CTV minimum dose criterion. All other optimization criteria were conventional DVH criteria. In a mature COP implementation, all optimization criteria will be DCH criteria, enabling direct planning control over probabilistic dose distributions. Further research is necessary to determine the benefits of COP planning, in terms of tumor control probability and/or normal tissue complication probabilities.},
  keywords = {imrt,margins,prostate,radiotherapy,setup errors},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\2US3X2XV\\Gordon et al. - 2010 - Coverage optimized planning probabilistic treatment planning based on dose coverage histogram criteria.pdf}
}

@article{Gorissen2019,
  title = {Guaranteed \$\textbackslash varepsilon\$ -optimal solutions with the linear optimizer {{ART3}}+{{O}}},
  author = {Gorissen, Bram L},
  date = {2019-04-04},
  journaltitle = {Physics in Medicine \& Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {64},
  number = {7},
  pages = {075017},
  issn = {1361-6560},
  doi = {10.1088/1361-6560/ab0a2e},
  url = {https://iopscience.iop.org/article/10.1088/1361-6560/ab0a2e},
  urldate = {2020-06-09},
  abstract = {The linear optimization algorithm ART3+O introduced by Chen et al (2010 Med. Phys. 37 4938–45) can efficiently solve large scale inverse planning problems encountered in radiation therapy by iterative projection. Its major weakness is that it cannot guarantee ε-optimality of the final solution due to an arbitrary stopping criterion. We propose an improvement to ART3+O where the stopping criterion is based on Farkas’ lemma. The same theory can be used to detect inconsistency in other projection methods as well. The proposed algorithm guarantees to find an ε-optimal solution in finite time. The algorithm is demonstrated on numerical examples in radiation therapy.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\TPK2JT6Z\\Gorissen - 2019 - Guaranteed $varepsilon$ -optimal solutions with t.pdf}
}

@article{Gottschalk1993,
  title = {Multiple {{Coulomb}} scattering of 160 {{MeV}} protons},
  author = {Gottschalk, B. and Koehler, A.M. and Schneider, R.J. and Sisterson, J.M. and Wagner, M.S.},
  date = {1993-06-01},
  journaltitle = {Nuclear Instruments and Methods in Physics Research Section B: Beam Interactions with Materials and Atoms},
  volume = {74},
  number = {4},
  pages = {467--490},
  publisher = {{North-Holland}},
  issn = {0168583X},
  doi = {10.1016/0168-583X(93)95944-Z},
  url = {https://www.sciencedirect.com/science/article/pii/0168583X9395944Z},
  urldate = {2018-04-16},
  abstract = {We have measured multiple Coulomb scattering of 158.6 MeV protons in fourteen materials from beryllium to uranium including brass and several plastics. Targets ranged from thin (negligible energy loss) to very thick (greater than the mean proton range). The angular distribution was measured by means of a single diode dosimeter scanned typically over two decades of dose falloff. Each data set was fitted with a Molière scattering distribution (using Bethe's tables) to extract a characteristic angle θM as well as a Gaussian distribution to extract a characteristic angle θ0. As expected in the small angle region, the Gaussian fits about as well as the Molière shape. The θM values were compared with Molière's predicted value (χcB2) including Fano's correction for scattering by atomic electrons and using Molière's formalism to account for energy loss and/or compound targets or mixtures. The distribution of the deviation from theory for 115 independent measurements is approximately normal, with a mean value − 0.5 ± 0.4\% and an rms spread of 5\%. The θ0 values were compared with Highland's formula and with an “improved Highland” formula of Lynch and Dahl, using our own generalization to thick targets. The overall accuracy of Highland's formula is slightly worse than that of Molière theory. The distribution of the deviation from theory for 115 independent measurements is normal, with a mean value − 2.6 ± 0.5\% and an rms spread of 6\%. The Lynch formula gives nearly the same average statistics though details of the fit are different. Some data were taken for very thick targets (thickness greater than 97\% of the mean proton range) where only a fraction of the incident protons emerge. Here the characteristic angle appears to level off or even to fall slightly with target thickness perhaps due to the filtering out of large-angle protons. These measurements are presented but were excluded from the comparison with theory. We have reviewed six other published proton measurements, partially reanalyzing four whose authors claimed that Molière theory either did not apply (because of thick targets) or was incorrect. These experiments range from 1 MeV to 200 GeV incident energy. Averaging each measurement including our own over everything but target material we obtain 39 independent measurements of the deviation from theory whose distribution is normal with a mean value − 0.3 ± 0.5\% and an rms spread of 3\%. We conclude that Molière theory with the Fano correction is accurate to better than 1\% on the average for protons. Systematic discrepancies on the order of a few percent with target thickness and/or target material cannot be ruled out at present. In particular there is some indication that the theory may be ≈ 4\% high for the highest-Z materials.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\5PLKQJBX\\Gottschalk et al. - 1993 - Multiple Coulomb scattering of 160 MeV protons.pdf}
}

@article{Gottschalk2015,
  title = {On the nuclear halo of a proton pencil beam stopping in water},
  author = {Gottschalk, Bernard and Cascio, Ethan W and Daartz, Juliane and Wagner, Miles S},
  date = {2015-07-21},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {60},
  number = {14},
  pages = {5627--5654},
  issn = {0031-9155, 1361-6560},
  doi = {10.1088/0031-9155/60/14/5627},
  url = {https://iopscience.iop.org/article/10.1088/0031-9155/60/14/5627},
  urldate = {2020-06-15},
  abstract = {The dose distribution of a proton beam stopping in water has components due to basic physics and may have others from beam contamination. We propose the concise terms core for the primary beam, halo (see Pedroni et al 2005 Phys. Med. Biol. 50 541–61) for the low dose region from charged secondaries, aura for the low dose region from neutrals, and spray for beam contamination.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\I2WZTN4U\\Gottschalk et al. - 2015 - On the nuclear halo of a proton pencil beam stoppi.pdf}
}

@book{Gradshtein2000,
  title = {Table of integrals, series, and products},
  author = {Gradshteĭn, Izrailʹ Solomonovich and Ryzhik, Iosif Moiseevich},
  editor = {Jeffrey, Alan and Zwillinger, Daniel},
  date = {2000},
  edition = {6},
  publisher = {{Academic Press}},
  location = {{San Diego}},
  url = {https://www.sciencedirect.com/science/book/9780122947575},
  urldate = {2018-03-22},
  isbn = {978-0-12-294757-5},
  pagetotal = {1163}
}

@incollection{Gradshtein2000a,
  title = {Definite {{Integrals}} of {{Elementary Functions}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  author = {Gradshteĭn, Izrailʹ Solomonovich and Ryzhik, Iosif Moiseevich},
  editor = {Jeffrey, Alan and Zwillinger, Daniel},
  date = {2000},
  edition = {6},
  pages = {243--614},
  publisher = {{Academic Press}},
  location = {{San Diego}},
  doi = {10.1016/B978-012294757-5/50010-6},
  url = {http://linkinghub.elsevier.com/retrieve/pii/B9780122947575500106},
  urldate = {2018-03-22},
  abstract = {This chapter discusses power and algebraic functions, exponential functions, hyperbolic functions, the change of variable in a definite integral, general formulas, improper integrals, the principal values of improper integrals, and trigonometric functions. The definitions of definite and multiple integrals are omitted because they are widely known and can easily be found in any textbook on the subject. Only certain theorems of a general nature that provide estimates, or that reduce the given integral to a simpler one are given. Expressions that can be reduced to square roots of third-and fourth-degree polynomials and their products with rational functions are also described.},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\K8PJIBAP\\Gradshteĭn, Ryzhik - 2000 - Definite Integrals of Elementary Functions.pdf}
}

@unpublished{Grasedyck2013,
  title = {A literature survey of low-rank tensor approximation techniques},
  author = {Grasedyck, Lars and Kressner, Daniel and Tobler, Christine},
  date = {2013-02-28},
  eprint = {1302.7121},
  eprinttype = {arxiv},
  issn = {09367195},
  doi = {10.1002/gamm.201310004},
  url = {http://arxiv.org/abs/1302.7121},
  abstract = {During the last years, low-rank tensor approximation has been established as a new tool in scientific computing to address large-scale linear and multilinear algebra problems, which would be intractable by classical techniques. This survey attempts to give a literature overview of current developments in this area, with an emphasis on function-related tensors.},
  archiveprefix = {arXiv},
  keywords = {eigenvalue problems,linear systems,low rank,multivariate functions,tensor},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\KZWZAUT7\\Grasedyck, Kressner, Tobler - 2013 - A literature survey of low-rank tensor approximation techniques.pdf}
}

@article{Grau2020,
  title = {Particle therapy in {{Europe}}},
  author = {Grau, Cai and Durante, Marco and Georg, Dietmar and Langendijk, Johannes A. and Weber, Damien C.},
  date = {2020-07},
  journaltitle = {Molecular Oncology},
  shortjournal = {Mol Oncol},
  volume = {14},
  number = {7},
  eprint = {32223048},
  eprinttype = {pmid},
  pages = {1492--1499},
  issn = {1574-7891},
  doi = {10.1002/1878-0261.12677},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7332216/},
  urldate = {2022-05-30},
  abstract = {Particle therapy using protons or heavier ions is currently the most advanced form of radiotherapy and offers new opportunities for improving cancer care and research. Ions deposit the dose with a sharp maximum – the Bragg peak – and normal tissue receives a much lower dose than what is delivered by X‐ray therapy. Particle therapy has also biological advantages due to the high linear energy transfer of the charged particles around the Bragg peak. The introduction of particle therapy has been slow in Europe, but within the last decade, more than 20 clinical facilities have opened and facilitated access to this frontline therapy. In this review article, the basic concepts of particle therapy are reviewed along with a presentation of the current clinical indications, the European clinical research, and the established networks., Particle therapy using protons, or heavier ions, is the most advanced form of radiotherapy today and offers new opportunities for improving cancer care and research. Within the last decade, more than 20 new clinical facilities have opened in Europe, facilitating access to this frontline therapy. This review presents the physics, biology, and clinical aspects of particle therapy.},
  pmcid = {PMC7332216},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\NFR8SGZL\\Grau et al. - 2020 - Particle therapy in Europe.pdf}
}

@article{Gregoire2011,
  title = {State of the art on dose prescription, reporting and recording in {{Intensity-Modulated Radiation Therapy}} ({{ICRU}} report {{No}}. 83).},
  author = {Grégoire, V and Mackie, T R},
  date = {2011-10},
  journaltitle = {Cancer radiothérapie : journal de la Société française de radiothérapie oncologique},
  volume = {15},
  number = {6-7},
  eprint = {21802333},
  eprinttype = {pmid},
  pages = {555--9},
  issn = {1769-6658},
  doi = {10.1016/j.canrad.2011.04.003},
  url = {http://www.sciencedirect.com/science/article/pii/S1278321811000989},
  urldate = {2014-02-27},
  abstract = {The International Commission on Radiation Units and Measurements (ICRU) report No. 83 provides the information necessary to standardize techniques and procedures and to harmonize the prescribing, recording, and reporting of intensity modulated radiation therapy. Applicable concepts and recommendations in previous ICRU reports concerning radiation therapy were adopted, and new concepts were elaborated. In particular, additional recommendations were given on the selection and delineation of the targets volumes and the organs at risk; concepts of dose prescription and dose-volume reporting have also been refined.},
  keywords = {Forms and Records Control,Humans,Intensity-Modulated,Intensity-Modulated: standards,International Agencies,Medical Records,Medical Records: standards,Neoplasms,Neoplasms: pathology,Neoplasms: radiotherapy,Prescriptions,Radiotherapy Dosage,Radiotherapy; Intensity-Modulated,Radiotherapy; Intensity-Modulated: standards,Research Report,Software Design,Tumor Burden},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\QWLZG5CB\\Grégoire, Mackie - 2011 - State of the art on dose prescription, reporting and recording in Intensity-Modulated Radiation Therapy (ICRU.pdf}
}

@incollection{Grevera2007,
  title = {Distance {{Transform Algorithms And Their Implementation And Evaluation}}},
  booktitle = {Deformable {{Models SE}} - 2},
  author = {Grevera, GeorgeJ.},
  date = {2007},
  series = {Topics in {{Biomedical Engineering}}. {{International Book Series}}},
  pages = {33--60},
  publisher = {{Springer New York}},
  doi = {10.1007/978-0-387-68413-0_2},
  url = {http://dx.doi.org/10.1007/978-0-387-68413-0_2},
  isbn = {978-0-387-31201-9},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Z5QTR69D\\Grevera - 2007 - Distance Transform Algorithms And Their Implementation And Evaluation.pdf}
}

@book{Griewank2008,
  title = {Evaluating {{Derivatives}}},
  author = {Griewank, Andreas and Walther, Andrea},
  date = {2008-01-01},
  series = {Other {{Titles}} in {{Applied Mathematics}}},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9780898717761},
  url = {https://epubs.siam.org/doi/book/10.1137/1.9780898717761},
  urldate = {2020-06-10},
  abstract = {The advent of high-speed computers and sophisticated software tools has made the computation of derivatives for functions defined by evaluation programs both easier and more important. On one hand, the dependence of certain program outputs on certain input parameters can now be determined and quantified more or less automatically, i.e., without the user having to append or rewrite the function evaluation procedure. On the other hand, such qualitative and quantitative dependence analysis is invaluable for the optimization of key output objectives with respect to suitable decision variables or the identification of model parameters with respect to given data. In fact, we may juxtapose the mere simulation of a physical or social system by the repeated running of an appropriate computer model for various input data with its optimization by a systematic adjustment of certain decision variables and model parameters. The transition from the former computational paradigm to the latter may be viewed as a central characteristic of present-day scientific computing. Optimization nowadays already forms an important application area for exact derivative calculation using algorithmic differentiation. This includes the provision of gradients and Hessians for the unconstrained case, as, for example, in nonlinear finite element calculations [Wri08], the optimal laser control of chemical reactions [BCL01] or the optimization of low-pass analog filters [Alk98]. In the constrained case, algorithmic differentiation can be used to compute the required Jacobians, Hessians, or Hessian-vector products. Here, the applications areas include chemical engineering [AB04], race car performance [CS+01], and industrial production processes [KW00]. Since 1997 the Network Enabled Optimization Server (NEOS) at Argonne National Laboratory has been using algorithmic differentiation to compute gradients and Jacobians of remotely supplied user code for optimization objectives and constraints [CMM97]. The modelling language AMPL and GAMS have incorporated both modes of algorithmic differentiation to provide first and second derivatives for various optimization solvers. Also multicriteria optimization benefits from exact derivatives, e.g., to optimize medical radiotherapy [JMF06]. For the field of parameter estimation, algorithmic differentiation is used to improve, for example, weather models [GK+06] or the simulation of the climate [KHL06]. The cover shows the independence between various vector quantities in optimal design as discussed in Chapter 15 superimposed on a global sensitivity map. It was provided to us by Patrick Heimbach of MIT and represents the derivative of the poleward heat transfer with respect to local maritime temperatures.},
  isbn = {978-0-89871-659-7},
  pagetotal = {448},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\KPNYQL29\\Griewank und Walther - 2008 - Evaluating Derivatives.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\PU3J6TY7\\1.html}
}

@article{Gu2019,
  title = {Robust {{Beam Orientation Optimization}} for {{Intensity}}‐{{Modulated Proton Therapy}}},
  author = {Gu, Wenbo and Neph, Ryan and Ruan, Dan and Zou, Wei and Dong, Lei and Sheng, Ke},
  date = {2019-06-06},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  issn = {0094-2405, 2473-4209},
  doi = {10.1002/mp.13641},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mp.13641},
  urldate = {2019-10-30},
  abstract = {Purpose: Dose conformality and robustness are equally important in intensity modulated proton therapy (IMPT). Despite the obvious implication of beam orientation on both dosimetry and robustness, an automated, robust beam orientation optimization algorithm has not been incorporated due to the problem complexity and paramount computational challenge. In this study, we developed a novel IMPT framework that integrates robust beam orientation optimization (BOO) and robust fluence map optimization (FMO) in a unified framework. Methods: The unified framework is formulated to include a dose fidelity term, a heterogeneityweighted group sparsity term, and a sensitivity regularization term. The L2, 1/2-norm group sparsity is used to reduce the number of active beams from the initial 1162 evenly distributed noncoplanar candidate beams, to between two and four. A heterogeneity index, which evaluates the lateral tissue heterogeneity of a beam, is used to weigh the group sparsity term. With this index, beams more resilient to setup uncertainties are encouraged. There is a symbiotic relationship between the heterogeneity index and the sensitivity regularization; the integrated optimization framework further improves beam robustness against both range and setup uncertainties. This Sensitivity regularization and Heterogeneity weighting based BOO and FMO framework (SHBOO-FMO) was tested on two skullbase tumor (SBT) patients and two bilateral head-and-neck (H\&N) patients. The conventional CTVbased optimized plans (Conv) with SHBOO-FMO beams (SHBOO-Conv) and manual beams (MAN-Conv) were compared to investigate the beam robustness of the proposed method. The dosimetry and robustness of SHBOO-FMO plan were compared against the manual beam plan with CTV-based voxel-wise worst-case scenario approach (MAN-WC). Results: With SHBOO-FMO method, the beams with superior range robustness over manual beams were selected while the setup robustness was maintained or improved. On average, the lowest [D95\%, V95\%, V100\%] of CTV were increased from [93.85\%, 91.06\%, 70.64\%] in MAN-Conv plans, to [98.62\%, 98.61\%, 96.17\%] in SHBOO-Conv plans with range uncertainties. With setup uncertainties, the average lowest [D98\%, D95\%, V95\%, V100\%] of CTV were increased from [92.06\%, 94.83\%, 94.31\%, 78.93\%] in MAN-Conv plans, to [93.54\%, 96.61\%, 97.01\%, 91.98\%] in SHBOO-Conv plans. Compared with the MAN-WC plans, the final SHBOO-FMO plans achieved comparable plan robustness and better OAR sparing, with an average reduction of [Dmean, Dmax] of [6.31, 6.55] GyRBE for the SBT cases and [1.89, 5.08] GyRBE for the H\&N cases from the MAN-WC plans. Conclusion: We developed a novel method to integrate robust BOO and robust FMO into IMPT optimization for a unified solution of both BOO and FMO, generating plans with superior dosimetry and good robustness. © 2019 American Association of Physicists in Medicine [https://doi.org/ 10.1002/mp.13641]},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\4YDWU4PM\\Gu et al. - 2019 - Robust Beam Orientation Optimization for Intensity.pdf}
}

@article{Gu2019a,
  title = {Robust optimization for intensity-modulated proton therapy with soft spot sensitivity regularization},
  author = {Gu, Wenbo and Ruan, Dan and O'Connor, Daniel and Zou, Wei and Dong, Lei and Tsai, Min-Yu and Jia, Xun and Sheng, Ke},
  date = {2019-03},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {46},
  number = {3},
  pages = {1408--1425},
  issn = {00942405},
  doi = {10.1002/mp.13344},
  url = {http://doi.wiley.com/10.1002/mp.13344},
  urldate = {2019-10-30},
  abstract = {Purpose: Proton dose distribution is sensitive to uncertainties in range estimation and patient positioning. Currently, the proton robustness is managed by worst-case scenario optimization methods, which are computationally inefficient. To overcome these challenges, we develop a novel intensitymodulated proton therapy (IMPT) optimization method that integrates dose fidelity with a sensitivity term that describes dose perturbation as the result of range and positioning uncertainties. Methods: In the integrated optimization framework, the optimization cost function is formulated to include two terms: a dose fidelity term and a robustness term penalizing the inner product of the scanning spot sensitivity and intensity. The sensitivity of an IMPT scanning spot to perturbations is defined as the dose distribution variation induced by range and positioning errors. To evaluate the sensitivity, the spatial gradient of the dose distribution of a specific spot is first calculated. The spot sensitivity is then determined by the total absolute value of the directional gradients of all affected voxels. The fast iterative shrinkage-thresholding algorithm is used to solve the optimization problem. This method was tested on three skull base tumor (SBT) patients and three bilateral head-and-neck (H\&N) patients. The proposed sensitivity-regularized method (SenR) was implemented on both clinic target volume (CTV) and planning target volume (PTV). They were compared with conventional PTV-based optimization method (Conv) and CTV-based voxel-wise worst-case scenario optimization approach (WC). Results: Under the nominal condition without uncertainties, the three methods achieved similar CTV dose coverage, while the CTV-based SenR approach better spared organs at risks (OARs) compared with the WC approach, with an average reduction of [Dmean, Dmax] of [4.72, 3.38] GyRBE for the SBT cases and [2.54, 3.33] GyRBE for the H\&N cases. The OAR sparing of the PTV-based SenR method was comparable with the WC method. The WC method, and SenR approaches all improved the plan robustness from the conventional PTV-based method. On average, under range uncertainties, the lowest [D95\%, V95\%, V100\%] of CTV were increased from [93.75\%, 88.47\%, 47.37\%] in the Conv method, to [99.28\%, 99.51\%, 86.64\%] in the WC method, [97.71\%, 97.85\%, 81.65\%] in the SenR-CTV method and [98.77\%, 99.30\%, 85.12\%] in the SenR-PTV method, respectively. Under setup uncertainties, the average lowest [D95\%, V95\%, V100\%] of CTV were increased from [95.35\%, 94.92\%, 65.12\%] in the Conv method, to [99.43\%, 99.63\%, 87.12\%] in the WC method, [96.97\%, 97.13\%, 77.86\%] in the SenR-CTV method, and [98.21\%, 98.34\%, 83.88\%] in the SenR-PTV method, respectively. The runtime of the SenR optimization is eight times shorter than that of the voxel-wise worst-case method. Conclusion: We developed a novel computationally efficient robust optimization method for IMPT. The robustness is calculated as the spot sensitivity to both range and shift perturbations. The dose fidelity term is then regularized by the sensitivity term for the flexibility and trade-off between the dosimetry and the robustness. In the stress test, SenR is more resilient to unexpected uncertainties. These advantages in combination with its fast computation time make it a viable candidate for clinical IMPT planning. © 2018 American Association of Physicists in Medicine [https://doi.org/10.1002/ mp.13344]},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\AWSLVNC6\\Gu et al. - 2019 - Robust optimization for intensity-modulated proton.pdf}
}

@article{Guan2009,
  title = {Dose calculation accuracy using cone-beam {{CT}} ({{CBCT}}) for pelvic adaptive radiotherapy},
  author = {Guan, Huaiqun and Dong, Hang},
  date = {2009-10},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {54},
  number = {20},
  pages = {6239--6250},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/54/20/013},
  url = {https://doi.org/10.1088/0031-9155/54/20/013},
  urldate = {2022-08-15},
  abstract = {This study is to evaluate the dose calculation accuracy using Varian's cone-beam CT (CBCT) for pelvic adaptive radiotherapy. We first calibrated the Hounsfield Unit (HU) to electron density (ED) for CBCT using a mini CT QC phantom embedded into an IMRT QA phantom. We then used a Catphan 500 with an annulus around it to check the calibration. The combined CT QC and IMRT phantom provided correct HU calibration, but not Catphan with an annulus. For the latter, not only was the Teflon an incorrect substitute for bone, but the inserts were also too small to provide correct HUs for air and bone. For the former, three different scan ranges (6 cm, 12 cm and 20.8 cm) were used to investigate the HU dependence on the amount of scatter. To evaluate the dose calculation accuracy, CBCT and plan-CT for a pelvic phantom were acquired and registered. The single field plan, 3D conformal and IMRT plans were created on both CT sets. Without inhomogeneity correction, the two CT generated nearly the same plan. With inhomogeneity correction, the dosimetric difference between the two CT was mainly from the HU calibration difference. The dosimetric difference for 6 MV was found to be the largest for the single lateral field plan (maximum 6.7\%), less for the 3D conformal plan (maximum 3.3\%) and the least for the IMRT plan (maximum 2.5\%). Differences for 18 MV were generally 1–2\% less. For a single lateral field, calibration with 20.8 cm achieved the minimum dosimetric difference. For 3D and IMRT plans, calibration with a 12 cm range resulted in better accuracy. Because Catphan is the standard QA phantom for the on-board imager (OBI) device, we specifically recommend not using it for the HU calibration of CBCT.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\2H4FRRIV\\Guan und Dong - 2009 - Dose calculation accuracy using cone-beam CT (CBCT.pdf}
}

@article{Guenter2022,
  title = {Superiorization versus regularization: {{A}} comparison of algorithms for solving image reconstruction problems with applications in computed tomography},
  shorttitle = {Superiorization versus regularization},
  author = {Guenter, Maria and Collins, Steve and Ogilvy, Andy and Hare, Warren and Jirasek, Andrew},
  date = {2022},
  journaltitle = {Medical Physics},
  volume = {49},
  number = {2},
  pages = {1065--1082},
  issn = {2473-4209},
  doi = {10.1002/mp.15373},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mp.15373},
  urldate = {2022-06-17},
  abstract = {Purpose A system matrix can be built in order to account for the refractions in an optical computed tomography (CT) system. In order to utilize this system matrix, iterative methods are employed to solve the image reconstruction problem. The purpose of this study is to compare potential iterative algorithms to solve this image reconstruction problem. Comparisons examine both solution time and the quality of the reconstructed image. While our work is motivated by optical CT, the results can be extended more generally to CT. Methods A collection of 21 algorithms for solving the image reconstruction problem were evaluated. Specifically, algorithms using (i) superiorization techniques and (ii) regularization to avoid overfitting were compared. Multiple test problems are investigated using 18 different image phantoms, parallel-beam and fan-beam system matrices, and varying noise levels. Comparison of the algorithms is done using performance profiles on three different performance measures. Results The results for both the synthetic and clinical test problems show that there is not one single algorithm outperforming all others, but instead a set of top algorithms that give the best values on the performance profiles. When qualitative analyses such as reliance on stopping conditions, number of input parameters, and run time are also considered, FISTA-TV shows slight advantages over the other top algorithms. Conclusions There is a set of top algorithms that all show good results in the performance profiles with a mix of superiorized and regularized model algorithms. As to which of these top algorithms outperforms the rest is undetermined and further research needs to be investigated.},
  langid = {english},
  keywords = {gel dosimetry,image reconstruction,iterative algorithms,optical computed tomography,regularization,superiorization},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mp.15373},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\FIX9RXHT\\mp.html}
}

@inproceedings{Gustafsson2008,
  title = {On nonlinear transformations of stochastic variables and its application to nonlinear filtering},
  booktitle = {2008 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}}},
  author = {Gustafsson, Fredrik and Hendeby, Gustaf},
  date = {2008-03},
  pages = {3617--3620},
  publisher = {{IEEE}},
  issn = {1520-6149},
  doi = {10.1109/ICASSP.2008.4518435},
  url = {http://ieeexplore.ieee.org/document/4518435/},
  urldate = {2018-04-29},
  isbn = {978-1-4244-1483-3},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\W7JHCX7X\\Gustafsson, Hendeby - 2008 - On nonlinear transformations of stochastic variables and its application to nonlinear filtering.pdf}
}

@article{Gustafsson2012,
  title = {Some {{Relations Between Extended}} and {{Unscented Kalman Filters}}},
  author = {Gustafsson, Fredrik and Hendeby, Gustaf},
  date = {2012-02},
  journaltitle = {IEEE Transactions on Signal Processing},
  volume = {60},
  number = {2},
  pages = {545--555},
  issn = {1053-587X},
  doi = {10.1109/TSP.2011.2172431},
  url = {http://ieeexplore.ieee.org/document/6051522/},
  urldate = {2018-04-29},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\HHUUBHLN\\Gustafsson, Hendeby - 2012 - Some Relations Between Extended and Unscented Kalman Filters.pdf}
}

@article{Han2021,
  title = {Computed tomography imaging spectrometry based on superiorization and guided image filtering},
  author = {Han, Weizhe and Wang, Qianlong and Cai, Weiwei},
  date = {2021-05-01},
  journaltitle = {Optics Letters},
  shortjournal = {Opt. Lett., OL},
  volume = {46},
  number = {9},
  pages = {2208--2211},
  publisher = {{Optica Publishing Group}},
  issn = {1539-4794},
  doi = {10.1364/OL.418355},
  url = {https://opg.optica.org/ol/abstract.cfm?uri=ol-46-9-2208},
  urldate = {2022-06-17},
  abstract = {Computed tomography imaging spectrometry (CTIS) is a snapshot hyperspectral imaging technique that can obtain a three-dimensional (\$\{2D +\}\textbackslash lambda\$) data cube of the target scene within a single exposure. Previous studies of CTIS suggest that reconstructions usually suffer from severe artifacts due to the limited number of projections available. To overcome this limitation, an iterative algorithm combining superiorization and guided image filtering is proposed to explore the intrinsic properties of the hyperspectral data cube as well as the characteristics of zero-order diffraction for the first time, to the best of our knowledge. Results from both simulative studies and proof-of-concept experiments demonstrate its superiority in suppressing artifacts and improving precision over the frequently used expectation maximization algorithm.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\SGT4XGDK\\abstract.html}
}

@book{Hassler2011,
  title = {Digital {{Painting Workbook}}},
  author = {Hassler, Roger},
  date = {2011},
  publisher = {{newart medien \& design}},
  url = {http://www.amazon.com/Digital-Painting-Workbook-Roger-Hassler/dp/394165604X},
  urldate = {2014-02-19},
  isbn = {3-941656-04-X},
  pagetotal = {196}
}

@article{Heath2006,
  title = {A direct voxel tracking method for four-dimensional {{Monte Carlo}} dose calculations in deforming anatomy},
  author = {Heath, Emily and Seuntjens, Jan},
  date = {2006},
  journaltitle = {Medical Physics},
  volume = {33},
  number = {2},
  pages = {434--445},
  issn = {2473-4209},
  doi = {10.1118/1.2163252},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1118/1.2163252},
  urldate = {2022-08-11},
  abstract = {In this work we present a method of calculating dose in deforming anatomy where the position and shape of each dose voxel is tracked as the anatomy changes. The EGSnrc/DOSXYZnrc Monte Carlo code was modified to calculate dose in voxels that are deformed according to deformation vectors obtained from a nonlinear image registration algorithm. The defDOSXYZ code was validated by consistency checks and by comparing calculations against DOSXYZnrc calculations. Calculations in deforming phantoms were compared with a dose remapping method employing trilinear interpolation. Dose calculations with the deforming voxels agree with DOSXYZnrc calculations within 1\%. In simple deforming rectangular phantoms the trilinear dose remapping method was found to underestimate the dose by up to 29\% for a voxel size within the field, with larger discrepancies in regions of steep dose gradients. The agreement between the two calculation methods improved with smaller voxel size and deformation magnitude. A comparison of dose remapping from Inhale to Exhale in an anatomical breathing phantom demonstrated that dose deformations are underestimated by up to 16\% in the penumbra and 8\% near the surface with trilinear interpolation.},
  langid = {english},
  keywords = {Anatomy,Ancillary equipment,biomechanics,Computed tomography,curve fitting,deformable dose calculations,dosimetry,Dosimetry,image registration,Image registration,Image transforms,interpolation,Interpolation,Lungs,Medical image segmentation,Medical imaging,Monte Carlo,Monte Carlo methods,organ motion,Photons,radiation therapy,Simulation,treatment planning,Treatment strategy},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1118/1.2163252},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\6W4BMXNP\\Heath und Seuntjens - 2006 - A direct voxel tracking method for four-dimensiona.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\MSDTDIYG\\1.html}
}

@incollection{Heilmann2013,
  title = {History of {{Radiation Oncology}}},
  booktitle = {Encyclopedia of {{Radiation Oncology}}},
  author = {Heilmann, Hans-Peter},
  editor = {Brady, Luther W. and Yaeger, Theodore E.},
  date = {2013},
  pages = {314--325},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-85516-3_441},
  url = {https://doi.org/10.1007/978-3-540-85516-3_441},
  urldate = {2019-09-11},
  isbn = {978-3-540-85516-3},
  langid = {english}
}

@article{Heinrich2014,
  title = {{{GPU-accelerated}} ray-tracing for real-time treatment planning},
  author = {Heinrich, H and Ziegenhein, P and Kamerling, C P and Froening, H and Oelfke, U},
  date = {2014-03-24},
  journaltitle = {Journal of Physics: Conference Series},
  volume = {489},
  pages = {012050},
  issn = {1742-6588},
  doi = {10.1088/1742-6596/489/1/012050},
  url = {http://stacks.iop.org/1742-6596/489/i=1/a=012050?key=crossref.aeea10e5c9247c59b801022fb9fb58a0},
  urldate = {2018-02-28},
  abstract = {Dose calculation methods in radiotherapy treatment planning require the radiological depth information of the voxels that represent the patient volume to correct for tissue inhomogeneities. This information is acquired by time consuming ray-tracing-based calculations. For treatment planning scenarios with changing geometries and real-time constraints this is a severe bottleneck. We implemented an algorithm for the graphics processing unit (GPU) which implements a ray-matrix approach to reduce the number of rays to trace. Furthermore, we investigated the impact of different strategies of accessing memory in kernel implementations as well as strategies for rapid data transfers between main memory and memory of the graphics device. Our study included the overlapping of computations and memory transfers to reduce the overall runtime using Hyper-Q. We tested our approach on a prostate case (9 beams, coplanar). The measured execution times for a complete ray-tracing range from 28 msec for the computations on the GPU to 99 msec when considering data transfers to and from the graphics device. Our GPU-based algorithm performed the ray-tracing in real-time. The strategies efficiently reduce the time consumption of memory accesses and data transfer overhead. The achieved runtimes demonstrate the viability of this approach and allow improved real-time performance for dose calculation methods in clinical routine.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\SWWBKUSH\\Heinrich et al. - 2014 - GPU-accelerated ray-tracing for real-time treatment planning.pdf}
}

@unpublished{Hennig2009,
  title = {Expectation {{Propagation}} on the {{Maximum}} of {{Correlated Normal Variables}}},
  author = {Hennig, Philipp},
  date = {2009-10-01},
  eprint = {0910.0115},
  eprinttype = {arxiv},
  pages = {1--11},
  url = {http://arxiv.org/abs/0910.0115},
  abstract = {Many inference problems involving questions of optimality ask for the maximum or the minimum of a finite set of unknown quantities. This technical report derives the first two posterior moments of the maximum of two correlated Gaussian variables and the first two posterior moments of the two generating variables (corresponding to Gaussian approximations minimizing relative entropy). It is shown how this can be used to build a heuristic approximation to the maximum relationship over a finite set of Gaussian variables, allowing approximate inference by Expectation Propagation on such quantities.},
  archiveprefix = {arXiv},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\PMGGPCD5\\Hennig - 2009 - Expectation Propagation on the Maximum of Correlated Normal Variables.pdf}
}

@report{Hennig2013,
  title = {Animating {{Samples}} from {{Gaussian Distributions}}},
  author = {Hennig, Philipp},
  date = {2013},
  number = {8},
  institution = {{Max Planck Institute for Intelligent Systems}},
  location = {{Tübingen}},
  abstract = {The animations displayed below are animated samples from correlated Gaussian beliefs, following closed trajectories along equipotential lines of the probability distribution. They offer a more expressive view of the structure of samples from Gaussian processes than static samples. This document explains how to generate them, using Matlab, tikz, and L ATEX, in that order. If you do not see two animations with wobbly lines on the first proper page of this document, try opening it with Adobe Reader.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\ZFMXGY2I\\Hennig - 2013 - Animating Samples from Gaussian Distributions.pdf}
}

@article{Henning2012,
  title = {Kernel {{Topic Models}}},
  author = {Henning, P and Stern, David and Herbrich, Ralf and Graepel, Thore and Hennig, Philipp},
  date = {2012},
  journaltitle = {Proceedings of the 15th International Conference on Artificial Intelligence and Statistics (AISTATS)},
  volume = {22},
  eprint = {1110.4713},
  eprinttype = {arxiv},
  pages = {511--519},
  issn = {15337928},
  abstract = {Latent Dirichlet Allocation models discrete data as a mixture of discrete distributions, using Dirichlet beliefs over the mixture weights. We study a variation of this concept, in which the documents’ mixture weight beliefs are replaced with squashed Gaussian distributions. This allows documents to be associated with elements of a Hilbert space, admitting kernel topic models (KTM), modelling temporal, spatial, hierarchical, social and other structure between documents. The main challenge is efficient approximate inference on the latent Gaussian. We present an approximate algorithm cast around a Laplace approximation in a transformed basis. The KTM can also be interpreted as a type of Gaussian process latent variable model, or as a topic model conditional on document features, uncovering links between earlier work in these areas.},
  archiveprefix = {arXiv},
  keywords = {Kernel methods,Laplace approximation,topic models},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\EWF2GLUD\\Henning et al. - 2012 - Kernel Topic Models.pdf}
}

@article{Henriquez2008a,
  title = {The effect of the different uncertainty models in dose expected volume histogram computation},
  author = {Cutanda Henríquez, Francisco and Vargas Castrillón, Silvia},
  date = {2008},
  journaltitle = {Australasian Physical and Engineering Sciences in Medicine},
  shortjournal = {Australas Phys Eng Sci Med},
  volume = {31},
  number = {3},
  pages = {196--202},
  issn = {01589938},
  keywords = {dose,dose distribution,dose uncertainty,expected volume histogram,probability distribution,treatment planning system},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\9RY6ZHIC\\Henríquez, Castrillón - 2008 - The effect of the different uncertainty models in dose expected volume histogram computation.pdf}
}

@article{Henriquez2010,
  title = {Confidence intervals in dose volume histogram computation},
  author = {Cutanda Henríquez, Francisco and Vargas Castrillón, Silvia},
  date = {2010-03-15},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {37},
  number = {4},
  eprint = {20443475},
  eprinttype = {pmid},
  pages = {1545--1553},
  issn = {00942405},
  doi = {10.1118/1.3355888},
  url = {http://doi.wiley.com/10.1118/1.3355888},
  abstract = {Dose volume histograms (DVHs) are used in radiation therapy plan optimization and evaluation. Irradiation strategies are decided at the planning step, and an assessment of the reliability of computed dose distributions and DVHs is needed to ensure that decisions are made based on reliable information. This work describes a method used to assign confidence intervals to DVHs, caused by the uncertainty associated with dose computation.},
  keywords = {dose distribution,dose uncertainty,dose volume histogram,probability distribution,treatment planning system},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\854L3Y2T\\Henríquez, Castrillón - 2010 - Confidence intervals in dose volume histogram computation.pdf}
}

@book{Herlihy2012,
  title = {The art of multiprocessor programming},
  author = {Herlihy, Maurice. and Shavit, Nir},
  date = {2012},
  edition = {Rev. 1},
  publisher = {{Morgan Kaufmann}},
  location = {{Waltham, MA}},
  isbn = {978-0-12-397337-5},
  pagetotal = {508}
}

@article{Herman2012,
  title = {Superiorization: {{An}} optimization heuristic for medical physics},
  shorttitle = {Superiorization},
  author = {Herman, Gabor T. and Garduño, Edgar and Davidi, Ran and Censor, Yair},
  date = {2012-08-22},
  journaltitle = {Medical Physics},
  shortjournal = {Med. Phys.},
  volume = {39},
  number = {9},
  pages = {5532--5546},
  issn = {00942405},
  doi = {10.1118/1.4745566},
  url = {http://doi.wiley.com/10.1118/1.4745566},
  urldate = {2020-09-01},
  abstract = {Purpose: To describe and mathematically validate the superiorization methodology, which is a recently developed heuristic approach to optimization, and to discuss its applicability to medical physics problem formulations that specify the desired solution (of physically given or otherwise obtained constraints) by an optimization criterion. Methods: The superiorization methodology is presented as a heuristic solver for a large class of constrained optimization problems. The constraints come from the desire to produce a solution that is constraints-compatible, in the sense of meeting requirements provided by physically or otherwise obtained constraints. The underlying idea is that many iterative algorithms for finding such a solution are perturbation resilient in the sense that, even if certain kinds of changes are made at the end of each iterative step, the algorithm still produces a constraints-compatible solution. This property is exploited by using permitted changes to steer the algorithm to a solution that is not only constraints-compatible, but is also desirable according to a specified optimization criterion. The approach is very general, it is applicable to many iterative procedures and optimization criteria used in medical physics. Results: The main practical contribution is a procedure for automatically producing from any given iterative algorithm its superiorized version, which will supply solutions that are superior according to a given optimization criterion. It is shown that if the original iterative algorithm satisfies certain mathematical conditions, then the output of its superiorized version is guaranteed to be as constraintscompatible as the output of the original algorithm, but it is superior to the latter according to the optimization criterion. This intuitive description is made precise in the paper and the stated claims are rigorously proved. Superiorization is illustrated on simulated computerized tomography data of a head cross section and, in spite of its generality, superiorization is shown to be competitive to an optimization algorithm that is specifically designed to minimize total variation. Conclusions: The range of applicability of superiorization to constrained optimization problems is very large. Its major utility is in the automatic nature of producing a superiorization algorithm from an algorithm aimed at only constraints-compatibility; while nonheuristic (exact) approaches need to be redesigned for a new optimization criterion. Thus superiorization provides a quick route to algorithms for the practical solution of constrained optimization problems. © 2012 American Association of Physicists in Medicine. [http://dx.doi.org/10.1118/1.4745566]},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Q8D9PXIQ\\Herman et al. - 2012 - Superiorization An optimization heuristic for med.pdf}
}

@inproceedings{Herman2014,
  title = {Superiorization for {{Image Analysis}}},
  booktitle = {Proceedings of the 16th {{International Workshop}} on {{Combinatorial Image Analysis}}},
  author = {Herman, Gabor T.},
  date = {2014-05-28},
  series = {{{IWCIA}} 2014},
  volume = {8466},
  pages = {1--7},
  publisher = {{Springer-Verlag}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-319-07148-0_1},
  url = {https://doi.org/10.1007/978-3-319-07148-0_1},
  urldate = {2021-12-01},
  abstract = {Many scientific, engineering and medical applications of image analysis use constrained optimization, with the constraints arising from the desire to produce a solution that is constraints-compatible. It is typically the case that a large number of solutions would be considered good enough from the point of view of being constraints-compatible. In such a case, an optimization criterion is introduced that helps us to distinguish the "better" constraints-compatible solutions. The superiorization methodology is a recently-developed heuristic approach to constrained optimization. The underlying idea is that in many applications there exist computationally-efficient iterative algorithms that produce solutions that are constraints-compatible. Often the algorithm is perturbation resilient in the sense that, even if certain kinds of changes are made at the end of each iterative step, the algorithm still produces a constraints-compatible solution. This property is exploited in superiorization by using such perturbations to steer the algorithm to a solution that is not only constraints-compatible, but is also desirable according to a specified optimization criterion. The approach is very general, it is applicable to many iterative procedures and optimization criteria. Most importantly, superiorization is a totally automatic procedure that turns an iterative algorithm into its superiorized version. This, and its practical consequences in various application areas, have been investigated for a variety of constrained optimization tasks.},
  isbn = {978-3-319-07147-3},
  keywords = {Constrained optimization,Image processing,Perturbation resilient algorithm,Superiorization}
}

@article{Higham1988,
  title = {Computing a nearest symmetric positive semidefinite matrix},
  author = {Higham, Nicholas J.},
  date = {1988-05-01},
  journaltitle = {Linear Algebra and its Applications},
  volume = {103},
  pages = {103--118},
  publisher = {{North-Holland}},
  issn = {00243795},
  doi = {10.1016/0024-3795(88)90223-6},
  url = {https://www.sciencedirect.com/science/article/pii/0024379588902236},
  urldate = {2018-03-05},
  abstract = {The nearest symmetric positive semidefinite matrix in the Frobenius norm to an arbitrary real matrix A is shown to be (B + H)/2, where H is the symmetric polar factor of B=(A + AT)/2. In the 2-norm a nearest symmetric positive semidefinite matrix, and its distance δ2(A) from A, are given by a computationally challenging formula due to Halmos. We show how the bisection method can be applied to this formula to compute upper and lower bounds for δ2(A) differing by no more than a given amount. A key ingredient is a stable and efficient test for positive definiteness, based on an attempted Choleski decomposition. For accurate computation of δ2(A) we formulate the problem as one of zero finding and apply a hybrid Newton-bisection algorithm. Some numerical difficulties are discussed and illustrated by example.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\ZLQPI3CF\\Higham - 1988 - Computing a nearest symmetric positive semidefinite matrix.pdf}
}

@article{Hinson2008,
  title = {Photon spectral characteristics of dissimilar 6 {{MV}} linear accelerators.},
  author = {Hinson, William H and Kearns, William T and {deGuzman}, Allan F and Bourland, J Daniel},
  date = {2008-05},
  journaltitle = {Medical physics},
  volume = {35},
  number = {5},
  eprint = {18561644},
  eprinttype = {pmid},
  pages = {1698--702},
  issn = {0094-2405},
  abstract = {This work measures and compares the energy spectra of four dosimetrically matched 6 MV beams, generated from four physically different linear accelerators. The goal of this work is twofold. First, this study determines whether the spectra of dosimetrically matched beams are measurably different. This study also demonstrates that the spectra of clinical photon beams can be measured as a part of the beam data collection process for input to a three-dimensional (3D) treatment planning system. The spectra of 6 MV beams that are dosimetrically matched for clinical use were studied to determine if the beam spectra are similarly matched. Each of the four accelerators examined had a standing waveguide, but with different physical designs. The four accelerators were two Varian 2100C/Ds (one 6 MV/18 MV waveguide and one 6 MV/10 MV waveguide), one Varian 600 C with a vertically mounted waveguide and no bending magnet, and one Siemens MD 6740 with a 6 MV/10 MV waveguide. All four accelerators had percent depth dose curves for the 6 MV beam that were matched within 1.3\%. Beam spectra were determined from narrow beam transmission measurements through successive thicknesses of pure aluminum along the central axis of the accelerator, made with a graphite Farmer ion chamber with a Lucite buildup cap. An iterative nonlinear fit using a Marquardt algorithm was used to find each spectrum. Reconstructed spectra show that all four beams have similar energy distributions with only subtle differences, despite the differences in accelerator design. The measured spectra of different 6 MV beams are similar regardless of accelerator design. The measured spectra show excellent agreement with those found by the auto-modeling algorithm in a commercial 3D treatment planning system that uses a convolution dose calculation algorithm. Thus, beam spectra can be acquired in a clinical setting at the time of commissioning as a part of the routine beam data collection.},
  keywords = {Algorithms,Electrons,Equipment Design,Graphite,Ions,Models; Statistical,Particle Accelerators,Photons,Quality Control,Radiotherapy Dosage,Radiotherapy Planning; Computer-Assisted,Radiotherapy Planning; Computer-Assisted: methods,Radiotherapy; High-Energy}
}

@article{Hisakado2006,
  title = {Correlated {{Binomial Models}} and {{Correlation Structures}}},
  author = {Hisakado, M. and Kitsukawa, K. and Mori, S.},
  date = {2006-12-15},
  journaltitle = {Journal of Physics A: Mathematical and General},
  shortjournal = {J Phys A Math Gen},
  volume = {39},
  number = {50},
  eprint = {physics/0605189},
  eprinttype = {arxiv},
  pages = {15365--15378},
  issn = {0305-4470, 1361-6447},
  doi = {10.1088/0305-4470/39/50/005},
  abstract = {We discuss a general method to construct correlated binomial distributions by imposing several consistent relations on the joint probability function. We obtain self-consistency relations for the conditional correlations and conditional probabilities. The beta-binomial distribution is derived by a strong symmetric assumption on the conditional correlations. Our derivation clarifies the 'correlation' structure of the beta-binomial distribution. It is also possible to study the correlation structures of other probability distributions of exchangeable (homogeneous) correlated Bernoulli random variables. We study some distribution functions and discuss their behaviors in terms of their correlation structures.},
  archiveprefix = {arXiv},
  keywords = {Physics - Data Analysis; Statistics and Probability},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\6L3H6G96\\Hisakado et al. - 2006 - Correlated Binomial Models and Correlation Structu.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\SXXND9S7\\0605189.html}
}

@article{Hishikawa2002,
  title = {Usefulness of positron-emission tomographic images after proton therapy},
  author = {Hishikawa, Yoshio and Kagawa, Kazufumi and Murakami, Masao and Sakai, Hiroto and Akagi, Takashi and Abe, Mitsuyuki},
  date = {2002-08-01},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {53},
  number = {5},
  pages = {1388--1391},
  issn = {0360-3016},
  doi = {10.1016/S0360-3016(02)02887-0},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301602028870},
  urldate = {2020-04-03},
  abstract = {Purpose: To examine the positron emission tomography (PET) image obtained after proton irradiation and investigate the usefulness of the image for confirmation of the irradiated volume in proton radiotherapy (RT). Methods and Materials: A homogenous phantom was irradiated separately by carbon-ion and proton beams and the images obtained were compared. The PET images of cancer patients just after proton RT were then taken after informed consent. Results: In the PET image produced by carbon-ion beams, the high pixel counts in the image corresponded to the Bragg peak; however, in that produced by proton beams, they were visible throughout the entire track of the proton beams and were not related to the Bragg peak. The PET image of patients treated with proton RT was similar to that of the phantom experiment. Conclusion: The PET image after proton RT was different from that of carbon-ion RT. It was found that the PET image was very useful in proton RT to verify treatment planning.},
  langid = {english},
  keywords = {Carbon ion,Positron emission tomography,Proton,Proton therapy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\323ITGGT\\Hishikawa et al. - 2002 - Usefulness of positron-emission tomographic images.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\7PQDY3WA\\S0360301602028870.html}
}

@article{Hofmann2019,
  title = {Dose reconstruction from {{PET}} images in carbon ion therapy: a deconvolution approach},
  shorttitle = {Dose reconstruction from {{PET}} images in carbon ion therapy},
  author = {Hofmann, T. and Pinto, M. and Mohammadi, A. and Nitta, M. and Nishikido, F. and Iwao, Y. and Tashima, H. and Yoshida, E. and Chacon, A. and Safavi-Naeini, M. and Rosenfeld, A. and Yamaya, T. and Parodi, K.},
  date = {2019-01},
  journaltitle = {Physics in Medicine \& Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {64},
  number = {2},
  pages = {025011},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/aaf676},
  url = {https://doi.org/10.1088%2F1361-6560%2Faaf676},
  urldate = {2020-03-20},
  abstract = {Dose and range verification have become important tools to bring carbon ion therapy to a higher level of confidence in clinical applications. Positron emission tomography is among the most commonly used approaches for this purpose and relies on the creation of positron emitting nuclei in nuclear interactions of the primary ions with tissue. Predictions of these positron emitter distributions are usually obtained from time-consuming Monte Carlo simulations or measurements from previous treatment fractions, and their comparison to the current, measured image allows for treatment verification. Still, a direct comparison of planned and delivered dose would be highly desirable, since the dose is the quantity of interest in radiation therapy and its confirmation improves quality assurance in carbon ion therapy. In this work, we present a deconvolution approach to predict dose distributions from PET images in carbon ion therapy. Under the assumption that the one-dimensional PET distribution is described by a convolution of the depth dose distribution and a filter kernel, an evolutionary algorithm is introduced to perform the reverse step and predict the depth dose distribution from a measured PET distribution. Filter kernels are obtained from either a library or are created for any given situation on-the-fly, using predictions of the -decay and depth dose distributions, and the very same evolutionary algorithm. The applicability of this approach is demonstrated for monoenergetic and polyenergetic carbon ion irradiation of homogeneous and heterogeneous solid phantoms as well as a patient computed tomography image, using Monte Carlo simulated distributions and measured in-beam PET data. Carbon ion ranges are predicted within less than 0.5 mm and 1 mm deviation for simulated and measured distributions, respectively.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\3EMI6XNS\\Hofmann et al. - 2019 - Dose reconstruction from PET images in carbon ion .pdf}
}

@article{Holdsworth2012,
  title = {The use of a multiobjective evolutionary algorithm to increase flexibility in the search for better {{IMRT}} plans.},
  author = {Holdsworth, Clay and Kim, Minsun and Liao, Jay and Phillips, Mark},
  date = {2012-04-03},
  journaltitle = {Medical physics},
  volume = {39},
  number = {4},
  eprint = {22482647},
  eprinttype = {pmid},
  pages = {2261--74},
  publisher = {{American Association of Physicists in Medicine}},
  issn = {0094-2405},
  doi = {10.1118/1.3697535},
  url = {http://scitation.aip.org/content/aapm/journal/medphys/39/4/10.1118/1.3697535},
  urldate = {2014-08-07},
  abstract = {PURPOSE: To evaluate how a more flexible and thorough multiobjective search of feasible IMRT plans affects performance in IMRT optimization. METHODS: A multiobjective evolutionary algorithm (MOEA) was used as a tool to investigate how expanding the search space to include a wider range of penalty functions affects the quality of the set of IMRT plans produced. The MOEA uses a population of IMRT plans to generate new IMRT plans through deterministic minimization of recombined penalty functions that are weighted sums of multiple, tissue-specific objective functions. The quality of the generated plans are judged by an independent set of nonconvex, clinically relevant decision criteria, and all dominated plans are eliminated. As this process repeats itself, better plans are produced so that the population of IMRT plans will approach the Pareto front. Three different approaches were used to explore the effects of expanding the search space. First, the evolutionary algorithm used genetic optimization principles to search by simultaneously optimizing both the weights and tissue-specific dose parameters in penalty functions. Second, penalty function parameters were individually optimized for each voxel in all organs at risk (OARs) in the MOEA. Finally, a heuristic voxel-specific improvement (VSI) algorithm that can be used on any IMRT plan was developed that incrementally improves voxel-specific penalty function parameters for all structures (OARs and targets). Different approaches were compared using the concept of domination comparison applied to the sets of plans obtained by multiobjective optimization. RESULTS: MOEA optimizations that simultaneously searched both importance weights and dose parameters generated sets of IMRT plans that were superior to sets of plans produced when either type of parameter was fixed for four example prostate plans. The amount of improvement increased with greater overlap between OARs and targets. Allowing the MOEA to search for voxel-specific penalty functions improved results for simple cases with three structures but did not improve results for a more complex case with seven structures. For this modification, the amount of improvement increased with less overlap between OARs and targets. The voxel-specific improvement algorithm improved results for all cases, and its clinical relevance was demonstrated in a complex prostate and a very complex head and neck case. CONCLUSIONS: Using an evolutionary algorithm as a tool, it was found that allowing more flexibility in the search space enhanced performance. The two strategies of (a) varying the weights and reference doses in the objective function and (b) removing the constraint of equal penalties for all voxels in a structure both generated sets of plans that dominated sets of plans considered to be "Pareto optimal" within the conventional, more limited search space. When considering voxel-specific objectives, the very large search space can lead to convergence problems in the MOEA for complex cases, but this is not an issue for the VSI algorithm.},
  isbn = {doi:10.1118/1.3697535},
  keywords = {Algorithms,Radiometry,Radiometry: methods,Radiotherapy Dosage,Radiotherapy Planning; Computer-Assisted,Radiotherapy Planning; Computer-Assisted: methods,Radiotherapy; Conformal,Radiotherapy; Conformal: methods,Software,Software Validation}
}

@inproceedings{Homolka2020,
  title = {{{PO-1490}}: {{Lung}} degradation effects on {{RBE-weighted}} dose in proton, carbon and helium treatment plans},
  shorttitle = {Lung degradation effects on {{RBE-weighted}} dose in proton, carbon and helium treatment plans},
  booktitle = {Radiotherapy and {{Oncology}}},
  author = {Homolka, Noa and Wieser, Hans-Peter and Bangert, Mark and Ellerbrock, Malte and Wahl, Niklas},
  date = {2020-11-01},
  volume = {152},
  pages = {S801-S802},
  location = {{Online}},
  doi = {10.1016/S0167-8140(21)01508-5},
  url = {https://www.thegreenjournal.com/article/S0167-8140(21)01508-5/abstract},
  urldate = {2021-07-05},
  eventtitle = {{{ESTRO}}},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\FTHUJ37R\\pdf.html}
}

@inproceedings{Homolka2022,
  title = {Degradation of particle depth dose in lung tissue: {{An}} efficient and consistent model for {{Monte Carlo}} and analytical dose calculation},
  booktitle = {Proceedings to the 59th {{Annual Conference}} of the {{Particle Therapy Cooperative Group}} ({{PTCOG59}} 2021 {{Online}})},
  author = {Homolka, Noa and Meder, Paul Anton and Burigo, Lucas and Wieser, Hans-Peter and Bangert, Mark and Jäkel, Oliver and Ellerbrock, Malte and Wahl, Niklas},
  date = {2022},
  series = {International {{Journal}} of {{Particle Therapy}}},
  pages = {23--24},
  location = {{Online}},
  doi = {10.14338/IJPT-22-PTCOG59-9.3},
  eventtitle = {{{PTCOG}} 59},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\LDSC6PHT\\Homolka et al. - 2022 - Degradation of particle depth dose in lung tissue.pdf}
}

@article{Hong1996,
  title = {A pencil beam algorithm for proton dose calculations},
  author = {Hong, Linda and Goitein, Michael and Bucciolini, Marta and Comiskey, Robert and Gottschalk, Bernard and Rosenthal, Skip and Serago, Chris and Urie, Marcia},
  date = {1996-08-01},
  journaltitle = {Physics in Medicine and Biology},
  volume = {41},
  number = {8},
  pages = {1305--1330},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/41/8/005},
  url = {http://stacks.iop.org/0031-9155/41/i=8/a=005},
  urldate = {2015-04-10},
  abstract = {The sharp lateral penumbra and the rapid fall-off of dose at the end of range of a proton beam are among the major advantages of proton radiation therapy. These beam characteristics depend on the position and characteristics of upstream beam-modifying devices such as apertures and compensating boluses. The extent of separation, if any, between these beam-modifying devices and the patient is particularly critical in this respect. We have developed a pencil beam algorithm for proton dose calculations which takes accurate account of the effects of materials upstream of the patient and of the air gap between them and the patient. The model includes a new approach to picking the locations of the pencil beams so as to more accurately model the penumbra and to more effectively account for the multiple-scattering effects of the media around the point of interest. We also present a faster broad-beam version of the algorithm which gives a reasonably accurate penumbra. Predictions of the algorithm and results from experiments performed in a large-field proton beam are presented. In general the algorithm agrees well with the measurements.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\MGHJF8BN\\Hong et al. - 1996 - A pencil beam algorithm for proton dose calculations.pdf}
}

@article{Huang2018,
  title = {Validation and clinical implementation of an accurate {{Monte Carlo}} code for pencil beam scanning proton therapy},
  author = {Huang, Sheng and Kang, Minglei and Souris, Kevin and Ainsley, Christopher and Solberg, Timothy D. and McDonough, James E. and Simone, Charles B. and Lin, Liyong},
  date = {2018-07},
  journaltitle = {Journal of Applied Clinical Medical Physics},
  volume = {19},
  number = {5},
  pages = {558--572},
  publisher = {{Wiley}},
  doi = {10.1002/acm2.12420}
}

@article{Hunt2018,
  title = {Adaptive {{Radiotherapy Enabled}} by {{MRI Guidance}}},
  author = {Hunt, A. and Hansen, V. N. and Oelfke, U. and Nill, S. and Hafeez, S.},
  date = {2018-11-01},
  journaltitle = {Clinical Oncology},
  shortjournal = {Clinical Oncology},
  series = {{{MRI}} and {{Radiotherapy}}},
  volume = {30},
  number = {11},
  pages = {711--719},
  issn = {0936-6555},
  doi = {10.1016/j.clon.2018.08.001},
  url = {https://www.sciencedirect.com/science/article/pii/S0936655518304084},
  urldate = {2022-08-11},
  abstract = {Adaptive radiotherapy (ART) strategies systematically monitor variations in target and neighbouring structures to inform treatment-plan modification during radiotherapy. This is necessary because a single plan designed before treatment is insufficient to capture the actual dose delivered to the target and adjacent critical structures during the course of radiotherapy. Magnetic resonance imaging (MRI) provides superior soft-tissue image contrast over current standard X-ray-based technologies without additional radiation exposure. With integrated MRI and radiotherapy platforms permitting motion monitoring during treatment delivery, it is possible that adaption can be informed by real-time anatomical imaging. This allows greater treatment accuracy in terms of dose delivered to target with smaller, individualised treatment margins. The use of functional MRI sequences would permit ART to be informed by imaging biomarkers, so allowing both personalised geometric and biological adaption. In this review, we discuss ART solutions enabled by MRI guidance and its potential gains for our patients across tumour types.},
  langid = {english},
  keywords = {Adaptive radiotherapy,gating,image guided,magnetic resonance imaging,radiotherapy planning,tracking},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\G9BEA8YE\\Hunt et al. - 2018 - Adaptive Radiotherapy Enabled by MRI Guidance.pdf}
}

@report{IARC2014,
  title = {World {{Cancer Report}} 2014},
  author = {Wild, Christopher P. and Stewart, Bernard W.},
  date = {2014},
  journaltitle = {IARC Press},
  institution = {{International Agency for Research on Cancer}},
  keywords = {Cancer},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\R7HKERW3\\International Agency for Research on Cancer - 2014 - World Cancer Report 2014.pdf}
}

@misc{Institute,
  title = {Official {{Website}} of {{Ingham Institute}}},
  author = {Institute, Ingham},
  url = {http://www.inghaminstitute.org.au/Mri-linac.html}
}

@article{Iqbal2013,
  title = {A histogram method for summarizing multi-dimensional probabilistic data},
  author = {Iqbal, Ashraf and Wang, Hai and Gao, Qigang},
  date = {2013},
  journaltitle = {Procedia Computer Science},
  volume = {19},
  pages = {971--976},
  publisher = {{Elsevier B.V.}},
  issn = {18770509},
  doi = {10.1016/j.procs.2013.06.135},
  url = {http://dx.doi.org/10.1016/j.procs.2013.06.135},
  abstract = {Currently, many database applications deal with large imprecise and uncertain datasets. Probabilistic data summarization has recently emerged and has already become an active research area in the database community. In this paper, we propose a data summarization method to summarize multidimensional probabilistic data using histograms. The proposed method iteratively constructs a histogram to represent the probabilistic data while maintaining a trade-off between minimizing the relative entropy among probability distributions and minimizing the space used by the histogram. The experimental results show that the proposed method achieves small errors for various compression ratios. © 2013 The Authors. Published by Elsevier B.V.},
  keywords = {Data summarization,Histogram,Probabilistic database,Uncertain database,Wavelet},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\57D9AVK5\\Iqbal, Wang, Gao - 2013 - A histogram method for summarizing multi-dimensional probabilistic data.pdf}
}

@article{Iseki2003,
  title = {Positron camera for range verification of heavy-ion radiotherapy},
  author = {Iseki, Yasushi and Mizuno, Hideyuki and Futami, Yasuyuki and Tomitani, Takehiro and Kanai, Tatsuaki and Kanazawa, Mitsutaka and Kitagawa, Atsushi and Murakami, Takeshi and Nishio, Teiji and Suda, Mitsuru and Urakabe, Eriko and Yunoki, Akira and Sakai, Hirotaka},
  date = {2003-12-11},
  journaltitle = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  shortjournal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  volume = {515},
  number = {3},
  pages = {840--849},
  issn = {0168-9002},
  doi = {10.1016/j.nima.2003.07.005},
  url = {http://www.sciencedirect.com/science/article/pii/S0168900203023106},
  urldate = {2020-04-03},
  abstract = {A positron camera, consisting of a pair of Anger-type scintillation detectors, has been developed to verify ranges by using positron emitter beams. Each detector head is equipped with a NaI(Tl) crystal (diameter: 600mm, thickness: 30mm) for high detection efficiency. To get a low counting rate for this application, the electric circuit was designed for flexibility in measurement and analysis by software. The energy and position were calibrated for high measurement accuracy. A spatial resolution of 8.6mm in FWHM within a ±50mm region (field of view) and a linear response of a 0.3mm standard deviation within a ±200mm region were obtained. The camera was designed so as to measure the ranges within an accuracy of 1mm under a dose limitation (about 100mGyE) to reduce the safety margin for the irradiation field, and it met the required characteristics.},
  langid = {english},
  keywords = {Heavy ion,HIMAC,Positron camera,Positron emitter,Radiotherapy,Spatial resolution},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Y8NXGI8E\\S0168900203023106.html}
}

@article{Jaccard2018,
  title = {High dose-per-pulse electron beam dosimetry: {{Commissioning}} of the {{Oriatron eRT6}} prototype linear accelerator for preclinical use},
  shorttitle = {High dose-per-pulse electron beam dosimetry},
  author = {Jaccard, Maud and Durán, Maria Teresa and Petersson, Kristoffer and Germond, Jean-François and Liger, Philippe and Vozenin, Marie-Catherine and Bourhis, Jean and Bochud, François and Bailat, Claude},
  date = {2018-02},
  journaltitle = {Medical Physics},
  shortjournal = {Med. Phys.},
  volume = {45},
  number = {2},
  pages = {863--874},
  issn = {00942405},
  doi = {10.1002/mp.12713},
  url = {http://doi.wiley.com/10.1002/mp.12713},
  urldate = {2020-05-07},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\LJK9RE4V\\Jaccard et al. - 2018 - High dose-per-pulse electron beam dosimetry Commi.pdf}
}

@thesis{Janus2007,
  type = {Diploma thesis},
  title = {Sampling of the {{Lateral Fluence Profile}} of a {{Proton Pencil Beam}} - {{An Enhanced Method}} for {{Proton Dose Calculation}}},
  author = {Janus, Michel},
  date = {2007},
  institution = {{University of Heidelberg}},
  url = {http://katalog.ub.uni-heidelberg.de/titel/66434525},
  abstract = {The primary advantage of hadronic particles in radiation therapy lies in their advantageous depth dose characteristic. The so-called “Bragg peak” allows improving the conformity of the dose distribution to the tumor. Currently multiple new hadron therapy facilities are being build. They apply a new beam delivery technique using magnetically scanned, nar- row beams. Todays analytical models, such as the pencil beam model, are not capable of accurately describing the dose from a narrow particle beam in the presence of lateral inhomogeneities. To improve the accuracy of the pencil beam model a method of sampling the Gaussian lateral fluence profile of a proton pencil beam was examined. The method is derived analytically and validated against the unsampled beam in water. When applied to geometries with lateral interfaces large differences to the unsampled pencil beam were observed in the depth dose distributions as well as the lateral profiles. The sampling algo- rithm predicts two Bragg peaks resulting from the protons on either side of the interface. Contrary to the model without sampling, the shape and lateral extent of the pencil beam were also strongly influenced by the presence of the lateral inhomogeneity. Sampling},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\923H3S7R\\Janus - 2007 - Sampling of the Lateral Fluence Profile of a Proton Pencil Beam - An Enhanced Method for Proton Dose Calculation.pdf}
}

@incollection{Jeffrey2000,
  title = {Preface to the {{Sixth Edition}}},
  booktitle = {Table of {{Integrals}}, {{Series}}, and {{Products}}},
  author = {Jeffrey, Alan and Zwillinger, Daniel},
  date = {2000},
  pages = {xxi},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-012294757-5/50000-3},
  url = {http://linkinghub.elsevier.com/retrieve/pii/B9780122947575500003},
  urldate = {2018-03-22},
  isbn = {978-0-12-294757-5},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\6HJWBSYP\\Jeffrey, Zwillinger - 2000 - Preface to the Sixth Edition.pdf}
}

@article{Jensen1998,
  title = {Some statistical properties of power averages for lognormal samples},
  author = {Jensen, Jerry L.},
  date = {1998-09},
  journaltitle = {Water Resources Research},
  volume = {34},
  number = {9},
  pages = {2415--2418},
  issn = {00431397},
  doi = {10.1029/98WR01557},
  url = {http://doi.wiley.com/10.1029/98WR01557},
  keywords = {doi:10.1029/98WR01557,http://dx.doi.org/10.1029/98WR01557},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\JVNJLXCP\\Jensen - 1998 - Some statistical properties of power averages for lognormal samples.pdf}
}

@book{Johnson1994,
  title = {Continuous univariate distributions, {{Volume}} 1},
  author = {Johnson, Norman Lloyd. and Kotz, Samuel. and Balakrishnan, N.},
  date = {1994},
  edition = {2},
  publisher = {{Wiley}},
  url = {https://www.wiley.com/en-us/Continuous+Univariate+Distributions%2C+Volume+1%2C+2nd+Edition-p-9780471584957},
  urldate = {2018-04-29},
  abstract = {2nd ed. "A Wiley-Interscience publication." Vol. 1. c1994.},
  isbn = {978-0-471-58495-7}
}

@book{Johnson1994a,
  title = {Continuous univariate distributions, {{Volume}} 2},
  author = {Johnson, Norman Lloyd. and Kotz, Samuel. and Balakrishnan, N.},
  date = {1994},
  edition = {2},
  publisher = {{Wiley}},
  url = {https://www.wiley.com/en-us/Continuous+Univariate+Distributions%2C+Volume+2%2C+2nd+Edition-p-9780471584940},
  urldate = {2018-04-29},
  abstract = {2nd ed. "A Wiley-Interscience publication." Vol. 1. c1994.},
  isbn = {978-0-471-58494-0}
}

@article{Johnstone2018,
  title = {Systematic {{Review}} of {{Synthetic Computed Tomography Generation Methodologies}} for {{Use}} in {{Magnetic Resonance Imaging}}–{{Only Radiation Therapy}}},
  author = {Johnstone, Emily and Wyatt, Jonathan J. and Henry, Ann M. and Short, Susan C. and Sebag-Montefiore, David and Murray, Louise and Kelly, Charles G. and McCallum, Hazel M. and Speight, Richard},
  date = {2018-01},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {100},
  number = {1},
  pages = {199--217},
  issn = {03603016},
  doi = {10.1016/j.ijrobp.2017.08.043},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0360301617338403},
  urldate = {2022-08-16},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\8LSFE3SU\\Johnstone et al. - 2018 - Systematic Review of Synthetic Computed Tomography.pdf}
}

@book{Joiner2009,
  title = {Basic clinical radiobiology},
  editor = {Joiner, Michael and family=Kogel, given=Albert, prefix=van der, useprefix=false},
  date = {2009},
  edition = {4},
  publisher = {{Hodder Arnold}},
  abstract = {4th ed. This book deals with the biological aspects of radiotherapy. It seeks to present, in a concise and interesting way, the main ideas and significant scientific developments that underlie current attempts to improve the radiotherapeutic management of cancer. Cover; Book title; Contents; List of contributors; Preface; 1 Introduction: the significance of radiobiology and radiotherapy for cancer treatment; 2 Irradiation-induced damage and the DNA damage response; 3 Cell death after irradiation: how, when and why cells die; 4 Quantifying cell kill and cell survival; 5 Dose-response relationships in radiotherapy; 6 Linear energy transfer and relative biological effectiveness; 7 Tumour growth and response to radiation; 8 Fractionation: the linear-quadratic approach; 9 The linear-quadratic approach in clinical practice; 10 Modified fractionation.},
  isbn = {978-1-4441-0961-0}
}

@article{Jones2006,
  title = {The case for particle therapy},
  author = {Jones, B},
  date = {2006-01-01},
  journaltitle = {The British Journal of Radiology},
  shortjournal = {BJR},
  volume = {79},
  number = {937},
  pages = {24--31},
  publisher = {{The British Institute of Radiology}},
  issn = {0007-1285},
  doi = {10.1259/bjr/81790390},
  url = {https://www.birpublications.org/doi/abs/10.1259/bjr/81790390},
  urldate = {2020-03-23},
  abstract = {Among the most important decisions facing the British Government regarding the treatment of cancer in the National Health Service (NHS) is the purchase of charged particle therapy (CPT) centres. CPT is different from conventional radiotherapy: the dose is deposited far more selectively in Bragg Peaks by either protons or “heavy” ions, such as carbon. In this way, it is possible to “dose paint” targets, voxel by voxel, with far less dose to surrounding tissues than with X-ray techniques. At present the UK possesses a 62\hspace{0.25em}MeV cyclotron proton facility at Clatterbridge (Wirral), which provides therapy for intraocular cancers such as melanoma; for deeper situated cancers in the pelvis, chest etc., much higher energies, over 200\hspace{0.25em}MeV are required from a synchrotron facility. There is an impressive expansion in particle beam therapy (PBT) centres worldwide, since they offer good prospects of improved quality of life with enhanced cancer cures in situations where conventional therapy is limited due to radioresistance or by the close proximity of critical normal tissues. There is a threat to UK Oncology, since it is anticipated that several thousand British patients may require referral abroad for therapy; this would severely disrupt their multidisciplinary management and require demanding logistical support.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\E6SIE6QW\\81790390.html}
}

@article{Jones2016,
  title = {Why {{RBE}} must be a variable and not a constant in proton therapy},
  author = {Jones, Bleddyn},
  date = {2016-07-05},
  journaltitle = {The British Journal of Radiology},
  volume = {89},
  number = {1063},
  pages = {20160116},
  publisher = {{The British Institute of Radiology.}},
  issn = {0007-1285},
  doi = {10.1259/bjr.20160116},
  url = {http://www.birpublications.org/doi/10.1259/bjr.20160116},
  urldate = {2018-04-19},
  abstract = {Objective:This article considered why the proton therapy (PT) relative biological effect (RBE) should be a variable rather than a constant.Methods:The reasons for a variable proton RBE are enumerated, with qualitative and quantitative arguments. The heterogeneous data sets collated by Paganetti et al (2002) and the more homogeneous data of Britten et al (2013) are further analyzed using linear regression fitting and RBE-inclusive adaptations of the linear–quadratic (LQ) radiation model.Results:The in vitro data show RBE increasing as dose per fraction is lowered. In the Paganetti et al (2002) data sets, the differences between observed and expected effects are smaller when the LQ model is used, but with such data heterogeneity, firm statistical conclusions cannot be obtained. The more homogeneous data set shows an unequivocal variation in RBE with dose per faction. The in vivo data are inappropriate for assessments of late normal tissue effects in radiotherapy. Also, if there is the same degree of uncerta...},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\QJLMT7YB\\Jones - 2016 - Why RBE must be a variable and not a constant in proton therapy.pdf}
}

@article{Kamal-Sayed2018,
  title = {Adaptive method for multicriteria optimization of intensity-modulated proton therapy},
  author = {Kamal-Sayed, Hisham and Ma, J. and Tseung, H. and Abdel-Rehim, A. and Herman, M. G. and Beltran, C. J.},
  date = {2018-12},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {45},
  number = {12},
  eprint = {30332515},
  eprinttype = {pmid},
  pages = {5643--5652},
  issn = {2473-4209},
  doi = {10.1002/mp.13239},
  abstract = {PURPOSE: Provide an adaptive multicriteria optimization (MCO) method for intensity-modulated proton therapy (IMPT) utilizing GPU technology. Previously described limitations of MCO such as Pareto approximation and limitation on the number of objectives were addressed. METHODS: The treatment planning process for IMPT must account for multiple objectives, which requires extensive treatment planning resources. Often a large number of objectives ({$>$}10) are required. Hence the need for an MCO algorithm that can handle large number of objectives. The novelty of the MCO method presented here lies on the introduction of the adaptive weighting scheme that can generate a well-distributed and dense representation of the Pareto surface for a large number of objectives in an efficient manner. In our approach the generated Pareto surface is constructed for a set of DVH objectives. The MCO algorithm is based on the augmented weighted Chebychev metric (AWCM) method with an adaptive weighting scheme. This scheme uses the differential evolution (DE) method to generate a set of well-distributed Pareto points. The quality of the Pareto points' distribution in the objective space was assessed quantitatively using the Pareto sampling metric. The MCO algorithm was developed to perform multiple parallel searches to achieve a rapid mapping of the Pareto surface, produce clinically deliverable plans, and was implemented on a GPU cluster. The MCO algorithm was tested on two clinical cases with 10 and 18 objectives. For each case one of the MCO-generated plans was selected for comparison with the clinically generated plan. The MCO plan was randomly selected out of the set of MCO plans that had target coverage similar to the clinically generated plan and the same or better sparing of the organs at risk (OAR). Additionally, a validation study of the AWCM method vs the weighted sum method was performed. RESULTS: The adaptive MCO algorithm generated Pareto points on the Pareto hypersurface in a fast (2-3 hr) and efficient manner for 2 cases with 10 and 18 objectives. The MCO algorithm generated a dense and well-distributed set of Pareto points on the objective space, and was able to achieve minimization of the Pareto sampling metric. The selected MCO plan showed an improvement of the DVH objectives in comparison to the clinically optimized plan in both cases. For case one, the MCO plan showed a 48\% reduction of the 50\% dose to OARs and a 16\% reduction of the 1\% dose to OARs. For case 2, the MCO plan showed a 72\% reduction of the 50\% dose to OARs and a 42\% reduction of the 1\% dose to OARs. The comparison of AWCM to WS showed that the AWCM method has a dosimetric advantage over WS for both patient cases. CONCLUSION: We introduced an adaptive MCO algorithm for IMPT accelerated using GPUs. The algorithm is based on an adaptive method for generating Pareto plans in the objective space. We have shown that the algorithm can provide rapid and efficient mapping of the multicriteria Pareto surface with clinically deliverable plans.},
  langid = {english},
  keywords = {Algorithms,Child,GPU,Head and Neck Neoplasms,Humans,multicriteria optimization,Orbital Neoplasms,proton therapy,Proton Therapy,Radiotherapy Planning; Computer-Assisted,Radiotherapy; Intensity-Modulated}
}

@thesis{Kamerlin2013,
  title = {Interactive dose shaping: development and evaluation of a novel treatment planning software application},
  author = {Kamerling, Cornelis Ph},
  date = {2014},
  institution = {{University of Heidelberg}}
}

@article{Kang2007,
  title = {{{4D Proton}} treatment planning strategy for mobile lung tumors},
  author = {Kang, Yixiu and Zhang, Xiaodong and Chang, Joe Y. and Wang, He and Wei, Xiong and Liao, Zhongxing and Komaki, Ritsuko and Cox, James D. and Balter, Peter A. and Liu, Helen and Zhu, X. Ronald and Mohan, Radhe and Dong, Lei},
  date = {2007-03-01},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {67},
  number = {3},
  pages = {906--914},
  issn = {0360-3016},
  doi = {10.1016/j.ijrobp.2006.10.045},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301606033852},
  urldate = {2020-03-23},
  abstract = {Purpose: To investigate strategies for designing compensator-based 3D proton treatment plans for mobile lung tumors using four-dimensional computed tomography (4DCT) images. Methods and Materials: Four-dimensional CT sets for 10 lung cancer patients were used in this study. The internal gross tumor volume (IGTV) was obtained by combining the tumor volumes at different phases of the respiratory cycle. For each patient, we evaluated four planning strategies based on the following dose calculations: (1) the average (AVE) CT; (2) the free-breathing (FB) CT; (3) the maximum intensity projection (MIP) CT; and (4) the AVE CT in which the CT voxel values inside the IGTV were replaced by a constant density (AVE\_RIGTV). For each strategy, the resulting cumulative dose distribution in a respiratory cycle was determined using a deformable image registration method. Results: There were dosimetric differences between the apparent dose distribution, calculated on a single CT dataset, and the motion-corrected 4D dose distribution, calculated by combining dose distributions delivered to each phase of the 4DCT. The AVE\_RIGTV plan using a 1-cm smearing parameter had the best overall target coverage and critical structure sparing. The MIP plan approach resulted in an unnecessarily large treatment volume. The AVE and FB plans using 1-cm smearing did not provide adequate 4D target coverage in all patients. By using a larger smearing value, adequate 4D target coverage could be achieved; however, critical organ doses were increased. Conclusion: The AVE\_RIGTV approach is an effective strategy for designing proton treatment plans for mobile lung tumors.},
  langid = {english},
  keywords = {4D treatment planning,4DCT,Lung cancer,Proton therapy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\C3PXQVTD\\Kang et al. - 2007 - 4D Proton treatment planning strategy for mobile l.pdf}
}

@article{Kang2015,
  title = {Machine {{Learning Approaches}} for {{Predicting Radiation Therapy Outcomes}}: {{A Clinician}}'s {{Perspective}}},
  shorttitle = {Machine {{Learning Approaches}} for {{Predicting Radiation Therapy Outcomes}}},
  author = {Kang, John and Schwartz, Russell and Flickinger, John and Beriwal, Sushil},
  date = {2015-12-01},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {93},
  number = {5},
  pages = {1127--1135},
  issn = {0360-3016},
  doi = {10.1016/j.ijrobp.2015.07.2286},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301615030783},
  urldate = {2020-11-12},
  abstract = {Radiation oncology has always been deeply rooted in modeling, from the early days of isoeffect curves to the contemporary Quantitative Analysis of Normal Tissue Effects in the Clinic (QUANTEC) initiative. In recent years, medical modeling for both prognostic and therapeutic purposes has exploded thanks to increasing availability of electronic data and genomics. One promising direction that medical modeling is moving toward is adopting the same machine learning methods used by companies such as Google and Facebook to combat disease. Broadly defined, machine learning is a branch of computer science that deals with making predictions from complex data through statistical models. These methods serve to uncover patterns in data and are actively used in areas such as speech recognition, handwriting recognition, face recognition, “spam” filtering (junk email), and targeted advertising. Although multiple radiation oncology research groups have shown the value of applied machine learning (ML), clinical adoption has been slow due to the high barrier to understanding these complex models by clinicians. Here, we present a review of the use of ML to predict radiation therapy outcomes from the clinician's point of view with the hope that it lowers the “barrier to entry” for those without formal training in ML. We begin by describing 7 principles that one should consider when evaluating (or creating) an ML model in radiation oncology. We next introduce 3 popular ML methods—logistic regression (LR), support vector machine (SVM), and artificial neural network (ANN)—and critique 3 seminal papers in the context of these principles. Although current studies are in exploratory stages, the overall methodology has progressively matured, and the field is ready for larger-scale further investigation.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\HVQIDLS3\\S0360301615030783.html}
}

@article{Kataria2012,
  title = {Homogeneity {{Index}}: {{An}} objective tool for assessment of conformal radiation treatments.},
  author = {Kataria, Tejinder and Sharma, Kuldeep and Subramani, Vikraman and Karrthick, K P and Bisht, Shyam S},
  date = {2012-10},
  journaltitle = {Journal of medical physics / Association of Medical Physicists of India},
  volume = {37},
  number = {4},
  eprint = {23293452},
  eprinttype = {pmid},
  pages = {207--13},
  issn = {0971-6203},
  doi = {10.4103/0971-6203.103606},
  url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3532749&tool=pmcentrez&rendertype=abstract},
  urldate = {2013-06-24},
  abstract = {Homogeneity Index (HI) is an objective tool to analyz the uniformity of dose distribution in the target volume. Various formulae have been described in literature for its calculation but there is paucity of data regarding the ideal formula and the factors affecting this index. This study was undertaken to analyze HI in our patients using various formulae and to find out the co-relation between HI and prescribed dose, target volume and target location. A retrospective review of 99 patients was performed. HI was calculated using five different formulae (A-E). The patients were divided in five groups each, based on prescribed dose, target volume and target location and mean HI of each group was analysed to find the co-relation between these factors and HI. When there were multiple target volumes the primary target volume was studied. The statistical calculation was done using SPSS version 16.0. Ninety nine patients were found evaluable with 75 males and 24 females. Ninety five patients were treated with radical intent and four with palliative intent. The sites treated were head and neck (46.4\%), Pelvis (17.1\%), brain (15.1\%), abdomen (12.1\%), and thorax (6.1\%). The mean prescribed dose was 4304 cGy (centiGray) and the mean target volume was 476.2 cc. The mean value of HI was 1.21, 2.08, 30.13, 21.51 and 1.27 with different formulae. There was considerable agreement between HI calculated using various formulae specially the formulae considering prescribed dose (C, D). On statistical analysis, there was no significant co-relation between the location and volume of target but there was a trend toward better HI with increasing prescribed dose. Future studies with more number of patients can confirm our results.}
}

@book{Kaul1976,
  title = {Medizinische {{Physik}}},
  author = {Kaul, A. and Frost, D.},
  date = {1976},
  journaltitle = {Physik Journal},
  volume = {32},
  number = {10},
  doi = {10.1002/phbl.19760321011},
  abstract = {To evaluate whether the interleukin-6 (IL-6) -174 G/C polymorphism might alter the effects of micronized fenofibrate or simvastatin therapy on inflammatory markers, we measured IL-6, C-reactive protein, CD40 ligand, adhesion molecules, P-selectin and monocyte chemoattractant protein-1 in hypercholesterolemic patients both before and after a 30-day treatment. Serum IL-6 levels were significantly higher in patients with the GC or CC genotypes (P=0.04). The presence of the C allele was associated with greater absolute reduction of IL-6 levels (P=0.04) following fenofibrate treatment. There was no significant association between the -174 G/C IL-6 polymorphism and the effects of simvastatin treatment. A relationship between the -174 G/C IL-6 polymorphism and the anti-inflammatory action of fenofibrate reported might be useful in the optimization of the treatment regimen in patients receiving this class of drugs},
  isbn = {978-3-662-54800-4},
  pagetotal = {467-473},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\2RYIYEL8\\Kaul, Frost - 1976 - Medizinische Physik.pdf}
}

@article{Kavanagh2010,
  title = {Radiation dose-volume effects in the stomach and small bowel.},
  author = {Kavanagh, Brian D and Pan, Charlie C and Dawson, Laura A and Das, Shiva K and Li, X Allen and Ten Haken, Randall K and Miften, Moyed},
  date = {2010-03-01},
  journaltitle = {International journal of radiation oncology, biology, physics},
  volume = {76},
  eprint = {20171503},
  eprinttype = {pmid},
  pages = {S101-7},
  issn = {1879-355X},
  doi = {10.1016/j.ijrobp.2009.05.071},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301609032866},
  urldate = {2014-01-22},
  abstract = {Published data suggest that the risk of moderately severe ({$>$}or=Grade 3) radiation-induced acute small-bowel toxicity can be predicted with a threshold model whereby for a given dose level, D, if the volume receiving that dose or greater (VD) exceeds a threshold quantity, the risk of toxicity escalates. Estimates of VD depend on the means of structure segmenting (e.g., V15 = 120 cc if individual bowel loops are outlined or V45 = 195 cc if entire peritoneal potential space of bowel is outlined). A similar predictive model of acute toxicity is not available for stomach. Late small-bowel/stomach toxicity is likely related to maximum dose and/or volume threshold parameters qualitatively similar to those related to acute toxicity risk. Concurrent chemotherapy has been associated with a higher risk of acute toxicity, and a history of abdominal surgery has been associated with a higher risk of late toxicity.},
  issue = {3 Suppl},
  keywords = {Antineoplastic Combined Chemotherapy Protocols,Antineoplastic Combined Chemotherapy Protocols: ad,Humans,Intestine; Small,Intestine; Small: radiation effects,Intestine; Small: radiography,Models; Biological,Radiation Injuries,Radiation Injuries: complications,Radiation Tolerance,Radiotherapy Dosage,Risk,Stomach,Stomach: radiation effects,Stomach: radiography},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\R43AVYXI\\Kavanagh et al. - 2010 - Radiation dose-volume effects in the stomach and small bowel.pdf}
}

@software{Kawrakow2000,
  title = {{{EGSnrc}} toolkit for {{Monte Carlo}} simulation of ionizing radiation transport},
  author = {Kawrakow, I and Rogers, DWO and Mainegra-Hing, E and Tessier, F and Townson, RW and Walters, BRB},
  date = {2000},
  doi = {10.4224/40001303}
}

@article{Keall2019,
  title = {See, {{Think}}, and {{Act}}: {{Real-Time Adaptive Radiotherapy}}},
  shorttitle = {See, {{Think}}, and {{Act}}},
  author = {Keall, Paul and Poulsen, Per and Booth, Jeremy T.},
  date = {2019-07-01},
  journaltitle = {Seminars in Radiation Oncology},
  shortjournal = {Seminars in Radiation Oncology},
  series = {Adaptive {{Radiotherapy}} and {{Automation}}},
  volume = {29},
  number = {3},
  pages = {228--235},
  issn = {1053-4296},
  doi = {10.1016/j.semradonc.2019.02.005},
  url = {https://www.sciencedirect.com/science/article/pii/S1053429619300141},
  urldate = {2022-08-11},
  abstract = {The world is embracing the information age, with real-time data at hand to assist with many decisions. Similarly, in cancer radiotherapy we are inexorably moving toward using information in a smarter and faster fashion, to usher in the age of real-time adaptive radiotherapy. The three critical steps of real-time adaptive radiotherapy, aligned with driverless vehicle technology are a continuous see, think, and act loop. See: use imaging systems to probe the patient anatomy or physiology as it evolves with time. Think: use current and prior information to optimize the treatment using the available adaptive degrees of freedom. Act: deliver the real-time adapted treatment. This paper expands upon these three critical steps for real-time adaptive radiotherapy, provides a historical context, reviews the clinical rationale, and gives a future outlook for real-time adaptive radiotherapy.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\6B5FTVAH\\Keall et al. - 2019 - See, Think, and Act Real-Time Adaptive Radiothera.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\MSZ2ZMS9\\S1053429619300141.html}
}

@article{Keinj2011,
  title = {Multinomial model-based formulations of {{TCP}} and {{NTCP}} for radiotherapy treatment planning},
  author = {Keinj, R. and Bastogne, T. and Vallois, P.},
  date = {2011-06-21},
  journaltitle = {Journal of Theoretical Biology},
  shortjournal = {Journal of Theoretical Biology},
  volume = {279},
  number = {1},
  pages = {55--62},
  issn = {0022-5193},
  doi = {10.1016/j.jtbi.2011.03.025},
  url = {https://www.sciencedirect.com/science/article/pii/S0022519311001718},
  urldate = {2021-04-05},
  abstract = {Hit and target models of tumor growth, typically assume that all surviving cells have a constant and homogeneous sensitivity during the radiotherapy period. In this study, we propose a new multinomial model based on a discrete-time Markov chain, able to take into account cell repair, cell damage heterogeneity and cell proliferation. The proposed model relies on the ‘Hit paradigm’ and ‘Target’ theory in radiobiology and assumes that a cancer cell contains m targets which must be all deactivated to produce cell death. The surviving cell population is then split up into m categories to introduce the variation of cancer cell radio-sensitivity according to their damage states. New expressions of the Tumor Control Probability (TCP) and Normal Tissue Complication Probability (NTCP) are provided. Moreover, we show that hit and target models may be regarded as particular cases of the multinomial model. Numerical results should permit to keep the efficiency of treatment with a lower total radiation dose then that given by the typical hit models, which allow to decrease side effects.},
  langid = {english},
  keywords = {Markov chain,Multinomial model,Radiotherapy,Tumor growth},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\H92JRNK6\\Keinj et al. - 2011 - Multinomial model-based formulations of TCP and NT.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\QDECN8PQ\\S0022519311001718.html}
}

@article{Kellerer1978,
  title = {A {{Generalized Formulation}} of {{Dual Radiation Action}}},
  author = {Kellerer, Albrecht M and Rossi, Harald H},
  date = {1978},
  journaltitle = {Radiation Research},
  shortjournal = {Radiat. Res.},
  volume = {75},
  pages = {471--488},
  url = {https://epub.ub.uni-muenchen.de/8404/1/8404.pdf},
  urldate = {2019-09-17},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\IJQHHJWX\\8404.pdf}
}

@book{Kelley1999,
  title = {Iterative methods for optimization},
  author = {Kelley, CT},
  date = {1999},
  url = {http://books.google.com/books?hl=en&lr=&id=7oqAh1MAZG0C&oi=fnd&pg=PR3&dq=Iterative+methods+for+optimization&ots=bSU7U7rbZE&sig=REHAAkh631RlEWPS8LFyKuDcQc4},
  urldate = {2014-03-02},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\TYSPYUEZ\\Kelley - 1999 - Iterative methods for optimization.pdf}
}

@article{Kierkels2014,
  title = {Direct use of multivariable normal tissue complication probability models in treatment plan optimisation for individualised head and neck cancer radiotherapy produces clinically acceptable treatment plans},
  author = {Kierkels, Roel G.J. and Korevaar, Erik W. and Steenbakkers, Roel J.H.M. and Janssen, Tomas and family=Veld, given=Aart A., prefix=van’t, useprefix=true and Langendijk, Johannes A. and Schilstra, Cornelis and family=Schaaf, given=Arjen, prefix=van der, useprefix=true},
  date = {2014-09},
  journaltitle = {Radiotherapy and Oncology},
  shortjournal = {Radiotherapy and Oncology},
  volume = {112},
  number = {3},
  pages = {430--436},
  issn = {01678140},
  doi = {10.1016/j.radonc.2014.08.020},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167814014003508},
  urldate = {2021-04-05},
  abstract = {Background and purpose: Recently, clinically validated multivariable normal tissue complication probability models (NTCP) for head and neck cancer (HNC) patients have become available. We test the feasibility of using multivariable NTCP-models directly in the optimiser for inverse treatment planning of radiotherapy to improve the dose distributions and corresponding NTCP-estimates in HNC patients. Material and methods: For 10 HNC cases, intensity-modulated radiotherapy plans were optimised either using objective functions based on the ‘generalised equivalent uniform dose’ (OFgEUD) or based on multivariable NTCP-models (OFNTCP). NTCP-models for patient-rated xerostomia, physician-rated RTOG grade II-IV dysphagia, and various patient-rated aspects of swallowing dysfunction were incorporated. The NTCP-models included dose–volume parameters as well as clinical factors contributing to a personalised optimisation process. Both optimisation techniques were compared by means of ‘pseudo Pareto fronts’ (target dose conformity vs. the sum of the NTCPs). Results: Both optimisation techniques resulted in clinically realistic treatment plans with only small differences. For nine patients the sum-NTCP was lower for the OFNTCP optimised plans (on average 5.7\% (95\%CI 1.7–9.9\%, p {$<$} 0.006)). Furthermore, the OFNTCP provided the advantages of fewer unknown optimisation parameters and an intrinsic mechanism of individualisation. Conclusions: Treatment plan optimisation using multivariable NTCP-models directly in the OF is feasible as has been demonstrated for HNC radiotherapy. Ó 2014 Elsevier Ireland Ltd. All rights reserved. Radiotherapy and Oncology 112 (2014) 430–436},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\PKSTHFQA\\Kierkels et al. - 2014 - Direct use of multivariable normal tissue complica.pdf}
}

@incollection{Kikinis2014,
  title = {{{3D Slicer}}: {{A Platform}} for {{Subject-Specific Image Analysis}}, {{Visualization}}, and {{Clinical Support}}},
  shorttitle = {{{3D Slicer}}},
  booktitle = {Intraoperative {{Imaging}} and {{Image-Guided Therapy}}},
  author = {Kikinis, Ron and Pieper, Steve D. and Vosburgh, Kirby G.},
  editor = {Jolesz, Ferenc A.},
  date = {2014},
  pages = {277--289},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4614-7657-3_19},
  url = {https://doi.org/10.1007/978-1-4614-7657-3_19},
  urldate = {2019-09-02},
  abstract = {3D Slicer is an open-source platform for the analysis and display of information derived from medical imaging and similar data sets. Such advanced software environments are in daily use by researchers and clinicians and in many nonmedical applications. 3D Slicer is unique through serving clinical users, multidisciplinary clinical research terms, and software architects within a single technology structure and user community. Functions such as interactive visualization, image registration, and model-based analysis are now being complemented by more advanced capabilities, most notably in neurological imaging and intervention. These functions, originally limited to offline use by technical factors, are integral to large scale, rapidly developing research studies, and they are being increasingly integrated into the management and delivery of care. This activity has been led by a community of basic, applied, and clinical scientists and engineers, from both academic and commercial perspectives. 3D Slicer, a free open-source software package, is based in this community; 3D Slicer provides a set of interactive tools and a stable platform that can quickly incorporate new analysis techniques and evolve to serve more sophisticated real-time applications while remaining compatible with the latest hardware and software generations of host computer systems.},
  isbn = {978-1-4614-7657-3},
  langid = {english},
  keywords = {Diffusion Magnetic Resonance Imaging,Iterative Close Point,Source Code Repository,Volume Rendering}
}

@article{Kim2006,
  title = {Imaging in {{Radiation Therapy}}},
  author = {Kim, Siyong and Suh, Tae-Suk},
  date = {2006},
  journaltitle = {Nuclear Engineering and Technology},
  volume = {38}
}

@article{Kirkby2010,
  title = {Lung dosimetry in a linac-{{MRI}} radiotherapy unit with a longitudinal magnetic field},
  author = {Kirkby, C and Murray, B and Rathee, S and Fallone, B.\textasciitilde G.},
  date = {2010},
  journaltitle = {Medical Physics},
  volume = {37},
  pages = {4722},
  doi = {10.1118/1.3475942}
}

@article{Kirkpatrick2010,
  title = {Radiation dose-volume effects in the spinal cord.},
  author = {Kirkpatrick, John P and family=Kogel, given=Albert J, prefix=van der, useprefix=true and Schultheiss, Timothy E},
  date = {2010-03-01},
  journaltitle = {International journal of radiation oncology, biology, physics},
  volume = {76},
  eprint = {20171517},
  eprinttype = {pmid},
  pages = {S42-9},
  issn = {1879-355X},
  doi = {10.1016/j.ijrobp.2009.04.095},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301609032969},
  urldate = {2014-02-23},
  abstract = {Dose-volume data for myelopathy in humans treated with radiotherapy (RT) to the spine is reviewed, along with pertinent preclinical data. Using conventional fractionation of 1.8-2 Gy/fraction to the full-thickness cord, the estimated risk of myelopathy is {$<$}1\% and {$<$}10\% at 54 Gy and 61 Gy, respectively, with a calculated strong dependence on dose/fraction (alpha/beta = 0.87 Gy.) Reirradiation data in animals and humans suggest partial repair of RT-induced subclinical damage becoming evident about 6 months post-RT and increasing over the next 2 years. Reports of myelopathy from stereotactic radiosurgery to spinal lesions appear rare ({$<$}1\%) when the maximum spinal cord dose is limited to the equivalent of 13 Gy in a single fraction or 20 Gy in three fractions. However, long-term data are insufficient to calculate a dose-volume relationship for myelopathy when the partial cord is treated with a hypofractionated regimen.},
  issue = {3 Suppl},
  keywords = {Age Factors,Animals,Dose-Response Relationship; Radiation,Humans,Radiation Injuries,Radiation Injuries: etiology,Radiation Tolerance,Radiosurgery,Radiosurgery: adverse effects,Radiotherapy,Radiotherapy: adverse effects,Rats,Retreatment,Retreatment: adverse effects,Spinal Cord,Spinal Cord: radiation effects},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\KIPPY8JK\\Kirkpatrick, van der Kogel, Schultheiss - 2010 - Radiation dose-volume effects in the spinal cord.pdf}
}

@article{Knopf2009,
  title = {Systematic analysis of biological and physical limitations of proton beam range verification with offline {{PET}}/{{CT}} scans},
  author = {Knopf, A. and Parodi, K. and Bortfeld, T. and Shih, H. A. and Paganetti, H.},
  date = {2009-06},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {54},
  number = {14},
  pages = {4477--4495},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/54/14/008},
  url = {https://doi.org/10.1088%2F0031-9155%2F54%2F14%2F008},
  urldate = {2020-04-03},
  abstract = {The clinical use of offline positron emission tomography/computed tomography (PET/CT) scans for proton range verification is currently under investigation at the Massachusetts General Hospital (MGH). Validation is achieved by comparing measured activity distributions, acquired in patients after receiving one fraction of proton irradiation, with corresponding Monte Carlo (MC) simulated distributions. Deviations between measured and simulated activity distributions can either reflect errors during the treatment chain from planning to delivery or they can be caused by various inherent challenges of the offline PET/CT verification method. We performed a systematic analysis to assess the impact of the following aspects on the feasibility and accuracy of the offline PET/CT method: (1) biological washout processes, (2) patient motion, (3) Hounsfield unit (HU) based tissue classification for the simulation of the activity distributions and (4) tumor site specific aspects. It was found that the spatial reproducibility of the measured activity distributions is within 1 mm. However, the feasibility of range verification is restricted to a limited amount of positions and tumor sites. Washout effects introduce discrepancies between the measured and simulated ranges of about 4 mm at positions where the proton beam stops in soft tissue. Motion causes spatial deviations of up to 3 cm between measured and simulated activity distributions in abdominopelvic tumor cases. In these later cases, the MC simulated activity distributions were found to be limited to about 35\% accuracy in absolute values and about 2 mm in spatial accuracy depending on the correlativity of HU into the physical and biological parameters of the irradiated tissue. Besides, for further specific tumor locations, the beam arrangement, the limited accuracy of rigid co-registration and organ movements can prevent the success of PET/CT range verification. All the addressed factors explain why the proton beam range can only be verified within an accuracy of 1–2 mm in low-perfused bony structures of head and neck patients for which an accurate co-registration of predominant bony anatomy is possible, as shown previously. However, most of the limitations of the current approach are conquerable. By implementing technological and methodological improvements like the use of in-room PET scanners, PET measurements could soon be used to provide proton range verification in clinical routine.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\42IQL8SP\\Knopf et al. - 2009 - Systematic analysis of biological and physical lim.pdf}
}

@article{Knopf2011,
  title = {Scanned proton radiotherapy for mobile targets—the effectiveness of re-scanning in the context of different treatment planning approaches and for different motion characteristics},
  author = {Knopf, Antje-Christin and Hong, Theodore S. and Lomax, Antony},
  date = {2011-10},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {56},
  number = {22},
  pages = {7257--7271},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/56/22/016},
  url = {https://doi.org/10.1088%2F0031-9155%2F56%2F22%2F016},
  urldate = {2020-04-03},
  abstract = {The most advanced delivery technique for proton radiotherapy is active spot scanning. So far, predominantly static targets have been treated with active spot scanning, since mobile targets in combination with dynamic treatment delivery can lead to interplay effects, causing inhomogeneous dose distributions. One way to mitigate motion effects is re-scanning. In this study we investigate the effectiveness of re-scanning in relation to different plan parameters (number of fields, field directions, number of re-scans) as well as in respect to different motion parameters (motion amplitude, motion starting phase). A systematic study was performed for three liver patients, for which ten different plans have been calculated, respectively. The treatment plans were evaluated for three different scenarios (static, motion/single-scan-delivery, motion/re-scanned-delivery). The choice of motion parameters was based on an evaluation of the 4D CT data sets of the three patients. It is shown that the effect of motion/re-scanning per fraction is largest the fewer fields per plan are used and the more the field direction differs from the main motion direction. For amplitudes up to 6 mm, re-scanning may not be required if multiple fields are used, since only dose blurring effects appear that cannot be compensated by re-scanning. For larger motion amplitudes two planning strategies are proposed.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Y6J9RZTT\\Knopf et al. - 2011 - Scanned proton radiotherapy for mobile targets—the.pdf}
}

@article{Knopf2013,
  title = {Adequate margin definition for scanned particle therapy in the incidence of intrafractional motion},
  author = {Knopf, Antje-Christin and Boye, Dirk and Lomax, Antony and Mori, Shininchiro},
  date = {2013-09-07},
  journaltitle = {Physics in Medicine and Biology},
  volume = {58},
  number = {17},
  pages = {6079--6094},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/58/17/6079},
  url = {http://stacks.iop.org/0031-9155/58/i=17/a=6079?key=crossref.10b4367c87384a12e5439aee93665029},
  urldate = {2016-07-20},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\PWU6ISAS\\Knopf et al. - 2013 - Adequate margin definition for scanned particle therapy in the incidence of intrafractional motion.pdf}
}

@inproceedings{Kolda2008,
  title = {Scalable {{Tensor Decompositions}} for {{Multi-aspect Data Mining}}},
  booktitle = {2008 {{Eighth IEEE International Conference}} on {{Data Mining}}},
  author = {Kolda, Tamara G. and Sun, Jimeng},
  date = {2008-12},
  pages = {363--372},
  publisher = {{IEEE}},
  doi = {10.1109/ICDM.2008.89},
  url = {http://ieeexplore.ieee.org/document/4781131/},
  urldate = {2018-04-14},
  isbn = {978-0-7695-3502-9},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\LWL4HDXI\\Kolda, Sun - 2008 - Scalable Tensor Decompositions for Multi-aspect Data Mining.pdf}
}

@book{Kommer2019,
  title = {Tutorium {{Physik}} fürs {{Nebenfach}}},
  author = {Kommer, Christoph and Tugendhat, Tim and Wahl, Niklas},
  date = {2019},
  edition = {2},
  publisher = {{Springer Spektrum}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-47244-6},
  url = {http://link.springer.com/10.1007/978-3-662-47244-6},
  isbn = {978-3-662-59395-0},
  preview = {phystut-cover.jpg},
  selected = {true}
}

@article{Kooy2010,
  title = {A {{Case Study}} in {{Proton Pencil-Beam Scanning Delivery}}},
  author = {Kooy, Hanne M. and Clasie, Benjamin M. and Lu, Hsiao-Ming and Madden, Thomas M. and Bentefour, Hassan and Depauw, Nicolas and Adams, Judy A. and Trofimov, Alexei V. and Demaret, Denis and Delaney, Thomas F. and Flanz, Jacob B.},
  date = {2010-02-01},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {Int J Radiat Oncol},
  volume = {76},
  number = {2},
  pages = {624--630},
  issn = {0360-3016},
  doi = {10.1016/j.ijrobp.2009.06.065},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301609010116},
  urldate = {2019-10-25},
  abstract = {Purpose We completed an implementation of pencil-beam scanning (PBS), a technology whereby a focused beam of protons, of variable intensity and energy, is scanned over a plane perpendicular to the beam axis and in depth. The aim of radiotherapy is to improve the target to healthy tissue dose differential. We illustrate how PBS achieves this aim in a patient with a bulky tumor. Methods and Materials Our first deployment of PBS uses “broad” pencil-beams ranging from 20 to 35 mm (full-width-half-maximum) over the range interval from 32 to 7 g/cm2. Such beam-brushes offer a unique opportunity for treating bulky tumors. We present a case study of a large (4,295 cc clinical target volume) retroperitoneal sarcoma treated to 50.4 Gy relative biological effectiveness (RBE) (presurgery) using a course of photons and protons to the clinical target volume and a course of protons to the gross target volume. Results We describe our system and present the dosimetry for all courses and provide an interdosimetric comparison. Discussion The use of PBS for bulky targets reduces the complexity of treatment planning and delivery compared with collimated proton fields. In addition, PBS obviates, especially for cases as presented here, the significant cost incurred in the construction of field-specific hardware. PBS offers improved dose distributions, reduced treatment time, and reduced cost of treatment.},
  langid = {english},
  keywords = {Optimization,Pencil-beam scanning,Proton radiotherapy,Treatment planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\A34Z36MR\\Kooy et al. - 2010 - A Case Study in Proton Pencil-Beam Scanning Delive.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\BTMWLCK5\\S0360301609010116.html}
}

@book{Kotz2000,
  title = {Continuous multivariate distributions,  {{Volume}} 1: {{Models}} and {{Applications}}},
  author = {Kotz, Samuel. and Johnson, Norman Lloyd. and Balakrishnan, N.},
  date = {2000},
  edition = {2},
  publisher = {{Wiley}},
  url = {https://www.wiley.com/en-us/Continuous+Multivariate+Distributions%2C+Volume+1%3A+Models+and+Applications%2C+2nd+Edition-p-9780471183877},
  urldate = {2018-04-14},
  isbn = {978-0-471-18387-7}
}

@article{Kraan2013,
  title = {Dose uncertainties in {{IMPT}} for oropharyngeal cancer in the presence of anatomical, range, and setup errors},
  author = {Kraan, Aafke C. and Van De Water, Steven and Teguh, David N. and Al-Mamgani, Abrahim and Madden, Tom and Kooy, Hanne M. and Heijmen, Ben J M and Hoogeman, Mischa S.},
  date = {2013},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {Int J Radiat Oncol Biol Phys},
  volume = {87},
  number = {5},
  eprint = {24351409},
  eprinttype = {pmid},
  pages = {888--896},
  publisher = {{Elsevier Inc.}},
  issn = {03603016},
  doi = {10.1016/j.ijrobp.2013.09.014},
  url = {http://dx.doi.org/10.1016/j.ijrobp.2013.09.014},
  abstract = {Purpose Setup, range, and anatomical uncertainties influence the dose delivered with intensity modulated proton therapy (IMPT), but clinical quantification of these errors for oropharyngeal cancer is lacking. We quantified these factors and investigated treatment fidelity, that is, robustness, as influenced by adaptive planning and by applying more beam directions. Methods and Materials We used an in-house treatment planning system with multicriteria optimization of pencil beam energies, directions, and weights to create treatment plans for 3-, 5-, and 7-beam directions for 10 oropharyngeal cancer patients. The dose prescription was a simultaneously integrated boost scheme, prescribing 66 Gy to primary tumor and positive neck levels (clinical target volume-66 Gy; CTV-66 Gy) and 54 Gy to elective neck levels (CTV-54 Gy). Doses were recalculated in 3700 simulations of setup, range, and anatomical uncertainties. Repeat computed tomography (CT) scans were used to evaluate an adaptive planning strategy using nonrigid registration for dose accumulation. Results For the recalculated 3-beam plans including all treatment uncertainty sources, only 69\% (CTV-66 Gy) and 88\% (CTV-54 Gy) of the simulations had a dose received by 98\% of the target volume (D98\%) {$>$}95\% of the prescription dose. Doses to organs at risk (OARs) showed considerable spread around planned values. Causes for major deviations were mixed. Adaptive planning based on repeat imaging positively affected dose delivery accuracy: in the presence of the other errors, percentages of treatments with D98\% {$>$}95\% increased to 96\% (CTV-66 Gy) and 100\% (CTV-54 Gy). Plans with more beam directions were not more robust. Conclusions For oropharyngeal cancer patients, treatment uncertainties can result in significant differences between planned and delivered IMPT doses. Given the mixed causes for major deviations, we advise repeat diagnostic CT scans during treatment, recalculation of the dose, and if required, adaptive planning to improve adequate IMPT dose delivery. ?? 2013 The Authors. Published by Elsevier Inc. All rights reserved.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\458QH5WL\\Kraan et al. - 2013 - Dose uncertainties in IMPT for oropharyngeal cancer in the presence of anatomical, range, and setup errors.pdf}
}

@article{Kramer2000,
  title = {Treatment planning for heavy-ion radiotherapy: calculation and optimization of biologically effective dose},
  shorttitle = {Treatment planning for heavy-ion radiotherapy},
  author = {Krämer, M. and Scholz, M.},
  date = {2000-10},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {45},
  number = {11},
  pages = {3319--3330},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/45/11/314},
  url = {https://doi.org/10.1088%2F0031-9155%2F45%2F11%2F314},
  urldate = {2019-10-27},
  abstract = {We describe a novel approach to treatment planning for heavy-ion radiotherapy based on the local effect model (LEM) which allows us to calculate the biologically effective dose not only for the target region but also for the entire irradiation volume. LEM is ideally suited for use as an integral part of treatment planning code systems for active dose shaping devices like the GSI raster scan system. Thus it has been incorporated into our standard treatment planning system for ion therapy (TRiP). Single intensity modulated fields can be optimized with respect to a homogeneous biologically effective dose. The relative biological effectiveness (RBE) is calculated separately for each voxel of the patient CT. Our radiobiologically oriented code system has been used since 1995 for the planning of irradiation experiments with cell cultures and animals such as rats and minipigs. It has been in regular and successful use for patient treatment planning since 1997.},
  langid = {english}
}

@article{Kramer2000a,
  title = {Treatment planning for heavy-ion radiotherapy: physical beam model and dose optimization},
  shorttitle = {Treatment planning for heavy-ion radiotherapy},
  author = {Krämer, M. and Jäkel, O. and Haberer, T. and Kraft, G. and Schardt, D. and Weber, U.},
  date = {2000-10},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {45},
  number = {11},
  pages = {3299--3317},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/45/11/313},
  url = {https://doi.org/10.1088%2F0031-9155%2F45%2F11%2F313},
  urldate = {2020-11-25},
  abstract = {We describe a novel code system, TRiP, dedicated to the planning of radiotherapy with energetic ions, in particular 12C. The software is designed to cooperate with three-dimensional active dose shaping devices like the GSI raster scan system. This unique beam delivery system allows us to select any combination from a list of 253 individual beam energies, 7 different beam spot sizes and 15 intensity levels. The software includes a beam model adapted to and verified for carbon ions. Inverse planning techniques are implemented in order to obtain a uniform target dose distribution from clinical input data, i.e. CT images and patient contours. This implies the automatic generation of intensity modulated fields of heavy ions with as many as 40 000 raster points, where each point corresponds to a specific beam position, energy and particle fluence. This set of data is directly passed to the beam delivery and control system. The treatment planning code has been in clinical use since the start of the GSI pilot project in December 1997. Forty-eight patients have been successfully planned and treated.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\FQY5IHZ5\\Krämer et al. - 2000 - Treatment planning for heavy-ion radiotherapy phy.pdf}
}

@article{Kramer2006,
  title = {Rapid calculation of biological effects in ion radiotherapy},
  author = {Krämer, M and Scholz, M},
  date = {2006-04-21},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {51},
  number = {8},
  pages = {1959--1970},
  issn = {0031-9155, 1361-6560},
  doi = {10.1088/0031-9155/51/8/001},
  url = {https://iopscience.iop.org/article/10.1088/0031-9155/51/8/001},
  urldate = {2020-07-20},
  abstract = {We describe a method for fast calculation of biological effects after ion irradiation. It is an alternative derivative of the established local effect model (LEM) and has been integrated into GSI’s TRiP98 treatment planning system. We show that deviations from our classic approach for treatment planning are less than 5\% for therapeutical doses, but calculational speed can be improved by one to two orders of magnitude. This will allow sophisticated methods of treatment planning for ion irradiation, taking biological effects fully into account.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\A7V2ZPEU\\Krämer und Scholz - 2006 - Rapid calculation of biological effects in ion rad.pdf}
}

@article{Krejcarek2007,
  title = {Physiologic and {{Radiographic Evidence}} of the {{Distal Edge}} of the {{Proton Beam}} in {{Craniospinal Irradiation}}},
  author = {Krejcarek, Stephanie C. and Grant, P. Ellen and Henson, John W. and Tarbell, Nancy J. and Yock, Torunn I.},
  date = {2007-07-01},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {68},
  number = {3},
  pages = {646--649},
  issn = {0360-3016},
  doi = {10.1016/j.ijrobp.2007.02.021},
  url = {http://www.sciencedirect.com/science/article/pii/S036030160700243X},
  urldate = {2020-04-03},
  abstract = {Purpose: Fatty replacement of bone marrow resulting from radiation therapy can be seen on T1-weighted magnetic resonance (MR) images. We evaluated the radiographic appearance of the vertebral bodies in children treated with proton craniospinal irradiation (CSI) to illustrate the distal edge effect of proton radiotherapy. Methods and Materials: The study cohort consisted of 13 adolescents aged 12–18 years who received CSI with proton radiotherapy at Massachusetts General Hospital. Ten of these patients had reached maximal or near-maximal growth. Proton beam radiation for these 10 patients was delivered to the thecal sac and exiting nerve roots only, whereas the remaining 3 patients had a target volume that included the thecal sac, exiting nerve roots, and entire vertebral bodies. Median CSI dose was 27 [range, 23.4–36] cobalt gray equivalent (CGE) given in 1.8-CGE fractions. Magnetic resonance images of the spine were obtained after completion of radiotherapy. Results: Magnetic resonance images of patients who received proton radiotherapy to the thecal sac only demonstrate a sharp demarcation of hyperintense T1-weighted signal in the posterior aspects of the vertebral bodies, consistent with radiation-associated fatty marrow replacement. Magnetic resonance images of the patients prescribed proton radiotherapy to the entire vertebral column had corresponding hyperintense T1-weighted signal involving the entire vertebral bodies. Conclusion: The sharp delineation of radiation-associated fatty marrow replacement in the vertebral bodies demonstrates the rapid decrease in energy at the edge of the proton beam. This provides evidence for a sharp fall-off in radiation dose and supports the premise that proton radiotherapy spares normal tissues unnecessary irradiation.},
  langid = {english},
  keywords = {Craniospinal irradiation,Dosimetry,Late effects,Medulloblastoma,Proton radiotherapy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\5GBF4K7U\\Krejcarek et al. - 2007 - Physiologic and Radiographic Evidence of the Dista.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\NFDQGZVZ\\S036030160700243X.html}
}

@article{Ku1966,
  title = {Notes on the use of propagation of error formulas},
  author = {Ku, H.H.},
  date = {1966-10},
  journaltitle = {Journal of Research of the National Bureau of Standards, Section C: Engineering and Instrumentation},
  volume = {70C},
  number = {4},
  pages = {263},
  issn = {0022-4316},
  doi = {10.6028/jres.070C.025},
  abstract = {Th e " la w of propagation o[ error" is a tool th a t physical sc ienti s ts have co nve nie ntly and fre qu en tly used in th e ir work for ma n y years, yet an adeq uate refere nce is diffi c u lt to find. In thi s paper an exposi-tory rev ie w of thi s topi c is prese nte d , partic ularly in the li ght of c urre nt prac ti ces a nd interpretation s. Examp les on t he acc uracy of th e approximations are give n. The reportin g of th e un ce rtainti es of final res ults is di sc ussed . Key Word s : Approximation, e rror, formula , imprecision, law of e rror, prod uc ts, propaga ti on of e rror, rand om, ratio, syste mati c, s um.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\PA2L3AJA\\Ku - 1966 - Notes on the use of propagation of error formulas.pdf}
}

@report{Kufer2005,
  type = {ITWM Report},
  title = {Multicriteria optimization in intensity modulated radiotherapy planning},
  author = {Küfer, Karl-Heinz and Monz, Michael and Scherrer, Alexander and Süss, P. and Alonso, Fernando and Sultan, A. S. A. and Bortfeld, Thomas and Craft, David and Thieke, Christian},
  date = {2005},
  series = {Berichte des {{Fraunhofer-Instituts}} für {{Techno-}} und {{Wirtschaftsmathematik}}},
  number = {77},
  institution = {{Fraunhofer (ITWM)}},
  url = {https://kluedo.ub.uni-kl.de/frontdoor/deliver/index/docId/1649/file/bericht77.pdf},
  urldate = {2021-12-01},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\TJY49LWM\\bericht77.pdf}
}

@article{Kurz2020,
  title = {Medical physics challenges in clinical {{MR-guided}} radiotherapy},
  author = {Kurz, Christopher and Buizza, Giulia and Landry, Guillaume and Kamp, Florian and Rabe, Moritz and Paganelli, Chiara and Baroni, Guido and Reiner, Michael and Keall, Paul J. and family=Berg, given=Cornelis A. T., prefix=van den, useprefix=true and Riboldi, Marco},
  date = {2020-05-05},
  journaltitle = {Radiation Oncology},
  shortjournal = {Radiation Oncology},
  volume = {15},
  number = {1},
  pages = {93},
  issn = {1748-717X},
  doi = {10.1186/s13014-020-01524-4},
  url = {https://doi.org/10.1186/s13014-020-01524-4},
  urldate = {2022-08-16},
  abstract = {The integration of magnetic resonance imaging (MRI) for guidance in external beam radiotherapy has faced significant research and development efforts in recent years. The current availability of linear accelerators with an embedded MRI unit, providing volumetric imaging at excellent soft tissue contrast, is expected to provide novel possibilities in the implementation of image-guided adaptive radiotherapy (IGART) protocols. This study reviews open medical physics issues in MR-guided radiotherapy (MRgRT) implementation, with a focus on current approaches and on the potential for innovation in IGART.},
  keywords = {adaptive radiotherapy,image-guided radiotherapy (IGRT),Magnetic Resonance Imaging (MRI),MR-guided radiotherapy (MRgRT),quality assurance (QA),quantitative MR imaging (qMRI)},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\8ELU8JWR\\Kurz et al. - 2020 - Medical physics challenges in clinical MR-guided r.pdf}
}

@article{Kutcher1991,
  title = {Histogram reduction method for calculating complication probabilities for three-dimensional treatment planning evaluations},
  author = {Kutcher, G. J. and Burman, C. and Brewster, L. and Goitein, M. and Mohan, R.},
  date = {1991-05-15},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {International Journal of Radiation Oncology*Biology*Physics},
  series = {Three-{{Dimensional Photon Treatment Planning Report}} of the {{Collaborative Working Group}} on the {{Evaluation}} of {{Treatment Planning}} for {{External Photon Beam Radiotherapy}}},
  volume = {21},
  number = {1},
  pages = {137--146},
  issn = {0360-3016},
  doi = {10.1016/0360-3016(91)90173-2},
  url = {https://www.sciencedirect.com/science/article/pii/0360301691901732},
  urldate = {2021-04-05},
  abstract = {New tools are needed to help in evaluating 3-D treatment plans because of the large volume of data. One technique which may prove useful is the application of complication probability calculations. A method of calculating complication probabilities for inhomogeneously irradiated normal tissues is presented in this paper. The method uses clinical estimates of tolerance doses for a few discreet conditions of uniform partial organ irradiation, an empirical fit of a continuous function to these data, and a technique (the effective volume method) for transforming nonuniform dose-volume histograms into equivalent uniform histograms. The behavior of the effective volume histogram reduction method for various boundary conditions is reviewed. The use of complication probabilities in evaluating treatment plans is presented, using examples from an NCI 3-D treatment planning contract.},
  langid = {english},
  keywords = {3-D treatment planning,Complication probability calculations,Scoring,Treatment planning evaluation}
}

@article{Lagendijk2005,
  title = {In {{Room Magnetic Resonance Imaging Guided Radiotherapy}} ({{MRIgRT}})},
  author = {Lagendijk, J and Raaymakers, B and family=Heide, given=U, prefix=van der, useprefix=true and Overweg, J and Brown, K and Bakker, C and Raaijmakers, A and Vulpen, M and Welleweerd, J and Jürgenliemk-Schulz, I},
  date = {2005},
  journaltitle = {Medical Physics},
  volume = {32},
  number = {6},
  pages = {2067},
  publisher = {{AAPM}},
  doi = {10.1118/1.1998294},
  url = {http://link.aip.org/link/?MPH/32/2067/2}
}

@article{Lagendijk2008,
  title = {{{MRI}}/linac integration.},
  author = {Lagendijk, Jan J W and Raaymakers, Bas W and Raaijmakers, Alexander J E and Overweg, Johan and Brown, Kevin J and Kerkhof, Ellen M and family=Put, given=Richard W, prefix=van der, useprefix=true and H�rdemark, Bj�rn and family=Vulpen, given=Marco, prefix=van, useprefix=true and family=Heide, given=Uulke A, prefix=van der, useprefix=true},
  date = {2008-01},
  journaltitle = {Radiother Oncol},
  volume = {86},
  number = {1},
  pages = {25--29},
  doi = {10.1016/j.radonc.2007.10.034},
  url = {http://dx.doi.org/10.1016/j.radonc.2007.10.034},
  abstract = {In radiotherapy the healthy tissue involvement still poses serious dose limitations. This results in sub-optimal tumour dose and complications. Daily image guided radiotherapy (IGRT) is the key development in radiation oncology to solve this problem. MRI yields superb soft-tissue visualization and provides several imaging modalities for identification of movements, function and physiology. Integrating MRI functionality with an accelerator can make these capacities available for high precision, real time IGRT.The system being built at the University Medical Center Utrecht is a 1.5T MRI scanner, with diagnostic imaging functionality and quality, integrated with a 6MV radiotherapy accelerator. The realization of a prototype of this hybrid system is a joint effort between the Radiotherapy Department of the University of Utrecht, the Netherlands, Elekta, Crawley, U.K., and Philips Research, Hamburg, Germany. Basically, the design is a 1.5 T Philips Achieva MRI scanner with a Magnex closed bore magnet surrounded by a single energy (6 MV) Elekta accelerator. Monte Carlo simulations are used to investigate the radiation beam properties of the hybrid system, dosimetry equipment and for the construction of patient specific dose deposition kernels},
  keywords = {Computer-Assisted,Humans; Magnetic Resonance Imaging; Particle Accel,instrumentation; Radiotherapy Dosage; Radiotherap}
}

@inproceedings{Lagendijk2011,
  title = {Real time {{MRI-gestuurde Radiotherapie}}},
  author = {Lagendijk, Jan and Raaymakers, Bas and family=Vulpen, given=Marco, prefix=van, useprefix=true},
  date = {2011}
}

@article{Lagendijk2014,
  title = {The {{Magnetic Resonance Imaging}}–{{Linac System}}},
  author = {Lagendijk, Jan J.W. and Raaymakers, Bas W. and family=Vulpen, given=Marco, prefix=van, useprefix=true},
  date = {2014-07},
  journaltitle = {Seminars in Radiation Oncology},
  volume = {24},
  number = {3},
  pages = {207--209},
  issn = {10534296},
  doi = {10.1016/j.semradonc.2014.02.009},
  url = {http://www.sciencedirect.com/science/article/pii/S1053429614000265},
  urldate = {2014-08-07},
  abstract = {The current image-guided radiotherapy systems are suboptimal in the esophagus, pancreas, kidney, rectum, lymph node, etc. These locations in the body are not easily accessible for fiducials and cannot be visualized sufficiently on cone-beam computed tomographies, making daily patient set-up prone to geometrical uncertainties and hinder dose optimization. Additional interfraction and intrafraction uncertainties for those locations arise from motion with breathing and organ filling. To allow real-time imaging of all patient tumor locations at the actual treatment position a fully integrated 1.5-T, diagnostic quality, magnetic resonance imaging with a 6-MV linear accelerator is presented. This system must enable detailed dose painting at all body locations.}
}

@article{Lamey2010,
  title = {Radio frequency shielding for a linac-{{MRI}} system.},
  author = {Lamey, M and Burke, B and Blosser, E and Rathee, S and De Zanche, N and Fallone, B G},
  date = {2010-02},
  journaltitle = {Phys Med Biol},
  volume = {55},
  number = {4},
  pages = {995--1006},
  doi = {10.1088/0031-9155/55/4/006},
  url = {http://dx.doi.org/10.1088/0031-9155/55/4/006},
  abstract = {The real-time operation of a linac-MRI system will require proper radio frequency (RF) shielding such that the MRI images can be acquired without extraneous RF noise from the linac. We report on the steps taken to successfully shield the linac from the MRI such that the two devices can operate independently of one another. RF power density levels are reported internally and externally to the RF cage which houses the linac and MRI. The shielding effectiveness of the RF cage has been measured in the frequency range 1-50 MHz and is presented. Lastly MRI images of two phantoms are presented during linac operation. This work illustrates that the accelerating structure of a linac and an MRI can be housed within the same RF cage. The 6 MV linac can be operated to produce radiation with no measurable degradation},
  keywords = {Algorithms; Artifacts; Magnetic Resonance Imaging,Imaging; Radio Waves; Radiosurgery,instrumentation/methods,instrumentation/methods; Phantoms}
}

@article{Lamey2010a,
  title = {Radio frequency noise from an {{MLC}}: a feasibility study of the use of an {{MLC}} for linac-{{MR}} systems.},
  author = {Lamey, M and Yun, J and Burke, B and Rathee, S and Fallone, B G},
  date = {2010-02},
  journaltitle = {Phys Med Biol},
  volume = {55},
  number = {4},
  pages = {981--994},
  doi = {10.1088/0031-9155/55/4/005},
  url = {http://dx.doi.org/10.1088/0031-9155/55/4/005},
  abstract = {Currently several groups are actively researching the integration of a megavoltage teletherapy unit with magnetic resonance (MR) imaging for real-time image-guided radiotherapy. The use of a multileaf collimator (MLC) for intensity-modulated radiotherapy for linac-MR units must be investigated. The MLC itself will likely reside in the fringe field of the MR and the motors will produce radio frequency (RF) noise. The RF noise power spectral density from a Varian 52-leaf MLC motor, a Varian Millennium MLC motor and a brushless fan motor has been measured as a function of the applied magnetic field using a near field probe set. For the Varian 52-leaf MLC system, the RF noise produced by 13 of 52 motors is studied as a function of distance from the MLC. Data are reported in the frequency range suitable for 0.2-1.5 T linac-MR systems. Below 40 MHz the Millennium MLC motor tested showed more noise than the Varian 52-leaf motor or the brushless fan motor. The brushless motor showed a small dependence on the applied magnetic field. Images of a phantom were taken by the prototype linac-MR system with the MLC placed in close proximity to the magnet. Several orientations of the MLC in both shielded and non-shielded configurations were studied. For the case of a non-shielded MLC and associated cables, the signal-to-noise ratio (SNR) was reduced when 13 of 52 MLC leaves were moved during imaging. When the MLC and associated cables were shielded, the measured SNR of the images with 13 MLC leaves moving was experimentally the same as the SNR of the stationary MLC image. When the MLC and cables are shielded, subtraction images acquired with and without MLC motion contains no systematic signal. This study illustrates that the small RF noise produced by functioning MLC motors can be effectively shielded to avoid SNR degradation. A functioning MLC can be incorporated into a linac-MR unit.},
  keywords = {Algorithms; Artifacts; Electromagnetic Fields; Fea,Imaging; Radio Waves; Radiotherapy,instrumentation/methods,instrumentation/methods; Phantoms,Intensity-Modulated}
}

@article{Landwehr1978,
  title = {Some properties of the geometric mean and its use in water quality standards},
  author = {Landwehr, Jurate Maciunas},
  date = {1978-06},
  journaltitle = {Water Resources Research},
  volume = {14},
  number = {3},
  pages = {467--473},
  issn = {00431397},
  doi = {10.1029/WR014i003p00467},
  url = {http://doi.wiley.com/10.1029/WR014i003p00467}
}

@article{Lechner2013,
  title = {Evaluation of treatment plan quality of {{IMRT}} and {{VMAT}} with and without flattening filter using {{Pareto}} optimal fronts},
  author = {Lechner, Wolfgang and Kragl, Gabriele and Georg, Dietmar},
  date = {2013},
  journaltitle = {Radiotherapy and Oncology},
  volume = {109},
  number = {3},
  pages = {437--441},
  issn = {0167-8140},
  doi = {http://dx.doi.org/10.1016/j.radonc.2013.09.020},
  url = {http://www.sciencedirect.com/science/article/pii/S0167814013004957},
  urldate = {2014-01-27},
  abstract = {PURPOSE To investigate the differences in treatment plan quality of IMRT and VMAT with and without flattening filter using Pareto optimal fronts, for two treatment sites of different anatomic complexity. MATERIALS AND METHODS Pareto optimal fronts (POFs) were generated for six prostate and head-and-neck cancer patients by stepwise reduction of the constraint (during the optimization process) of the primary organ-at-risk (OAR). 9-static field IMRT and 360°-single-arc VMAT plans with flattening filter (FF) and without flattening filter (FFF) were compared. The volume receiving 5Gy or more (V5Gy) was used to estimate the low dose exposure. Furthermore, the number of monitor units (MUs) and measurements of the delivery time (T) were used to assess the efficiency of the treatment plans. RESULTS A significant increase in MUs was found when using FFF-beams while the treatment plan quality was at least equivalent to the FF-beams. T was decreased by 18\% for prostate for IMRT with FFF-beams and by 4\% for head-and-neck cases, but increased by 22\% and 16\% for VMAT. A reduction of up to 5\% of V5Gy was found for IMRT prostate cases with FFF-beams. CONCLUSIONS The evaluation of the POFs showed an at least comparable treatment plan quality of FFF-beams compared to FF-beams for both treatment sites and modalities. For smaller targets the advantageous characteristics of FFF-beams could be better exploited.},
  keywords = {FFF,Flattening filter free,IMRT,Pareto optimal fronts,VMAT},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\ANXD5AUQ\\Lechner, Kragl, Georg - 2013 - Evaluation of treatment plan quality of IMRT and VMAT with and without flattening filter using Pareto opt.pdf}
}

@book{Lehmann1998,
  title = {Theory of {{Point Estimation}}},
  author = {Lehmann, E L and Casella, George},
  date = {1998},
  series = {Springer {{Texts}} in {{Statistics}}},
  edition = {2},
  publisher = {{Springer-Verlag}},
  location = {{New York}},
  doi = {10.1007/b98854},
  url = {http://link.springer.com/10.1007/b98854},
  urldate = {2016-11-15},
  isbn = {0-387-98502-6}
}

@article{Li2010,
  title = {On-line adaptive radiation therapy: feasibility and clinical study.},
  author = {Li, Taoran and Zhu, Xiaofeng and Thongphiew, Danthai and Lee, W Robert and Vujaskovic, Zeljko and Wu, Qiuwen and Yin, Fang-Fang and Wu, Q Jackie},
  date = {2010-01},
  journaltitle = {Journal of oncology},
  volume = {2010},
  eprint = {21113304},
  eprinttype = {pmid},
  pages = {407236},
  issn = {1687-8469},
  doi = {10.1155/2010/407236},
  url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2990023&tool=pmcentrez&rendertype=abstract},
  urldate = {2013-12-12},
  abstract = {The purpose of this paper is to evaluate the feasibility and clinical dosimetric benefit of an on-line, that is, with the patient in the treatment position, Adaptive Radiation Therapy (ART) system for prostate cancer treatment based on daily cone-beam CT imaging and fast volumetric reoptimization of treatment plans. A fast intensity-modulated radiotherapy (IMRT) plan reoptimization algorithm is implemented and evaluated with clinical cases. The quality of these adapted plans is compared to the corresponding new plans generated by an experienced planner using a commercial treatment planning system and also evaluated by an in-house developed tool estimating achievable dose-volume histograms (DVHs) based on a database of existing treatment plans. In addition, a clinical implementation scheme for ART is designed and evaluated using clinical cases for its dosimetric qualities and efficiency.},
  issue = {Mlc},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\M3AYPX9I\\Li et al. - 2010 - On-line adaptive radiation therapy feasibility and clinical study.pdf}
}

@article{Li2012,
  title = {The use and {{QA}} of biologically related models for treatment planning: {{Short}} report of the {{TG-166}} of the therapy physics committee of the {{AAPM}}},
  shorttitle = {The use and {{QA}} of biologically related models for treatment planning},
  author = {Li, X. Allen and Alber, Markus and Deasy, Joseph O. and Jackson, Andrew and Jee, Kyung-Wook Ken and Marks, Lawrence B. and Martel, Mary K. and Mayo, Charles and Moiseenko, Vitali and Nahum, Alan E. and Niemierko, Andrzej and Semenenko, Vladimir A. and Yorke, Ellen D.},
  date = {2012},
  journaltitle = {Medical Physics},
  volume = {39},
  number = {3},
  pages = {1386--1409},
  issn = {2473-4209},
  doi = {10.1118/1.3685447},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.3685447},
  urldate = {2020-11-02},
  abstract = {Treatment planning tools that use biologically related models for plan optimization and/or evaluation are being introduced for clinical use. A variety of dose-response models and quantities along with a series of organ-specific model parameters are included in these tools. However, due to various limitations, such as the limitations of models and available model parameters, the incomplete understanding of dose responses, and the inadequate clinical data, the use of biologically based treatment planning system (BBTPS) represents a paradigm shift and can be potentially dangerous. There will be a steep learning curve for most planners. The purpose of this task group is to address some of these relevant issues before the use of BBTPS becomes widely spread. In this report, the authors (1) discuss strategies, limitations, conditions, and cautions for using biologically based models and parameters in clinical treatment planning; (2) demonstrate the practical use of the three most commonly used commercially available BBTPS and potential dosimetric differences between biologically model based and dose-volume based treatment plan optimization and evaluation; (3) identify the desirable features and future directions in developing BBTPS; and (4) provide general guidelines and methodology for the acceptance testing, commissioning, and routine quality assurance (QA) of BBTPS.},
  langid = {english},
  keywords = {Anatomy,biologically based treatment planning,Biomedical modeling,Cancer,Dose-volume analysis,dosimetry,Dosimetry,EUD,Lungs,Medical treatment planning,NTCP,Numerical modeling,outcome modeling,planning system QA,radiation therapy,Radiation therapy,Radiation treatment,TCP,Tissues,Vision modeling},
  annotation = {\_eprint: https://aapm.onlinelibrary.wiley.com/doi/pdf/10.1118/1.3685447},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\5SB3ZVDN\\Li et al. - 2012 - The use and QA of biologically related models for .pdf;C\:\\Users\\Niklas\\Zotero\\storage\\K3HYDV8E\\1.html}
}

@article{Li2013,
  title = {Automatic treatment plan re-optimization for adaptive radiotherapy guided with the initial plan {{DVHs}}.},
  author = {Li, Nan and Zarepisheh, Masoud and Uribe-Sanchez, Andres and Moore, Kevin and Tian, Zhen and Zhen, Xin and Graves, Yan Jiang and Gautier, Quentin and Mell, Loren and Zhou, Linghong and Jia, Xun and Jiang, Steve},
  date = {2013-12-21},
  journaltitle = {Physics in medicine and biology},
  volume = {58},
  number = {24},
  eprint = {24301071},
  eprinttype = {pmid},
  pages = {8725--38},
  issn = {1361-6560},
  doi = {10.1088/0031-9155/58/24/8725},
  url = {http://stacks.iop.org/0031-9155/58/i=24/a=8725},
  urldate = {2014-08-07},
  abstract = {Adaptive radiation therapy (ART) can reduce normal tissue toxicity and/or improve tumor control through treatment adaptations based on the current patient anatomy. Developing an efficient and effective re-planning algorithm is an important step toward the clinical realization of ART. For the re-planning process, manual trial-and-error approach to fine-tune planning parameters is time-consuming and is usually considered unpractical, especially for online ART. It is desirable to automate this step to yield a plan of acceptable quality with minimal interventions. In ART, prior information in the original plan is available, such as dose-volume histogram (DVH), which can be employed to facilitate the automatic re-planning process. The goal of this work is to develop an automatic re-planning algorithm to generate a plan with similar, or possibly better, DVH curves compared with the clinically delivered original plan. Specifically, our algorithm iterates the following two loops. An inner loop is the traditional fluence map optimization, in which we optimize a quadratic objective function penalizing the deviation of the dose received by each voxel from its prescribed or threshold dose with a set of fixed voxel weighting factors. In outer loop, the voxel weighting factors in the objective function are adjusted according to the deviation of the current DVH curves from those in the original plan. The process is repeated until the DVH curves are acceptable or maximum iteration step is reached. The whole algorithm is implemented on GPU for high efficiency. The feasibility of our algorithm has been demonstrated with three head-and-neck cancer IMRT cases, each having an initial planning CT scan and another treatment CT scan acquired in the middle of treatment course. Compared with the DVH curves in the original plan, the DVH curves in the resulting plan using our algorithm with 30 iterations are better for almost all structures. The re-optimization process takes about 30~s using our in-house optimization engine.},
  keywords = {Algorithms,Automation,Head and Neck Neoplasms,Head and Neck Neoplasms: pathology,Head and Neck Neoplasms: radiotherapy,Humans,Organ Size,Radiation Dosage,Radiotherapy Dosage,Radiotherapy Planning; Computer-Assisted,Radiotherapy Planning; Computer-Assisted: methods,Radiotherapy; Intensity-Modulated,Radiotherapy; Intensity-Modulated: methods}
}

@article{Liao2018,
  title = {Bayesian {{Adaptive Randomization Trial}} of {{Passive Scattering Proton Therapy}} and {{Intensity-Modulated Photon Radiotherapy}} for {{Locally Advanced Non-Small-Cell Lung Cancer}}},
  author = {Liao, Zhongxing and Lee, J. Jack and Komaki, Ritsuko and Gomez, Daniel R. and O'Reilly, Michael S. and Fossella, Frank V. and Blumenschein, George R. and Heymach, John V. and Vaporciyan, Ara A. and Swisher, Stephen G. and Allen, Pamela K. and Choi, Noah Chan and DeLaney, Thomas F. and Hahn, Stephen M. and Cox, James D. and Lu, Charles S. and Mohan, Radhe},
  date = {2018-06-20},
  journaltitle = {Journal of Clinical Oncology: Official Journal of the American Society of Clinical Oncology},
  shortjournal = {J. Clin. Oncol.},
  volume = {36},
  number = {18},
  eprint = {29293386},
  eprinttype = {pmid},
  pages = {1813--1822},
  issn = {1527-7755},
  doi = {10.1200/JCO.2017.74.0720},
  abstract = {Purpose This randomized trial compared outcomes of passive scattering proton therapy (PSPT) versus intensity-modulated (photon) radiotherapy (IMRT), both with concurrent chemotherapy, for inoperable non-small-cell lung cancer (NSCLC). We hypothesized that PSPT exposes less lung tissue to radiation than IMRT and thereby reduces toxicity without compromising tumor control. The primary end points were grade ≥ 3 radiation pneumonitis (RP) and local failure (LF). Patients and Methods Eligible patients had stage IIB to IIIB NSCLC (or stage IV NSCLC with a single brain metastasis or recurrent lung or mediastinal disease after surgery) who were candidates for concurrent chemoradiation therapy. Pairs of treatment plans for IMRT and PSPT were created for each patient. Patients were eligible for random assignment only if both plans satisfied the same prespecified dose-volume constraints for at-risk organs at the same tumor dose. Results Compared with IMRT (n = 92), PSPT (n = 57) exposed less lung tissue to doses of 5 to 10 Gy(RBE), which is the absorbed Gy dose multiplied by the relative biologic effectiveness (RBE) factor for protons; exposed more lung tissue to ≥ 20 Gy(RBE), but exposed less heart tissue at all dose levels between 5 and 80 Gy(RBE). The grade ≥ 3 RP rate for all patients was 8.1\% (IMRT, 6.5\%; PSPT, 10.5\%); corresponding LF rates were 10.7\% (all), 10.9\% (IMRT), and 10.5\% (PSPT). The posterior probability of IMRT being better than PSPT was 0.54. Exploratory analysis showed that the RP and LF rates at 12 months for patients enrolled before versus after the trial midpoint were 21.1\% (before) versus 18.2\% (after) for the IMRT group (P = .047) and 31.0\% (before) versus 13.1\% (after) for the PSPT group (P = .027). Conclusion PSPT did not improve dose-volume indices for lung but did for heart. No benefit was noted in RP or LF after PSPT. Improvements in both end points were observed over the course of the trial.},
  langid = {english},
  pmcid = {PMC6008104},
  keywords = {Aged,Bayes Theorem,Carcinoma; Non-Small-Cell Lung,Chemoradiotherapy,Female,Humans,Lung Neoplasms,Male,Middle Aged,Proportional Hazards Models,Proton Therapy,Radiation Pneumonitis,Radiotherapy Planning; Computer-Assisted,Radiotherapy; Intensity-Modulated,Risk Factors},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\ILT47JWB\\Liao et al. - 2018 - Bayesian Adaptive Randomization Trial of Passive S.pdf}
}

@article{Limbrunner2000,
  title = {Estimation of {{Harmonic Mean}} of a {{Lognormal Variable}}},
  author = {Limbrunner, James F and Vogel, Richard M and Brown, Linfield C},
  date = {2000-01},
  journaltitle = {Journal of Hydrologic Engineering},
  volume = {5},
  number = {1},
  pages = {59--66},
  issn = {1084-0699},
  doi = {10.1061/(ASCE)1084-0699(2000)5:1(59)},
  url = {http://ascelibrary.org/doi/10.1061/%28ASCE},
  urldate = {2018-04-08},
  abstract = {See, stats, and : https : / / www . researchgate . net / publication / 236325092 Estimation Variable Article DOI : 10. 1061 / (ASCE) 1084 - 0699 (2000) 5 : 1 (59) CITATIONS 23 READS 229 3 , including : Some : Robust , Jordan Optimization , Beirut , Lebanon Richard Tufts , Medford , Massachusetts , Unit… 237 , 235 SEE Linfield Tufts 20 SEE All . The . ABSTRACT : The harmonic mean has numerous engineering applications including characterization of the large - scale effective permeability in layered porous media , characterization of petrochemical properties of heteroge - neous media , and the design of declining rate filter beds . The U . S . EPA also recommends the use of the harmonic mean daily streamflow as a design streamflow for the protection of human health against lifetime exposure to suspected carcinogens . The sampling properties of various estimators of the harmonic mean are derived and compared for observations arising from a lognormal distribution . Previous applications have recommended the use of a moment estimator of the harmonic mean . We document that the moment estimator of the harmonic mean exhibits significant upward bias and large root - mean - square error , particularly for large skews . A maximum likelihood estimator of the harmonic mean is generally preferred because it is nearly unbiased and can provide dramatic reductions in the root - mean - square error , compared with the moment estimator . In addition , a maximum likelihood estimator of the generalized mean (or p - norm) of a lognormal distribution is introduced .},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\QUFQSA77\\Limbrunner, Vogel, Brown - 2000 - Estimation of Harmonic Mean of a Lognormal Variable.pdf}
}

@article{Lin2019,
  title = {Minimum-{{MU}} and sparse-energy-layer ({{MMSEL}}) constrained inverse optimization method for efficiently deliverable {{PBS}} plans},
  author = {Lin, Yuting and Clasie, Benjamin and Liu, Tian and McDonald, Mark and Langen, Katja M and Gao, Hao},
  date = {2019-10-10},
  journaltitle = {Physics in Medicine \& Biology},
  shortjournal = {Phys Med Biol},
  volume = {64},
  number = {20},
  pages = {205001},
  issn = {1361-6560},
  doi = {10.1088/1361-6560/ab4529},
  url = {https://iopscience.iop.org/article/10.1088/1361-6560/ab4529},
  urldate = {2019-10-30},
  abstract = {The deliverability of proton pencil beam scanning (PBS) plans is subject to the minimum monitorunit (MU) constraint, while the delivery efficiency depends on the number of proton energy layers. This work develops an inverse optimization method for generating efficiently deliverable PBS plans. The proposed minimum-MU and sparse-energy-layer (MMSEL) constrained inverse optimization method utilizes iterative convex relaxations to handle the nonconvexity from minimum-MU constraint and dose-volume constraints, and regularizes group sparsity of proton spots to minimize the number of energy layers. The tradeoff between plan quality and delivery efficiency (in terms of the number of used energy layers) is controlled by the objective weighting of group sparsity regularization. MMSEL consists of two steps: first minimize for appropriate energy layers, and then with selected energy layers solve for the deliverable PBS plan. The solution algorithm for MMSEL is developed using alternating direction method of multipliers (ADMM). Range and setup uncertainties are modelled by robust optimization. MMSEL was validated using representative prostate, lung, and head-and-neck (HN) cases. The minimum-MU constraint was strictly enforced for all cases, so that all plans were deliverable. The number of energy layers was reduced by MMSEL to 78\%, 76\%, and 61\% for prostate, lung and HN, respectively, while the similar plan quality was achieved. The number of energy layers was reduced by MMSEL to 54\%, 57\%, and 37\% for prostate, lung and HN, respectively, while the plan quality was comprised and acceptable. MMSEL is proposed to strictly enforce minimum-MU constraint and minimize the number of energy layers during inverse optimization for efficiently deliverable PBS plans. In particular, the preliminary results suggest MMSEL potentially enables 25\% to 40\% reduction of energy layers while maintaining the similar plan quality.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\RNVDIKCJ\\Lin et al. - 2019 - Minimum-MU and sparse-energy-layer (MMSEL) constra.pdf}
}

@article{Liu2012,
  title = {Robust optimization of intensity modulated proton therapy},
  author = {Liu, Wei and Zhang, Xiaodong and Li, Yupeng and Mohan, Radhe},
  date = {2012-02},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {39},
  number = {2},
  eprint = {22320818},
  eprinttype = {pmid},
  pages = {1079--1091},
  publisher = {{American Association of Physicists in Medicine}},
  issn = {0094-2405},
  doi = {10.1118/1.3679340},
  url = {http://scitation.aip.org/content/aapm/journal/medphys/39/2/10.1118/1.3679340},
  urldate = {2016-07-25},
  abstract = {PURPOSE: Intensity modulated proton therapy (IMPT) is highly sensitive to range uncertainties and uncertainties caused by setup variation. The conventional inverse treatment planning of IMPT optimized based on the planning target volume (PTV) is not often sufficient to ensure robustness of treatment plans. In this paper, a method that takes the uncertainties into account during plan optimization is used to mitigate the influence of uncertainties in IMPT.\textbackslash n\textbackslash nMETHODS: The authors use the so-called "worst-case robust optimization" to render IMPT plans robust in the face of uncertainties. For each iteration, nine different dose distributions are computed-one each for ± setup uncertainties along anteroposterior (A-P), lateral (R-L) and superior-inferior (S-I) directions, for ± range uncertainty, and the nominal dose distribution. The worst-case dose distribution is obtained by assigning the lowest dose among the nine doses to each voxel in the clinical target volume (CTV) and the highest dose to each voxel outside the CTV. Conceptually, the use of worst-case dose distribution is similar to the dose distribution achieved based on the use of PTV in traditional planning. The objective function value for a given iteration is computed using this worst-case dose distribution. The objective function used has been extended to further constrain the target dose inhomogeneity.\textbackslash n\textbackslash nRESULTS: The worst-case robust optimization method is applied to a lung case, a skull base case, and a prostate case. Compared with IMPT plans optimized using conventional methods based on the PTV, our method yields plans that are considerably less sensitive to range and setup uncertainties. An interesting finding of the work presented here is that, in addition to reducing sensitivity to uncertainties, robust optimization also leads to improved optimality of treatment plans compared to the PTV-based optimization. This is reflected in reduction in plan scores and in the lower normal tissue doses for the same coverage of the target volume when subjected to uncertainties.\textbackslash n\textbackslash nCONCLUSIONS: The authors find that the worst-case robust optimization provides robust target coverage without sacrificing, and possibly even improving, the sparing of normal tissues. Our results demonstrate the importance of robust optimization. The authors assert that all IMPT plans should be robustly optimized.},
  keywords = {impt,robust optimization},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Q3J8CVMB\\Liu et al. - 2012 - Robust optimization of intensity modulated proton therapy.pdf}
}

@article{Liu2012a,
  title = {Influence of robust optimization in intensity-modulated proton therapy with different dose delivery techniques.},
  author = {Liu, Wei and Li, Yupeng and Li, Xiaoqiang and Cao, Wenhua and Zhang, Xiaodong},
  date = {2012},
  journaltitle = {Medical physics},
  volume = {39},
  number = {6},
  eprint = {22755694},
  eprinttype = {pmid},
  pages = {3089--101},
  issn = {0094-2405},
  doi = {10.1118/1.4711909},
  abstract = {The distal edge tracking (DET) technique in intensity-modulated proton therapy (IMPT) allows for high energy efficiency, fast and simple delivery, and simple inverse treatment planning; however, it is highly sensitive to uncertainties. In this study, the authors explored the application of DET in IMPT (IMPT-DET) and conducted robust optimization of IMPT-DET to see if the planning technique's sensitivity to uncertainties was reduced. They also compared conventional and robust optimization of IMPT-DET with three-dimensional IMPT (IMPT-3D) to gain understanding about how plan robustness is achieved.},
  keywords = {Algorithms,Humans,Male,Prostatic Neoplasms,Prostatic Neoplasms: radiotherapy,Protons,Protons: therapeutic use,Radiation Dosage,Radiotherapy Dosage,Radiotherapy Planning; Computer-Assisted,Radiotherapy; Intensity-Modulated,Radiotherapy; Intensity-Modulated: methods,Skull Base Neoplasms,Skull Base Neoplasms: radiotherapy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\JP6ZSGIL\\Liu et al. - 2012 - Influence of robust optimization in intensity-modulated proton therapy with different dose delivery techniques.pdf}
}

@article{Liu2020,
  title = {{{CBCT-based}} synthetic {{CT}} generation using deep-attention {{cycleGAN}} for pancreatic adaptive radiotherapy},
  author = {Liu, Yingzi and Lei, Yang and Wang, Tonghe and Fu, Yabo and Tang, Xiangyang and Curran, Walter J. and Liu, Tian and Patel, Pretesh and Yang, Xiaofeng},
  date = {2020},
  journaltitle = {Medical Physics},
  volume = {47},
  number = {6},
  pages = {2472--2483},
  issn = {2473-4209},
  doi = {10.1002/mp.14121},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mp.14121},
  urldate = {2022-08-11},
  abstract = {Purpose Current clinical application of cone-beam CT (CBCT) is limited to patient setup. Imaging artifacts and Hounsfield unit (HU) inaccuracy make the process of CBCT-based adaptive planning presently impractical. In this study, we developed a deep-learning-based approach to improve CBCT image quality and HU accuracy for potential extended clinical use in CBCT-guided pancreatic adaptive radiotherapy. Methods Thirty patients previously treated with pancreas SBRT were included. The CBCT acquired prior to the first fraction of treatment was registered to the planning CT for training and generation of synthetic CT (sCT). A self-attention cycle generative adversarial network (cycleGAN) was used to generate CBCT-based sCT. For the cohort of 30 patients, the CT-based contours and treatment plans were transferred to the first fraction CBCTs and sCTs for dosimetric comparison. Results At the site of abdomen, mean absolute error (MAE) between CT and sCT was 56.89 ± 13.84 HU, comparing to 81.06 ± 15.86 HU between CT and the raw CBCT. No significant differences (P {$>$} 0.05) were observed in the PTV and OAR dose-volume-histogram (DVH) metrics between the CT- and sCT-based plans, while significant differences (P {$<$} 0.05) were found between the CT- and the CBCT-based plans. Conclusions The image similarity and dosimetric agreement between the CT and sCT-based plans validated the dose calculation accuracy carried by sCT. The CBCT-based sCT approach can potentially increase treatment precision and thus minimize gastrointestinal toxicity.},
  langid = {english},
  keywords = {adaptive radiotherapy,GANCBCT-based synthetic CT generation,self-attention cycle},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mp.14121},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\57ALUU36\\Liu et al. - 2020 - CBCT-based synthetic CT generation using deep-atte.pdf}
}

@misc{Liu2022,
  title = {An {{Integrated Biological Optimization}} framework for proton {{SBRT FLASH}} treatment planning allows dose, dose rate, and {{LET}} optimization using patient-specific ridge filters},
  author = {Liu, Ruirui and Charyyev, Serdar and Wahl, Niklas and Liu, Wei and Kang, Minglei and Zhou, Jun and Yang, Xiaofeng and Baltazar, Filipa and Palkowitsch, Martina and Higgins, Kristin and Dynan, William and Bradley, Jeffrey and Lin, Liyong},
  date = {2022-07-16},
  number = {2207.08016},
  eprint = {2207.08016},
  eprinttype = {arxiv},
  primaryclass = {physics},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2207.08016},
  url = {http://arxiv.org/abs/2207.08016},
  urldate = {2022-07-19},
  abstract = {Purpose: Patient-specific ridge filters can modulate proton energy to obtain a conformal dose. We describe a new framework for optimization of filter design and spot maps to meet the unique demands of FLASH radiotherapy. We demonstrate an Integrated Biological Optimization IMPT (IBO-IMPT) approach for optimization of dose, dose-averaged dose rate (DADR), and dose-averaged LET (LETd). Methods: We developed inverse planning software to design patient-specific ridge filters that spread the Bragg peak from a fixed-energy, 250 MeV beam to a proximal beam-specific planning target volume. The software optimizes patient-specific ridge filter and uses a Monte Carlo calculation engine, based on Geant4, to provide dose and LET influence matrices. Plan optimization, using matRAD, accommodates the IBO-IMPT objective function considering dose, dose rate, and LET simultaneously with minimum MU constraints. The framework enables design of both regularly spaced and sparse-optimized ridge filters, which allow faster delivery and selective LET optimization. Volume distributions and histograms for dose, DADR, and LETd are compared using evaluation structures specific to the heart and lung. Results: We used IBO-IMPT to design ridge filters for a central lung tumor patient. The IBO-IMPT framework selectively spared heart and lung by reducing LET and increasing dose rate, relative to IMPT planning. Sparse-optimized ridge filters were superior to regularly spaced ridge filters in dose rate. Together, these innovations substantially increased the DADR in the heart and lung while maintaining good target coverage. The volume that received a FLASH dose rate of higher 40 Gy/second increased by 31\% for heart and 50\% for lung. Conclusion: This proof-of-concept study demonstrates the feasibility of using an IBO-IMPT framework to accomplish proton FLASH SBPT, accounting for dose, DADR, and LETd simultaneously.},
  archiveprefix = {arXiv},
  keywords = {Physics - Medical Physics},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\SBJAF8CI\\Liu et al. - 2022 - An Integrated Biological Optimization framework fo.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\A8F8A5QG\\2207.html}
}

@article{Liu2023,
  title = {An {{Integrated Physical Optimization}} framework for proton {{SBRT FLASH}} treatment planning allows dose, dose rate, and {{LET}} optimization using patient-specific ridge filters},
  author = {Liu, Ruirui and Charyyev, Serdar and Wahl, Niklas and Liu, Wei and Kang, Minglei and Zhou, Jun and Yang, Xiaofeng and Baltazar, Filipa and Palkowitsch, Martina and Higgins, Kristin and Dynan, William and Bradley, Jeffrey and Lin, Liyong},
  date = {2023-01-31},
  journaltitle = {International Journal of Radiation Oncology, Biology, Physics},
  shortjournal = {IJROBP},
  publisher = {{Elsevier}},
  issn = {0360-3016},
  doi = {10.1016/j.ijrobp.2023.01.048},
  url = {https://www.redjournal.org/article/S0360-3016(23)00097-4/fulltext},
  urldate = {2023-02-01},
  langid = {english},
  keywords = {dose rate,FLASH,IMPT,integrated physical optimization,LET,Patient-specific ridge filter,SBPT,sparse optimized ridge filter}
}

@article{Lomax1999,
  title = {Intensity modulation methods for proton radiotherapy},
  author = {Lomax, Antony},
  date = {1999-01-01},
  journaltitle = {Physics in Medicine and Biology},
  volume = {44},
  number = {1},
  pages = {185--205},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/44/1/014},
  url = {http://stacks.iop.org/0031-9155/44/i=1/a=014?key=crossref.4d961e9c70528846231301b77dc0ef6a},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\8YG3RGRF\\Lomax - 1999 - Intensity modulation methods for proton radiotherapy.pdf}
}

@article{Lomax2004,
  title = {The clinical potential of intensity modulated proton therapy.},
  author = {Lomax, Antony J and Pedroni, Eros and Rutz, Hanspeter and Goitein, Gudrun},
  date = {2004},
  journaltitle = {Zeitschrift fur medizinische Physik},
  volume = {14},
  number = {3},
  eprint = {15462415},
  eprinttype = {pmid},
  pages = {147--52},
  issn = {0939-3889},
  abstract = {Intensity Modulated Proton Therapy (IMPT) differs from conventional proton therapy in its ability to deliver depth-shifted, arbitrarily complex proton fluence maps from each incident field direction. As the individual Bragg peaks delivered from any field can be distributed in three-dimensions throughout the target volume, IMPT provides many more degrees of freedom for designing dose distributions than IMRT or conventional proton therapy techniques. So how can the flexibility of IMPT best be exploited? Here we argue that IMPT has two main advantages over photon IMRT and conventional proton therapy: the ability to better 'sculpt' the dose to the target and around neighbouring critical structures, and the ability to find clinically acceptable solutions whilst simultaneously reducing the sensitivity of the treatments to potential delivery errors. The concept of IMPT as a tool for generating 'safer' plans opens an interesting new avenue of research from the point of view of plan optimisation, the potential of which is only just beginning to be explored.}
}

@article{Lomax2008,
  ids = {Lomax2008b},
  title = {Intensity modulated proton therapy and its sensitivity to treatment uncertainties 1: the potential effects of calculational uncertainties.},
  author = {Lomax, Antony John},
  date = {2008},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {53},
  number = {4},
  eprint = {18263956},
  eprinttype = {pmid},
  pages = {1027--1042},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/53/4/014},
  abstract = {The effects of calculational uncertainties on 3D and distal edge tracking (DET) intensity modulated proton therapy (IMPT) treatment plans have been investigated. Dose calculation uncertainties have been assessed by comparing analytical and Monte Carlo dose calculations, and potential range uncertainties by recalculating plans with all CT values modified by +/-3\%. Analysis of the volume of PTV agreeing to within +/-3\% between the two calculations shows that the 3D approach provides significantly improved agreement (87.1 versus 80.3\% of points for the 3D and DET approaches, respectively). For the DET approach, doses in the CTV have also been found to globally change by 5\% as a result of 3\% changes in CT value. When varying the intra-field gradients of the plans a similar trend is seen, but with the more complex plans also being found to be more sensitive to both uncertainties. In conclusion, the DET approach has been found to be relatively sensitive to the calculational errors investigated here. In contrast, the 3D approach appears to be quite robust, unless strong internal gradients are present. Nevertheless, the routine use of uncertainty analysis is advised when assessing all forms of IMPT plans.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\JZFZXXZH\\Lomax - 2008 - Intensity modulated proton therapy and its sensitivity to treatment uncertainties 1 the potential effects of calculationa.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\XQYF83PV\\Lomax - 2008 - Intensity modulated proton therapy and its sensitivity to treatment uncertainties 2 the potential effects of inter-fra(2).pdf}
}

@article{Lomax2008a,
  title = {Intensity modulated proton therapy and its sensitivity to treatment uncertainties 2: the potential effects of inter-fraction and inter-field motions},
  shorttitle = {Intensity modulated proton therapy and its sensitivity to treatment uncertainties 2},
  author = {Lomax, A. J.},
  date = {2008-02-21},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {53},
  number = {4},
  eprint = {18263957},
  eprinttype = {pmid},
  pages = {1043--1056},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/53/4/015},
  abstract = {Simple tools for studying the effects of inter-fraction and inter-field motions on intensity modulated proton therapy (IMPT) plans have been developed, and have been applied to both 3D and distal edge tracking (DET) IMPT plans. For the inter-fraction motion, we have investigated the effects of misaligned density heterogeneities, whereas for the inter-field motion analysis, the effects of field misalignment on the plans have been assessed. Inter-fraction motion problems have been analysed using density differentiated error (DDE) distributions, which specifically show the additional problems resulting from misaligned density heterogeneities for proton plans. Likewise, for inter-field motion, we present methods for calculating motion differentiated error (MDE) distributions. DDE and MDE analysis of all plans demonstrate that the 3D approach is generally more robust to both inter-fraction and inter-field motions than the DET approach, but that strong in-field dose gradients can also adversely affect a plan's robustness. An important additional conclusion is that, for certain IMPT plans, even inter-fraction errors cannot necessarily be compensated for by the use of a simple PTV margins, implying that more sophisticated tools need to be developed for uncertainty management and assessment for IMPT treatments at the treatment planning level.},
  langid = {english},
  keywords = {Dose Fractionation; Radiation,Humans,Models; Biological,Movement,Proton Therapy,Sensitivity and Specificity,Treatment Outcome,Uncertainty}
}

@article{Lougovski2010,
  title = {Toward truly optimal {{IMRT}} dose distribution: inverse planning with voxel-specific penalty},
  author = {Lougovski, P and LeNoach, J and Zhu, L},
  date = {2010},
  journaltitle = {Technology in cancer research and treatment},
  volume = {9},
  number = {6},
  eprint = {21070085},
  eprinttype = {pmid},
  pages = {629--636},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3057528/},
  urldate = {2013-06-24},
  abstract = {Purpose: To establish an inverse planning framework with adjustable voxel penalty for more conformal IMRT dose distribution as well as improved interactive controllability over the regional dose distribution of the resultant plan. Materials and Method: In the proposed coarse-to-fine planning scheme, a conventional inverse planning with organ specific parameters is first performed. The voxel penalty scheme is then “switched on” by allowing the prescription dose to change on an individual voxel scale according to the deviation of the actual voxel dose from the ideally desired dose. The rationale here is intuitive: when the dose at a voxel does not meet its ideal dose, it simply implies that this voxel is not competitive enough when compared with the ones that have met their planning goal. In this case, increasing the penalty of the voxel by varying the prescription can boost its competitiveness and thus improve its dose. After the prescription adjustment, the plan is re-optimized. The dose adjustment/re-optimization procedure is repeated until the resultant dose distribution cannot be improved anymore. The prescription adjustment on a finer scale can be accomplished either automatically or manually. In the latter case, the regions/voxels where a dose improvement is needed are selected visually, unlike in the automatic case where the selection is done purely based on the difference of the actual dose at a given voxel and its ideal prescription. The performance of the proposed method is evaluated using a head and neck and a prostate case. Results: An inverse planning framework with the voxel-specific penalty is established. By adjusting voxel prescriptions iteratively to boost the region where large mismatch between the actual calculated and desired doses occurs, substantial improvements can be achieved in the final dose distribution. The proposed method is applied to a head and neck case and a prostate case. For the former case, a significant reduction in the maximum dose to the brainstem is achieved while the PTV dose coverage is greatly improved. The doses to other organs at risk are also reduced, ranging from 10\% to 30\%. For the prostate case, the use of the voxel penalty scheme also results in vast improvements to the final dose distribution. The PTV experiences improved dose uniformity and the mean dose to the rectum and bladder is reduced by as much as 15\%. Conclusion: Introduction of the spatially non-uniform and adjustable prescription provides room for further improvements of currently achievable dose distributions and equips the planner with an effective tool to modify IMRT dose distributions interactively. The technique is easily implementable in any existing inverse planning platform, which should facilitate clinical IMRT planning process and, in future, off-line/on-line adaptive IMRT.},
  keywords = {Adaptive radiation therapy,Dose optimization,IMRT,Inverse planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\7JIEHM58\\Lougovski, LeNoach, Zhu - 2010 - Toward truly optimal IMRT dose distribution inverse planning with voxel-specific penalty.pdf}
}

@article{Low1998,
  title = {A technique for the quantitative evaluation of dose distributions.},
  author = {Low, Daniel A. and Harms, William B. and Mutic, Sasa and Purdy, James A.},
  date = {1998},
  journaltitle = {Medical physics},
  volume = {25},
  number = {5},
  eprint = {9608475},
  eprinttype = {pmid},
  pages = {656--61},
  publisher = {{American Association of Physicists in Medicine}},
  issn = {0094-2405},
  doi = {10.1118/1.598248},
  abstract = {The commissioning of a three-dimensional treatment planning system requires comparisons of measured and calculated dose distributions. Techniques have been developed to facilitate quantitative comparisons, including superimposed isodoses, dose-difference, and distance-to-agreement (DTA) distributions. The criterion for acceptable calculation performance is generally defined as a tolerance of the dose and DTA in regions of low and high dose gradients, respectively. The dose difference and DTA distributions complement each other in their useful regions. A composite distribution has recently been developed that presents the dose difference in regions that fail both dose-difference and DTA comparison criteria. Although the composite distribution identifies locations where the calculation fails the preselected criteria, no numerical quality measure is provided for display or analysis. A technique is developed to unify dose distribution comparisons using the acceptance criteria. The measure of acceptability is the multidimensional distance between the measurement and calculation points in both the dose and the physical distance, scaled as a fraction of the acceptance criteria. In a space composed of dose and spatial coordinates, the acceptance criteria form an ellipsoid surface, the major axis scales of which are determined by individual acceptance criteria and the center of which is located at the measurement point in question. When the calculated dose distribution surface passes through the ellipsoid, the calculation passes the acceptance test for the measurement point. The minimum radial distance between the measurement point and the calculation points (expressed as a surface in the dose-distance space) is termed the gamma index. Regions where gamma {$>$} 1 correspond to locations where the calculation does not meet the acceptance criteria. The determination of gamma throughout the measured dose distribution provides a presentation that quantitatively indicates the calculation accuracy. Examples of a 6 MV beam penumbra are used to illustrate the gamma index.},
  isbn = {0094-2405 (Print)\textbackslash n0094-2405 (Linking)},
  keywords = {Computer-Assisted,Gamma Rays,Imaging,Models,Phantoms,Photons,Radiotherapy Dosage,Radiotherapy Planning,Theoretical},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\FAC9Z7FX\\Low et al. - 1998 - A technique for the quantitative evaluation of dose distributions.pdf}
}

@article{Lowe2016,
  title = {Incorporating the effect of fractionation in the evaluation of proton plan robustness to setup errors},
  author = {Lowe, Matthew and Albertini, Francesca and Aitkenhead, Adam and Lomax, Antony John and MacKay, Ranald I},
  date = {2016-01-07},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {61},
  number = {1},
  eprint = {26675133},
  eprinttype = {pmid},
  pages = {413--429},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/61/1/413},
  abstract = {To ensure the safe delivery of proton therapy treatments it is important to evaluate the effect of potential uncertainties, such as patient mispositioning, on the intended dose distribution. However, it can be expected that the uncertainty resulting from patient positioning is reduced in a fractionated treatment due to the convergence of random variables with the delivery of repeated treatments. This is neglected by current approaches to robustness analysis resulting in an overly conservative assessment of the robustness which can lead to sub-optimal plans. Here, a fast method of accounting for this reduced uncertainty is presented. An estimated bound to the error in the dose distribution resulting from setup uncertainty over a specified number of fractions is calculated by considering the distribution of values for each voxel across 14 initial error scenarios. The bound on the error in a given voxel is estimated using a 99.9\% confidence limit assuming a convergence towards a normal distribution in line with the central limit theorem, and a correction of [Formula: see text] accounting for the reduction in the standard deviation over n fractions. The proposed method was validated in 5 patients by comparison to Monte Carlo simulations of 300 treatment courses. A voxelwise and volumetric analysis of the estimated and simulated bounds to the uncertainty in the dose distribution demonstrate that the proposed technique can be used to assess proton plan robustness more accurately allowing for less conservative treatment plans.},
  keywords = {proton therapy,robustness,uncertainty},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\UCWYTP4N\\Lowe et al. - 2016 - Incorporating the effect of fractionation in the evaluation of proton plan robustness to setup errors.pdf}
}

@article{Lowe2017,
  title = {A robust optimisation approach accounting for the effect of fractionation on setup uncertainties},
  author = {Lowe, Matthew and Aitkenhead, Adam and Albertini, Francesca and Lomax, Antony J and MacKay, Ranald I},
  date = {2017-10-04},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {62},
  number = {20},
  pages = {8178--8196},
  publisher = {{IOP Publishing}},
  issn = {1361-6560},
  doi = {10.1088/1361-6560/aa8c58},
  url = {http://stacks.iop.org/0031-9155/62/i=20/a=8178?key=crossref.65fca1cc1e4869e819bdda018cd1c9f2},
  urldate = {2018-03-09},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\B46AC9K2\\Lowe et al. - 2017 - A robust optimisation approach accounting for the effect of fractionation on setup uncertainties.pdf}
}

@article{Lu2008,
  title = {A point dose method forin vivorange verification in proton therapy},
  author = {Lu, Hsiao-Ming},
  date = {2008-11},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {53},
  number = {23},
  pages = {N415--N422},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/53/23/N01},
  url = {https://doi.org/10.1088%2F0031-9155%2F53%2F23%2Fn01},
  urldate = {2020-04-10},
  abstract = {Range uncertainty in proton therapy is a recognized concern. For certain treatment sites, less optimal beam directions are used to avoid the potential risk, but also with reduced benefit. In vivo dosimetry, with implanted or intra-cavity dosimeters, has been widely used for treatment verification in photon/electron therapy. The method cannot, however, verify the beam range for proton treatment, unless we deliver the treatment in a different manner. Specifically, we split the spread-out Bragg peaks in a proton field into two separate fields, each delivering a ‘sloped’ depth–dose distribution, rather than the usual plateau in a typical proton field. The two fields are ‘sloped’ in opposite directions so that the total depth–dose distribution retains the constant dose plateau covering the target volume. By measuring the doses received from both fields and calculating the ratio, the water-equivalent path length to the location of the implanted dosimeter can be verified, thus limiting range uncertainty to only the remaining part of the beam path. Production of such subfields has been experimented with a passive scattering beam delivery system. Phantom measurements have been performed to illustrate the application for in vivo beam range verification.},
  langid = {english}
}

@book{Luenberger2008,
  title = {Linear and nonlinear programming},
  author = {Luenberger, David G. and Ye, Yinyu},
  date = {2008},
  series = {International {{Series}} in {{Operations Research}} and {{Management Science}}},
  edition = {3},
  publisher = {{Springer}},
  location = {{New York, NY}},
  isbn = {978-0-387-74502-2},
  langid = {english},
  pagetotal = {546},
  keywords = {Linear programming,Nonlinear programming},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\MWC9TMK5\\Luenberger und Ye - 2008 - Linear and nonlinear programming.pdf}
}

@article{MacFarlane2019,
  title = {A fast inverse direct aperture optimization algorithm for intensity-modulated radiation therapy},
  author = {MacFarlane, Michael and Hoover, Douglas A. and Wong, Eugene and Goldman, Pedro and Battista, Jerry J. and Chen, Jeff Z.},
  date = {2019-03},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {46},
  number = {3},
  pages = {1127--1139},
  issn = {00942405},
  doi = {10.1002/mp.13368},
  url = {http://doi.wiley.com/10.1002/mp.13368},
  urldate = {2019-10-30},
  abstract = {Purpose: The goal of this work was to develop and evaluate a fast inverse direct aperture optimization (FIDAO) algorithm for IMRT treatment planning and plan adaptation. Methods: A previously proposed fluence map optimization algorithm called fast inverse dose optimization (FIDO) was extended to optimize the aperture shapes and weights of IMRT beams. FIDO is a very fast fluence map optimization algorithm for IMRT that finds the global minimum using direct matrix inversion without unphysical negative beam weights. In this study, an equivalent second-order Taylor series expansion of the FIDO objective function was used, which allowed for the objective function value and gradient vector to be computed very efficiently during direct aperture optimization, resulting in faster optimization. To evaluate the speed gained with FIDAO, a proof-of-concept algorithm was developed in MATLAB using an interior-point optimization method to solve the reformulated aperture-based FIDO problem. The FIDAO algorithm was used to optimize four step-andshoot IMRT cases: on the AAPM TG-119 phantom as well as a liver, prostate, and head-and-neck clinical cases. Results were compared with a conventional DAO algorithm that uses the same interior-point method but using the standard formulation of the objective function and its gradient vector. Results: A substantial gain in optimization speed was obtained with the prototype FIDAO algorithm compared to the conventional DAO algorithm while producing plans of similar quality. The optimization time (number of iterations) for the prototype FIDAO algorithm vs the conventional DAO algorithm was 0.3 s (17) vs 56.7 s (50); 2.0 s (28) vs 134.1 s (57); 2.5 s (26) vs 180.6 s (107); and 6.7 s (20) vs 469.4 s (482) in the TG-119 phantom, liver, prostate, and head-and-neck examples, respectively. Conclusions: A new direct aperture optimization algorithm based on FIDO was developed. For the four IMRT test cases examined, this algorithm executed approximately 70–200 times faster without compromising the IMRT plan quality. © 2018 American Association of Physicists in Medicine [https://doi.org/10.1002/mp.13368]},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\NMMYJ8AP\\MacFarlane et al. - 2019 - A fast inverse direct aperture optimization algori.pdf}
}

@book{Mackay2005,
  title = {Information {{Theory}}, {{Inference}}, and {{Learning Algorithms}}},
  author = {Mackay, David J C},
  date = {2005},
  edition = {4},
  publisher = {{Cambridge University Press}},
  url = {http://www.cambridge.org/0521642981},
  urldate = {2018-03-23},
  isbn = {978-0-521-64298-9},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\9PFXG27U\\Mackay - 2005 - Information Theory, Inference, and Learning Algorithms.pdf}
}

@article{Maes2018,
  title = {Advanced proton beam dosimetry part {{II}}: {{Monte Carlo}} vs. pencil beam-based planning for lung cancer},
  author = {Maes, Dominic and Saini, Jatinder and Zeng, Jing and Rengan, Ramesh and Wong, Tony and Bowen, Stephen R.},
  date = {2018-04},
  journaltitle = {Translational Lung Cancer Research},
  volume = {7},
  number = {2},
  pages = {114--121},
  publisher = {{AME Publishing Company}},
  doi = {10.21037/tlcr.2018.04.04}
}

@article{Majumdar2014,
  title = {Extreme value statistics of correlated random variables},
  author = {Majumdar, Satya N and Pal, Arnab},
  date = {2014-06-26},
  journaltitle = {Arxiv},
  eprint = {1406.6768},
  eprinttype = {arxiv},
  pages = {1--14},
  url = {http://arxiv.org/abs/1406.6768},
  abstract = {Extreme value statistics (EVS) concerns the study of the statistics of the maximum or the minimum of a set of random variables. This is an important problem for any time-series and has applications in climate, finance, sports, all the way to physics of disordered systems where one is interested in the statistics of the ground state energy. While the EVS of uncorrelated variables are well understood, little is known for strongly correlated random variables. Only recently this subject has gained much importance both in statistical physics and in probability theory. In this note, we will first review the classical EVS for uncorrelated variables and discuss few examples of correlated variables where analytical progress can be made.},
  archiveprefix = {arXiv},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\DP2J45PY\\Majumdar, Pal - 2014 - Extreme value statistics of correlated random variables.pdf}
}

@article{Mar2015,
  title = {Adaptive and robust radiation therapy in the presence of drift},
  author = {Mar, Philip Allen and Chan, Timothy C Y},
  date = {2015},
  journaltitle = {Physics in Medicine and Biology},
  volume = {60},
  number = {9},
  pages = {3599--3615},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/60/9/3599},
  url = {http://stacks.iop.org/0031-9155/60/i=9/a=3599?key=crossref.01e655bc0545254888e4fcf9f86e24ed},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\7TNLEPDG\\Mar, Chan - 2015 - Adaptive and robust radiation therapy in the presence of drift.pdf}
}

@article{Marc2021,
  title = {Combined proton-photon treatment for breast cancer},
  author = {Marc, Louise and Fabiano, Silvia and Wahl, Niklas and Linsenmeier, Claudia and Lomax, Antony John and Unkelbach, Jan},
  date = {2021},
  journaltitle = {Physics in Medicine \& Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {66},
  number = {23},
  pages = {235002},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/ac36a3},
  url = {http://iopscience.iop.org/article/10.1088/1361-6560/ac36a3},
  urldate = {2021-11-08},
  abstract = {Objective: Proton therapy remains a limited resource due to gantry size and its cost. Recently, a new design without a gantry has been suggested. It may enable combined proton-photon therapy (CPPT) in conventional bunkers and allow the widespread use of protons. In this work, we explore this concept for breast cancer. Methods: The treatment room consists of a LINAC for IMRT, a fixed proton beamline (FBL) with beam scanning and a motorized couch for treatments in lying positions with accurate patient setup. Thereby, proton and photon beams are delivered in the same fraction. Treatment planning is performed by simultaneously optimizing IMRT and IMPT plans based on the cumulative dose. The concept is investigated for three breast cancers where the goal is to minimize mean dose to the heart and lung while delivering 40.05 Gy in 15 fractions to the PTV with a SIB of 48 Gy to the tumor bed. The probabilistic approach is applied to mitigate the sensitivity to range uncertainties. Results: CPPT is particularly advantageous for irradiating concave target volumes that wrap around a curved chest wall. There, protons may deliver dose to the peripheral and medial parts of the target volume including lymph nodes. Thereby, the mean dose in normal tissues is reduced compared to single-modality IMRT. However, tangential photon beams may treat parts of the target volume near the interface to the lung. To ensure target coverage for range undershoot in an IMPT plan, proton beams have to deliberately overshoot into the lung tissue - a problem that can be mitigated via the photon component which ensures plan conformity and robustness. Conclusion: CPPT using an FBL may represent a realistic approach to make protons available to more patients. In addition, CPPT may generally improve treatment quality compared to both single-modality proton and photon treatments.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\FDVKMUTD\\document.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\LYTMKWDJ\\Marc et al. - 2021 - Combined proton-photon treatment for breast cancer.pdf}
}

@inproceedings{Marc2021a,
  title = {{{PO-1905}}: {{Combined}} proton-photon treatment for breast cancer using a fixed proton beamline},
  booktitle = {Radiotherapy and {{Oncology}}},
  author = {Marc, Louise and Fabiano, Silvia and Wahl, Niklas and Linsenmeier, Claudia and Lomax, Antony John and Unkelbach, Jan},
  date = {2021-08-01},
  volume = {161},
  pages = {S1625-S1627},
  publisher = {{Elsevier}},
  location = {{Online}},
  doi = {10.1016/S0167-8140(21)08356-0},
  url = {https://www.thegreenjournal.com/article/S0167-8140(21)08356-0/fulltext#relatedArticles},
  urldate = {2021-11-15},
  eventtitle = {{{ESTRO}}},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\KHBVCXZM\\fulltext.html}
}

@article{Marks2010,
  ids = {Marks2010a},
  title = {Use of normal tissue complication probability models in the clinic.},
  author = {Marks, Lawrence B and Yorke, Ellen D and Jackson, Andrew and Ten Haken, Randall K and Constine, Louis S and Eisbruch, Avraham and Bentzen, Søren M and Nam, Jiho and Deasy, Joseph O},
  date = {2010-03-01},
  journaltitle = {International journal of radiation oncology, biology, physics},
  volume = {76},
  eprint = {20171502},
  eprinttype = {pmid},
  pages = {S10-S19},
  issn = {1879-355X},
  doi = {10.1016/j.ijrobp.2009.07.1754},
  url = {http://www.sciencedirect.com/science/article/pii/S036030160903288X},
  urldate = {2014-01-20},
  abstract = {The Quantitative Analysis of Normal Tissue Effects in the Clinic (QUANTEC) review summarizes the currently available three-dimensional dose/volume/outcome data to update and refine the normal tissue dose/volume tolerance guidelines provided by the classic Emami et al. paper published in 1991. A "clinician's view" on using the QUANTEC information in a responsible manner is presented along with a description of the most commonly used normal tissue complication probability (NTCP) models. A summary of organ-specific dose/volume/outcome data, based on the QUANTEC reviews, is included.},
  issue = {3 Suppl},
  pmcid = {PMC4041542},
  keywords = {Adult,Biological,Child,Dose Fractionation,Dose-Response Relationship; Radiation,Humans,Models; Biological,Models; Statistical,Organ Specificity,Practice Guidelines as Topic,Radiation,Radiation Injuries,Radiation Injuries: prevention & control,Radiation Oncology,Radiation Tolerance,Statistical},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\6ZERQBCL\\Marks et al. - 2010 - Use of normal tissue complication probability models in the clinic.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\HZJIFLYC\\Marks et al. - 2010 - The Use of Normal Tissue Complication Probability .pdf}
}

@article{Maspero2020,
  title = {A single neural network for cone-beam computed tomography-based radiotherapy of head-and-neck, lung and breast cancer},
  author = {Maspero, Matteo and Houweling, Antonetta C. and Savenije, Mark H. F. and family=Heijst, given=Tristan C. F., prefix=van, useprefix=false and Verhoeff, Joost J. C. and Kotte, Alexis N. T. J. and family=Berg, given=Cornelis A. T., prefix=van den, useprefix=false},
  date = {2020-04-01},
  journaltitle = {Physics and Imaging in Radiation Oncology},
  shortjournal = {Physics and Imaging in Radiation Oncology},
  volume = {14},
  pages = {24--31},
  publisher = {{Elsevier}},
  issn = {2405-6316},
  doi = {10.1016/j.phro.2020.04.002},
  url = {https://phiro.science/article/S2405-6316(20)30012-9/fulltext},
  urldate = {2022-08-16},
  langid = {english},
  keywords = {Adaptive radiotherapy,Artificial intelligence,CBCT,Deep learning,Dose calculation,Image-guided radiotherapy,Image-to-image translation,Machine learning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\UDZFK9GK\\Maspero et al. - 2020 - A single neural network for cone-beam computed tom.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\BY5CRXXG\\fulltext.html}
}

@article{Maspero2020a,
  title = {Deep learning-based synthetic {{CT}} generation for paediatric brain {{MR-only}} photon and proton radiotherapy},
  author = {Maspero, Matteo and Bentvelzen, Laura G. and Savenije, Mark H. F. and Guerreiro, Filipa and Seravalli, Enrica and Janssens, Geert O. and family=Berg, given=Cornelis A. T., prefix=van den, useprefix=false and Philippens, Marielle E. P.},
  date = {2020-12-01},
  journaltitle = {Radiotherapy and Oncology},
  shortjournal = {Radiotherapy and Oncology},
  volume = {153},
  eprint = {32976877},
  eprinttype = {pmid},
  pages = {197--204},
  publisher = {{Elsevier}},
  issn = {0167-8140, 1879-0887},
  doi = {10.1016/j.radonc.2020.09.029},
  url = {https://www.thegreenjournal.com/article/S0167-8140(20)30804-5/fulltext},
  urldate = {2022-08-16},
  langid = {english},
  keywords = {Artificial intelligence,Brain tumors,Image-to-image translation,Machine learning,Pediatric oncology,Synthetic CT},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\TX65YWVS\\Maspero et al. - 2020 - Deep learning-based synthetic CT generation for pa.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\E9W8Z9FV\\fulltext.html}
}

@software{MathWorks2017,
  title = {{{MATLAB}}: {{C}}/{{C}}++, {{Fortran}}, {{Java}}, and {{Python API Reference}}},
  author = {{MathWorks}},
  date = {2017},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\KEUQ4ECR\\MathWorks - 2017 - MATLAB CC, Fortran, Java, and Python API Reference.pdf}
}

@report{MatlabObjectOriented2019,
  type = {Documentation},
  title = {Matlab {{Object Oriented Programming}}},
  author = {{The MathWorks, Inc.}},
  date = {2019},
  number = {R2019b},
  url = {https://de.mathworks.com/help/pdf_doc/matlab/matlab_oop.pdf},
  urldate = {2019-09-17},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Z92IRCDF\\matlab_oop.pdf}
}

@software{matRad,
  title = {{{matRad}}},
  author = {Ackermann, Benjamin and Bangert, Mark and Bennan, Amit Ben Antony and Burigo, Lucas and Cabal, Gonzalo and Cisternas, Eduardo and Charton, Louis and Christiansen, Eric and Ecker, Swantje and Ellerbrock, Malte and Gabryś, Hubert and Handrack, Josefine and Heath, Emily and Hermann, Cindy and Homolka, Noa and Jäkel, Oliver and Klinge, Thomas and Mairani, Andrea and Mescher, Hennig and Müller, Lucas-Raphael and Neishabouri, Ahmad and Palkowitsch, Martina and Parodi, Katia and Pezzano, Guiseppe and Ramirez, Daniel and Stadler, Alexander and Ulrich, Silke and Wahl, Niklas and Welsch, Jona and Wieser, Hans-Peter and Winter, Johanna and Xu, Tong},
  date = {2020-11-20},
  location = {{Heidelberg}},
  doi = {10.5281/zenodo.3879615},
  abstract = {This patch fixes some bugs from v2.10.0 and introduces some minor new configuration possibilities. See ChangeLog.txt for more details. In addition to the Matlab source code, this release also contains updated installers that can provide a standalone version (e.g., for educational purposes). The standalone only features the graphical user interface, and not all new features are accessible. We also have an experimental Docker Container. Check our Wiki for how to set-up matRad (as source code or standalone): https://github.com/e0404/matRad/wiki/Setting-up-matRad - DO NOT USE MATRAD CLINICALLY - Check LICENSE.md and README.md for more infos},
  organization = {{Deutsches Krebsforschungszentrum}},
  keywords = {dose optimization,particle therapy,radiotherapy,treatment planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\ABUIWLZ3\\hx.html}
}

@incollection{matRad2015,
  title = {{{matRad}} - a multi-modality open source {{3D}} treatment planning toolkit},
  booktitle = {{{IFMBE Proceedings}}},
  author = {Cisternas, E. and Mairani, A. and Ziegenhein, P. and Jäkel, O. and Bangert, Mark},
  date = {2015},
  volume = {51},
  pages = {1608--1611},
  issn = {16800737},
  doi = {10.1007/978-3-319-19387-8_391},
  url = {http://link.springer.com/10.1007/978-3-319-19387-8_391},
  abstract = {We present matRad, an open source software for three-dimensional radiation treatment planning of intensity-modulated photon, proton, and carbon ion therapy. matRad is developed for educational and research purposes; it is entirely written in MATLAB. A first beta release is available for down-load1. The toolkit features a highly modular design with a set of individual functions modeling the entire treatment planning workflow based on a segmented patient CT. All algorithms, e.g. for ray tracing, photon/proton/carbon dose calculation, fluence optimization, and multileaf collimator sequencing, follow well-established approaches and operate on clinically adequate voxel and bixel resolution. Patient data as well as base data for all required computations is included in matRad. We achieve computation times of 60-100s (60-400s) for realistic patient cases including photon (particle) dose calculation and fluence optimization. Memory consumption ranges between 0.2GB and 2.2GB. Dose distributions of a treatment planning study for a phantom and prostate patient case considering multiple radiation modalities are shown. Both the computa-tional and dosimetric results encourage a future use of matRad in an educational and scientific setting.},
  isbn = {978-3-319-19387-8},
  keywords = {Open source software,Particle therapy,Radiation therapy,Treatment planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\8854EV5G\\Cisternas et al. - 2015 - matRad - a multi-modality open source 3D treatment planning toolkit.pdf}
}

@software{matRadAlan,
  title = {{{matRad}}},
  author = {Bangert, Mark and Cisternas, Eduardo and Gabryś, Hubert and Klinge, Thomas and Mescher, Hennig and Müller, Lucas-Raphael and Stadler, Alexander and Wahl, Niklas and Wieser, Hans-Peter},
  date = {2016-05-23},
  location = {{Heidelberg}},
  doi = {10.5281/zenodo.7107805},
  url = {https://zenodo.org/record/7107805},
  urldate = {2022-09-23},
  abstract = {First official matRad release including new optimizer IPOPT for constrained optimization validated ray tracing validated pencil beam particle dose calcualtion DICOM import including dose and particle pencil beam scanning plan objects matRad standalone version improved GUI workflow many bug fixes and many new bugs... Have fun and let us know what you think at contact@matrad.org... - DO NOT USE MATRAD CLINICALLY - Check LICENSE.md and README.md for more info},
  organization = {{Deutsches Krebsforschungszentrum}},
  version = {2.1.0},
  keywords = {dose optimization,particle therapy,radiotherapy,treatment planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\8AMFTL64\\7107805.html}
}

@software{matRadBlaise,
  title = {{{matRad}}},
  author = {Ackermann, Benjamin and Bangert, Mark and Bennan, Amit Ben Antony and Burigo, Lucas and Cabal, Gonzalo and Cisternas, Eduardo and Charton, Louis and Christiansen, Eric and Doerner, Edgardo and Ecker, Swantje and Ellerbrock, Malte and Gabryś, Hubert and Handrack, Josefine and Heath, Emily and Hermann, Cindy and Homolka, Noa and Jäkel, Oliver and Klinge, Thomas and Mairani, Andrea and Mescher, Hennig and Müller, Lucas-Raphael and Neishabouri, Ahmad and Palkowitsch, Martina and Parodi, Katia and Pezzano, Guiseppe and Ramirez, Daniel and Stadler, Alexander and Ulrich, Silke and Wahl, Niklas and Welsch, Jona and Wieser, Hans-Peter and Winter, Johanna and Xu, Tong},
  date = {2020-06-05},
  location = {{Heidelberg}},
  doi = {10.5281/zenodo.3879616},
  url = {https://zenodo.org/record/3879616},
  urldate = {2022-09-23},
  abstract = {Second major release of matRad. A lot has changed in Blaise going from Alan! Check the ChangeLog: ChangeLog.txt In addition to the Matlab source code, this release also contains installers that can provide a standalone version (e.g., for educational purposes). The standalone only features the graphical user interface, and not all new features are accessible. Look in the readme for installation instructions: readme\_standalone\_mac.txt readme\_standalone\_windows.txt readme\_standalone\_linux.txt Have fun! If you find any issues or have questions about matRad feel free to post an Issue on GitHub or contact us at contact@matrad.org.},
  organization = {{Deutsches Krebsforschungszentrum}},
  version = {2.10.0},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\LUISW82W\\hx.html}
}

@software{matRadBlaisePatch1,
  title = {{{matRad}}},
  author = {Ackermann, Benjamin and Bangert, Mark and Bennan, Amit Ben Antony and Burigo, Lucas and Cabal, Gonzalo and Cisternas, Eduardo and Charton, Louis and Christiansen, Eric and Ecker, Swantje and Ellerbrock, Malte and Gabryś, Hubert and Handrack, Josefine and Heath, Emily and Hermann, Cindy and Homolka, Noa and Jäkel, Oliver and Klinge, Thomas and Mairani, Andrea and Mescher, Hennig and Müller, Lucas-Raphael and Neishabouri, Ahmad and Palkowitsch, Martina and Parodi, Katia and Pezzano, Guiseppe and Ramirez, Daniel and Stadler, Alexander and Ulrich, Silke and Wahl, Niklas and Welsch, Jona and Wieser, Hans-Peter and Winter, Johanna and Xu, Tong},
  date = {2020-11-20},
  location = {{Heidelberg}},
  doi = {10.5281/zenodo.7107719},
  url = {https://zenodo.org/record/7107719},
  urldate = {2022-09-23},
  abstract = {This patch fixes some bugs from v2.10.0 and introduces some minor new configuration possibilities. See ChangeLog.txt for more details. In addition to the Matlab source code, this release also contains updated installers that can provide a standalone version (e.g., for educational purposes). The standalone only features the graphical user interface, and not all new features are accessible. We also have an experimental Docker Container. Check our Wiki for how to set-up matRad (as source code or standalone): https://github.com/e0404/matRad/wiki/Setting-up-matRad - DO NOT USE MATRAD CLINICALLY - Check LICENSE.md and README.md for more infos},
  organization = {{Deutsches Krebsforschungszentrum}},
  version = {2.10.1},
  keywords = {dose optimization,particle therapy,radiotherapy,treatment planning}
}

@article{Mcfadden1978,
  title = {Modeling the {{Choice}} of {{Residential Location}}},
  author = {Mcfadden, Daniel},
  date = {1978},
  journaltitle = {ransportation Research Record},
  volume = {673},
  pages = {72--77},
  abstract = {The problem of translating the theory of economic choice behavior into concrete models suitable for analyzing housing location is discussed. The analysis is based on the premise that the classical, economically rational consumer will choose a residential location by weighing the attributes of each available alternative and by selecting the alternative that maximizes utility. The assumption of independence in the commonly used multi· nomial logit model of choice Is relaxed to permit a structure of perceived similarities among alternatives. In this analysis, choice is described by a multinomial logit model for aggregates of similar alternatives. Also discussed are methods for controlling the size of data collection and estimation tasks by sampling alternatives from the full set of alterna-tives. The classical, economically rational consumer will choose a residential location by weighing the attributes of each available alternative-accessibility to work place, shopping, and schools; quality of neighborhood life and availability of public services; costs, including price, taxes, and ti·avel costs; and dwelling character-istics, such as age, number of rooms, type of appli-ances-and by choosing the alternative that maximizes utility. This paper considers the problem of translating the theory of economic choice behavior into concrete models suitable for the empirical analysis of housing location. We are concerned particularly with two problems in the modeling of individual, or disaggregate, choice among residential locations. First, there may be a structure of perceived similarities among alternatives that invali-dates the commonly used joint multinomial logit model of choice. We treat individual dwelling units as the basic alternatives among which choice is made. Each unit will have a list of attributes, observed and unob-served, to which the individual responds. We assume that the space of attributes, including unobserved attri-butes, is sufficiently ric. h so that each physical dwelling unit is represented by a unique point in attribute space. Of course, the individual may perceive two dwellings that are similar in some attributes as quite similar overall; it is the impact of such perceptions on choice that I wish to model. I shall introduce a family of probabilistic choice models, of which the joint multinomial logit model is a special case, that has the property of aggregating dwelling units perceived as similar. The weight given to an aggregate of alternatives in the choice process will depend on the degree of perceived similarity. At one extreme, the elements of the aggregate will be perceived as independent, and choice will be de-scribed by a multinomial logit model with individual dwellings as alternatives. At the other extreme, all dwellings with the same observed attributes will be per-ceived as virtually the same, and choice will be de-scribed by a multinomial logit model with dwelling types, which are distinguished by observed attributes, as the alternatives. The family of models introduced here permits empirical estimation of the degree of perceived similarity and tests of the two extreme cases men-tioned above. The second problem treated in this paper is that of estimation of individual choice models when the number of elemental alternatives is impractically large. The section on limiting the number of alternatives establishes that, if choice among a set of alternatives is described by a multinomial logit model, then the model can be estimated by sampling from the full set of alternatives, with appropriate adjustment in the estimation mecha-nism. Thus, estimation can be carried out with limited data collection and computation. The solutions I give to the two problems above will be applied to empirical studies of housing location by},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\6P9QXRX4\\Mcfadden - 1978 - Modeling the Choice of Residential Location.pdf}
}

@article{McGowan2015,
  title = {Defining robustness protocols: a method to include and evaluate robustness in clinical plans.},
  author = {McGowan, S E and Albertini, F and Thomas, S J and Lomax, A J},
  date = {2015-04-07},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {60},
  number = {7},
  eprint = {25768095},
  eprinttype = {pmid},
  pages = {2671--2684},
  publisher = {{IOP Publishing}},
  issn = {1361-6560},
  doi = {10.1088/0031-9155/60/7/2671},
  url = {http://stacks.iop.org/0031-9155/60/i=7/a=2671?key=crossref.092f8f208f90dc19331c51799573c57f},
  urldate = {2015-03-17},
  abstract = {We aim to define a site-specific robustness protocol to be used during the clinical plan evaluation process. Plan robustness of 16 skull base IMPT plans to systematic range and random set-up errors have been retrospectively and systematically analysed. This was determined by calculating the error-bar dose distribution (ebDD) for all the plans and by defining some metrics used to define protocols aiding the plan assessment. Additionally, an example of how to clinically use the defined robustness database is given whereby a plan with sub-optimal brainstem robustness was identified. The advantage of using different beam arrangements to improve the plan robustness was analysed. Using the ebDD it was found range errors had a smaller effect on dose distribution than the corresponding set-up error in a single fraction, and that organs at risk were most robust to the range errors, whereas the target was more robust to set-up errors. A database was created to aid planners in terms of plan robustness aims in these volumes. This resulted in the definition of site-specific robustness protocols. The use of robustness constraints allowed for the identification of a specific patient that may have benefited from a treatment of greater individuality. A new beam arrangement showed to be preferential when balancing conformality and robustness for this case. The ebDD and error-bar volume histogram proved effective in analysing plan robustness. The process of retrospective analysis could be used to establish site-specific robustness planning protocols in proton therapy. These protocols allow the planner to determine plans that, although delivering a dosimetrically adequate dose distribution, have resulted in sub-optimal robustness to these uncertainties. For these cases the use of different beam start conditions may improve the plan robustness to set-up and range uncertainties.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\SBWWJDT2\\McGowan et al. - 2015 - Defining robustness protocols a method to include and evaluate robustness in clinical plans.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\WLKCP8ZH\\McGowan et al. - 2015 - Defining robustness protocols a method to include and evaluate robustness in clinical plans.pdf}
}

@article{McKenzie2000,
  title = {The width of margins in radiotherapy treatment plans.},
  author = {McKenzie, Alan L and family=Herk, given=Marcel, prefix=van, useprefix=false and Mijnheer, Ben and family=Herk, given=Marcel, prefix=van, useprefix=true and Mijnheer, Ben},
  date = {2000-11-01},
  journaltitle = {Physics in medicine and biology},
  volume = {45},
  number = {11},
  eprint = {11098907},
  eprinttype = {pmid},
  pages = {3331--42},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/45/11/315},
  abstract = {Publication of ICRU Reports 50 and 62 has highlighted the need to devise protocols for the process of drawing the planning target volume (PTV) around the clinical target volume (CTV). The margin surrounding the CTV should be wide enough to account for all geometric errors so that no part of the CTV accumulates a dose less than, for instance, 95\% of that prescribed. One approach to the problem has been to draw a margin around the CTV delineated at the treatment preparation stage which is sufficiently wide that the mean position of the CTV will be encompassed in a specific percentage of cases, for example 90\%. This accounts for the systematic errors. A further margin is then drawn to account for random set-up and organ-motion uncertainties during treatment. The width of this second margin has previously been shown to be 1.64(sigma - sigmap). Here sigma, a vector quantity, is the standard deviation which results from convolving the penumbra spread function of standard deviation sigmap with the Gaussian distributions of the daily positional uncertainties of organ motion and set-up error. However, it is shown in this paper that the calculation should take into account the beam configuration of the treatment plan. In a typical coplanar multibeam plan, usually in the transverse plane, any given edge of the target volume is normally defined by a single beam or two parallel and opposed beams. However, because of the presence of the other beams, the effect of the blurring of the edge-defining beam(s) is reduced, which changes the value of the required margin to beta (sigma - sigmap) where, for example, beta can be as low as 1.04 in the transverse plane of a three-beam plan. The width of the required margins is calculated for up to six beams and presented in a table. It is shown that, while the table was derived using an idealized plan of equally weighted plane beams irradiating a spherical target, it is also valid for non-uniform beam weightings, wedged-beam plans, target volumes of general shape and intensity-modulated radiotherapy (IMRT).},
  keywords = {Computer-Assisted,Computer-Assisted: methods,Conformal,Conformal: methods,Humans,Models,Radiotherapy,Radiotherapy Planning,Reproducibility of Results,Statistical},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\FNJ3HJ64\\McKenzie et al. - 2000 - The width of margins in radiotherapy treatment plans.pdf}
}

@article{McNamara2015,
  title = {A phenomenological relative biological effectiveness ({{RBE}}) model for proton therapy based on all published in vitro cell survival data},
  author = {McNamara, Aimee L. and Schuemann, Jan and Paganetti, Harald},
  date = {2015-11-07},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {60},
  number = {21},
  eprint = {26459756},
  eprinttype = {pmid},
  pages = {8399--8416},
  issn = {1361-6560},
  doi = {10.1088/0031-9155/60/21/8399},
  abstract = {Proton therapy treatments are currently planned and delivered using the assumption that the proton relative biological effectiveness (RBE) relative to photons is 1.1. This assumption ignores strong experimental evidence that suggests the RBE varies along the treatment field, i.e. with linear energy transfer (LET) and with tissue type. A recent review study collected over 70 experimental reports on proton RBE, providing a comprehensive dataset for predicting RBE for cell survival. Using this dataset we developed a model to predict proton RBE based on dose, dose average LET (LETd) and the ratio of the linear-quadratic model parameters for the reference radiation (α/β)x, as the tissue specific parameter. The proposed RBE model is based on the linear quadratic model and was derived from a nonlinear regression fit to 287 experimental data points. The proposed model predicts that the RBE increases with increasing LETd and decreases with increasing (α/β)x. This agrees with previous theoretical predictions on the relationship between RBE, LETd and (α/β)x. The model additionally predicts a decrease in RBE with increasing dose and shows a relationship between both α and β with LETd. Our proposed phenomenological RBE model is derived using the most comprehensive collection of proton RBE experimental data to date. Previously published phenomenological models, based on a limited data set, may have to be revised.},
  langid = {english},
  pmcid = {PMC4634882},
  keywords = {Cell Line,Cell Survival,Humans,Linear Energy Transfer,Models; Theoretical,Proton Therapy,Relative Biological Effectiveness},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\WWUZSTC4\\McNamara et al. - 2015 - A phenomenological relative biological effectivene.pdf}
}

@manual{MCsqDoc,
  type = {manual},
  title = {Commissioning procedure for {{MCsquare}}},
  author = {Souris, Kevin and Cohilis, Marie and Huang, Sheng and Barragan, Ana},
  url = {http://openMCsquare.org/documentation_commissioning.html},
  urldate = {2021-01-09}
}

@misc{Medicalphysicsweb2012,
  title = {Siteman {{Cancer Center}} begins imaging with {{ViewRay}}'s {{IGRT}} system},
  author = {{medicalphysicsweb}},
  date = {2012},
  url = {http://medicalphysicsweb.org/cws/article/newsfeed/50241}
}

@book{MedPhysBook2002,
  title = {Medizinische {{Strahlenphysik}}},
  author = {Schlegel, Wolfgang and Bille, Josef},
  date = {2002},
  publisher = {{Springer}},
  url = {http://katalog.ub.uni-heidelberg.de/cgi-bin/titel.cgi?katkey=65505052&sess=ad52029a2b19861729c29cdca756bb47&query=Medizinische%20Strahlenphysik},
  urldate = {2014-01-23},
  isbn = {978-3-540-65254-0},
  keywords = {(s)Medizinische Radiologie}
}

@article{Mein2019,
  title = {Biophysical modeling and experimental validation of relative biological effectiveness ({{RBE}}) for {{4He}} ion beam therapy},
  author = {Mein, Stewart and Dokic, Ivana and Klein, Carmen and Tessonnier, Thomas and Böhlen, Till Tobias and Magro, Guiseppe and Bauer, Julia and Ferrari, Alfredo and Parodi, Katia and Haberer, Thomas and Debus, Jürgen and Abdollahi, Amir and Mairani, Andrea},
  date = {2019-07-11},
  journaltitle = {Radiation Oncology},
  shortjournal = {Radiat Oncol},
  volume = {14},
  number = {1},
  pages = {123},
  issn = {1748-717X},
  doi = {10.1186/s13014-019-1295-z},
  url = {https://doi.org/10.1186/s13014-019-1295-z},
  urldate = {2019-10-28},
  abstract = {BackgroundHelium (4He) ion beam therapy provides favorable biophysical characteristics compared to currently administered particle therapies, i.e., reduced lateral scattering and enhanced biological damage to deep-seated tumors like heavier ions, while simultaneously lessened particle fragmentation in distal healthy tissues as observed with lighter protons. Despite these biophysical advantages, raster-scanning 4He ion therapy remains poorly explored e.g., clinical translational is hampered by the lack of reliable and robust estimation of physical and radiobiological uncertainties. Therefore, prior to the upcoming 4He ion therapy program at the Heidelberg Ion-beam Therapy Center (HIT), we aimed to characterize the biophysical phenomena of 4He ion beams and various aspects of the associated models for clinical integration.MethodsCharacterization of biological effect for 4He ion beams was performed in both homogenous and patient-like treatment scenarios using innovative models for estimation of relative biological effectiveness (RBE) in silico and their experimental validation using clonogenic cell survival as the gold-standard surrogate. Towards translation of RBE models in patients, the first GPU-based treatment planning system (non-commercial) for raster-scanning 4He ion beams was devised in-house (FRoG).ResultsOur data indicate clinically relevant uncertainty of ±5–10\% across different model simulations, highlighting their distinct biological and computational methodologies. The in vitro surrogate for highly radio-resistant tissues presented large RBE variability and uncertainty within the clinical dose range.ConclusionsExisting phenomenological and mechanistic/biophysical models were successfully integrated and validated in both Monte Carlo and GPU-accelerated analytical platforms against in vitro experiments, and tested using pristine peaks and clinical fields in highly radio-resistant tissues where models exhibit the greatest RBE uncertainty. Together, these efforts mark an important step towards clinical translation of raster-scanning 4He ion beam therapy to the clinic.},
  langid = {english},
  keywords = {Helium ions,Particle therapy,Relative biological effectiveness,Translational research},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Y5W942NF\\Mein et al. - 2019 - Biophysical modeling and experimental validation o.pdf}
}

@thesis{Mescher2016,
  type = {mathesis},
  title = {Constraint-based coverage optimized planning in intensity-modulated radiotherapy},
  author = {Mescher, Henning},
  date = {2016},
  institution = {{University of Heidelberg}},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\PSQY2EZS\\Mescher - 2016 - Constraint-based coverage optimized planning in intensity-modulated radiotherapy.pdf}
}

@article{Mescher2017,
  title = {Coverage-based constraints for {{IMRT}} optimization},
  author = {Mescher, H and Ulrich, S and Bangert, M},
  date = {2017-09-05},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {62},
  number = {18},
  pages = {N460-N473},
  publisher = {{IOP Publishing}},
  issn = {1361-6560},
  doi = {10.1088/1361-6560/aa8132},
  url = {http://stacks.iop.org/0031-9155/62/i=18/a=N460?key=crossref.f05e3801e9bf4cfba9eb57e115758556},
  urldate = {2018-04-13},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\3JT96U5J\\Mescher, Ulrich, Bangert - 2017 - Coverage-based constraints for IMRT optimization.pdf}
}

@article{MITK2005,
  title = {The medical imaging interaction toolkit},
  author = {Wolf, Ivo and Vetter, Marcus and Wegner, Ingmar and Böttger, Thomas and Nolden, Marco and Schöbinger, Max and Hastenteufel, Mark and Kunert, Tobias and Meinzer, Hans Peter},
  date = {2005},
  journaltitle = {Medical Image Analysis},
  shortjournal = {Med Image Anal},
  volume = {9},
  number = {6},
  eprint = {15896995},
  eprinttype = {pmid},
  pages = {594--604},
  issn = {13618415},
  doi = {10.1016/j.media.2005.04.005},
  abstract = {Thoroughly designed, open-source toolkits emerge to boost progress in medical imaging. The Insight Toolkit (ITK) provides this for the algorithmic scope of medical imaging, especially for segmentation and registration. But medical imaging algorithms have to be clinically applied to be useful, which additionally requires visualization and interaction. The Visualization Toolkit (VTK) has powerful visualization capabilities, but only low-level support for interaction. In this paper, we present the Medical Imaging Interaction Toolkit (MITK). The goal of MITK is to significantly reduce the effort required to construct specifically tailored, interactive applications for medical image analysis. MITK allows an easy combination of algorithms developed by ITK with visualizations created by VTK and extends these two toolkits with those features, which are outside the scope of both. MITK adds support for complex interactions with multiple states as well as undo-capabilities, a very important prerequisite for convenient user interfaces. Furthermore, MITK facilitates the realization of multiple, different views of the same data (as a multiplanar reconstruction and a 3D rendering) and supports the visualization of 3D+t data, whereas VTK is only designed to create one kind of view of 2D or 3D data. MITK reuses virtually everything from ITK and VTK. Thus, it is not at all a competitor to ITK or VTK, but an extension, which eases the combination of both and adds the features required for interactive, convenient to use medical imaging software. MITK is an open-source project (www.mitk.org). © 2005 Elsevier B.V. All rights reserved.},
  keywords = {Interaction,ITK,Toolkit,Visualization,VTK},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\I5KJC7GJ\\Wolf et al. - 2005 - The medical imaging interaction toolkit.pdf}
}

@article{Mohan1985,
  title = {Energy and angular distributions of photons from medical linear accelerators},
  author = {Mohan, Radhe},
  date = {1985},
  journaltitle = {Medical Physics},
  volume = {12},
  number = {5},
  pages = {592},
  issn = {00942405},
  doi = {10.1118/1.595680},
  url = {http://link.aip.org/link/?MPH/12/592/1&Agg=doi},
  urldate = {2013-12-10},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\TKMSKQPQ\\Mohan - 1985 - Energy and angular distributions of photons from medical linear accelerators.pdf}
}

@article{Mohan1992,
  title = {Clinically relevant optimization of 3-{{D}} conformal treatments},
  author = {Mohan, R. and Mageras, G. S. and Baldwin, B. and Brewster, L. J. and Kutcher, G. J. and Leibel, S. and Burman, C. M and Ling, C. C. and Fuks, Z.},
  date = {1992-07-01},
  journaltitle = {Medical Physics},
  volume = {19},
  number = {4},
  pages = {933--944},
  publisher = {{Wiley-Blackwell}},
  issn = {00942405},
  doi = {10.1118/1.596781},
  url = {http://doi.wiley.com/10.1118/1.596781},
  urldate = {2018-04-07},
  keywords = {87.53.10.b,87.53.10.g,87.53.10.h,Annealing,Cancer,Computer modeling,Field shaping,including brachytherapy,MEDICINE,Optimization,OPTIMIZATION,RADIATION DOSE DISTRIBUTIONS,RADIOTHERAPY,Therapeutic applications,Tissues,TISSUES,TUMOR CELLS},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\JMFQ7PFJ\\Mohan et al. - 1992 - Clinically relevant optimization of 3-D conformal treatments.pdf}
}

@article{Mohan2017,
  title = {Radiobiological issues in proton therapy},
  author = {Mohan, Radhe and Peeler, Christopher R. and Guan, Fada and Bronk, Lawrence and Cao, Wenhua and Grosshans, David R.},
  date = {2017-11-02},
  journaltitle = {Acta Oncologica},
  volume = {56},
  number = {11},
  pages = {1367--1373},
  publisher = {{Taylor \& Francis}},
  issn = {0284-186X},
  doi = {10.1080/0284186X.2017.1348621},
  url = {https://www.tandfonline.com/doi/full/10.1080/0284186X.2017.1348621},
  urldate = {2018-04-19},
  abstract = {AbstractBackground: The relative biological effectiveness (RBE) for particle therapy is a complex function of particle type, radiation dose, linear energy transfer (LET), cell type, endpoint, etc. In the clinical practice of proton therapy, the RBE is assumed to have a fixed value of 1.1. This assumption, along with the effects of physical uncertainties, may mean that the biologically effective dose distributions received by the patient may be significantly different from what is seen on treatment plans. This may contribute to unforeseen toxicities and/or failure to control the disease.Variability of Proton RBE: It has been shown experimentally that proton RBE varies significantly along the beam path, especially near the end of the particle range. While there is now an increasing acceptance that proton RBE is variable, there is an ongoing debate about whether to change the current clinical practice.Clinical Evidence: A rationale against the change is the uncertainty in the models of variable RBE. Secondly...}
}

@article{Molitoris2018,
  title = {Advances in the use of motion management and image guidance in radiation therapy treatment for lung cancer},
  author = {Molitoris, Jason K. and Diwanji, Tejan and Snider, James W. and Mossahebi, Sina and Samanta, Santanu and Badiyan, Shahed N. and Simone, Charles B. and Mohindra, Pranshu},
  date = {2018-08},
  journaltitle = {Journal of Thoracic Disease},
  shortjournal = {J Thorac Dis},
  volume = {10},
  eprint = {30206490},
  eprinttype = {pmid},
  pages = {S2437-S2450},
  issn = {2072-1439},
  doi = {10.21037/jtd.2018.01.155},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6123191/},
  urldate = {2020-03-23},
  abstract = {The development of advanced radiation technologies, including intensity-modulated radiation therapy (IMRT), stereotactic body radiation therapy (SBRT) and proton therapy, has resulted in increasingly conformal radiation treatments. Recent evidence for the importance of minimizing dose to normal critical structures including the heart and lungs has led to incorporation of these advanced treatment modalities into radiation therapy (RT) for non-small cell lung cancer (NSCLC). While such technologies have allowed for improved dose delivery, implementation requires improved target accuracy with treatments, placing increasing importance on evaluating tumor motion at the time of planning and verifying tumor position at the time of treatment. In this review article, we describe issues and updates related both to motion management and image guidance in the treatment of NSCLC.},
  issue = {Suppl 21},
  pmcid = {PMC6123191},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\BK7I4QIR\\Molitoris et al. - 2018 - Advances in the use of motion management and image.pdf}
}

@article{Moore2009,
  title = {Comparisons of treatment optimization directly incorporating random patient setup uncertainty with a margin-based approach.},
  author = {Moore, Joseph A and Gordon, John J and Anscher, Mitchell S and Siebers, Jeffrey V},
  date = {2009},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {36},
  number = {9},
  eprint = {19810460},
  eprinttype = {pmid},
  pages = {3880--3890},
  issn = {0094-2405},
  doi = {10.1118/1.3176940},
  abstract = {The purpose of this study is to incorporate the dosimetric effect of random patient positioning uncertainties directly into a commercial treatment planning system's IMRT plan optimization algorithm through probabilistic treatment planning (PTP) and compare coverage of this method with margin-based planning. In this work, PTP eliminates explicit margins and optimizes directly on the estimated integral treatment dose to determine optimal patient dose in the presence of setup uncertainties. Twenty-eight prostate patient plans adhering to the RTOG-0126 criteria are optimized using both margin-based and PTP methods. Only random errors are considered. For margin-based plans, the planning target volume is created by expanding the clinical target volume (CTV) by 2.1 mm to accommodate the simulated 3 mm random setup uncertainty. Random setup uncertainties are incorporated into IMRT dose evaluation by convolving each beam's incident fluence with a sigma = 3 mm Gaussian prior to dose calculation. PTP optimization uses the convolved fluence to estimate dose to ensure CTV coverage during plan optimization. PTP-based plans are compared to margin-based plans with equal CTV coverage in the presence of setup errors based on dose-volume metrics. The sensitivity of the optimized plans to patient-specific setup uncertainty variations is assessed by evaluating dose metrics for dose distributions corresponding to halving and doubling of the random setup uncertainty used in the optimization. Margin-based and PTP-based plans show similar target coverage. A physician review shows that PTP is preferred for 21 patients, margin-based plans are preferred in 2 patients, no preference is expressed for 1 patient, and both autogenerated plans are rejected for 4 patients. For the PTP-based plans, the average CTV receiving the prescription dose decreases by 0.5\%, while the mean dose to the CTV increases by 0.7\%. The CTV tumor control probability (TCP) is the same for both methods with the exception of one case in which PTP gave a slightly higher TCP. For critical structures that do not meet the optimization criteria, PTP shows a decrease in the volume receiving the maximum specified dose. PTP reduces local normal tissue volumes receiving the maximum dose on average by 48\%. PTP results in lower mean dose to all critical structures for all plans. PTP results in a 2.5\% increase in the probability of uncomplicated control (P+), along with a 1.9\% reduction in rectum normal tissue complication probability (NTCP), and a 0.7\% reduction in bladder NTCP. PTP-based plans show improved conformality as compared with margin-based plans with an average PTP-based dosimetric margin at 7100 cGy of 0.65 cm compared with the margin-based 0.90 cm and a PTP-based dosimetric margin at 3960 cGy of 1.60 cm compared with the margin-based 1.90 cm. PTP-based plans show similar sensitivity to variations of the uncertainty during treatment from the uncertainty used in planning as compared to margin-based plans. For equal target coverage, when compared to margin-based plans, PTP results in equal or lower doses to normal structures. PTP results in more conformal plans than margin-based plans and shows similar sensitivity to variations in uncertainty.},
  keywords = {imrt,margins,probabilistic planning,prostate,setup errors},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\PVXJEPDN\\Moore et al. - 2009 - Comparisons of treatment optimization directly incorporating random patient setup uncertainty with a margin-based.pdf}
}

@article{Mori2016,
  title = {Carbon-{{Ion Pencil Beam Scanning Treatment With Gated Markerless Tumor Tracking}}: {{An Analysis}} of {{Positional Accuracy}}},
  shorttitle = {Carbon-{{Ion Pencil Beam Scanning Treatment With Gated Markerless Tumor Tracking}}},
  author = {Mori, Shinichiro and Karube, Masataka and Shirai, Toshiyuki and Tajiri, Minoru and Takekoshi, Takuro and Miki, Kentaro and Shiraishi, Yurika and Tanimoto, Katsuyuki and Shibayama, Kouichi and Yasuda, Shigeo and Yamamoto, Naoyoshi and Yamada, Shigeru and Tsuji, Hiroshi and Noda, Koji and Kamada, Tadashi},
  date = {2016-05-01},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {International Journal of Radiation Oncology*Biology*Physics},
  series = {Particle {{Therapy Special Edition}}},
  volume = {95},
  number = {1},
  pages = {258--266},
  issn = {0360-3016},
  doi = {10.1016/j.ijrobp.2016.01.014},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301616000249},
  urldate = {2020-03-23},
  abstract = {Purpose Having implemented amplitude-based respiratory gating for scanned carbon-ion beam therapy, we sought to evaluate its effect on positional accuracy and throughput. Methods and Materials A total of 10 patients with tumors of the lung and liver participated in the first clinical trials at our center. Treatment planning was conducted with 4-dimensional computed tomography (4DCT) under free-breathing conditions. The planning target volume (PTV) was calculated by adding a 2- to 3-mm setup margin outside the clinical target volume (CTV) within the gating window. The treatment beam was on when the CTV was within the PTV. Tumor position was detected in real time with a markerless tumor tracking system using paired x-ray fluoroscopic imaging units. Results The patient setup error (mean~±~SD) was 1.1~±~1.2~mm/0.6~±~0.4°. The mean internal gating accuracy (95\% confidence interval [CI]) was 0.5~mm. If external gating had been applied to this treatment, the mean gating accuracy (95\% CI) would have been 4.1~mm. The fluoroscopic radiation doses (mean~±~SD) were 23.7~±~21.8~mGy per beam and less than 487.5~mGy total throughout the treatment course. The setup, preparation, and irradiation times (mean~±~SD) were 8.9~±~8.2~min, 9.5~±~4.6~min, and 4.0~±~2.4~min, respectively. The treatment room occupation time was 36.7~±~67.5~min. Conclusions Internal gating had a much higher accuracy than external gating. By the addition of a setup margin of 2 to 3~mm, internal gating positional error was less than 2.2~mm at 95\% CI.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\24TSG9FJ\\Mori et al. - 2016 - Carbon-Ion Pencil Beam Scanning Treatment With Gat.pdf}
}

@article{Motwani2007,
  title = {Estimating {{Sum}} by {{Weighted Sampling}}},
  author = {Motwani, Rajeev and Panigrahy, Rina and Xu, Ying},
  date = {2007},
  journaltitle = {Icalp 2007},
  pages = {53--64},
  issn = {03029743},
  doi = {dx.doi.org/10.1007/978-3-540-73420-8_7},
  url = {http://dx.doi.org/10.1007/978-3-540-73420-8_7},
  abstract = {We study the classic problem of estimating the sum of n variables. The traditional uniform sampling approach requires a linear number of samples to provide any non-trivial guarantees on the estimated sum. In this paper we consider various sampling methods besides uniform sampling, in particular sampling a variable with probability proportional to its value, referred to as linear weighted sampling. If only linear weighted sampling is allowed, we show an algorithm for estimating sum with O\textasciitilde (n\^0.5) samples, and it is almost optimal in the sense that Ω(n\^0.5) samples are necessary for any reasonable sum estimator. If both uniform sampling and linear weighted sampling are allowed, we show a sum estimator with O\textasciitilde (n\^1/3) samples. More generally, we may allow general weighted sampling where the probability of sampling a variable is proportional to any function of its value. We prove a lower bound of Ω(n\^1/3) samples for any reasonable sum estimator using general weighted sampling, which implies that our algorithm combining uniform and linear weighted sampling is an almost optimal sum estimator.},
  isbn = {3540734198},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\7DJEIBL3\\Motwani, Panigrahy, Xu - 2007 - Estimating Sum by Weighted Sampling.pdf}
}

@article{Motzkin1954,
  title = {The {{Relaxation Method}} for {{Linear Inequalities}}},
  author = {Motzkin, T. S. and Schoenberg, I. J.},
  date = {1954},
  journaltitle = {Canadian Journal of Mathematics},
  volume = {6},
  pages = {393--404},
  publisher = {{Cambridge University Press}},
  issn = {0008-414X, 1496-4279},
  doi = {10.4153/CJM-1954-038-x},
  url = {https://www.cambridge.org/core/journals/canadian-journal-of-mathematics/article/relaxation-method-for-linear-inequalities/8EDDF8B5F08B146AC71A5CF4F304A560},
  urldate = {2021-12-16},
  abstract = {Let A be a closed set of points in the n-dimensional euclidean space En. If p and p                1 are points of En such that                                                1.1                                                              then p                1 is said to be point-wise closer than p to the set A. If p is such that there is no point p1 which is point-wise closer than p to A, then p is called a closest point to the set A.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\CHHWNYEZ\\Motzkin und Schoenberg - 1954 - The Relaxation Method for Linear Inequalities.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\392FXVM9\\8EDDF8B5F08B146AC71A5CF4F304A560.html}
}

@book{Muirhead1982,
  title = {Aspects of {{Multivariate Statistical Theory}}},
  author = {Muirhead, Robb J.},
  date = {1982-03-25},
  series = {Wiley {{Series}} in {{Probability}} and {{Statistics}}},
  publisher = {{John Wiley \& Sons, Inc.}},
  location = {{Hoboken, NJ, USA}},
  doi = {10.1002/9780470316559},
  url = {http://doi.wiley.com/10.1002/9780470316559},
  urldate = {2018-04-29},
  isbn = {978-0-470-31655-9}
}

@article{Nadarajah2017,
  title = {A new bivariate beta distribution},
  author = {Nadarajah, Saralees and Shih, Shou Hsing and Nagar, Daya K.},
  date = {2017-03-04},
  journaltitle = {Statistics},
  shortjournal = {Statistics},
  volume = {51},
  number = {2},
  pages = {455--474},
  publisher = {{Taylor \& Francis}},
  issn = {0233-1888},
  doi = {10.1080/02331888.2016.1240681},
  url = {https://www.tandfonline.com/doi/full/10.1080/02331888.2016.1240681},
  urldate = {2018-07-24},
  abstract = {ABSTRACTA new bivariate beta distribution capable of providing better fits than all its competitors is introduced. Various representations are derived for its product moments, marginal densities, marginal moments, conditional densities and conditional moments. The method of maximum likelihood is used to derive the associated estimation procedure. Applications to six bivariate data sets are illustrated.},
  keywords = {Estimation,pollen count,product moments}
}

@inproceedings{Neishabouri2020,
  title = {{{OC-0215}}: {{LSTM}} networks for proton dose calculation in highly heterogeneous tissues},
  shorttitle = {{{LSTM}} networks for proton dose calculation in highly heterogeneous tissues},
  booktitle = {Radiotherapy and {{Oncology}}},
  author = {Neishabouri, Ahmad and Wahl, Niklas and Burigo, Lucas Norberto and Köthe, Ullrich and Bangert, Mark},
  date = {2020-11-01},
  volume = {152},
  pages = {S108-S109},
  publisher = {{Elsevier}},
  location = {{Online}},
  doi = {10.1016/S0167-8140(21)00239-5},
  url = {https://www.thegreenjournal.com/article/S0167-8140(21)00239-5/abstract},
  urldate = {2022-09-02},
  eventtitle = {{{ESTRO}}},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\HRS6MP67\\pdf.html}
}

@article{Neishabouri2021,
  title = {Long short‐term memory networks for proton dose calculation in highly heterogeneous tissues},
  author = {Neishabouri, Ahmad and Wahl, Niklas and Mairani, Andrea and Köthe, Ullrich and Bangert, Mark},
  date = {2021-04},
  journaltitle = {Medical Physics},
  shortjournal = {Med. Phys.},
  volume = {48},
  number = {4},
  eprint = {2006.06085},
  eprinttype = {arxiv},
  pages = {1893--1908},
  issn = {0094-2405, 2473-4209},
  doi = {10.1002/mp.14658},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/mp.14658},
  urldate = {2021-03-11},
  abstract = {Purpose: To investigate the feasibility and accuracy of proton dose calculations with artificial neural networks (ANNs) in challenging three-dimensional (3D) anatomies. Methods: A novel proton dose calculation approach was designed based on the application of a long short-term memory (LSTM) network. It processes the 3D geometry as a sequence of two-dimensional (2D) computed tomography slices and outputs a corresponding sequence of 2D slices that forms the 3D dose distribution. The general accuracy of the approach is investigated in comparison to Monte Carlo reference simulations and pencil beam dose calculations. We consider both artificial phantom geometries and clinically realistic lung cases for three different pencil beam energies. Results: For artificial phantom cases, the trained LSTM model achieved a 98.57\% γ-index pass rate ([1\%, 3 mm]) in comparison to MC simulations for a pencil beam with initial energy 104.25 MeV. For a lung patient case, we observe pass rates of 98.56\%, 97.74\%, and 94.51\% for an initial energy of 67.85, 104.25, and 134.68 MeV, respectively. Applying the LSTM dose calculation on patient cases that were fully excluded from the training process yields an average γ-index pass rate of 97.85\%. Conclusions: LSTM networks are well suited for proton dose calculation tasks. Further research, especially regarding model generalization and computational performance in comparison to established dose calculation methods, is warranted. © 2020 The Authors. Medical Physics published by Wiley Periodicals LLC on behalf of American Association of Physicists in Medicine. [https://doi.org/10.1002/mp.14658]},
  archiveprefix = {arXiv},
  langid = {english},
  preview = {proton\_lstm.png},
  selected = {true},
  keywords = {Physics - Medical Physics},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\3HDFVYW7\\Neishabouri et al. - 2020 - Long short-term memory networks for proton dose ca.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\75EGQGDY\\Neishabouri et al. - 2021 - Long short‐term memory networks for proton dose ca.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\2HABJYQG\\mp.html;C\:\\Users\\Niklas\\Zotero\\storage\\B6RDP7TN\\2006.html;C\:\\Users\\Niklas\\Zotero\\storage\\EA9PQW4B\\mp.html}
}

@article{Newhauser2007,
  title = {Monte {{Carlo}} simulations for configuring and testing an analytical proton dose-calculation algorithm},
  author = {Newhauser, Wayne and Fontenot, Jonas and Zheng, Yuanshui and Polf, Jerimy and Titt, Uwe and Koch, Nicholas and Zhang, Xiaodong and Mohan, Radhe},
  date = {2007-07},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {52},
  number = {15},
  pages = {4569--4584},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/52/15/014},
  url = {https://doi.org/10.1088%2F0031-9155%2F52%2F15%2F014},
  urldate = {2020-04-03},
  abstract = {Contemporary treatment planning systems for proton radiotherapy typically use analytical pencil-beam algorithms—which require a comprehensive set of configuration data—to predict the absorbed dose distributions in the patient. In order to reduce the time required to prepare a new proton treatment planning system for clinical use, it was desirable to configure the planning system before measured beam data were available. However, it was not known if the Monte Carlo simulation method was a practical alternative to measuring beam profiles. The purpose of this study was to develop a model of a passively scattered proton therapy unit, to simulate the properties of the proton fields using the Monte Carlo technique and to configure an analytical treatment planning system using the simulated beam data. Additional simulations and treatment plans were calculated in order to validate the pencil-beam predictions against the Monte Carlo simulations using realistic treatment beams. Comparison of dose distributions in a water phantom revealed small dose difference and distances to agreement under the validation conditions. The total simulation time for generating the 768 beam configuration profiles was approximately 6 weeks using 30 nodes in a parallel processing cluster. The results of this study show that it is possible to configure and test a proton treatment planning system prior to the availability of measured proton beam data. The model presented here provided a means to reduce by several months the time required to prepare an analytical treatment planning system for patient treatments.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\W7KX964N\\Newhauser et al. - 2007 - Monte Carlo simulations for configuring and testin.pdf}
}

@article{Newhauser2015,
  title = {The physics of proton therapy},
  author = {Newhauser, Wayne D and Zhang, Rui},
  date = {2015-04-21},
  journaltitle = {Physics in Medicine and Biology},
  volume = {60},
  number = {8},
  pages = {R155-R209},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/60/8/R155},
  url = {http://stacks.iop.org/0031-9155/60/i=8/a=R155?key=crossref.e17ea27b3e09d2ae08a7471562523fb1},
  urldate = {2018-04-16},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\9R4NRMLJ\\Newhauser, Zhang - 2015 - The physics of proton therapy.pdf}
}

@article{Nickolls2008,
  title = {Scalable parallel programming with {{CUDA}}},
  author = {Nickolls, John and Buck, Ian and Garland, Michael and Skadron, Kevin},
  date = {2008-03-01},
  journaltitle = {Queue},
  volume = {6},
  number = {2},
  pages = {40},
  publisher = {{ACM}},
  issn = {15427730},
  doi = {10.1145/1365490.1365500},
  url = {http://portal.acm.org/citation.cfm?doid=1365490.1365500},
  urldate = {2016-11-16},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\D4MX9V6H\\Nickolls et al. - 2008 - Scalable parallel programming with CUDA.pdf}
}

@article{Niemierko1997,
  title = {Reporting and analyzing dose distributions: {{A}} concept of equivalent uniform dose},
  author = {Niemierko, Andrzej},
  date = {1997-01-01},
  journaltitle = {Medical Physics},
  volume = {24},
  number = {1},
  pages = {103--110},
  publisher = {{Wiley-Blackwell}},
  issn = {00942405},
  doi = {10.1118/1.598063},
  url = {http://doi.wiley.com/10.1118/1.598063},
  urldate = {2018-04-07},
  keywords = {87.53.10.k,Anatomy,Cancer,Data analysis,dosimetry,Dosimetry,Medical treatment planning,Physicists,Poisson's equation,radiation therapy,Treatment strategy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\J83NI9AN\\Niemierko - 1997 - Reporting and analyzing dose distributions A concept of equivalent uniform dose.pdf}
}

@article{Niemierko1999a,
  title = {A generalized concept of equivalent uniform dose ({{EUD}})},
  author = {Niemierko, Andrzej},
  date = {1999},
  journaltitle = {Medical Phyics},
  volume = {26},
  pages = {1100}
}

@article{Nill2001,
  title = {Development and application of a multi-modality inverse treatment planning system},
  author = {Nill, Simeon},
  date = {2001},
  publisher = {{Heidelberg University Library}},
  doi = {10.11588/HEIDOK.00001802},
  keywords = {530 Physics}
}

@article{Niyazi2013,
  title = {Analysis of equivalent uniform dose ({{EUD}}) and conventional radiation treatment parameters after primary and re-irradiation of malignant glioma},
  author = {Niyazi, Maximilian and Karin, Ivan and Söhn, Matthias and Nachbichler, Silke B and Lang, Peter and Belka, Claus and Ganswindt, Ute},
  date = {2013-12-13},
  journaltitle = {Radiation Oncology},
  volume = {8},
  number = {1},
  eprint = {24330746},
  eprinttype = {pmid},
  pages = {287},
  publisher = {{BioMed Central}},
  issn = {1748-717X},
  doi = {10.1186/1748-717X-8-287},
  abstract = {BACKGROUND Re-irradiation is a reasonable second treatment option for patients with recurrent malignant glioma (MG) after previous radio(chemo)therapy. However, only limited data is available allowing for a precise selection of patients suitable for re-treatment in regard to safety and efficacy. METHODS Using the department database, 58 patients with two courses of percutaneous radiation were identified. Besides classical dose-volume histogram (DVH) parameters equivalent uniform dose (EUD) values were calculated for the tumor and organs at risk (OARs), retrospectively analyzed and correlated to survival outcome parameters. Cumulative EUD values were also calculated in all cases where previous OAR DVHs were available. RESULTS Median follow-up was 265 days and no relevant toxicity was observed after re-irradiation in our patient cohort during follow-up. Time interval between first and second irradiation was regularly above 6 months. As a conservative estimation of the cumulative EUD to the OARs, the EUDs of first and second irradiation were added. Median cumulative EUD to the optic chiasm was 48.8 Gy (range, 2.5-76.5 Gy), 57.4 Gy (range, 2.7-75.3 Gy) to the brainstem, 20.9/22.1 Gy (range, 0.0-68.3 Gy) to the right/left optic nerve and 73.8 Gy (range, 64.9-77.3 Gy) to the brain. No correlation between treated volume and survival was seen. CONCLUSIONS This study provides retrospective estimates on cumulative doses at the OARs. EUD values are derived and may serve as reference for further studies, including planning studies where specific constraints are needed.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\PTQT3VP7\\Niyazi et al. - 2013 - Analysis of equivalent uniform dose (EUD) and conventional radiation treatment parameters after primary and re-ir.pdf}
}

@book{Nocedal1999,
  title = {Numerical {{Optimization}}},
  author = {Nocedal, Jorge and Wright, Stephen J.},
  date = {1999},
  series = {Springer series in operations research},
  publisher = {{Springer}},
  location = {{New York}},
  isbn = {978-0-387-98793-4},
  langid = {english},
  pagetotal = {636},
  keywords = {Mathematical optimization},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\K6L73NLL\\Nocedal und Wright - 1999 - Numerical optimization.pdf}
}

@book{Nocedal2006,
  title = {Numerical {{Optimization}}},
  author = {Nocedal, Jorge and Wright, Stephen J.},
  date = {2006},
  series = {Springer {{Series}} in {{Operations Research}} and {{Financial Engineering}}},
  edition = {2},
  publisher = {{Springer-Verlag New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-0-387-40065-5},
  url = {http://katalog.ub.uni-heidelberg.de/cgi-bin/titel.cgi?katkey=65072750&sess=10ba67387fb028f7be6581f9c3efd1e7&query=Numerical%20Optimization},
  urldate = {2014-01-30},
  isbn = {978-0-387-30303-1},
  langid = {english},
  keywords = {(s)Optimierung / (s)Numerisches Verfahren},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\PTSNJ68V\\Nocedal, Wright - 2006 - Numerical Optimization.pdf}
}

@article{Nolden2013,
  title = {The {{Medical Imaging Interaction Toolkit}}: challenges and advances 10 years of open-source development},
  author = {Nolden, Marco and Zelzer, Sascha and Seitel, Alexander and Wald, Diana and Müller, Michael and Franz, Alfred M and Maleike, Daniel and Fangerau, Markus and Baumhauer, Matthias and Maier-Hein, Lena and Maier-Hein, Klaus H and Meinzer, Hans-Peter and Wolf, Ivo and Nolden, M and Zelzer, S and Seitel, A and Wald, D and Müller, M and Franz, A M and Fangerau, M and Baumhauer, · M and Maier-Hein, · L and Maier-Hein, K H and Meinzer, H.-P and Wolf, I and Maleike, D and Baumhauer, M},
  date = {2013},
  journaltitle = {International Journal of Computer Assisted Radiology and Surgery},
  shortjournal = {Int J CARS},
  volume = {8},
  pages = {607--620},
  doi = {10.1007/s11548-013-0840-8},
  abstract = {Purpose The Medical Imaging Interaction Toolkit (MITK) has been available as open-source software for almost 10 years now. In this period the requirements of software sys-tems in the medical image processing domain have become increasingly complex. The aim of this paper is to show how MITK evolved into a software system that is able to cover all steps of a clinical workflow including data retrieval, image analysis, diagnosis, treatment planning, intervention support, and treatment control. Methods MITK provides modularization and extensibility on different levels. In addition to the original toolkit, a mod-ule system, micro services for small, system-wide features, a service-oriented architecture based on the Open Services Gateway initiative (OSGi) standard, and an extensible and configurable application framework allow MITK to be used, extended and deployed as needed. A refined software process was implemented to deliver high-quality software, ease the fulfillment of regulatory requirements, and enable teamwork in mixed-competence teams. Results MITK has been applied by a worldwide community and integrated into a variety of solutions, either at the toolkit level or as an application framework with custom exten-sions. The MITK Workbench has been released as a highly extensible and customizable end-user application. Optional support for tool tracking, image-guided therapy, diffusion imaging as well as various external packages (e.g. CTK, DCMTK, OpenCV, SOFA, Python) is available. MITK has also been used in several FDA/CE-certified applications, which demonstrates the high-quality software and rigorous development process. Conclusions MITK provides a versatile platform with a high degree of modularization and interoperability and is well suited to meet the challenging tasks of today's and tomor-row's clinically motivated research.},
  keywords = {Extensible ·,Image-guided therapy,Introduction,Medical image analysis ·,Open-source ·,Platform ·,Quality management ·,Service-oriented architecture ·,Software process ·},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\GKCCV45M\\Nolden et al. - 2013 - The Medical Imaging Interaction Toolkit challenges and advances 10 years of open-source development.pdf}
}

@article{Oelfke2001a,
  title = {Inverse planning for photon and proton beams.},
  author = {Oelfke, Uwe and Bortfeld, Thomas},
  date = {2001-01},
  journaltitle = {Medical Dosimetry},
  volume = {26},
  number = {2},
  eprint = {11444513},
  eprinttype = {pmid},
  pages = {113--124},
  publisher = {{Elsevier}},
  issn = {09583947},
  doi = {10.1016/S0958-3947(01)00057-7},
  url = {http://www.meddos.org/article/S0958-3947(01)00057-7/abstract},
  urldate = {2014-01-30},
  abstract = {The concept of inverse planning for intensity-modulated radiation therapy and its application for photon and charged particle beams is presented. Starting from theoretical solutions of the "inverse problem" in radiation therapy, a clinically applied optimization approach is discussed. A central topic is the mathematical formulation of clinical objectives in terms of physical parameters such as dose levels and irradiated volumes. Examples for practical inverse treatment planning and its clinical application for photon beams are provided. Inverse treatment planning of dose delivery techniques with charged particle beams is discussed by extending the conventional planning concept. A new multimodality inverse planning tool is described and applied to an example of comparative planning between photon and proton IMRT.},
  keywords = {Intensity modulation,Inverse planning,Mathematics,Photons,Proton-therapy,Protons,Radiation therapy,Radiotherapy,Radiotherapy: methods}
}

@misc{Oelfke2012,
  title = {Private {{Communication}}},
  author = {Oelfke, Uwe},
  date = {2012}
}

@article{Oh2012,
  title = {Study of the penumbra for high-energy photon beams with {{Gafchromic}}\textbackslash trademark {{EBT2}} films},
  author = {Oh, Se An and Kang, Min Kyu and Yea, Ji Woon and Kim, Sung Kyu and Oh, Young Kee},
  date = {2012-06-13},
  journaltitle = {Journal of the Korean Physical Society},
  volume = {60},
  number = {11},
  pages = {1973--1976},
  issn = {0374-4884},
  doi = {10.3938/jkps.60.1973},
  url = {http://www.springerlink.com/index/10.3938/jkps.60.1973},
  urldate = {2014-02-11}
}

@article{Olkin2015,
  title = {Constructions for a bivariate beta distribution},
  author = {Olkin, Ingram and Trikalinos, Thomas A.},
  date = {2015-01-01},
  journaltitle = {Statistics \& Probability Letters},
  shortjournal = {Stat Probab Lett},
  volume = {96},
  eprint = {1406.5881},
  eprinttype = {arxiv},
  pages = {54--60},
  publisher = {{North-Holland}},
  issn = {01677152},
  doi = {10.1016/j.spl.2014.09.013},
  url = {https://www.sciencedirect.com/science/article/pii/S0167715214003241},
  urldate = {2018-06-29},
  abstract = {We provide a new bivariate distribution with beta marginal distributions, positive probability over the unit square, and correlations over the full range. We discuss its extension to three or more dimensions.},
  archiveprefix = {arXiv},
  keywords = {Bayesian analysis,Bivariate beta distribution,Bivariate families,Dirichlet distribution,Hypergeometric functions}
}

@book{Olver2010,
  title = {{{NIST}} handbook of mathematical functions},
  editor = {Olver, Frank W J and Lozier, Daniel W and Boisvert, Ronald F and Clark, Charles},
  date = {2010},
  edition = {1},
  publisher = {{Cambridge University Press}},
  location = {{New York, NY}},
  url = {http://www.cambridge.org/de/academic/subjects/mathematics/abstract-analysis/nist-handbook-mathematical-functions?format=WW&isbn=9780521192255#K1CbbQmmc1mjyh5G.97},
  urldate = {2018-03-22},
  isbn = {978-0-521-19225-5},
  pagetotal = {951}
}

@software{OpenMP2002,
  title = {{{OpenMP C}} and {{C}}++ {{Application Program Interface}}, {{Version}} 2.0},
  author = {{OpenMP Architecture Review Board}},
  date = {2002},
  journaltitle = {Review Literature And Arts Of The Americas},
  organization = {{OpenMP Architecture Review Board}}
}

@software{OptimizationToolbox,
  title = {{{MATLAB Optimization Toolbox User}}'s {{Guide}}},
  date = {2017},
  location = {{Natick, MA}},
  organization = {{The MathWorks, Inc.}}
}

@article{Oseledets2011,
  title = {Tensor-{{Train Decomposition}}},
  author = {Oseledets, I. V.},
  date = {2011},
  journaltitle = {SIAM Journal on Scientific Computing},
  volume = {33},
  number = {5},
  pages = {2295--2317},
  issn = {1064-8275},
  doi = {10.1137/090752286},
  abstract = {Asimple nonrecursive form of the tensor decomposition in d dimensions is presented. It does not inherently suffer from the curse of dimensionality, it has asymptotically the same number of parameters as the canonical decomposition, but it is stable and its computation is based on low- rank approximation of auxiliary unfolding matrices.The new form gives a clear and convenient way to implement all basic operations efficiently. A fast rounding procedure is presented, as well as basic linear algebra operations. Examples showing the benefits of the decomposition are given, and the efficiency is demonstrated by the computation of the smallest eigenvalue of a 19-dimensional operator.},
  keywords = {090752286,1,10,1137,15a23,15a69,65f99,ams subject classifications,doi,generalizations of ma-,high-dimensional problems,introduction,svd,tensors,tensors are natural multidimensional,tt-format},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\4YQFMF9N\\Oseledets - 2011 - Tensor-Train Decomposition.pdf}
}

@article{Oseledets2011a,
  title = {Tensor-{{Train}} ranks for matrices and their inverses},
  author = {Oseledets, Ivan V and Tyrtyshnikov, Eugene E and Zamarashkin, Nickolai L},
  date = {2011},
  journaltitle = {Comput. Meth. Appl. Math},
  pages = {1--13},
  issn = {16094840},
  keywords = {banded matrices,inverse,matrices,multilevel matrices,qtt-ranks,tensor ranks,tensor-train decomposition,toeplitz matrices},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\MCJRSM2C\\Oseledets, Tyrtyshnikov, Zamarashkin - 2011 - Tensor-Train ranks for matrices and their inverses.pdf}
}

@article{Oseledets2011b,
  title = {{{DMRG Approach}} to {{Fast Linear Algebra}} in the {{TT-Format}}},
  author = {Oseledets, Ivan},
  date = {2011},
  journaltitle = {Computational Methods in Applied Mathematics},
  volume = {11},
  number = {3},
  issn = {1609-4840},
  doi = {10.2478/cmam-2011-0021},
  url = {http://spring.inm.ras.ru/osel},
  urldate = {2018-03-29},
  abstract = {In this paper the concept of DMRG minimization scheme is ex-tended for important operations in the TT-format, like matrix-by-vector product and conversion from the canonical format to the TT-format. Fast algorithms are implemented in the TT-Toolbox stabilization scheme based on randomization is proposed, and the comparison with the direct method is performed on a sequence of matrices and vectors coming as approximate solutions of linear systems in the TT-format. An generated example is provided to show that randomization is really needed in some cases. The matrices and vectors used are available from the author or at http://spring.inm.ras.ru/osel},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\ZG4KGI7Z\\Oseledets - 2011 - DMRG Approach to Fast Linear Algebra in the TT-Format.pdf}
}

@article{Owen1980,
  title = {A table of normal integrals},
  author = {Owen, D B},
  date = {1980-01-27},
  journaltitle = {Communications in Statistics - Simulation and Computation},
  volume = {9},
  number = {4},
  pages = {389--419},
  issn = {0361-0918},
  doi = {10.1080/03610918008812164},
  url = {http://www.tandfonline.com/doi/abs/10.1080/03610918008812164},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\XQAG546V\\Owen - 1980 - A table of normal integrals.pdf}
}

@online{Ozradonc,
  title = {{{OzRadOnc}}},
  date = {2014},
  url = {http://ozradonc.wikidot.com/descriptors-of-dose-distribution-photons}
}

@article{PadillaCabal2020,
  title = {Implementation of a dose calculation algorithm based on {{Monte Carlo}} simulations for treatment planning towards {{MRI}} guided ion beam therapy},
  author = {Padilla-Cabal, Fatima and Resch, Andreas Franz and Georg, Dietmar and Fuchs, Hermann},
  date = {2020-06},
  journaltitle = {Physica Medica},
  volume = {74},
  pages = {155--165},
  publisher = {{Elsevier BV}},
  doi = {10.1016/j.ejmp.2020.04.027}
}

@article{Paganetti2012,
  title = {Range uncertainties in proton therapy and the role of {{Monte Carlo}} simulations},
  author = {Paganetti, Harald},
  date = {2012-06-07},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {57},
  number = {11},
  eprint = {22571913},
  eprinttype = {pmid},
  pages = {R99-R117},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/57/11/R99},
  abstract = {The main advantages of proton therapy are the reduced total energy deposited in the patient as compared to photon techniques and the finite range of the proton beam. The latter adds an additional degree of freedom to treatment planning. The range in tissue is associated with considerable uncertainties caused by imaging, patient setup, beam delivery and dose calculation. Reducing the uncertainties would allow a reduction of the treatment volume and thus allow a better utilization of the advantages of protons. This paper summarizes the role of Monte Carlo simulations when aiming at a reduction of range uncertainties in proton therapy. Differences in dose calculation when comparing Monte Carlo with analytical algorithms are analyzed as well as range uncertainties due to material constants and CT conversion. Range uncertainties due to biological effects and the role of Monte Carlo for in vivo range verification are discussed. Furthermore, the current range uncertainty recipes used at several proton therapy facilities are revisited. We conclude that a significant impact of Monte Carlo dose calculation can be expected in complex geometries where local range uncertainties due to multiple Coulomb scattering will reduce the accuracy of analytical algorithms. In these cases Monte Carlo techniques might reduce the range uncertainty by several mm.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\LZBCJEVV\\Paganetti - 2012 - Range uncertainties in proton therapy and the role of Monte Carlo simulations.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\YDY5QMJC\\Paganetti - 2012 - Range uncertainties in proton therapy and the role of Monte Carlo simulations.pdf}
}

@book{Paganetti2012c,
  title = {Proton therapy physics},
  editor = {Paganetti, Harald},
  date = {2012},
  edition = {1},
  publisher = {{CRC Press/Taylor \& Francis}},
  abstract = {"Compared to x-ray-based radiotherapeutic modalities, proton therapy provides greater 3D localization, higher beam doses, access to deeper tumors, and less damage to surrounding healthy tissue. Though over fifty years old, it is now coming to the forefront of cancer treatment with greater understanding of the biophysics and better treatment and patient outcomes. This text presents an overview of proton therapy that addresses all key topics including, biophysics, accelerators, hardware, beam delivery, treatment planning, dose calculation, quality assurance, and precision. Features (1) Provides an overview of proton therapy; (2) Covers beam delivery using passive scattering and magnetic beam scanning; (3) Details the physics of treatment planning for homogenous fields and intensity-modulated fields; and (4) Discusses precision and uncertainties for both moving and non-moving targets"--Provided by publisher. 1. Proton therapy : history and rationale / Harald Paganetti -- 2. Physics of proton interactions in matter / Bernard Gottschalk -- 3. Proton accelerators / Marco Schippers -- 4. Characteristics of clinical proton beams / Hsiao-Ming Lu and Jacob Flanz -- 5. Beam delivery using passive scattering / Roelf Slopsema -- 6. Particle beam scanning / Jacob Flanz -- 7. Dosimetry / Hugo Palmans -- 8. Quality assurance and commissioning / Zuofeng Li [and others] -- 9. Monte Carlo simulations / Harald Paganetti -- 10. Physics of treatment planning for single-field uniform dose / Martijn Engelsman -- 11. Physics of treatment planning using scanned beams / Antony Lomax -- 12. Dose calculation algorithms / Benjamin Clasie, Harald Paganetti, and Hanne M. Kooy -- 13. Precision and uncertainties in proton therapy for nonmoving targets / Jatinder R. Palta and Daniel K. Yeung -- 14. Precision and uncertainties in proton therapy for moving targets / Martijn Engelsman and Christoph Bert -- 15. Treatment-planning optimization / Alexei V. Trofimov, Jan H. Unkelbach, and David Craft -- 16. In vivo dose verification / Katia Parodi -- 17. Basic aspects of shielding / Nisy Elizabeth Ipe -- 18. Late effects from scattered and secondary radiation / Harold Paganetti -- 19. The physics of proton biology / Harald Paganetti -- 20. Fully exploiting the benefits of protons : using risk models for normal tissue complications in treatment optimization / Peter van Luijk and Marco Schippers.},
  isbn = {978-1-4398-3644-6}
}

@article{Pakkaranang2020,
  title = {Superiorization methodology and perturbation resilience of inertial proximal gradient algorithm with application to signal recovery},
  author = {Pakkaranang, Nuttapol and Kumam, Poom and Berinde, Vasile and Suleiman, Yusuf I.},
  date = {2020-12-01},
  journaltitle = {The Journal of Supercomputing},
  shortjournal = {J Supercomput},
  volume = {76},
  number = {12},
  pages = {9456--9477},
  issn = {1573-0484},
  doi = {10.1007/s11227-020-03215-z},
  url = {https://doi.org/10.1007/s11227-020-03215-z},
  urldate = {2022-06-17},
  abstract = {In this paper, we construct a novel algorithm for solving non-smooth composite optimization problems. By using inertial technique, we propose a modified proximal gradient algorithm with outer perturbations, and under standard mild conditions, we obtain strong convergence results for finding a solution of composite optimization problem. Based on bounded perturbation resilience, we present our proposed algorithm with the superiorization method and apply it to image recovery problem. Finally, we provide the numerical experiments to show efficiency of the proposed algorithm and comparison with previously known algorithms in signal recovery.},
  langid = {english},
  keywords = {47H05,47H09,49M37,65K10,Bounded perturbation resilience,Composite optimization problems,Inertial algorithm,Proximal gradient algorithm,Superiorization methodology}
}

@unpublished{Palkowitsch2021,
  type = {Oral Presentation},
  title = {The role of uncertainties in jointly optimised mixed carbon/photon treatments},
  author = {Palkowitsch, Martina and Bennan, Amit Ben Antony and Wahl, Niklas},
  date = {2021},
  eventtitle = {{{DGMP}} 2021},
  venue = {{Online}}
}

@article{Park2012,
  title = {A {{Beam-Specific Planning Target Volume}} ({{PTV}}) {{Design}} for {{Proton Therapy}} to {{Account}} for {{Setup}} and {{Range Uncertainties}}},
  author = {Park, Peter C and Zhu, X Ronald and Lee, Andrew K and Sahoo, Narayan and Melancon, Adam D and Zhang, Lifei and Dong, Lei},
  date = {2012-02-01},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {82},
  number = {2},
  eprint = {21703781},
  eprinttype = {pmid},
  pages = {e329-e336},
  publisher = {{Elsevier}},
  issn = {03603016},
  doi = {10.1016/j.ijrobp.2011.05.011},
  abstract = {PURPOSE To report a method for explicitly designing a planning target volume (PTV) for treatment planning and evaluation in heterogeneous media for passively scattered proton therapy and scanning beam proton therapy using single-field optimization (SFO). METHODS AND MATERIALS A beam-specific PTV (bsPTV) for proton beams was derived by ray-tracing and shifting ray lines to account for tissue misalignment in the presence of setup error or organ motion. Range uncertainties resulting from inaccuracies in computed tomography-based range estimation were calculated for proximal and distal surfaces of the target in the beam direction. The bsPTV was then constructed based on local heterogeneity. The bsPTV thus can be used directly as a planning target as if it were in photon therapy. To test the robustness of the bsPTV, we generated a single-field proton plan in a virtual phantom. Intentional setup and range errors were introduced. Dose coverage to the clinical target volume (CTV) under various simulation conditions was compared between plans designed based on the bsPTV and a conventional PTV. RESULTS The simulated treatment using the bsPTV design performed significantly better than the plan using the conventional PTV in maintaining dose coverage to the CTV. With conventional PTV plans, the minimum coverage to the CTV dropped from 99\% to 67\% in the presence of setup error, internal motion, and range uncertainty. However, plans using the bsPTV showed minimal drop of target coverage from 99\% to 94\%. CONCLUSIONS The conventional geometry-based PTV concept used in photon therapy does not work well for proton therapy. We investigated and validated a beam-specific PTV method for designing and evaluating proton plans.},
  keywords = {Proton therapy,PTV,Range uncertainties,Setup errors,Treatment planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\JTN4UJ9M\\Park et al. - 2012 - A Beam-Specific Planning Target Volume (PTV) Design for Proton Therapy to Account for Setup and Range Uncertainties.pdf}
}

@article{Park2013,
  title = {Statistical assessment of proton treatment plans under setup and range uncertainties},
  author = {Park, Peter C. and Cheung, Joey P. and Zhu, X. Ronald and Lee, Andrew K. and Sahoo, Narayan and Tucker, Susan L. and Liu, Wei and Li, Heng and Mohan, Radhe and Court, Laurence E. and Dong, Lei},
  date = {2013},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {Int J Radiat Oncol Biol Phys},
  volume = {86},
  number = {5},
  eprint = {23688812},
  eprinttype = {pmid},
  pages = {1007--1013},
  publisher = {{Elsevier Inc.}},
  issn = {03603016},
  doi = {10.1016/j.ijrobp.2013.04.009},
  url = {http://dx.doi.org/10.1016/j.ijrobp.2013.04.009},
  abstract = {Purpose: To evaluate a method for quantifying the effect of setup errors and range uncertainties on dose distribution and dose-volume histogram using statistical parameters; and to assess existing planning practice in selected treatment sites under setup and range uncertainties. Methods and Materials: Twenty passively scattered proton lung cancer plans, 10 prostate, and 1 brain cancer scanning-beam proton plan(s) were analyzed. To account for the dose under uncertainties, we performed a comprehensive simulation in which the dose was recalculated 600 times per given plan under the influence of random and systematic setup errors and proton range errors. On the basis of simulation results, we determined the probability of dose variations and calculated the expected values and standard deviations of dose-volume histograms. The uncertainties in dose were spatially visualized on the planning CT as a probability map of failure to target coverage or overdose of critical structures. Results: The expected value of target coverage under the uncertainties was consistently lower than that of the nominal value determined from the clinical target volume coverage without setup error or range uncertainty, with a mean difference of -1.1\% (-0.9\% for breath-hold), -0.3\%, and -2.2\% for lung, prostate, and a brain cases, respectively. The organs with most sensitive dose under uncertainties were esophagus and spinal cord for lung, rectum for prostate, and brain stem for brain cancer. Conclusions: A clinically feasible robustness plan analysis tool based on direct dose calculation and statistical simulation has been developed. Both the expectation value and standard deviation are useful to evaluate the impact of uncertainties. The existing proton beam planning method used in this institution seems to be adequate in terms of target coverage. However, structures that are small in volume or located near the target area showed greater sensitivity to uncertainties. ?? 2013 Elsevier Inc.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\FUDZWF87\\Park et al. - 2013 - Statistical assessment of proton treatment plans under setup and range uncertainties.pdf}
}

@article{Parodi2000,
  title = {Potential application of {{PET}} in quality assurance of proton therapy},
  author = {Parodi, K. and Enghardt, W.},
  date = {2000-10},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {45},
  number = {11},
  pages = {N151--N156},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/45/11/403},
  url = {https://doi.org/10.1088%2F0031-9155%2F45%2F11%2F403},
  urldate = {2020-04-03},
  abstract = {Our investigation supporting the feasibility of in situ PET monitoring in proton therapy is presented. We simulated by means of the FLUKA code the number and the spatial distribution of the main β+ emitters created in PMMA targets by protons at typical therapeutic energies. The quantitative comparison with the activation induced by 12C ions of energies corresponding to the same range shows that the available signal at the same physical dose level should be up to twice as intense for protons than that actually successfully used for the control of carbon ion therapy at GSI Darmstadt. The spatial correlation between the activity and the dose profile for protons is poorer than for 12C nuclei. However, an important check of the particle range, dose localization and stability of the treatment during all the fractions seems to be possible.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\SGR4M6GB\\Parodi und Enghardt - 2000 - Potential application of PET in quality assurance .pdf}
}

@article{Parodi2012,
  title = {Monte {{Carlo}} simulations to support start-up and treatment planning of scanned proton and carbon ion therapy at a synchrotron-based facility},
  author = {Parodi, K. and Mairani, A. and Brons, S. and Hasch, B. G. and Sommerer, F. and Naumann, J. and Jäkel, O. and Haberer, T. and Debus, J.},
  date = {2012-05},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {57},
  number = {12},
  pages = {3759--3784},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/57/12/3759},
  url = {https://doi.org/10.1088%2F0031-9155%2F57%2F12%2F3759},
  urldate = {2019-09-17},
  abstract = {Reliable treatment planning of highly conformal scanned ion beam therapy demands accurate tools for the determination and characterization of the individual pencil-like beams building up the integral dose delivery and related mixed radiation field. At present, clinically practicable inverse treatment planning systems (TPSs) can only rely on fast-performing analytical algorithms. However, the rapidly emerging though more computationally intensive Monte Carlo (MC) methods can be employed to complement analytical TPS, e.g., via accurate calculations of the input beam-model data, together with a considerable reduction of the measuring time. Here we present the work done for the application of the FLUKA MC code to support several aspects of scanned ion beam delivery and treatment planning at the Heidelberg Ion Beam Therapy Center (HIT). Emphasis is given to the generation of the accelerator library and of experimentally validated TPS input basic data which are now in clinical use for proton and carbon ion therapy. Additionally, MC dose calculations of planned treatments in water are shown to represent a valuable tool for supporting treatment plan verification in comparison to dosimetric measurements. This paper can thus provide useful information and guidelines for the start-up and clinical operation of forthcoming ion beam therapy facilities similar to HIT.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\JRY44U7D\\Parodi et al. - 2012 - Monte Carlo simulations to support start-up and tr.pdf}
}

@article{Parodi2013,
  title = {Monte {{Carlo-based}} parametrization of the lateral dose spread for clinical treatment planning of scanned proton and carbon ion beams},
  author = {Parodi, Katia and Mairani, Andrea and Sommerer, Florian},
  date = {2013},
  journaltitle = {Journal of Radiation Research},
  volume = {54},
  eprint = {23824133},
  eprinttype = {pmid},
  pages = {91--96},
  issn = {04493060},
  doi = {10.1093/jrr/rrt051},
  abstract = {Ion beam therapy using state-of-the-art pencil-beam scanning offers unprecedented tumour-dose conformality with superior sparing of healthy tissue and critical organs compared to conventional radiation modalities for external treatment of deep-seated tumours. For inverse plan optimization, the commonly employed analytical treatment-planning systems (TPSs) have to meet reasonable compromises in the accuracy of the pencil-beam modelling to ensure good performances in clinically tolerable execution times. In particular, the complex lateral spreading of ion beams in air and in the traversed tissue is typically approximated with ideal Gaussian-shaped distributions, enabling straightforward superimposition of several scattering contributions. This work presents the double Gaussian parametrization of scanned proton and carbon ion beams in water that has been introduced in an upgraded version of the worldwide first commercial ion TPS for clinical use at the Heidelberg Ion Beam Therapy Center (HIT). First, the Monte Carlo results obtained from a detailed implementation of the HIT beamline have been validated against available experimental data. Then, for generating the TPS lateral parametrization, radial beam broadening has been calculated in a water target placed at a representative position after scattering in the beamline elements and air for 20 initial beam energies for each ion species. The simulated profiles were finally fitted with an idealized double Gaussian distribution that did not perfectly describe the nature of the data, thus requiring a careful choice of the fitting conditions. The obtained parametrization is in clinical use not only at the HIT center, but also at the Centro Nazionale di Adroterapia Oncologica.},
  isbn = {1349-9157},
  issue = {Suppl 1},
  keywords = {ion therapy,lateral dose distribution,Monte Carlo,treatment planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\DYR3X8TK\\Parodi, Mairani, Sommerer - 2013 - Monte Carlo-based parametrization of the lateral dose spread for clinical treatment planning of scann.pdf}
}

@article{Partridge2017,
  title = {Recent progress in applications of computing to radiotherapy ({{ICCR}} 2016)},
  author = {Partridge, Mike and Oelfke, Uwe},
  date = {2017-05},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {62},
  number = {11},
  pages = {E8--E9},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/aa6b3c},
  url = {https://doi.org/10.1088%2F1361-6560%2Faa6b3c},
  urldate = {2019-10-25},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\FD5JH77S\\Partridge and Oelfke - 2017 - Recent progress in applications of computing to ra.pdf}
}

@article{Pathak2013,
  title = {A quantitative analysis of intensity-modulated radiation therapy plans and comparison of homogeneity indices for the treatment of gynecological cancers.},
  author = {Pathak, Pushpraj and Vashisht, Sanjeev},
  date = {2013-04},
  journaltitle = {Journal of medical physics / Association of Medical Physicists of India},
  volume = {38},
  number = {2},
  eprint = {23776309},
  eprinttype = {pmid},
  pages = {67--73},
  issn = {0971-6203},
  doi = {10.4103/0971-6203.111309},
  url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3683303&tool=pmcentrez&rendertype=abstract},
  urldate = {2013-06-24},
  abstract = {The aim of present study was to evaluate the intensity-modulated radiation therapy (IMRT) plans using different homogeneity and conformity indices in gynecological cancers, as well as to compare and find out the most reliable and accurate measure of the dose homogeneity among the available indices. In this study, a cohort of 12 patients were registered for evaluation, those receiving dynamic IMRT treatment on Clinac-2300C/D linear accelerator with 15-Mega Voltage (MV) photon beam. Dynamic IMRT plans were created on Eclipse treatment planning system with Helios dose volume optimization software. Homogeneity indices (HI) such as H index, modified H index, HI index, modified HI index, and S-index (sigma-index) proposed by M Yoon et al. (2007) were calculated and compared. The values of S-index vary from 1.63 to 2.99. The results indicate that the H and HI indices and their modified versions may not provide the correct dose homogeneity information, but the S-index provides accurate information about the dose homogeneity in the Planning Target Volume (PTV). Each plan was compared with 6-MV photon energy on the basis of S-index and conformity index (CI). Organs at risk (OAR) doses with 6-MV and 15-MV beams were also reported.}
}

@article{Pedroni2005,
  title = {Experimental characterization and physical modelling of the dose distribution of scanned proton pencil beams},
  author = {Pedroni, E and Scheib, S and Böhringer, T and Coray, A and Grossmann, M and Lin, S and Lomax, A},
  date = {2005-02-07},
  journaltitle = {Physics in Medicine and Biology},
  volume = {50},
  number = {3},
  pages = {541--561},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/50/3/011},
  url = {http://stacks.iop.org/0031-9155/50/i=3/a=011?key=crossref.214c71b01689c00d8c99393880efdfa6},
  urldate = {2018-04-02}
}

@article{Penfold2015,
  title = {Techniques in {{Iterative Proton CT Image Reconstruction}}},
  author = {Penfold, Scott and Censor, Yair},
  date = {2015-10-30},
  journaltitle = {Sensing and Imaging},
  shortjournal = {Sens Imaging},
  volume = {16},
  number = {1},
  pages = {19},
  issn = {1557-2072},
  doi = {10.1007/s11220-015-0122-3},
  url = {https://doi.org/10.1007/s11220-015-0122-3},
  urldate = {2020-09-11},
  abstract = {This is a review paper on some of the physics, modeling, and iterative algorithms in proton computed tomography (pCT) image reconstruction. The primary challenge in pCTimage reconstruction lies in the degraded spatial resolution resulting from multiple Coulomb scattering within the imaged object. Analytical models such as the most likely path have been proposed to predict the scattered trajectory from measurements of individual proton location and direction before and after the object. Iterative algorithms provide a flexible tool with which to incorporate these models into image reconstruction. The modeling leads to a large and sparse linear system of equations that can efficiently be solved by projection methods-based iterative algorithms. Such algorithms perform projections of the iterates onto the hyperlanes that are represented by the linear equations of the system.They perform these projections in possibly various algorithmic structures, such as block-iterative projections, string-averaging projections. These algorithmic schemes allow flexibility of choosing blocks, strings, and other parameters. They also cater for parallel implementations which are apt to further save clock time in computations. Experimental results are presented which compare some of those algorithmic options.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\T974J6Q5\\Penfold und Censor - 2015 - Techniques in Iterative Proton CT Image Reconstruc.pdf}
}

@article{Penfold2017,
  title = {Sparsity constrained split feasibility for dose-volume constraints in inverse planning of intensity-modulated photon or proton therapy},
  author = {Penfold, Scott and Zalas, Rafał and Casiraghi, Margherita and Brooke, Mark and Censor, Yair and Schulte, Reinhard},
  date = {2017-05-07},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {62},
  number = {9},
  pages = {3599--3618},
  issn = {0031-9155, 1361-6560},
  doi = {10.1088/1361-6560/aa602b},
  url = {https://iopscience.iop.org/article/10.1088/1361-6560/aa602b},
  urldate = {2020-09-01},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\HSWW5MR9\\Penfold et al. - 2017 - Sparsity constrained split feasibility for dose-vo.pdf}
}

@article{Perez1982,
  title = {Impact of irradiation technique and tumor extent in tumor control and survival of patients with unresectable non-oat cell carcinoma of the lung. {{Report}} by the radiation therapy oncology group},
  author = {Perez, Carlos A. and Stanley, Kenneth and Grundy, Graham and Hanson, William and Rubin, Philip and Kramer, Simon and Brady, Luther W. and Marks, James E. and Perez‐Tamayo, Ruheri and Brown, G. Stephen and Concannon, Joseph P. and Rotman, Marvin},
  date = {1982},
  journaltitle = {Cancer},
  volume = {50},
  number = {6},
  pages = {1091--1099},
  issn = {1097-0142},
  doi = {10.1002/1097-0142(19820915)50:6<1091::AID-CNCR2820500612>3.0.CO;2-0},
  url = {https://acsjournals.onlinelibrary.wiley.com/doi/abs/10.1002/1097-0142%2819820915%2950%3A6%3C1091%3A%3AAID-CNCR2820500612%3E3.0.CO%3B2-0},
  urldate = {2020-03-23},
  abstract = {An analysis of intrathoracic tumor control was carried out in 378 patients with histologically proven unresectable non-oat cell carcinoma of the lung treated with definitive radiotherapy, randomized to one of four treatment regimens: 4000 rad split course (2000 rad in five fractions in one week, two weeks rest and additional 2000 rad in five fractions in one week) or 4000, 5000 or 6000 rad continuous courses, five fractions per week. Between 85 and 101 patients are analyzed in each treatment group. The complete plus partial response was 46–51\% in the 4000 rad groups in contrast to 61–66\% in the 5000 to 6000 rad groups (P = 0.008). The overall two year survival rate was 10–11\% for the patients treated with 4000 rad split or continuous course, and 19\% in the patients treated with 5000 to 6000 rad. The complete response in patients with tumors 3 cm or less in diameter was 16\% when treated with 4000 rad in contrast to 20–31\% in those treated with 5000–6000 rad. In the patients with lesions from 4 to 6 cm in diameter, complete and partial tumor regression was 48\% in the 4000 rad group, 67\% with 5000 rad, and 71\% with 6000 rad. These differences are statistically significant (P = 0.033). Intrathoracic recurrences were correlated with the dose of irradiation given: 52\% with 4000 rad, 41\% with 5000 rad, and 30\% with 6000 rad (P = 0.006). An analysis of protocol compliance was carried out in 301 patients with available data, irradiated at the primary site according to protocol instruction (none or minor variation). Median survival for patients treated to the ipsilateral or contralateral hilar lymph nodes according to the protocol varied from 46–50 weeks in contrast to 20–30 weeks for those with major protocol variations in nodal irradiation. Variations in ipsilateral and contralateral nodal irradiation correlated with significant reductions in tumor control (P = 0.02 and P = 0.009, respectively). In addition to patient and tumor characteristics, the technical factors of irradiation are critical parameters that affect tumor control and survival in patients with non-oat cell bronchogenic carcinoma. Strict quality assurance criteria in radiotherapy are necessary to achieve optimal treatment results and a careful program to evaluate techniques of irradiation and protocol compliance should be maintained in cooperative group studies in order to enhance the validity of clinical trials.},
  langid = {english},
  annotation = {\_eprint: https://acsjournals.onlinelibrary.wiley.com/doi/pdf/10.1002/1097-0142\%2819820915\%2950\%3A6\%3C1091\%3A\%3AAID-CNCR2820500612\%3E3.0.CO\%3B2-0}
}

@article{Perk??2014a,
  title = {Large scale applicability of a {{Fully Adaptive Non-Intrusive Spectral Projection}} technique: {{Sensitivity}} and uncertainty analysis of a transient},
  author = {Perkó, Zoltán and Lathouwers, Danny and Kloosterman, Jan Leen and family=Hagen, given=Tim, prefix=van der, useprefix=true},
  date = {2014-09},
  journaltitle = {Annals of Nuclear Energy},
  volume = {71},
  pages = {272--292},
  issn = {03064549},
  doi = {10.1016/j.anucene.2014.03.035},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0306454914001571},
  abstract = {Since the early years of reactor physics the most prominent sensitivity and uncertainty (S\&U) analysis methods in the nuclear community have been adjoint based techniques. While these are very effective for pure neutronics problems due to the linearity of the transport equation, they become complicated when coupled non-linear systems are involved. With the continuous increase in computational power such complicated multi-physics problems are becoming progressively tractable, hence affordable and easily applicable S\&U analysis tools also have to be developed in parallel. For reactor physics problems for which adjoint methods are prohibitive Polynomial Chaos (PC) techniques offer an attractive alternative to traditional random sampling based approaches. At TU Delft such PC methods have been studied for a number of years and this paper presents a large scale application of our Fully Adaptive Non-Intrusive Spectral Projection (FANISP) algorithm for performing the sensitivity and uncertainty analysis of a Gas Cooled Fast Reactor (GFR) Unprotected Loss Of Flow (ULOF) transient. The transient was simulated using the Cathare 2 code system and a fully detailed model of the GFR2400 reactor design that was investigated in the European FP7 GoFastR project. Several sources of uncertainty were taken into account amounting to an unusually high number of stochastic input parameters (42) and numerous output quantities were investigated. The results show consistently good performance of the applied adaptive PC methods, being superior to standard Monte Carlo sampling both in terms of accuracy and computational cost. This demonstrates that such PC techniques can provide a viable alternative to random sampling even for larger scale systems, which is especially appealing for the S\&U analysis of problems using legacy codes common in the nuclear field. ?? 2014 Elsevier Ltd. All rights reserved.},
  keywords = {Adaptive sparse grids,Basis adaptivity,Gas Cooled Fast Reactor,Generalized Polynomial Chaos,Sensitivity analysis,Uncertainty quantification},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Q2YJEMIJ\\Perkó et al. - 2014 - Large scale applicability of a Fully Adaptive Non-Intrusive Spectral Projection technique Sensitivity and uncertai.pdf}
}

@article{Perko2014,
  title = {Grid and basis adaptive polynomial chaos techniques for sensitivity and uncertainty analysis},
  author = {Perkó, Zoltán and Gilli, Luca and Lathouwers, Danny and Kloosterman, Jan Leen},
  date = {2014},
  journaltitle = {Journal of Computational Physics},
  volume = {260},
  pages = {54--84},
  publisher = {{Elsevier Inc.}},
  issn = {00219991},
  doi = {10.1016/j.jcp.2013.12.025},
  url = {http://dx.doi.org/10.1016/j.jcp.2013.12.025},
  abstract = {The demand for accurate and computationally affordable sensitivity and uncertainty techniques is constantly on the rise and has become especially pressing in the nuclear field with the shift to Best Estimate Plus Uncertainty methodologies in the licensing of nuclear installations. Besides traditional, already well developed methods - such as first order perturbation theory or Monte Carlo sampling - Polynomial Chaos Expansion (PCE) has been given a growing emphasis in recent years due to its simple application and good performance. This paper presents new developments of the research done at TU Delft on such Polynomial Chaos (PC) techniques. Our work is focused on the Non-Intrusive Spectral Projection (NISP) approach and adaptive methods for building the PCE of responses of interest. Recent efforts resulted in a new adaptive sparse grid algorithm designed for estimating the PC coefficients. The algorithm is based on Gerstner's procedure for calculating multi-dimensional integrals but proves to be computationally significantly cheaper, while at the same it retains a similar accuracy as the original method.More importantly the issue of basis adaptivity has been investigated and two techniques have been implemented for constructing the sparse PCE of quantities of interest. Not using the traditional full PC basis set leads to further reduction in computational time since the high order grids necessary for accurately estimating the near zero expansion coefficients of polynomial basis vectors not needed in the PCE can be excluded from the calculation. Moreover the sparse PC representation of the response is easier to handle when used for sensitivity analysis or uncertainty propagation due to the smaller number of basis vectors. The developed grid and basis adaptive methods have been implemented in Matlab as the Fully Adaptive Non-Intrusive Spectral Projection (FANISP) algorithm and were tested on four analytical problems. These show consistent good performance both in terms of the accuracy of the resulting PC representation of quantities and the computational costs associated with constructing the sparse PCE. Basis adaptivity also seems to make the employment of PC techniques possible for problems with a higher number of input parameters (15-20), alleviating a well known limitation of the traditional approach. The prospect of larger scale applicability and the simplicity of implementation makes such adaptive PC algorithms particularly appealing for the sensitivity and uncertainty analysis of complex systems and legacy codes. © 2013 Elsevier Inc.},
  keywords = {Adaptive sparse grids,Basis adaptivity,Generalized polynomial chaos,Polynomial chaos expansion,Sensitivity analysis,Uncertainty quantification},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\XHHE8X5H\\Perkó et al. - 2014 - Grid and basis adaptive polynomial chaos techniques for sensitivity and uncertainty analysis.pdf}
}

@article{Perko2016,
  title = {Fast and accurate sensitivity analysis of {{IMPT}} treatment plans using {{Polynomial Chaos Expansion}}.},
  author = {Perkó, Zoltán and family=Voort, given=Sebastian R, prefix=van der, useprefix=true and family=Water, given=Steven, prefix=van de, useprefix=true and Hartman, Charlotte M H and Hoogeman, Mischa and Lathouwers, Danny},
  date = {2016-06-21},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {61},
  number = {12},
  eprint = {27227661},
  eprinttype = {pmid},
  pages = {4646--4664},
  publisher = {{IOP Publishing}},
  issn = {1361-6560},
  doi = {10.1088/0031-9155/61/12/4646},
  url = {http://stacks.iop.org/0031-9155/61/i=12/a=4646?key=crossref.0937074c86bf618a62c04c86e4929f71},
  urldate = {2016-07-29},
  abstract = {The highly conformal planned dose distribution achievable in intensity modulated proton therapy (IMPT) can severely be compromised by uncertainties in patient setup and proton range. While several robust optimization approaches have been presented to address this issue, appropriate methods to accurately estimate the robustness of treatment plans are still lacking. To fill this gap we present Polynomial Chaos Expansion (PCE) techniques which are easily applicable and create a meta-model of the dose engine by approximating the dose in every voxel with multidimensional polynomials. This Polynomial Chaos (PC) model can be built in an automated fashion relatively cheaply and subsequently it can be used to perform comprehensive robustness analysis. We adapted PC to provide among others the expected dose, the dose variance, accurate probability distribution of dose-volume histogram (DVH) metrics (e.g. minimum tumor or maximum organ dose), exact bandwidths of DVHs, and to separate the effects of random and systematic errors. We present the outcome of our verification experiments based on 6 head-and-neck (HN) patients, and exemplify the usefulness of PCE by comparing a robust and a non-robust treatment plan for a selected HN case. The results suggest that PCE is highly valuable for both research and clinical applications.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\JLIQDQEK\\Perkó et al. - 2016 - Fast and accurate sensitivity analysis of IMPT treatment plans using Polynomial Chaos Expansion.pdf}
}

@article{Perl2012,
  title = {{{TOPAS}}: an innovative proton {{Monte Carlo}} platform for research and clinical applications},
  shorttitle = {{{TOPAS}}},
  author = {Perl, J. and Shin, J. and Schumann, J. and Faddegon, B. and Paganetti, H.},
  date = {2012-11},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {39},
  number = {11},
  eprint = {23127075},
  eprinttype = {pmid},
  pages = {6818--6837},
  publisher = {{Wiley}},
  issn = {0094-2405},
  doi = {10.1118/1.4758060},
  abstract = {PURPOSE: While Monte Carlo particle transport has proven useful in many areas (treatment head design, dose calculation, shielding design, and imaging studies) and has been particularly important for proton therapy (due to the conformal dose distributions and a finite beam range in the patient), the available general purpose Monte Carlo codes in proton therapy have been overly complex for most clinical medical physicists. The learning process has large costs not only in time but also in reliability. To address this issue, we developed an innovative proton Monte Carlo platform and tested the tool in a variety of proton therapy applications. METHODS: Our approach was to take one of the already-established general purpose Monte Carlo codes and wrap and extend it to create a specialized user-friendly tool for proton therapy. The resulting tool, TOol for PArticle Simulation (TOPAS), should make Monte Carlo simulation more readily available for research and clinical physicists. TOPAS can model a passive scattering or scanning beam treatment head, model a patient geometry based on computed tomography (CT) images, score dose, fluence, etc., save and restart a phase space, provides advanced graphics, and is fully four-dimensional (4D) to handle variations in beam delivery and patient geometry during treatment. A custom-designed TOPAS parameter control system was placed at the heart of the code to meet requirements for ease of use, reliability, and repeatability without sacrificing flexibility. RESULTS: We built and tested the TOPAS code. We have shown that the TOPAS parameter system provides easy yet flexible control over all key simulation areas such as geometry setup, particle source setup, scoring setup, etc. Through design consistency, we have insured that user experience gained in configuring one component, scorer or filter applies equally well to configuring any other component, scorer or filter. We have incorporated key lessons from safety management, proactively removing possible sources of user error such as line-ordering mistakes. We have modeled proton therapy treatment examples including the UCSF eye treatment head, the MGH stereotactic alignment in radiosurgery treatment head and the MGH gantry treatment heads in passive scattering and scanning modes, and we have demonstrated dose calculation based on patient-specific CT data. Initial validation results show agreement with measured data and demonstrate the capabilities of TOPAS in simulating beam delivery in 3D and 4D. CONCLUSIONS: We have demonstrated TOPAS accuracy and usability in a variety of proton therapy setups. As we are preparing to make this tool freely available for researchers in medical physics, we anticipate widespread use of this tool in the growing proton therapy community.},
  langid = {english},
  pmcid = {PMC3493036},
  keywords = {Eye Neoplasms,Humans,Melanoma,Monte Carlo Method,Precision Medicine,Proton Therapy,Radiosurgery,Radiotherapy Dosage,Scattering; Radiation,Software,Tomography; X-Ray Computed},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\ICSUVELJ\\Perl et al. - 2012 - TOPAS an innovative proton Monte Carlo platform f.pdf}
}

@book{Petersen2012,
  title = {The {{Matrix Cookbook}}},
  author = {Petersen, Kaare Brandt and Pedersen, Michael Syskind},
  date = {2012},
  publisher = {{Technical University of Denmark}},
  abstract = {Introduction What is this? These pages are a collection of facts (identities, approxima-tions, inequalities, relations, ...) about matrices and matters relating to them. It is collected in this form for the convenience of anyone who wants a quick desktop reference . Disclaimer: The identities, approximations and relations presented here were obviously not invented but collected, borrowed and copied from a large amount of sources. These sources include similar but shorter notes found on the internet and appendices in books -see the references for a full list. Errors: Very likely there are errors, typos, and mistakes for which we apolo-gize and would be grateful to receive corrections at cookbook@2302.dk. Its ongoing: The project of keeping a large repository of relations involving matrices is naturally ongoing and the version will be apparent from the date in the header. Suggestions: Your suggestion for additional content or elaboration of some topics is most welcome acookbook@2302.dk.},
  keywords = {derivative of determinant,derivative of inverse matrix,differentiate a matrix,Matrix algebra,matrix identities,matrix relations},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\VU3MXY3N\\Petersen, Pedersen - 2012 - The Matrix Cookbook.pdf}
}

@article{Pettersen2019,
  title = {Design optimization of a pixel-based range telescope for proton computed tomography},
  author = {Pettersen, Helge Egil Seime and Alme, Johan and Barnaföldi, Gergely Gábor and Barthel, Rene and family=Brink, given=Anthony, prefix=van den, useprefix=false and Chaar, Mamdouh and Eikeland, Viljar and García-Santos, Alba and Genov, Georgi and Grimstad, Silje and Grøttvik, Ola and Helstrup, Håvard and Hetland, Kristin Fanebust and Mehendale, Shruti and Meric, Ilker and Odland, Odd Harald and Papp, Gábor and Peitzmann, Thomas and Piersimoni, Pierluigi and Rehman, Attiq Ur and Richter, Matthias and Samnøy, Andreas Tefre and Seco, Joao and Shafiee, Hesam and Skjæveland, Eivind Vågslid and Sølie, Jarle Rambo and Tambave, Ganesh and Ullaland, Kjetil and Varga-Kofarago, Monika and Volz, Lennart and Wagner, Boris and Yang, Shiming and Röhrich, Dieter},
  date = {2019-07-01},
  journaltitle = {Physica Medica: European Journal of Medical Physics},
  shortjournal = {Physica Medica: European Journal of Medical Physics},
  volume = {63},
  eprint = {31221414},
  eprinttype = {pmid},
  pages = {87--97},
  issn = {1120-1797},
  doi = {10.1016/j.ejmp.2019.05.026},
  url = {https://www.physicamedica.com/article/S1120-1797(19)30135-8/abstract},
  urldate = {2020-03-25},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}h3{$>$}Purpose{$<$}/h3{$><$}p{$>$}A pixel-based range telescope for tracking particles during proton imaging is described. The detector applies a 3D matrix of stacked Monolithic Active Pixel Sensors with fast readout speeds. This study evaluates different design alternatives of the range telescope on basis of the protons' range accuracy and the track reconstruction efficiency.{$<$}/p{$><$}h3{$>$}Method{$<$}/h3{$><$}p{$>$}Detector designs with different thicknesses of the energy-absorbing plates between each sensor layer are simulated using the GATE/Geant4 Monte Carlo software. Proton tracks traversing the detector layers are individually reconstructed, and a Bragg curve fitting procedure is applied for the calculation of each proton's range.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}Simulations show that the setups with 4 mm and thinner absorber layers of aluminum have a low range uncertainty compared to the physical range straggling, systematic errors below 0.3 mm water equivalent thickness and a track reconstruction capability exceeding ten million protons per second.{$<$}/p{$><$}h3{$>$}Conclusions{$<$}/h3{$><$}p{$>$}In order to restrict the total number of layers and to yield the required tracking and range resolution properties, a design recommendation is reached where the proposed range telescope applies 3.5 mm thick aluminum absorber slabs between each sensor layer.{$<$}/p{$>$}},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\PV874VDU\\fulltext.html}
}

@article{Pflugfelder2008,
  title = {Worst case optimization: a method to account for uncertainties in the optimization of intensity modulated proton therapy.},
  author = {Pflugfelder, Daniel and Wilkens, Jan Jakob and Oelfke, Uwe},
  date = {2008-03-21},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {53},
  number = {6},
  eprint = {18367797},
  eprinttype = {pmid},
  pages = {1689--700},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/53/6/013},
  url = {http://stacks.iop.org/0031-9155/53/i=6/a=013?key=crossref.f26e33d9f0cb93a513fbd6d79e3981f0},
  urldate = {2016-07-25},
  abstract = {The sharp dose gradients which are possible in intensity modulated proton therapy (IMPT) not only offer the possibility of generating excellent target coverage while sparing neighbouring organs at risk, but can also lead to treatment plans which are very sensitive to uncertainties in treatment variables such as the range of individual Bragg peaks. We developed a method to account for uncertainties of treatment variables in the optimization based on a worst case dose distribution. The worst case dose distribution is calculated using several possible realizations of the uncertainties. This information is used by the objective function of the inverse treatment planning system to generate treatment plans which are acceptable under all considered realizations of the uncertainties. The worst case optimization method was implemented in our in-house treatment planning software KonRad in order to demonstrate the usefulness of this approach for clinical cases. In this paper, we investigated range uncertainties, setup uncertainties and a combination of both uncertainties. Using our method the sensitivity of the resulting treatment plans to these uncertainties is considerably reduced.},
  keywords = {Humans,Intensity-Modulated,Protons,Protons: therapeutic use,Radiotherapy,Radiotherapy Dosage,Uncertainty},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\JZXLYFUS\\Pflugfelder, Wilkens, Oelfke - 2008 - Worst case optimization a method to account for uncertainties in the optimization of intensity mod.pdf}
}

@article{Piersimoni2018,
  title = {Helium {{CT}}: {{Monte Carlo}} simulation results for an ideal source and detector with comparison to proton {{CT}}},
  shorttitle = {Helium {{CT}}},
  author = {Piersimoni, Pierluigi and Faddegon, Bruce A. and Méndez, José Ramos and Schulte, Reinhard W. and Volz, Lennart and Seco, Joao},
  date = {2018-07},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {45},
  number = {7},
  eprint = {29727481},
  eprinttype = {pmid},
  pages = {3264--3274},
  issn = {2473-4209},
  doi = {10.1002/mp.12942},
  abstract = {PURPOSE: To evaluate the accuracy of relative stopping power and spatial resolution of images reconstructed with simulated helium CT (HeCT) in comparison to proton CT (pCT). METHODS: A Monte Carlo (MC) study with the TOPAS tool was performed to compare the accuracy of relative stopping power (RSP) reconstruction and spatial resolution of low-fluence HeCT to pCT, both using 200~MeV/u particles. An ideal setup consisting of a flat beam source and a totally absorbing energy-range detector was implemented to estimate the theoretically best achievable RSP accuracy for the calibration and reconstruction methods currently used for pCT. The phantoms imaged included a cylindrical water phantom with inserts of different materials, sizes, and positions, a Catphan phantom with a module containing high-contrast line pairs (CTP528) and a module with cylindrical inserts of different RSP (CTP404), as well as a voxelized 10-year-old female phantom. Dose to the cylindrical water phantom was also calculated. The RSP accuracy was studied for all phantoms except the CTP528 module. The latter was used for the estimation of the spatial resolution, evaluated as the modulation transfer function (MTF) at 10\%. RESULTS: An overall error under 0.5\% was achieved for HeCT for the water phantoms with the different inserts, in all cases better than that for pCT, in some cases by a factor 3. The inserts in the CTP404 module were reconstructed with an average RSP accuracy of 0.3\% for HeCT and 0.2\% for pCT. Anatomic structures (brain, bones, air cavities, etc.) in the digitized head phantom were well recognizable and no artifacts were visible with both HeCT and pCT. The three main tissue materials (soft tissue, brain, and cranium) were well identifiable in the reconstructed RSP-volume distribution with both imaging modalities. Using 360 projection angles, the spatial resolution was 4~lp/cm for HeCT and 3~lp/cm for pCT. Generally, spatial resolution increased with the number of projection angles and was always higher for HeCT than for pCT for the same number of projections. When HeCT and pCT scan were performed to deliver the same dose in the phantom, the resolution for HeCT was higher than pCT. CONCLUSION: MC simulations were used to compare HeCT and pCT image reconstruction. HeCT images had similar or better RSP accuracy and higher spatial resolution compared to pCT. Further investigation of the potential of helium ion imaging is warranted.},
  langid = {english},
  keywords = {alpha-particles,Calibration,Helium,Image Processing; Computer-Assisted,Monte Carlo,Monte Carlo Method,particle CT,Phantoms; Imaging,Protons,Radiation Dosage,stopping power,Tomography; X-Ray Computed,TOPAS,Water}
}

@article{Pinter2012,
  ids = {pinterSlicerRTRadiationTherapy2012},
  title = {{{SlicerRT}}: {{Radiation}} therapy research toolkit for {{3D Slicer}}},
  shorttitle = {{{SlicerRT}}},
  author = {Pinter, Csaba and Lasso, Andras and Wang, An and Jaffray, David and Fichtinger, Gabor},
  date = {2012-09-27},
  journaltitle = {Medical Physics},
  shortjournal = {Med. Phys.},
  volume = {39},
  number = {10},
  pages = {6332--6338},
  publisher = {{American Association of Physicists in Medicine}},
  issn = {00942405},
  doi = {10.1118/1.4754659},
  url = {http://doi.wiley.com/10.1118/1.4754659},
  urldate = {2018-02-27},
  abstract = {Purpose: Interest in adaptive radiation therapy research is constantly growing, but software tools available for researchers are mostly either expensive, closed proprietary applications, or free opensource packages with limited scope, extensibility, reliability, or user support. To address these limitations, we propose SlicerRT, a customizable, free, and open-source radiation therapy research toolkit. SlicerRT aspires to be an open-source toolkit for RT research, providing fast computations, convenient workflows for researchers, and a general image-guided therapy infrastructure to assist clinical translation of experimental therapeutic approaches. It is a medium into which RT researchers can integrate their methods and algorithms, and conduct comparative testing. Methods: SlicerRT was implemented as an extension for the widely used 3D Slicer medical image visualization and analysis application platform. SlicerRT provides functionality specifically designed for radiation therapy research, in addition to the powerful tools that 3D Slicer offers for visualization, registration, segmentation, and data management. The feature set of SlicerRT was defined through consensus discussions with a large pool of RT researchers, including both radiation oncologists and medical physicists. The development processes used were similar to those of 3D Slicer to ensure software quality. Standardized mechanisms of 3D Slicer were applied for documentation, distribution, and user support. The testing and validation environment was configured to automatically launch a regression test upon each software change and to perform comparison with ground truth results provided by other RT applications. Results: Modules have been created for importing and loading DICOM-RT data, computing and displaying dose volume histograms, creating accumulated dose volumes, comparing dose volumes, and visualizing isodose lines and surfaces. The effectiveness of using 3D Slicer with the proposed SlicerRT extension for radiation therapy research was demonstrated on multiple use cases. Conclusions: A new open-source software toolkit has been developed for radiation therapy research. SlicerRT can import treatment plans from various sources into 3D Slicer for visualization, analysis, comparison, and processing. The provided algorithms are extensively tested and they are accessible through a convenient graphical user interface as well as a flexible application programming interface. © 2012 American Association of Physicists in Medicine. [http://dx.doi.org/10.1118/1.4754659]},
  keywords = {3D Slicer,Cancer,Computer software,data visualisation,DICOM‐RT,Digital computing or data processing equipment or,dose comparison,dose volume histogram,Dosimetry,Image data processing or generation,in general,medical computing,medical image processing,Medical imaging,public domain software,radiation therapy,Radiation therapy,Radiation treatment,Researchers,software tools,specially adapted for specific applications,Testing procedures,Treatment strategy,User interfaces,Visualization},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\6EMMWI3S\\Pinter et al. - 2012 - SlicerRT Radiation therapy research toolkit for 3.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\3ZKZCVCR\\Pinter et al. - 2012 - SlicerRT Radiation therapy research toolkit for 3D Slicer.pdf}
}

@article{Plackett1954,
  title = {A {{Reduction Formula}} for {{Normal Multivariate Integrals}}},
  author = {Plackett, R L},
  date = {1954-12},
  journaltitle = {Biometrika},
  volume = {41},
  number = {3/4},
  eprint = {2332716},
  eprinttype = {jstor},
  pages = {351--360},
  issn = {00063444},
  doi = {10.2307/2332716},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\7EAFENUD\\Plackett - 1954 - A Reduction Formula for Normal Multivariate Integrals.pdf}
}

@article{Powlis1989,
  title = {Semi-automated radiotherapy treatment planning with a mathematical model to satisfy treatment goals},
  author = {Powlis, William D. and Altschuler, Martin D. and Censor, Yair and Buhle, E. Loren},
  date = {1989-01-01},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {16},
  number = {1},
  pages = {271--276},
  issn = {0360-3016},
  doi = {10.1016/0360-3016(89)90042-4},
  url = {https://www.sciencedirect.com/science/article/pii/0360301689900424},
  urldate = {2021-11-30},
  abstract = {Iterative algorithms can provide a feasible solution, if any exists, to specified treatment goals. Our model subdivides both the patient's cross section into a fine grid of points and the radiation beam into a set of “pencil” rays. The anatomy, treatment machine parameters, dose limits and homogeneity, are all defined. This process of subdivision leads to a large system of linear inequalities with a solution that provides a radiation intensity distribution that will deliver a prescribed dose distribution. The clinical results from two different algorithms will be presented and contrasted. Once the anatomy, treatment, and machine parameters have been entered, the computerized algorithms yield an answer in several minutes. The Cimmino algorithm also allows “weights” or priority assignments of the treatment goals. The resulting solution is biased towards fulfilling the specified doses for the anatomic regions which were given greater weight. It is desirable to have a systematic search of possible treatment alternatives in complex clinical situations, including 3-dimensional radiation therapy treatment planning (RTTP). Our method has been applied to 2-D RTTP, but is equally applicable to 3-D RTTP with minor modifications.},
  langid = {english},
  keywords = {Computer-assisted,Feasibility,Linear inequalities,Optimization,Semi-automated,Treatment planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\T59KJA67\\Powlis et al. - 1989 - Semi-automated radiotherapy treatment planning wit.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\ELRT62BB\\0360301689900424.html}
}

@inproceedings{Preiser1997,
  title = {A new program for inverse radiotherapy planning},
  booktitle = {Proc. 12th {{ICCR}}},
  author = {Preiser, K and Bortfeld, Thomas and Hartwig, K and Schlegel, Wolfgang and Stein, J},
  date = {1997},
  pages = {425--428}
}

@article{Qin2017,
  title = {Initial development of {{goCMC}}: a {{GPU-oriented}} fast cross-platform {{Monte Carlo}} engine for carbon ion therapy},
  shorttitle = {Initial development of {{goCMC}}},
  author = {Qin, Nan and Pinto, Marco and Tian, Zhen and Dedes, Georgios and Pompos, Arnold and Jiang, Steve B. and Parodi, Katia and Jia, Xun},
  date = {2017-04},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {62},
  number = {9},
  pages = {3682--3699},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/aa5d43},
  url = {https://doi.org/10.1088/1361-6560/aa5d43},
  urldate = {2022-05-17},
  abstract = {Monte Carlo (MC) simulation is considered as the most accurate method for calculation of absorbed dose and fundamental physics quantities related to biological effects in carbon ion therapy. To improve its computational efficiency, we have developed a GPU-oriented fast MC package named goCMC, for carbon therapy. goCMC simulates particle transport in voxelized geometry with kinetic energy up to 450 MeV u−1. Class II condensed history simulation scheme with a continuous slowing down approximation was employed. Energy straggling and multiple scattering were modeled. δ-electrons were terminated with their energy locally deposited. Four types of nuclear interactions were implemented in goCMC, i.e. carbon–hydrogen, carbon–carbon, carbon–oxygen and carbon–calcium inelastic collisions. Total cross section data from Geant4 were used. Secondary particles produced in these interactions were sampled according to particle yield with energy and directional distribution data derived from Geant4 simulation results. Secondary charged particles were transported following the condensed history scheme, whereas secondary neutral particles were ignored. goCMC was developed under OpenCL framework and is executable on different platforms, e.g. GPU and multi-core CPU. We have validated goCMC with Geant4 in cases with different beam energy and phantoms including four homogeneous phantoms, one heterogeneous half-slab phantom, and one patient case. For each case carbon ions were simulated, such that in the region with dose greater than 10\% of maximum dose, the mean relative statistical uncertainty was less than 1\%. Good agreements for dose distributions and range estimations between goCMC and Geant4 were observed. 3D gamma passing rates with 1\%/1 mm criterion were over 90\% within 10\% isodose line except in two extreme cases, and those with 2\%/1 mm criterion were all over 96\%. Efficiency and code portability were tested with different GPUs and CPUs. Depending on the beam energy and voxel size, the computation time to simulate carbons was 9.9–125 s, 2.5–50 s and 60–612 s on an AMD Radeon GPU card, an NVidia GeForce GTX 1080 GPU card and an Intel Xeon E5-2640 CPU, respectively. The combined accuracy, efficiency and portability make goCMC attractive for research and clinical applications in carbon ion therapy.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\AXMYDGXG\\Qin et al. - 2017 - Initial development of goCMC a GPU-oriented fast .pdf}
}

@article{Raaijmakers2005,
  title = {Dose distribution in a patient anatomy for an integrated {{MRI-linear}} accelerator system: boosting the dose around air cavities using the magnetic field},
  author = {Raaijmakers, A J E and Raaymakers, B W and Lagendijk, J J W},
  date = {2005},
  journaltitle = {Radiotherapy and Oncology},
  volume = {76},
  pages = {109}
}

@article{Raaijmakers2005a,
  title = {Integrating a {{MRI}} scanner with a 6 {{MV}} radiotherapy accelerator: dose increase at tissue�air interfaces in a lateral magnetic field due to returning electrons},
  author = {Raaijmakers, A J E and Raaymakers, B W and Lagendijk, J J W},
  date = {2005},
  journaltitle = {Physics in Medicine and Biology},
  volume = {50},
  number = {7},
  pages = {1363},
  url = {http://stacks.iop.org/0031-9155/50/i=7/a=002}
}

@article{Raaijmakers2007,
  title = {Dose optimization for the {{MRI-accelerator}}: {{IMRT}} in the presence of a magnetic field.},
  author = {Raaijmakers, A J E and H�rdemark, B and Raaymakers, B W and Raaijmakers, C P J and Lagendijk, J J W},
  date = {2007},
  journaltitle = {Phys Med Biol},
  volume = {52},
  number = {23},
  pages = {7045--7054},
  doi = {10.1088/0031-9155/52/23/018},
  url = {http://dx.doi.org/10.1088/0031-9155/52/23/018},
  abstract = {A combined system of a 6 MV linear accelerator and a 1.5 T MRI scanner},
  keywords = {Biological; Prostatic Neoplasms,Computer Simulation; Electromagnetic Fields; Human,Computer-Assisted,Conformal,diagnosis/physiopathology/radiotherapy; Radiometr,methods,methods; Male; Models,methods; Radiotherapy,methods; Radiotherapy Dosage; Radiotherapy Planni}
}

@article{Raaijmakers2007a,
  title = {Dose optimization for the {{MRI-accelerator}}: {{IMRT}} in the presence of a magnetic field},
  shorttitle = {Dose optimization for the {{MRI-accelerator}}},
  author = {Raaijmakers, A. J. E. and Hårdemark, B. and Raaymakers, B. W. and Raaijmakers, C. P. J. and Lagendijk, J. J. W.},
  date = {2007-11},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {52},
  number = {23},
  pages = {7045--7054},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/52/23/018},
  url = {https://doi.org/10.1088/0031-9155/52/23/018},
  urldate = {2022-08-11},
  abstract = {A combined system of a 6 MV linear accelerator and a 1.5 T MRI scanner is currently being developed. In this system, the patient will be irradiated in the presence of a 1.5 T magnetic field. This causes a strong dose increase at tissue–air interfaces. Around air cavities in the patient, these effects may become problematic. Homogeneous dose distributions can be obtained around regularly shaped symmetrical cavities using opposing beams. However, for more irregularly shaped cavities this approach may not be sufficient. This study will investigate whether IMRT can be used to cope with magnetic field dose effects, in particular for target volumes adjacent to irregularly shaped air cavities. Therefore, an inverse treatment planning approach has been designed based on pre-calculated beamlet dose distribution kernels. Using this approach, optimized dose distributions were calculated for B = 1.5 T and for B = 0 T. Investigated target sites include a prostate cancer, a laryngeal cancer and an oropharyngeal cancer. Differences in the dose distribution between B = 0 and 1.5 T were minimal; only the skin dose increased for B = 1.5 T. Homogeneous dose distributions were obtained for target structures adjacent to air cavities without the use of opposing beams. These results show that a 1.5 T magnetic field does not compromise the ability to achieve desired dose distributions with IMRT.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\IGHU4JC2\\Raaijmakers et al. - 2007 - Dose optimization for the MRI-accelerator IMRT in.pdf}
}

@article{Raaijmakers2008,
  title = {Magnetic-field-induced dose effects in {{MR-guided}} radiotherapy systems: dependence on the magnetic field strength.},
  author = {Raaijmakers, A J E and Raaymakers, B W and Lagendijk, J J W},
  date = {2008-02},
  journaltitle = {Phys Med Biol},
  volume = {53},
  number = {4},
  pages = {909--923},
  doi = {10.1088/0031-9155/53/4/006},
  url = {http://dx.doi.org/10.1088/0031-9155/53/4/006},
  abstract = {Several institutes are currently working on the development of a radiotherapy treatment system with online MR imaging (MRI) modality. The main difference between their designs is the magnetic field strength of the MRI system. While we have chosen a 1.5 Tesla (T) magnetic field strength, the Cross Cancer Institute in Edmonton will be using a 0.2 T MRI scanner and the company Viewray aims to use 0.3 T. The magnetic field strength will affect the severity of magnetic field dose effects, such as the electron return effect (ERE): considerable dose increase at tissue air boundaries due to returning electrons. This paper has investigated how the ERE dose increase depends on the magnetic field strength. Therefore, four situations where the ERE occurs have been simulated: ERE at the distal side of the beam, the lateral ERE, ERE in cylindrical air cavities and ERE in the lungs. The magnetic field comparison values were 0.2, 0.75, 1.5 and 3 T. Results show that, in general, magnetic field dose effects are reduced at lower magnetic field strengths. At the distal side, the ERE dose increase is largest for B = 0.75 T and depends on the irradiation field size for B = 0.2 T. The lateral ERE is strongest for B = 3 T but shows no effect for B = 0.2 T. Around cylindrical air cavities, dose inhomogeneities disappear if the radius of the cavity becomes small relative to the in-air radius of the secondary electron trajectories. At larger cavities (r {$>$} 1 cm), dose inhomogeneities exist for all magnetic field strengths. In water-lung-water phantoms, the ERE dose increase takes place at the water-lung transition and the dose decreases at the lung-water transition, but these effects are minimal for B = 0.2 T. These results will contribute to evaluating the trade-off between magnetic field dose effects and image quality of MR-guided radiotherapy systems.},
  keywords = {Computer-Assisted,cytology; Magnetic Resonance Imaging; Magnetics;,Electrons; Lung,methods}
}

@article{Raaymakers2004,
  title = {Integrating a {{MRI}} scanner with a 6 {{MV}} radiotherapy accelerator: dose deposition in a transverse magnetic field},
  author = {Raaymakers, B W and Raaijmakers, A J E and Kotte, A N T J and Jette, D and Lagendijk, J J W},
  date = {2004},
  journaltitle = {Physics in Medicine and Biology},
  volume = {49},
  number = {17},
  pages = {4109},
  url = {http://stacks.iop.org/0031-9155/49/i=17/a=019}
}

@article{Raaymakers2004a,
  title = {Integrating a {{MRI}} scanner with a 6 {{MV}} radiotherapy accelerator: dose deposition in a transverse magnetic field},
  shorttitle = {Integrating a {{MRI}} scanner with a 6 {{MV}} radiotherapy accelerator},
  author = {Raaymakers, B. W. and Raaijmakers, A. J. E. and Kotte, A. N. T. J. and Jette, D. and Lagendijk, J. J. W.},
  date = {2004-08},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {49},
  number = {17},
  pages = {4109--4118},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/49/17/019},
  url = {https://doi.org/10.1088/0031-9155/49/17/019},
  urldate = {2022-08-11},
  abstract = {Integrating magnetic resonance imaging (MRI) functionality with a radiotherapy accelerator can facilitate on-line, soft-tissue based, position verification. A technical feasibility study, in collaboration with Elekta Oncology Systems and Philips Medical Systems, led to the preliminary design specifications of a MRI accelerator. Basically the design is a 6 MV accelerator rotating around a 1.5 T MRI system. Several technical issues and the clinical rational are currently under investigation. The aim of this paper is to determine the impact of the transverse 1.5 T magnetic field on the dose deposition. Monte Carlo simulations were used to calculate the dose deposition kernel in the presence of 1.5 T. This kernel in turn was used to determine the dose deposition for larger fields. Also simulations and measurements were done in the presence of 1.1 T. The pencil beam dose deposition is asymmetric. For larger fields the asymmetry persists but decreases. For the latter the distance to dose maximum is reduced by approximately 5 mm, the penumbra is increased by approximately 1 mm, and the 50\% isodose line is shifted approximately 1 mm. The dose deposition in the presence of 1.5 T is affected, but the effect can be taken into account in a conventional treatment planning procedure. The impact of the altered dose deposition for clinical IMRT treatments is the topic of further research.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\GQ5YUXN2\\Raaymakers et al. - 2004 - Integrating a MRI scanner with a 6 MV radiotherapy.pdf}
}

@article{Raaymakers2009,
  title = {Integrating a 1.5 {{T MRI}} scanner with a 6 {{MV}} accelerator: proof of concept.},
  author = {Raaymakers, B W and Lagendijk, J J W and Overweg, J and Kok, J G M and Raaijmakers, A J E and Kerkhof, E M and family=Put, given=R W, prefix=van der, useprefix=true and Meijsing, I and Crijns, S P M and Benedosso, F and family=Vulpen, given=M, prefix=van, useprefix=true and family=Graaff, given=C H W, prefix=de, useprefix=true and Allen, J and Brown, K J},
  date = {2009-06},
  journaltitle = {Phys Med Biol},
  volume = {54},
  number = {12},
  pages = {N229--N237},
  doi = {10.1088/0031-9155/54/12/N01},
  url = {http://dx.doi.org/10.1088/0031-9155/54/12/N01},
  abstract = {At the UMC Utrecht, The Netherlands, we have constructed a prototype MRI accelerator. The prototype is a modified 6 MV Elekta (Crawley, UK) accelerator next to a modified 1.5 T Philips Achieva (Best, The Netherlands) MRI system. From the initial design onwards, modifications to both systems were aimed to yield simultaneous and unhampered operation of the MRI and the accelerator. Indeed, the simultaneous operation},
  keywords = {Computer-Assisted,Equipment Design; Equipment Failure Analysis; Magn,instrumentation; Particle Accelerators,instrumentation; Pilot Projects; Radiotherapy,instrumentation; Systems Integration}
}

@article{Ramos-Mendez2018,
  title = {Fast calculation of nanodosimetric quantities in treatment planning of proton and ion therapy},
  author = {Ramos-Méndez, José and Burigo, Lucas N. and Schulte, Reinhard and Chuang, Cynthia and Faddegon, Bruce},
  date = {2018-11},
  journaltitle = {Physics in Medicine \&amp\$\textbackslash mathsemicolon\$ Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {63},
  number = {23},
  pages = {235015},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/aaeeee},
  url = {https://doi.org/10.1088/1361-6560/aaeeee},
  urldate = {2022-09-29},
  abstract = {Details of the pattern of ionization formed by particle tracks extends knowledge of dose effects on the nanometer scale. Ionization detail (ID), frequently characterized by ionization cluster size distributions (ICSD), is obtained through time-consuming Monte Carlo (MC) track-structure simulations. In this work, TOPAS-nBio was used to generate a highly precise database of biologically significant ID quantities, sampled with randomly oriented 2.3 nm diameter cylinders, 3.4 nm (10 base pairs) long, inside a chromatin-size cylinder, irradiated by 1–1000 MeV/u ions of Z = 1–8. A macroscopic method developed to utilize the database using condensed-history MC was used to calculate distributions of the ICSD first moment and cumulative probability in a 20 × 20 × 40 cm3 water phantom irradiated with proton and carbon spread-out Bragg peak (SOBP) of 10.5 cm range, 2 cm width. Results were verified against detailed MC track-structure simulations using phase space scored at several depths. ID distributions were then obtained for intensity modulated proton and carbon radiotherapy plans in a digitized anthropomorphic phantom of a base of skull tumor to demonstrate clinical application of this approach. The database statistical uncertainties were 0.5\% (3 standard deviations). Fluence-averaged ID as implemented proved unsuitable for macroscopic calculation. Edep-averaged ID agreed with track-structure results within 0.8\% for protons. For carbon, maximum absolute differences of 2.9\% ± 1.6\% and 5.6\% ± 1.9\% for , 1.7\% ± 0.8\% and 1.9\% ± 0.4\% (1 standard deviation) for , were found in the plateau and SOBP, respectively, up to 11.5\% ± 5.6\% in the tail region. Macroscopic ID calculation was demonstrated for a realistic treatment plan. Computation times with or without ID calculation were comparable in all cases. Pre-calculated nanodosimetric data may be used for condensed-history MC for nanodosimetric ID-based treatment planning in ion radiotherapy in the future. The macroscopic approach developed has the calculation speed of condensed-history MC while approaching the accuracy of full track structure simulations.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\WJ3UYXHA\\Ramos-Méndez et al. - 2018 - Fast calculation of nanodosimetric quantities in t.pdf}
}

@book{Rasmussen2006,
  title = {Gaussian {{Processes}} for {{Machine Learning}}},
  author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
  date = {2006},
  series = {Adaptive computation and machine learning},
  publisher = {{MIT Press}},
  location = {{Cambridge, Mass}},
  isbn = {978-0-262-18253-9},
  langid = {english},
  pagetotal = {248},
  keywords = {Data processing,Gaussian processes,Machine learning,Mathematical models},
  annotation = {OCLC: ocm61285753},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\3TNYUVAS\\Rasmussen und Williams - 2006 - Gaussian processes for machine learning.pdf}
}

@book{Rath2016,
  title = {Particle {{Radiotherapy}}},
  editor = {Rath, Arabinda Kumar and Sahoo, Narayan},
  date = {2016},
  edition = {1},
  publisher = {{Springer India}},
  location = {{New Delhi}},
  doi = {10.1007/978-81-322-2622-2},
  url = {http://link.springer.com/10.1007/978-81-322-2622-2},
  urldate = {2018-01-18},
  isbn = {978-81-322-2621-5}
}

@incollection{Rath2016a,
  title = {Particle {{Radiotherapy}}: {{An Introduction}}},
  booktitle = {Particle {{Radiotherapy}}},
  editor = {Rath, Arabinda Kumar and Sahoo, Narayan},
  date = {2016},
  pages = {1--6},
  publisher = {{Springer India}},
  location = {{New Delhi}},
  doi = {10.1007/978-81-322-2622-2_1},
  url = {http://link.springer.com/10.1007/978-81-322-2622-2_1},
  urldate = {2018-01-18},
  isbn = {978-81-322-2621-5}
}

@article{Riboldi2012,
  title = {Real-time tumour tracking in particle therapy: technological developments and future perspectives},
  shorttitle = {Real-time tumour tracking in particle therapy},
  author = {Riboldi, Marco and Orecchia, Roberto and Baroni, Guido},
  date = {2012-09-01},
  journaltitle = {The Lancet Oncology},
  shortjournal = {The Lancet Oncology},
  volume = {13},
  number = {9},
  pages = {e383-e391},
  issn = {1470-2045},
  doi = {10.1016/S1470-2045(12)70243-7},
  url = {http://www.sciencedirect.com/science/article/pii/S1470204512702437},
  urldate = {2020-04-03},
  abstract = {A key challenge in radiation oncology is accurate delivery of the prescribed dose to tumours that move because of respiration. Tumour tracking involves real-time target localisation and correction of radiation beam geometry to compensate for motion. Uncertainties in tumour localisation are important in particle therapy (proton therapy, carbon-ion therapy) because charged particle beams are highly sensitive to geometrical and associated density and radiological variations in path length, which will affect the treatment plan. Target localisation and motion compensation methods applied in x-ray photon radiotherapy require careful performance assessment for clinical applications in particle therapy. In this Review, we summarise the efforts required for an application of real-time tumour tracking in particle therapy, by comparing and assessing competing strategies for time-resolved target localisation and related clinical outcomes in x-ray radiation oncology.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\QCIFRQTH\\Riboldi et al. - 2012 - Real-time tumour tracking in particle therapy tec.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\NNB4W7KQ\\S1470204512702437.html}
}

@article{Rietzel2010,
  title = {Respiratory motion management in particle therapy},
  author = {Rietzel, Eike and Bert, Christoph},
  date = {2010},
  journaltitle = {Medical Physics},
  volume = {37},
  number = {2},
  pages = {449--460},
  issn = {2473-4209},
  doi = {10.1118/1.3250856},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.3250856},
  urldate = {2020-03-23},
  abstract = {Clinical outcomes of charged particle therapy are very promising. Currently, several dedicated centers that use scanning beam technology are either close to clinical use or under construction. Since scanned beam treatments of targets that move with respiration most likely result in marked local over- and underdosage due to interplay of target motion and dynamic beam application, dedicated motion mitigation techniques have to be employed. To date, the motion mitigation techniques, rescanning, beam gating, and beam tracking, have been proposed and tested in experimental studies. Rescanning relies on repeated irradiations of the target with the number of particles reduced accordingly per scan to statistically average local misdosage. Specific developments to prohibit temporal correlation between beam scanning and target motion will be required to guarantee adequate averaging. For beam gating, residual target motion within gating windows has to be mitigated in order to avoid local misdosage. Possibly the most promising strategy is to increase the overlap of adjacent particle pencil beams laterally as well as longitudinally to effectively reduce the sensitivity against small residual target motion. The most conformal and potentially most precise motion mitigation technique is beam tracking. Individual particle pencil beams have to be adapted laterally as well as longitudinally according to the target motion. Within the next several years, it can be anticipated that rescanning as well as beam gating will be ready for clinical use. For rescanning, treatment planning margins that incorporate the full extent of target motion as well as motion induced density variations in the beam paths will result in reduced target conformity of the applied dose distributions. Due to the limited precision of motion monitoring devices, it seems likely that beam gating will be used initially to mitigate interplay effects only but not to considerably decrease treatment planning margins. Then, in the next step, beam gating, based on more accurate motion monitoring systems, provides the possibility to restore target conformity as well as steep dose gradients due to reduced treatment planning margins. Accurate motion monitoring systems will be required for beam tracking. Even though beam tracking has already been successfully tested experimentally, full clinical implementation requires direct feedback of the actual target position in quasireal time to the treatment control system and can be anticipated to be several more years ahead.},
  langid = {english},
  keywords = {cancer,Cancer,Carbon,Charged particle motion,charged particle therapy,Dose-volume analysis,dosimetry,Dosimetry,Dosimetry/exposure assessment,including brachytherapy,lung,Medical treatment planning,motion mitigation,organ motion,Particle beam detectors,Particle beams,Photons,Pneumodyamics,pneumodynamics,Protons,radiation therapy,Radiography,respiration,Therapeutic applications,tumours},
  annotation = {\_eprint: https://aapm.onlinelibrary.wiley.com/doi/pdf/10.1118/1.3250856}
}

@article{Rockafellar1997,
  title = {Optimization of conditional value-at-risk},
  author = {Rockafellar, R. Tyrrell and Uryasev, Stanislav},
  date = {1997},
  journaltitle = {Journal of Risk},
  volume = {2},
  eprint = {25246403},
  eprinttype = {pmid},
  pages = {21--41},
  issn = {10769986},
  doi = {10.2307/1165345},
  abstract = {A new approach to optimizing or hedging a portfolio of financial instruments to reduce risk is presented and tested on applications. It focuses on minimizing conditional value-at-risk (CVaR) rather than minimizing value-at-risk (VaR), but portfolios with low CVaR necessarily have low VaR as well. CVaR, also called mean excess loss, mean shortfall, or tail VaR, is in any case considered to be a more consistent measure of risk than VaR. Central to the new approach is a technique for portfolio optimization which calculates VaR and optimizes CVaR simultaneously. This technique is suitable for use by investment companies, brokerage firms, mutual funds, and any business that evaluates risk. It can be combined with analytical or scenario-based methods to optimize portfolios with large numbers of instruments, in which case the calculations often come down to linear programming or nonsmooth programming. The methodology can also be applied to the optimization of percentiles in contexts outside of finance.},
  archiveprefix = {arXiv},
  isbn = {1465-1211},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\4MG8V939\\Rockafellar, Uryasev - 1997 - Optimization of conditional value-at-risk.pdf}
}

@article{Roman1978,
  title = {The umbral calculus},
  author = {Roman, Steven M and Rota, Gian-Carlo},
  date = {1978-02},
  journaltitle = {Advances in Mathematics},
  volume = {27},
  number = {2},
  pages = {95--188},
  issn = {00018708},
  doi = {10.1016/0001-8708(78)90087-7},
  url = {http://linkinghub.elsevier.com/retrieve/pii/0001870878900877},
  urldate = {2018-03-22},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\BIATNPFQ\\Roman, Rota - 1978 - The umbral calculus.pdf}
}

@article{Romeijn2003,
  title = {A novel linear programming approach to fluence map optimization for intensity modulated radiation therapy treatment planning.},
  author = {Romeijn, H Edwin and Ahuja, Ravindra K and Dempsey, James F and Kumar, Arvind and Li, Jonathan G},
  date = {2003},
  journaltitle = {Physics in medicine and biology},
  volume = {48},
  number = {21},
  eprint = {14653560},
  eprinttype = {pmid},
  pages = {3521--3542},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/48/21/005},
  abstract = {We present a novel linear programming (LP) based approach for efficiently solving the intensity modulated radiation therapy (IMRT) fluence-map optimization (FMO) problem to global optimality. Our model overcomes the apparent limitations of a linear-programming approach by approximating any convex objective function by a piecewise linear convex function. This approach allows us to retain the flexibility offered by general convex objective functions, while allowing us to formulate the FMO problem as a LP problem. In addition, a novel type of partial-volume constraint that bounds the tail averages of the differential dose-volume histograms of structures is imposed while retaining linearity as an alternative approach to improve dose homogeneity in the target volumes, and to attempt to spare as many critical structures as possible. The goal of this work is to develop a very rapid global optimization approach that finds high quality dose distributions. Implementation of this model has demonstrated excellent results. We found globally optimal solutions for eight 7-beam head-and-neck cases in less than 3 min of computational time on a single processor personal computer without the use of partial-volume constraints. Adding such constraints increased the running times by a factor of 2-3, but improved the sparing of critical structures. All cases demonstrated excellent target coverage ({$>$} 95\%), target homogeneity ({$<$} 10\% overdosing and {$<$} 7\% underdosing) and organ sparing using at least one of the two models.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\X8J7Q6K3\\Romeijn et al. - 2003 - A novel linear programming approach to fluence map optimization for intensity modulated radiation therapy treatm.pdf}
}

@book{Rontgen1896,
  title = {Eine neue {{Art}} von {{Strahlen}}},
  author = {Röntgen, Wilhelm Conrad},
  date = {1896},
  publisher = {{Stahel}},
  location = {{Würzburg}},
  url = {http://www.deutschestextarchiv.de/book/show/roentgen_strahlen_1896},
  urldate = {2013-12-11}
}

@article{Rosenschold2010,
  title = {A treatment planning study of the potential of geometrical tracking for intensity modulated proton therapy of lung cancer},
  author = {Rosenschöld, Per Munck Af and Aznar, Marianne C. and Nygaard, Ditte E. and Persson, Gitte F. and Korreman, Stine S. and Engelholm, Svend Aage and Nyström, Håkan},
  date = {2010-10-01},
  journaltitle = {Acta Oncologica},
  volume = {49},
  number = {7},
  pages = {1141--1148},
  issn = {0284-186X},
  doi = {10.3109/0284186X.2010.500620},
  url = {https://doi.org/10.3109/0284186X.2010.500620},
  urldate = {2020-04-03},
  abstract = {Background. Proton therapy of lung cancer holds the potential for a reduction of the volume of irradiated normal lung tissue. In this work we investigate the robustness of intensity modulated proton therapy (IMPT) plans to motion, and evaluate a geometrical tumour tracking method to compensate for tumour motion. Material and methods. Seven patients with a nine targets with 4DCT scans were selected. IMPT plans were made on the midventilation phase using a 3-field technique. The plans were transferred and calculated on the remaining nine phases of the 4DCT, and the combined dose distribution was summed using deformable image registration (DIR). An additional set of plans were made in which the proton beam was simply geometrically shifted to the centre of the gross tumour volume (GTV), i.e. simulating tracking of the tumour motion but without on-line adjustment of the proton energies. A possible interplay effect between the dynamics of the spot scanning delivery and the tumour motion has not been considered in this work. Results. Around 97–100\% of the GTV was covered by 95\% of the prescribed dose (V95) for a tumour displacement of less than about 1 cm with a static beam. For the remaining three of nine targets with a larger motion the tracking method studied provided a marked improvement over static beam; raising the GTV V95 from 95 to 100\%, 82 to 98\% and 51 to 97\%, respectively. Conclusion. The possibility of performing DIR and summing the dose on the 4DCT data set was shown to be feasible. The fairly simplistic tracking method suggested here resulted in a marked improvement in GTV coverage for tumours with large intra-fractional motion ({$>$}1 cm displacement), indicating that on-line adjustment of the proton energies may be redundant.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\IGXYH3WR\\Rosenschöld et al. - 2010 - A treatment planning study of the potential of geo.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\JNRIXQH4\\0284186X.2010.html}
}

@report{RTOG0415,
  title = {{{RTOG}} 0415: {{A}} phase {{III}} randomized study of hypofractionated {{3D-CRT}}/{{IMRT}} versus conventionally fractionated {{3D-CRT}}/{{IMRT}} in patients with favorable risk prostate cancer.},
  shorttitle = {{{RTOG}} 0415},
  author = {Amin, Mahul B and Angeles, Los and Bruner, Deborah Watkins and Building, Nursing Education and Swanson, Gregory P and Antonio, San and Statistician, Senior and Hunt, Daniel and Lee, W Robert and Low, Daniel},
  date = {2011},
  institution = {{Radiation Therapy Oncology Group}},
  isbn = {3104236631},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\FUUI9PC8\\Amin et al. - 2011 - RTOG 0415 A phase III randomized study of hypofractionated 3D-CRTIMRT versus conventionally fractionated 3D-CRTIMRT.pdf}
}

@article{Russo2016,
  title = {A novel algorithm for the calculation of physical and biological irradiation quantities in scanned ion beam therapy: the beamlet superposition approach},
  shorttitle = {A novel algorithm for the calculation of physical and biological irradiation quantities in scanned ion beam therapy},
  author = {Russo, G and Attili, A and Battistoni, G and Bertrand, D and Bourhaleb, F and Cappucci, F and Ciocca, M and Mairani, A and Milian, F M and Molinelli, S and Morone, M C and Muraro, S and Orts, T and Patera, V and Sala, P and Schmitt, E and Vivaldo, G and Marchetto, F},
  date = {2016-01-07},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {61},
  number = {1},
  pages = {183--214},
  issn = {0031-9155, 1361-6560},
  doi = {10.1088/0031-9155/61/1/183},
  url = {http://stacks.iop.org/0031-9155/61/i=1/a=183?key=crossref.93bb8d2bb864e5cb618195218c8be3bd},
  urldate = {2020-03-24},
  abstract = {The calculation algorithm of a modern treatment planning system for ionbeam radiotherapy should ideally be able to deal with different ion species (e.g. protons and carbon ions), to provide relative biological effectiveness (RBE) evaluations and to describe different beam lines. In this work we propose a new approach for ion irradiation outcomes computations, the beamlet superposition (BS) model, which satisfies these requirements.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\URKUAP4W\\Russo et al. - 2016 - A novel algorithm for the calculation of physical .pdf}
}

@article{Safai2012,
  title = {Improving the precision and performance of proton pencil beam scanning},
  author = {Safai, Sairos and Bula, Christian and Meer, David and Pedroni, Eros},
  date = {2012},
  journaltitle = {Translational Cancer Research},
  volume = {1},
  number = {3},
  pages = {196--206},
  issn = {2218-676X},
  doi = {10.3978/j.issn.2218-676X.2012.10.08},
  abstract = {In this report we present the technical features of Gantry 2, the new second generation scanning system of PSI. On the basis of the experience and success with the first prototype, Gantry 1, built in the 90s for introducing pencil beam scanning and IMPT into the field of proton therapy, we have recently implemented a new system capable of offering much faster repainted conformal scanning for being able to treat moving targets with scanning under image guidance, the next challenge in the field of proton therapy. The new technical developments are conducted in parallel to the ongoing basic commissioning of Gantry 2, which should go into operation with usual discrete spot scanning for treating static targets in 2013. The innovative layout of Gantry 2 and the integration in the treatment area of the basic equipment for image guidance are presented. Noteworthy are the sliding CT within reach of the patient table and the unique new Beam’s-Eye-View X-ray fluoroscopy system for taking images in the beam direction synchronized with the proton beam delivery. The first preliminary results with the development of much faster scanning modes look very encouraging. We can change the beam energy with the beam line within 80 ms for typical 0.5 cm range steps. We can deliver whole fluence-shaped energy layers within a time of the order of 100 ms. Dose lines are painted by changing the velocity of the scan magnets. The instantaneous dose rate of the pencil beam can be varied dynamically as well. The dose is precisely controlled with a feedback loop connecting the main gantry beam monitor with a vertical deflector plate at the ion source. These new fast scanning modes should be used for providing scanning with repainting, gating and tracking for treating moving targets. The goal is to develop pencil beam scanning as a universal beam delivery solution capable of treating optimally all possible clinical indications for proton therapy. Scanning could then completely replace the old beam delivery methods based on passive scattering from the market. The long term projects of Gantry 2 should represent the new contributions of PSI to the proton therapy field in the next 5-10 years, by providing direct translational cancer research from the physics laboratory into industry and clinics.},
  keywords = {08,10,2012,2218-676x,23,3978,599,accepted for publication oct,article,article at,conformal therapy,device or view this,doi,dynamic therapy,html,http,image guidance,issn,j,moving targets,org,proton therapy,scan to your mobile,submitted sep 22,thetcr,view,www},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\SECL4T9F\\Safai et al. - 2012 - Improving the precision and performance of proton pencil beam scanning.pdf}
}

@article{Saini2017,
  title = {Dosimetric evaluation of a commercial proton spot scanning {{Monte-Carlo}} dose algorithm: comparisons against measurements and simulations},
  author = {Saini, Jatinder and Maes, Dominic and Egan, Alexander and Bowen, Stephen R and James, Sara St and Janson, Martin and Wong, Tony and Bloch, Charles},
  date = {2017-09},
  journaltitle = {Physics in Medicine \& Biology},
  volume = {62},
  number = {19},
  pages = {7659--7681},
  publisher = {{IOP Publishing}},
  doi = {10.1088/1361-6560/aa82a5}
}

@article{Sanchez-Crespo2004,
  title = {Positron flight in human tissues and its influence on {{PET}} image spatial resolution},
  author = {Sánchez-Crespo, Alejandro and Andreo, Pedro and Larsson, Stig A.},
  date = {2004-01-01},
  journaltitle = {European Journal of Nuclear Medicine and Molecular Imaging},
  shortjournal = {Eur J Nucl Med Mol Imaging},
  volume = {31},
  number = {1},
  pages = {44--51},
  issn = {1619-7089},
  doi = {10.1007/s00259-003-1330-y},
  url = {https://doi.org/10.1007/s00259-003-1330-y},
  urldate = {2020-04-03},
  abstract = {The influence of the positron distance of flight in various human tissues on the spatial resolution in positron emission tomography (PET) was assessed for positrons from carbon-11, nitrogen-13, oxygen-15, fluorine-18, gallium-68 and rubidium-82. The investigation was performed using the Monte Carlo code PENELOPE to simulate the transport of positrons within human compact bone, adipose, soft and lung tissue. The simulations yielded 3D distributions of annihilation origins that were projected on the image plane in order to assess their impact on PET spatial resolution. The distributions obtained were cusp-shaped with long tails rather than Gaussian shaped, thus making conventional full width at half maximum (FWHM) measures uncertain. The full width at 20\% of the maximum amplitude (FW20M) of the annihilation distributions yielded more appropriate values for root mean square addition of spatial resolution loss components. Large differences in spatial resolution losses due to the positron flight in various human tissues were found for the selected radionuclides. The contribution to image blur was found to be up to three times larger in lung tissue than in soft tissue or fat and five times larger than in bone tissue. For 18F, the spatial resolution losses were 0.54~mm in soft tissue and 1.52~mm in lung tissue, compared with 4.10 and 10.5~mm, respectively, for 82Rb. With lung tissue as a possible exception, the image blur due to the positron flight in all human tissues has a minor impact as long as PET cameras with a spatial resolution of 5–7~mm are used in combination with 18F-labelled radiopharmaceuticals. However, when ultra-high spatial resolution PET cameras, with 3–4~mm spatial resolution, are applied, especially in combination with other radionuclides, the positron flight may enter as a limiting factor for the total PET spatial resolution—particularly in lung tissue.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\ZXPEEFIS\\Sánchez-Crespo et al. - 2004 - Positron flight in human tissues and its influence.pdf}
}

@article{Sanchez-Parcerisa2014,
  title = {{{FoCa}}: a modular treatment planning system for proton radiotherapy with research and educational purposes},
  shorttitle = {{{FoCa}}},
  author = {Sánchez-Parcerisa, D. and Kondrla, M. and Shaindlin, A. and Carabe, A.},
  date = {2014-11},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {59},
  number = {23},
  pages = {7341--7360},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/59/23/7341},
  url = {https://doi.org/10.1088%2F0031-9155%2F59%2F23%2F7341},
  urldate = {2019-10-25},
  abstract = {FoCa is an in-house modular treatment planning system, developed entirely in MATLAB, which includes forward dose calculation of proton radiotherapy plans in both active and passive modalities as well as a generic optimization suite for inverse treatment planning.The software has a dual education and research purpose. From the educational point of view, it can be an invaluable teaching tool for educating medical physicists, showing the insights of a treatment planning system from a well-known and widely accessible software platform. From the research point of view, its current and potential uses range from the fast calculation of any physical, radiobiological or clinical quantity in a patient CT geometry, to the development of new treatment modalities not yet available in commercial treatment planning systems.The physical models in FoCa were compared with the commissioning data from our institution and show an excellent agreement in depth dose distributions and longitudinal and transversal fluence profiles for both passive scattering and active scanning modalities. 3D dose distributions in phantom and patient geometries were compared with a commercial treatment planning system, yielding a gamma-index pass rate of above 94\% (using FoCa’s most accurate algorithm) for all cases considered.Finally, the inverse treatment planning suite was used to produce the first prototype of intensity-modulated, passive-scattered proton therapy, using 13 passive scattering proton fields and multi-leaf modulation to produce a concave dose distribution on a cylindrical solid water phantom without any field-specific compensator.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\5AK4VBWI\\Sánchez-Parcerisa et al. - 2014 - FoCa a modular treatment planning system for prot.pdf}
}

@article{Sanchez-Parcerisa2019,
  title = {{{MultiRBE}}: {{Treatment}} planning for protons with selective radiobiological effectiveness},
  shorttitle = {{{MultiRBE}}},
  author = {Sánchez‐Parcerisa, Daniel and López‐Aguirre, Miguel and Dolcet Llerena, Ana and Udías, José Manuel},
  date = {2019-09},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {46},
  number = {9},
  pages = {4276--4284},
  issn = {0094-2405, 2473-4209},
  doi = {10.1002/mp.13718},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mp.13718},
  urldate = {2019-10-30},
  abstract = {Purpose: Clinical treatment planning protocols for protons recommend a uniform value radiobiological effectiveness (RBE) of protons of 1.1 throughout the treatment field, despite evidence from in-vitro and animal studies that proton RBE increases with linear energy transfer (LET), causing tissues placed distally to the target location to receive a presumably higher biological dose than estimated. While several voices in the medical physics community have advocated for variable RBE-based optimization, the uncertainties in RBE models have prevented its implementation in clinical practice, since an overestimation of RBE could cause significant target underdosage. Methods: We propose a mixed RBE model (MultiRBE), where a uniform RBE is used in the target contours to ensure an adequate tumor coverage in terms of physical dose, but a variable RBE is used elsewhere. Our model was implemented in the open-source treatment planning system matRad and three example cases were planned: a homogeneous phantom, a prostate tumor and a head-and-neck case. MultiRBE was used for plan optimization, and the produced plans were subsequently evaluated in terms of physical dose coverage (V95\%) and variable RBEweighted dose in organs at risk and normal tissue complication probabilities (NTCP), where prediction models were available. Results: The planning algorithm showed potential for reducing the biological dose in organs surrounding the planning target and thus decreasing the probability for complications in normal tissue (by up to 62\% in the prostate case and 37\% in the head-and-neck patient). This was achieved without compromising the target coverage or homogeneity in terms of physical dose, as a result of a smarter redistribution of dose among the surrounding tissues with regard to the optimization constraints. Conclusions: The results prove the ability of the MultiRBE model to reduce biological dose at healthy tissues without compromising the dose coverage of the tumor, with independence of the variable RBE models used. © 2019 American Association of Physicists in Medicine [https://doi.org/ 10.1002/mp.13718]},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\JRYLSGHQ\\Sánchez‐Parcerisa et al. - 2019 - MultiRBE Treatment planning for protons with sele.pdf}
}

@article{Sandve2013,
  title = {Ten {{Simple Rules}} for {{Reproducible Computational Research}}},
  author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
  date = {2013-10-24},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {9},
  number = {10},
  pages = {e1003285},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1003285},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285},
  urldate = {2021-09-21},
  langid = {english},
  keywords = {Archives,Computer and information sciences,Computer applications,Genome analysis,Habits,Replication studies,Reproducibility,Source code},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\58DNV8ST\\Sandve et al. - 2013 - Ten Simple Rules for Reproducible Computational Re.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\XDK4QAML\\article.html}
}

@article{Santos2012,
  title = {Magnetic shielding investigation for a 6 {{MV}} in-line linac within the parallel configuration of a linac-{{MR}} system.},
  author = {Santos, D M and St Aubin, J and Fallone, B G and Steciw, S},
  date = {2012-02},
  journaltitle = {Med Phys},
  volume = {39},
  number = {2},
  pages = {788--797},
  doi = {10.1118/1.3676692},
  url = {http://dx.doi.org/10.1118/1.3676692},
  abstract = {In our current linac-magnetic resonance (MR) design, a 6 MV in-line linac is placed along the central axis of the MR's magnet where the MR's fringe magnetic fields are parallel to the overall electron trajectories in the linac waveguide. Our previous study of this configuration comprising a linac-MR SAD of 100 cm and a 0.5 T superconducting (open, split) MR imager. It showed the presence of longitudinal magnetic fields of 0.011 T at the electron gun, which caused a reduction in target current to 84\% of nominal. In this study, passive and active magnetic shielding was investigated to recover the linac output losses caused by magnetic deflections of electron trajectories in the linac within a parallel linac-MR configuration.Magnetic materials and complex shield structures were used in a 3D finite element method (FEM) magnetic field model, which emulated the fringe magnetic fields of the MR imagers. The effects of passive magnetic shielding was studied by surrounding the electron gun and its casing with a series of capped steel cylinders of various inner lengths (26.5-306.5 mm) and thicknesses (0.75-15 mm) in the presence of the fringe magnetic fields from a commercial MR imager. In addition, the effects of a shield of fixed length (146.5 mm) with varying thicknesses were studied against a series of larger homogeneous magnetic fields (0-0.2 T). The effects of active magnetic shielding were studied by adding current loops around the electron gun and its casing. The loop currents, separation, and location were optimized to minimize the 0.011 T longitudinal magnetic fields in the electron gun. The magnetic field solutions from the FEM model were added to a validated linac simulation, consisting of a 3D electron gun (using OPERA-3d/scala) and 3D waveguide (using comsol Multiphysics and PARMELA) simulations. PARMELA's target current and output phase-space were analyzed to study the linac's output performance within the magnetic shields.The FEM model above agreed within 1.5\% with the manufacturer supplied fringe magnetic field isoline data. When passive magnetic shields are used, the target current is recoverable to greater than 99\% of nominal for shield thicknesses greater than 0.75 mm. The optimized active shield which resulted in 100\% target current recovery consists of two thin current rings 110 mm in diameter with 625 and 430 A-turns in each ring. With the length of the passive shield kept constant, the thickness of the shield had to be increased to achieve the same target current within the increased longitudinal magnetic fields.A ?99\% original target current is recovered with passive shield thicknesses {$>$}0.75 mm. An active shield consisting of two current rings of diameter of 110 mm with 625 and 430 A-turns fully recovers the loss that would have been caused by the magnetic fields. The minimal passive or active shielding requirements to essentially fully recover the current output of the linac in our parallel-configured linac-MR system have been determined and are easily achieved for practical implementation of the system.},
  keywords = {Artifacts; Computer Simulation; Computer-Aided Des,High-Energy,Image-Guided,instrumentation,instrumentation; Magnetic Resonance Imaging,instrumentation; Models,instrumentation; Radiotherapy,Theoretical; Particle Accelerators; Radiation Pro}
}

@article{Sawakuchi2010,
  title = {Monte {{Carlo}} investigation of the low-dose envelope from scanned proton pencil beams},
  author = {Sawakuchi, Gabriel O and Titt, Uwe and Mirkovic, Dragan and Ciangaru, George and Zhu, X Ronald and Sahoo, Narayan and Gillin, Michael T and Mohan, Radhe},
  date = {2010-02-07},
  journaltitle = {Physics in Medicine and Biology},
  volume = {55},
  number = {3},
  pages = {711--721},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/55/3/011},
  url = {http://stacks.iop.org/0031-9155/55/i=3/a=011?key=crossref.da70469d0ae74d3710e94ccd0a7a51bb},
  urldate = {2018-04-02}
}

@article{Schaffner1999,
  title = {Dose calculation models for proton treatment planning using a dynamic beam delivery system: an attempt to include density heterogeneity effects in the analytical dose calculation},
  author = {Schaffner, Barbara and Pedroni, Eros and Lomax, Antony},
  date = {1999-01-01},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {44},
  number = {1},
  pages = {27--41},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/44/1/004},
  url = {http://stacks.iop.org/0031-9155/44/i=1/a=004?key=crossref.5b31b0fc0fb8d274bd73e0975ca69b84},
  urldate = {2016-11-15},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\ESIUZ6J6\\Schaffner, Pedroni, Lomax - 1999 - Dose calculation models for proton treatment planning using a dynamic beam delivery system an attempt.pdf}
}

@article{Schatti2013,
  title = {Experimental verification of motion mitigation of discrete proton spot scanning by re-scanning},
  author = {Schätti, A. and Zakova, M. and Meer, D. and Lomax, A. J.},
  date = {2013-11},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {58},
  number = {23},
  pages = {8555--8572},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/58/23/8555},
  url = {https://doi.org/10.1088%2F0031-9155%2F58%2F23%2F8555},
  urldate = {2020-04-03},
  abstract = {In order to be able to treat mobile tumours with active, scanned proton therapy, adequate motion mitigation techniques have to be applied. Re-scanning is such an approach, where the interplay effect between tumour motion and treatment delivery is statistically smeared out. Different re-scanning methods have been used for the irradiation of a spherical target volume and motion amplitudes of up to 10 mm. The resulting dose distributions have been captured in two dimensions by imaging a scintillating screen at the iso-centre for different motion starting phases. Dose inhomogeneity increased approximately linearly with motion amplitude, while the influence of motion period and direction was small. Re-scanning the whole target volume reduced the interplay effect more than re-scanning only the iso-energy layers. Even for 10 mm motion amplitude, no hot or cold spots were seen for 10 re-scans of the whole volume. A fast energy change and fast beam scanning is vital for this kind of re-scanning, as available on Gantry 2 at the Paul Scherrer Institute. For larger motion amplitudes, re-scanning should be combined with gating, breath-hold or tracking to reduce the internal target volume.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\EWLS2ADY\\Schätti et al. - 2013 - Experimental verification of motion mitigation of .pdf}
}

@article{Schatti2014,
  title = {The effectiveness of combined gating and re-scanning for treating mobile targets with proton spot scanning. {{An}} experimental and simulation-based investigation},
  author = {Schätti, A. and Zakova, M. and Meer, D. and Lomax, A. J.},
  date = {2014-06},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {59},
  number = {14},
  pages = {3813--3828},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/59/14/3813},
  url = {https://doi.org/10.1088%2F0031-9155%2F59%2F14%2F3813},
  urldate = {2020-04-03},
  abstract = {Organ motion is one of the major obstacles in radiotherapy and charged particle therapy. Even more so, the theoretical advantages of dose distributions in scanned ion beam therapy may be lost due to the interplay between organ motion and beam scanning. Several techniques for dealing with this problem have been devised. In re-scanning, the target volume is scanned several times to average out the motion effects. In gating and breath-hold, dose is only delivered if the tumour is in a narrow window of position. Experiments have been performed to verify if gating and re-scanning are effective means of motion mitigation. Dose distributions were acquired in a lateral plane of a homogeneous phantom. For a spherical target volume and regular motion gating was sufficient. However, for realistic, irregular motion or a patient target volume, gating did not reduce the interplay effect to an acceptable level. Combining gating with re-scanning recovered the dose distributions. The simplest re-scanning approach, where a treatment plan is duplicated several times and applied in sequence, was not efficient. Simulations of different combinations of gating window sizes and re-scanning schemes revealed that reducing the gating window is the most efficient approach. However, very small gating windows are not robust for irregular motion.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\VBNJTF5D\\Schätti et al. - 2014 - The effectiveness of combined gating and re-scanni.pdf}
}

@article{Schiavi2017,
  title = {Fred: a {{GPU-accelerated}} fast-{{Monte Carlo}} code for rapid treatment plan recalculation in ion beam therapy},
  shorttitle = {Fred},
  author = {Schiavi, A. and Senzacqua, M. and Pioli, S. and Mairani, A. and Magro, G. and Molinelli, S. and Ciocca, M. and Battistoni, G. and Patera, V.},
  date = {2017-09-05},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {62},
  number = {18},
  eprint = {28873069},
  eprinttype = {pmid},
  pages = {7482--7504},
  issn = {1361-6560},
  doi = {10.1088/1361-6560/aa8134},
  abstract = {Ion beam therapy is a rapidly growing technique for tumor radiation therapy. Ions allow for a high dose deposition in the tumor region, while sparing the surrounding healthy tissue. For this reason, the highest possible accuracy in the calculation of dose and its spatial distribution is required in treatment planning. On one hand, commonly used treatment planning software solutions adopt a simplified beam-body interaction model by remapping pre-calculated dose distributions into a 3D water-equivalent representation of the patient morphology. On the other hand, Monte Carlo (MC) simulations, which explicitly take into account all the details in the interaction of particles with human tissues, are considered to be the most reliable tool to address the complexity of mixed field irradiation in a heterogeneous environment. However, full MC calculations are not routinely used in clinical practice because they typically demand substantial computational resources. Therefore MC simulations are usually only used to check treatment plans for a restricted number of difficult cases. The advent of general-purpose programming GPU cards prompted the development of trimmed-down MC-based dose engines which can significantly reduce the time needed to recalculate a treatment plan with respect to standard MC codes in CPU hardware. In this work, we report on the development of fred, a new MC simulation platform for treatment planning in ion beam therapy. The code can transport particles through a 3D voxel grid using a class II MC algorithm. Both primary and secondary particles are tracked and their energy deposition is scored along the trajectory. Effective models for particle-medium interaction have been implemented, balancing accuracy in dose deposition with computational cost. Currently, the most refined module is the transport of proton beams in water: single pencil beam dose-depth distributions obtained with fred agree with those produced by standard MC codes within 1-2\% of the Bragg peak in the therapeutic energy range. A comparison with measurements taken at the CNAO treatment center shows that the lateral dose tails are reproduced within 2\% in the field size factor test up to 20\,cm. The tracing kernel can run on GPU hardware, achieving 10 million primary [Formula: see text] on a single card. This performance allows one to recalculate a proton treatment plan at 1\% of the total particles in just a few minutes.},
  langid = {english},
  keywords = {Algorithms,Computer Graphics,Humans,Monte Carlo Method,Neoplasms,Phantoms; Imaging,Protons,Radiotherapy Dosage,Radiotherapy Planning; Computer-Assisted,Software}
}

@article{Schiavi2017a,
  title = {Fred: a {{GPU-accelerated}} fast-{{Monte Carlo}} code for rapid treatment plan recalculation in ion beam therapy},
  shorttitle = {Fred},
  author = {Schiavi, A. and Senzacqua, M. and Pioli, S. and Mairani, A. and Magro, G. and Molinelli, S. and Ciocca, M. and Battistoni, G. and Patera, V.},
  date = {2017-09},
  journaltitle = {Physics in Medicine \&amp\$\textbackslash mathsemicolon\$ Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {62},
  number = {18},
  pages = {7482--7504},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/aa8134},
  url = {https://doi.org/10.1088/1361-6560/aa8134},
  urldate = {2022-05-17},
  abstract = {Ion beam therapy is a rapidly growing technique for tumor radiation therapy. Ions allow for a high dose deposition in the tumor region, while sparing the surrounding healthy tissue. For this reason, the highest possible accuracy in the calculation of dose and its spatial distribution is required in treatment planning. On one hand, commonly used treatment planning software solutions adopt a simplified beam–body interaction model by remapping pre-calculated dose distributions into a 3D water-equivalent representation of the patient morphology. On the other hand, Monte Carlo (MC) simulations, which explicitly take into account all the details in the interaction of particles with human tissues, are considered to be the most reliable tool to address the complexity of mixed field irradiation in a heterogeneous environment. However, full MC calculations are not routinely used in clinical practice because they typically demand substantial computational resources. Therefore MC simulations are usually only used to check treatment plans for a restricted number of difficult cases. The advent of general-purpose programming GPU cards prompted the development of trimmed-down MC-based dose engines which can significantly reduce the time needed to recalculate a treatment plan with respect to standard MC codes in CPU hardware. In this work, we report on the development of fred, a new MC simulation platform for treatment planning in ion beam therapy. The code can transport particles through a 3D voxel grid using a class II MC algorithm. Both primary and secondary particles are tracked and their energy deposition is scored along the trajectory. Effective models for particle–medium interaction have been implemented, balancing accuracy in dose deposition with computational cost. Currently, the most refined module is the transport of proton beams in water: single pencil beam dose–depth distributions obtained with fred agree with those produced by standard MC codes within 1–2\% of the Bragg peak in the therapeutic energy range. A comparison with measurements taken at the CNAO treatment center shows that the lateral dose tails are reproduced within 2\% in the field size factor test up to 20 cm. The tracing kernel can run on GPU hardware, achieving 10 million primary on a single card. This performance allows one to recalculate a proton treatment plan at 1\% of the total particles in just a few minutes.},
  langid = {english}
}

@book{Schlegel2007,
  title = {{{3D Conformal Radiation Therapy}}: {{Multimedia Introduction}} to {{Methods}} and {{Techniques}}},
  author = {Schlegel, Wolfgang and Mahr, Andreas},
  date = {2007-06-27},
  edition = {2},
  publisher = {{Springer Publishing Company, Incorporated}},
  url = {http://dl.acm.org/citation.cfm?id=1535416},
  urldate = {2014-01-27},
  isbn = {3-540-71550-9 978-3-540-71550-4}
}

@book{Schlegel2018,
  title = {Medizinische Physik: Grundlagen – Bildgebung – Therapie – Technik},
  shorttitle = {Medizinische Physik},
  editor = {Schlegel, Wolfgang and Karger, Christian P. and Jäkel, Oliver},
  date = {2018},
  publisher = {{Springer Spektrum}},
  doi = {10.1007/978-3-662-54801-1},
  url = {https://www.springer.com/de/book/9783662548004},
  urldate = {2021-06-24},
  abstract = {Das vorliegende Werk bietet eine im deutschsprachigen Raum einzigartige, umfassende und aktuelle Darstellung der Medizinischen Physik. Es liefert damit das Fundament für die Anwendung physikalischer Methoden in der Medizin, der Entwicklung neuer oder verbesserter Verfahren zur Untersuchung und Behandlung von Patienten sowie für die Bereitstellung und den Einsatz physikalischer Methoden in der klinischen Anwendung. Es unterstützt als Lehrbuch den Bedarf nach einer systematischen medizinphysikalischen Aus- und Weiterbildung von Physikern, die an medizinischen Einrichtungen tätig sind.Das Buch orientiert sich am Stoffkatalog der Deutschen Gesellschaft für Medizinische Physik (DGMP) und legt den Schwerpunkt auf die Medizinische Physik in der Radiologie und Radioonkologie. Das Werk ist in fünf Teile unterteilt:· In Teil I werden die Grundlagen der Strahlenphysik, der biostatistischen Methoden, der Medizinischen Informatik, der organisatorischen und rechtlichen Aspekte sowie des Strahlenschutzes abgehandelt. · Teil II behandelt die radiologische Diagnostik und umfasst die bildgebenden Verfahren der Röntgendiagnostik, der Röntgen-Computertomographie, der Magnetresonanztomographie sowie des Ultraschalls. · Teil III beschreibt die Methoden der nuklearmedizinischen Diagnostik und Therapie. · In Teil IV wird die Medizinische Physik der Strahlentherapie in vertiefter Form dargestellt. · Teil V beschreibt ausgewählte Themen aus dem Gebiet der Medizintechnik. Zu allen Teilen werden Übungsaufgaben und Kontrollfragen angeboten, mit denen der Leser das Gelernte überprüfen kann. Ergänzend werden auf einer Website Musterlösungen, zusätzliches vertiefendes Text- und Bildmaterial sowie Animationen und Videos zur Verfügung gestellt. Das Buch versteht sich als Lehrbuch und Nachschlagewerk, das begleitend zu Weiterbildungsveranstaltungen und Studiengängen oder auch zum Selbststudium auf dem Gebiet der Medizinischen Physik eingesetzt werden kann. Es basiert auf dem Heidelberger Weiterbildungskurs „Medizinische Physik für Physiker“ und richtet sich vornehmlich an Physik-Absolventen und Naturwissenschaftler mit grundlegenden physikalischen Kenntnissen. Die Herausgeber sind als Wissenschaftler am Deutschen Krebsforschungszentrum (dkfz) tätig und lehren als Professoren für Medizinische Physik an der Universität Heidelberg.},
  isbn = {978-3-662-54800-4},
  langid = {ngerman},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\LWDW7KGS\\9783662548004.html}
}

@book{Schmidt-Aßmann2013,
  title = {Besonderes {{Verwaltungsrecht}}},
  author = {Schmidt-Aßmann, Eberhard and Schoch, Friedrich and Breuer, Rüdiger and Huber, Peter M.},
  date = {2013},
  publisher = {{De Gruyter Recht}},
  abstract = {15. Aufl.},
  isbn = {978-3-11-027363-2}
}

@article{Schneider1995,
  title = {Proton radiography as a tool for quality control in proton therapy},
  author = {Schneider, Uwe and Pedroni, Eros},
  date = {1995},
  journaltitle = {Medical Physics},
  volume = {22},
  number = {4},
  pages = {353--363},
  issn = {2473-4209},
  doi = {10.1118/1.597470},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.597470},
  urldate = {2020-04-03},
  abstract = {Proton radiography is investigated for its use as a quality control tool in proton therapy. Images were produced both with range and range uncertainty information of protons passing through phantoms (Alderson phantom and a sheep's head). With the range images the correct positioning of the patient with respect to the beam could be verified. The range uncertainty images were used to quantitatively detect range variations of protons passing through inhomogeneities in the patient. These measurements can be used to indicate critical situations during proton therapy or to determine the safety margin around the tumor volume. With the range information the precision of different calibrations of computer tomography Hounsfield values to relative proton stopping power, used for proton treatment planning, was determined. It is found that the precision in range can be improved by a detailed analysis of the calibration data obtained from tissue-substitute measurements, by a factor of 2.5. The resulting range errors are in the order of the positioning precision (∼1 mm).},
  langid = {english},
  keywords = {87.53.08.a,87.53.10.j,87.56.05,BIOMEDICAL RADIOGRAPHY,Calibration,CALIBRATION,Cancer,Computed radiography,Computer science and technology,Dosimetry/exposure assessment,Medical imaging,Medical radiation safety,PROTON COMPUTED TOMOGRAPHY,PROTON DOSIMETRY,Proton therapy,Protons,Quality assurance,QUALITY CONTROL,Radiography,RADIOTHERAPY,RANGE,SPATIAL DOSE DISTRIBUTIONS,Tomography,Treatment strategy,USES},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\9P95YZJV\\1.html}
}

@article{Schneider1996,
  title = {The calibration of {{CT Hounsfield}} units for radiotherapy treatment planning},
  author = {Schneider, Uwe and Pedroni, Eros and Lomax, Antony},
  date = {1996-01},
  journaltitle = {Physics in Medicine \& Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {41},
  number = {1},
  pages = {111},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/41/1/009},
  url = {https://dx.doi.org/10.1088/0031-9155/41/1/009},
  urldate = {2022-12-01},
  abstract = {Computer tomographic (CT) scans are used to correct for tissue inhomogeneities in radiotherapy treatment planning. In order to guarantee a precise treatment, it is important to obtain the relationship between CT Hounsfield units and electron densities (or proton stopping powers for proton radiotherapy), which is the basic input for radiotherapy planning systems which consider tissue heterogeneities. A method is described to determine improved CT calibrations for biological tissue (a stoichiometric calibration) based on measurements using tissue equivalent materials. The precision of this stoichiometric calibration and the more usual tissue substitute calibration is determined by a comparison of calculated proton radiographic images based on these calibrations and measured radiographs of a biological sample. It has been found that the stoichiometric calibration is more precise than the tissue substitute calibration.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\5N676D9Q\\Schneider et al. - 1996 - The calibration of CT Hounsfield units for radioth.pdf}
}

@article{Schneider2000,
  title = {Correlation between {{CT}} numbers and tissue parameters needed for {{Monte Carlo}} simulations of clinical dose distributions},
  author = {Schneider, Wilfried and Bortfeld, Thomas and Schlegel, Wolfgang},
  date = {2000-02-01},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {45},
  number = {2},
  pages = {459--478},
  issn = {0031-9155, 1361-6560},
  doi = {10.1088/0031-9155/45/2/314},
  url = {https://iopscience.iop.org/article/10.1088/0031-9155/45/2/314},
  urldate = {2021-03-10},
  abstract = {We describe a new method to convert CT numbers into mass density and elemental weights of tissues required as input for dose calculations with Monte Carlo codes such as EGS4. As a first step, we calculate the CT numbers for 71 human tissues. To reduce the effort for the necessary fits of the CT numbers to mass density and elemental weights, we establish four sections on the CT number scale, each confined by selected tissues. Within each section, the mass density and elemental weights of the selected tissues are interpolated. For this purpose, functional relationships between the CT number and each of the tissue parameters, valid for media which are composed of only two components in varying proportions, are derived. Compared with conventional data fits, no loss of accuracy is accepted when using the interpolation functions. Assuming plausible values for the deviations of calculated and measured CT numbers, the mass density can be determined with an accuracy better than 0.04 g cm−3. The weights of phosphorus and calcium can be determined with maximum uncertainties of 1 or 2.3 percentage points (pp) respectively. Similar values can be achieved for hydrogen (0.8 pp) and nitrogen (3 pp). For carbon and oxygen weights, errors up to 14 pp can occur. The influence of the elemental weights on the results of Monte Carlo dose calculations is investigated and discussed.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\N7SJ8IC2\\Schneider et al. - 2000 - Correlation between CT numbers and tissue paramete.pdf}
}

@article{Scholz1996,
  ids = {Scholz1996a},
  title = {Track structure and the calculation of biological effects of heavy charged particles},
  author = {Scholz, M. and Kraft, G.},
  date = {1996-01},
  journaltitle = {Advances in Space Research},
  shortjournal = {Advances in Space Research},
  volume = {18},
  number = {1-2},
  pages = {5--14},
  issn = {02731177},
  doi = {10.1016/0273-1177(95)00784-C},
  url = {https://linkinghub.elsevier.com/retrieve/pii/027311779500784C},
  urldate = {2020-11-20},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\QYYFF6UF\\Scholz und Kraft - 1996 - Track structure and the calculation of biological .pdf;C\:\\Users\\Niklas\\Zotero\\storage\\RSF5X6E7\\Scholz und Kraft - 1996 - Track structure and the calculation of biological .pdf}
}

@article{Schreiber2006,
  title = {{{SU-FF-T-362}}: {{PLanUNC}} as {{An Open-Source Radiotherapy Planning System}} for {{Research}} and {{Education}}},
  author = {Schreiber, E. and Xu, Z. and Lorenzen, A. and Foskey, M. and Cullip, T. and Tracton, G. and Chaney, E.},
  date = {2006},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {33},
  number = {6},
  pages = {2129--2129},
  issn = {2473-4209},
  doi = {10.1118/1.2241282},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.2241282},
  urldate = {2019-09-11},
  abstract = {Purpose: PLanUNC is a radiotherapy planning software package that has been under development and clinical use at the University of North Carolina for approximately 20 years. Under a joint grant from the NCRR and NCI (R01 RR 018615), PLanUNC has been documented, commented, and prepared for distribution as a freely available open-source treatment planning tool for use as an adaptable and common platform for radiotherapy research. Method and Materials: The software and source code have been made available to qualifying users through a web portal located at http://planunc.radonc.unc.edu. Licenses for PLanUNC are available without fee to institutions, departments, and other facilities engaged in research and education involving radiation therapy. Results: Recent research milestones demonstrating the extensibility and increasing utility of PLanUNC include tools for 4D planning, interfaces with ITK segmentation and registration tools, daily correction of patient positioning, and interfaces with a variety of Monte Carlo dose engines. PLanUNC is currently supported for Linux and Windows operating systems, but has been successfully compiled on Alpha, Macintosh, Solaris, and other platforms. Conclusion: Licensed users will have access to PLanUNC source code, user and development documentation, annual training workshops, and limited support from UNC and the PLanUNC research community. PLanUNC is distributed as source code, making it customizable and extensible to meet the needs of a diverse range of research applications.},
  langid = {english},
  keywords = {Dosimetry,Educational computer software,Medical treatment planning,Radiation therapy,Radiotherapy sources},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\I6AG5R89\\1.html}
}

@article{Schrenk2017,
  title = {Effects of magnetic field orientation and strength on the treatment planning of nonsmall cell lung cancer},
  author = {Schrenk, Oliver and Spindeldreier, Claudia Katharina and Burigo, Lucas Norberto and Hoerner‐Rieber, Juliane and Pfaffenberger, Asja},
  date = {2017},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {44},
  number = {12},
  pages = {6621--6631},
  issn = {2473-4209},
  doi = {10.1002/mp.12631},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.12631},
  urldate = {2019-10-25},
  abstract = {Purpose Magnetic resonance image-guided radiotherapy (MRgRT) has the potential to increase the accuracy of radiation treatment delivery. Several research groups have developed hybrid MRgRT devices differing by radiation source used and magnetic field orientation and strength. In this work, we investigate the impact of different magnetic field orientations and strengths on the treatment planning of nonsmall cell lung cancer patients (NSCLC). Methods A framework using the in-house developed treatment planning system matRad and the EGSnrc Monte Carlo code system was introduced to perform Monte Carlo-based treatment planning in the presence of a magnetic field. A specialized spectrum-based source model for the beam qualities of 6 MV and cobalt-60 was applied. Optimized plans for stereotactic body radiation therapy (SBRT) and intensity-modulated radiation therapy (IMRT) were generated for four NSCLC patients in the presence of different magnetic field orientations and strengths which are applied in hybrid MRgRT devices currently under development or in clinical use. Results SBRT and IMRT treatment planning could be performed with consistent plan quality for all magnetic field setups. Only minor effects on the treatment planning outcome were found in the case of magnetic fields orientated perpendicular to the beam direction. Compared to the perpendicular magnetic field orientation, the inline orientation showed the capability to reduce the dose to lung while maintaining equal target coverage. Particularly for tumors with a central position in lung, a distinct dose reduction was obtained which led to a maximum reduction of mean lung dose by 18.5\% (0.5 Gy), when applying a 1 T inline magnetic field. Conclusion All plans generated in this work obtained dose metrics within clinical constraints according to RTOG guidelines. When considering conventional dose metrics, no detrimental effects due to the magnetic fields were observed on the dose to the tumor or to organs at risk. An evaluation of the effects on skin dose was not ascertainable due to the simplified specification of the source model used. By accounting for the magnetic field during treatment planning, a dose reduction in lung could be achieved for inline-oriented magnetic fields. An inline orientation of the magnetic field therefore showed a potential benefit when treating NSCLC with MRgRT.},
  langid = {english},
  keywords = {IMRT,Monte Carlo,MRgRT,SBRT},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\38B4JTDI\\Schrenk et al. - 2017 - Effects of magnetic field orientation and strength.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\CG2R5HTT\\mp.html}
}

@software{Schroeder2005,
  title = {The {{ITK Software Guide Second Edition Updated}} for {{ITK}} version 2 . 4},
  author = {Ibáñez, Luis and Schroeder, Will and Ng, Lydia and Cates, Josh and {Insight Software Consrotium}},
  date = {2005},
  journaltitle = {FEBS Letters},
  volume = {525},
  eprint = {1000070720},
  eprinttype = {pmid},
  issn = {10445323},
  doi = {10.1016/S0014-5793(02)03066-1},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.127.2199},
  abstract = {The Insight Toolkit (ITK) is an open-source software toolkit for performing registration and segmentation. Segmentation is the process of identifying and classifying data found in a digi- tally sampled representation. Typically the sampled representation is an image acquired from suchmedical instrumentation as CT orMRI scanners. Registration is the task of aligning or de- veloping correspondences between data. For example, in the medical environment, a CT scan may be aligned with aMRI scan in order to combine the information contained in both. ITK is implemented in C++. It is cross-platform, using a build environment known as CMake to manage the compilation process in a platform-independent way. In addition, an automated wrapping process (Cable) generates interfaces between C++ and interpreted programming lan- guages such as Tcl, Java, and Python. This enables developers to create software using a variety of programming languages. ITKs C++ implementation style is referred to as generic program- ming, which is to say that it uses templates so that the same code can be applied generically to any class or type that happens to support the operations used. Such C++ templating means that the code is highly efficient, and that many software problems are discovered at compile-time, rather than at run-time during programexecution. Because ITKis an open-source project, developers fromaround theworld can use, debug,main- tain, and extend the software. ITKuses amodel of software development referred to as Extreme Programming. Extreme Programming collapses the usual software creation methodology into a simultaneous and iterative process of design-implement-test-release. The key features of Ex- treme Programming are communication and testing. Communication among the members of the ITK community is what helps manage the rapid evolution of the software. Testing is what keeps the software stable. In ITK, an extensive testing process (using a system known as Dart) is in place that measures the quality on a daily basis. The ITK Testing Dashboard is posted continuously, reflecting the quality of the software at any moment. This book is a guide to using and developing with ITK. The sample code in the directory pro- vides a companion to the material presented here. The most recent version of this document is available online at http://www.itk.org/ItkSoftwareGuide.pdf.},
  archiveprefix = {arXiv},
  isbn = {1-930934-15-7},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\I3WKSAG6\\Ibáñez et al. - 2005 - The ITK Software Guide Second Edition Updated for ITK version 2 . 4.pdf}
}

@article{Schulte2004,
  title = {Conceptual design of a proton computed tomography system for applications in proton radiation therapy},
  author = {Schulte, R. and Bashkirov, V. and Tianfang Li and Zhengrong Liang and Mueller, K. and Heimann, J. and Johnson, L.R. and Keeney, B. and Sadrozinski, H.F.-W. and Seiden, A. and Williams, D.C. and Lan Zhang and Zhang Li and Peggs, S. and Satogata, T. and Woody, C.},
  date = {2004-06},
  journaltitle = {IEEE Transactions on Nuclear Science},
  volume = {51},
  number = {3},
  pages = {866--872},
  issn = {1558-1578},
  doi = {10.1109/TNS.2004.829392},
  abstract = {Proton computed tomography (pCT) has the potential to improve the accuracy of dose calculations for proton treatment planning, and will also be useful for pretreatment verification of patient positioning relative to the proton beam. A design study was performed to define the optimal approach to a pCT system based on specifications for applications in proton therapy. Conceptual and detailed design of a pCT system is presented; the system consists of a silicon-based particle tracking system and a crystal calorimeter to measure energy loss of individual protons. We discuss the formation of pCT images based on the reconstruction of volume electron density maps and the suitability of analytic and statistical algorithms for image reconstruction.},
  keywords = {Accuracy,analytic algorithm,biological effects of ionising particles,Biomedical applications of radiation,Computed tomography,computerised tomography,crystal calorimeter,dose calculation,dosimetry,energy loss of particles,Energy measurement,GEANT4 method,image reconstruction,Image reconstruction,Loss measurement,Medical treatment,Monte Carlo methods,optimal approach,Particle beams,particle calorimetry,particle track visualisation,Particle tracking,patient position,position sensitive particle detectors,pretreatment verification,proton beam,proton beams,proton computed tomography system,proton energy loss,proton radiation therapy,proton treatment planning,Protons,radiation therapy,silicon radiation detectors,silicon-based particle tracking system,statistical algorithm,volume electron density map},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\6VQAQ93M\\1311983.html}
}

@article{Schulte2008,
  title = {A maximum likelihood proton path formalism for application in proton computed tomography},
  author = {Schulte, R. W. and Penfold, S. N. and Tafas, J. T. and Schubert, K. E.},
  date = {2008},
  journaltitle = {Medical Physics},
  volume = {35},
  number = {11},
  pages = {4849--4856},
  issn = {2473-4209},
  doi = {10.1118/1.2986139},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.2986139},
  urldate = {2020-04-03},
  abstract = {The limited spatial resolution in proton computed tomography (pCT) in comparison to x-ray CT is related to multiple Coulomb scattering (MCS) within the imaged object. The current generation pCT design utilizes silicon detectors that measure the position and direction of individual protons prior to and post-traversing the patient to maximize the knowledge of the path of the proton within the imaged object. For efficient reconstruction with the proposed pCT system, one needs to develop compact and flexible mathematical formalisms that model the effects of MCS as the proton traverses the imaged object. In this article, a compact, matrix-based most likely path (MLP) formalism is presented employing Bayesian statistics and a Gaussian approximation of MCS. Using GEANT4 simulations in a homogeneous water cube, the MLP expression was found to be able to predict the Monte Carlo tracks of protons to within on average when employing cuts on the relative exit angle and exit energy. These cuts were found to eliminate the majority of events not conforming to the Gaussian model of MCS used in the MLP derivation.},
  langid = {english},
  keywords = {Collisional energy loss,Computed tomography,computerised tomography,Elastic collisions,Image reconstruction,Medical image reconstruction,Medical image spatial resolution,Medical imaging,most likely path formalism,Multiple scattering,Optical microcavities,Proton computed tomography,Protons,spatial resolution,Spatial resolution,statistics},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\88EVNRNW\\Schulte et al. - 2008 - A maximum likelihood proton path formalism for app.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\JCDJRF4F\\1.html}
}

@article{Schultze2020,
  title = {An {{Improved Method}} of {{Total Variation Superiorization Applied}} to {{Reconstruction}} in {{Proton Computed Tomography}}},
  author = {Schultze, Blake and Censor, Yair and Karbasi, Paniz and Schubert, Keith E. and Schulte, Reinhard W.},
  date = {2020-02},
  journaltitle = {IEEE Transactions on Medical Imaging},
  volume = {39},
  number = {2},
  pages = {294--307},
  issn = {1558-254X},
  doi = {10.1109/TMI.2019.2911482},
  abstract = {Previous work has shown that total variation superiorization (TVS) improves reconstructed image quality in proton computed tomography (pCT). The structure of the TVS algorithm has evolved since then and this paper investigated if this new algorithmic structure provides additional benefits to pCT image quality. Structural and parametric changes introduced to the original TVS algorithm included: (1) inclusion or exclusion of TV reduction requirement, (2) a variable number, N, of TV perturbation steps per feasibility-seeking iteration, and (3) introduction of a perturbation kernel 0 {$<$}; α {$<$}; 1. The structural change of excluding the TV reduction requirement check tended to have a beneficial effect for 3 ≤ N ≤ 6 and allows full parallelization of the TVS algorithm. Repeated perturbations per feasibility-seeking iterations reduced total variation (TV) and material dependent standard deviations for 3 ≤ N ≤ 6. The perturbation kernel α, effectively equal to α = 0.5 in the original TVS algorithm, reduced TV and standard deviations as α was increased beyond α = 0.5, but negatively impacted reconstructed relative stopping power (RSP) values for α {$>$} 0.75. The reductions in TV and standard deviations allowed feasibility-seeking with a larger relaxation parameter λ than previously used, without the corresponding increases in standard deviations experienced with the original TVS algorithm. This paper demonstrates that the modifications related to the evolution of the original TVS algorithm provide benefits in terms of both pCT image quality and computational efficiency for appropriately chosen parameter values.},
  eventtitle = {{{IEEE Transactions}} on {{Medical Imaging}}},
  keywords = {Computed tomography,Feasibility-seeking algorithms,Image quality,image reconstruction,Image reconstruction,Perturbation methods,perturbations,proton computed tomography (pCT),Protons,Standards,superiorization,total variation superiorization (TVS),TV},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\M6Y8XXY3\\Schultze et al. - 2020 - An Improved Method of Total Variation Superiorizat.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\8X94K7TL\\8692608.html}
}

@article{Schulz-Ertner2007,
  title = {Particle {{Radiation Therapy Using Proton}} and {{Heavier Ion Beams}}},
  author = {Schulz-Ertner, Daniela and Tsujii, Hirohiko},
  date = {2007-03-10},
  journaltitle = {Journal of Clinical Oncology},
  volume = {25},
  number = {8},
  eprint = {17350944},
  eprinttype = {pmid},
  pages = {953--964},
  issn = {0732-183X},
  doi = {10.1200/JCO.2006.09.7816},
  url = {http://ascopubs.org/doi/10.1200/JCO.2006.09.7816},
  abstract = {Particle beams like protons and heavier ions offer improved dose distributions\textbackslash ncompared with photon (also called x-ray) beams and thus enable dose\textbackslash nescalation within the tumor while sparing normal tissues. Although\textbackslash nprotons have a biologic effectiveness comparable to photons, ions,\textbackslash nbecause they are heavier than protons, provide a higher biologic\textbackslash neffectiveness. Recent technologic developments in the fields of accelerator\textbackslash nengineering, treatment planning, beam delivery, and tumor visualization\textbackslash nhave stimulated the process of transferring particle radiation therapy\textbackslash n(RT) from physics laboratories to the clinic. This review describes\textbackslash nthe physical, biologic, and technologic aspects of particle beam\textbackslash ntherapy. Clinical trials investigating proton and carbon ion RT will\textbackslash nbe summarized and discussed in the context of their relevance to\textbackslash nrecent concepts of treatment with RT.},
  isbn = {0732-183X},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\69EJ2ZP4\\Schulz-Ertner, Tsujii - 2007 - Particle Radiation Therapy Using Proton and Heavier Ion Beams.pdf}
}

@article{Schwaab2011,
  title = {Experimental characterization of lateral profiles of scanned proton and carbon ion pencil beams for improved beam models in ion therapy treatment planning},
  author = {Schwaab, J and Brons, S and Fieres, J and Parodi, K},
  date = {2011-12-21},
  journaltitle = {Physics in Medicine and Biology},
  volume = {56},
  number = {24},
  pages = {7813--7827},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/56/24/009},
  url = {http://stacks.iop.org/0031-9155/56/i=24/a=7813?key=crossref.5e369ab79e9b6c9990f26ce57a13abc6},
  urldate = {2018-04-02}
}

@article{Scott2012,
  title = {Characterizing the influence of detector density on dosimeter response in non-equilibrium small photon fields.},
  author = {Scott, Alison J D and Kumar, Sudhir and Nahum, Alan E and Fenwick, John D},
  date = {2012-07-21},
  journaltitle = {Physics in medicine and biology},
  volume = {57},
  number = {14},
  eprint = {22722374},
  eprinttype = {pmid},
  pages = {4461--76},
  publisher = {{IOP Publishing}},
  issn = {1361-6560},
  doi = {10.1088/0031-9155/57/14/4461},
  url = {http://iopscience.iop.org/0031-9155/57/14/4461/article/},
  urldate = {2014-01-24},
  abstract = {The impact of density and atomic composition on the dosimetric response of various detectors in small photon radiation fields is characterized using a 'density-correction' factor, F(detector), defined as the ratio of Monte Carlo calculated doses delivered to water and detector voxels located on-axis, 5~cm deep in a water phantom with a SSD of 100~cm. The variation of F(detector)~with field size has been computed for detector voxels of various materials and densities. For ion chambers and solid-state detectors, the well-known variation of F(detector)~at small field sizes is shown to be due to differences between the densities of detector active volumes and water, rather than differences in atomic number. However, associated changes in the measured shapes of small-field profiles offset these variations in F(detector), so that integral doses measured using the different detectors are quite similar, at least for slit fields. Since changes in F(detector)~with field size arise primarily from differences between the densities of the detector materials and water, ideal small-field relative dosimeters should have small active volumes and water-like density.},
  langid = {english},
  keywords = {Diamond,Photons,Radiometry,Radiometry: methods,Silicon,Water},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\PMQFBFXS\\Scott et al. - 2012 - Characterizing the influence of detector density on dosimeter response in non-equilibrium small photon fields.pdf}
}

@article{Seco2009,
  title = {Breathing interplay effects during proton beam scanning: simulation and statistical analysis},
  shorttitle = {Breathing interplay effects during proton beam scanning},
  author = {Seco, Joao and Robertson, Daniel and Trofimov, Alexei and Paganetti, Harald},
  date = {2009-06},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {54},
  number = {14},
  pages = {N283--N294},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/54/14/N01},
  url = {https://doi.org/10.1088%2F0031-9155%2F54%2F14%2Fn01},
  urldate = {2020-03-25},
  abstract = {Treatment delivery with active beam scanning in proton radiation therapy introduces the problem of interplay effects when pencil beam motion occurs on a similar time scale as intra-fractional tumor motion. In situations where fractionation may not provide enough repetition to blur the effects of interplay, repeated delivery or ‘repainting’ of each field several times within a fraction has been suggested. The purpose of this work was to investigate the effectiveness of different repainting strategies in proton beam scanning. To assess the dosimetric impact of interplay effects, we performed a series of simulations considering the following parameters: tumor motion amplitude, breathing period, asymmetry in the motion trajectory for the target and time required to change the beam energy for the delivery system. Several repainting strategies were compared in terms of potential vulnerability to a dose delivery error. Breathing motion perpendicular to the beam direction (representing superior–inferior type tumor motion in patients) was considered and modeled as an asymmetric sine function with a peak-to-peak amplitude of between 10 and 30 mm. The results show that motion effects cause a narrowing of the high-dose profile and widening of the penumbra. The 90\% isodose area was reduced significantly when considering a large motion amplitude of 3 cm. The broadening of the penumbra appears to depend only on the amplitude of tumor motion (assuming harmonic motion). The delivered dose exhibits a shift of 10–15\% of the tumor amplitude (or 1–5 mm) in the caudal direction due to breathing asymmetry observed for both sin4(x) and sin6(x) motion. Of the five repainting techniques studied, so-called ‘breath sampling’ turned out to be most effective in reducing dose errors with a minimal increase in treatment time. In this method, each energy level is repainted at several evenly spaced times within one breathing period. To keep dose delivery errors below 5\% while minimizing treatment time, it is recommended that breath sampling repainting be employed using 5–10 paintings per field for an assumed tumor volume of 8.5 × 8.5 × 10 cm3. For smaller tumor volumes more repaintings will be required, while for larger volumes five repaintings should be sufficient to achieve the required dose accuracy.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\LQ8WS9E9\\Seco et al. - 2009 - Breathing interplay effects during proton beam sca.pdf}
}

@book{Seco2016,
  title = {Monte {{Carlo Techniques}} in {{Radiation Therapy}}},
  author = {Seco, Joao and Verhaegen, Frank},
  date = {2016-04-19},
  eprint = {CDnSBQAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{Taylor \& Francis}},
  abstract = {Modern cancer treatment relies on Monte Carlo simulations to help radiotherapists and clinical physicists better understand and compute radiation dose from imaging devices as well as exploit four-dimensional imaging data. With Monte Carlo-based treatment planning tools now available from commercial vendors, a complete transition to Monte Carlo-base},
  isbn = {978-1-4665-0794-4},
  langid = {english},
  pagetotal = {334},
  keywords = {Mathematics / General,Medical / Oncology,Science / Physics / General,Technology & Engineering / Biomedical}
}

@misc{Shepard,
  title = {{{IMRT Optimization Algorithms}}},
  author = {Shepard, David},
  publisher = {{AAPM}},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\KIHCE2NV\\Shepard - Unknown - IMRT Optimization Algorithms.pdf}
}

@article{Shi2013,
  title = {Order statistics for correlated random variables and its application to at-speed testing},
  author = {Shi, Yiyu and Xiong, Jinjun and Zolotov, Vladimir and Visweswariah, Chandu},
  date = {2013-07-01},
  journaltitle = {ACM Transactions on Design Automation of Electronic Systems},
  volume = {18},
  number = {3},
  pages = {1--20},
  issn = {10844309},
  doi = {10.1145/2491477.2491486},
  url = {http://dl.acm.org/citation.cfm?doid=2491477.2491486},
  isbn = {1084-4309},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\WRB8YXX6\\Shi et al. - 2013 - Order statistics for correlated random variables and its application to at-speed testing.pdf}
}

@article{Shipley1979,
  title = {Proton radiation as boost therapy for localized prostatic carcinoma.},
  author = {Shipley, W U and Tepper, J E and Prout, G R and Verhey, L J and Mendiondo, O A and Goitein, M and Koehler, A M and Suit, H D},
  date = {1979},
  journaltitle = {JAMA : the journal of the American Medical Association},
  volume = {241},
  number = {18},
  eprint = {107338},
  eprinttype = {pmid},
  pages = {1912--1915},
  issn = {00987484},
  doi = {10.1001/jama.241.18.1912},
  abstract = {A 160-MeV proton beam has been modified to irradiate patients with localized tumors by using convention treatment schedules. This proton beam has the physical advantage of megavoltage x-rays of reducing the radiation dose to normal tissues adjacent to the tumor volume. A perineal proton technique used as boost therapy (2,000 to 2,500 rads) was evaluated in the definitive irradiation of 17 patients with localized prostatic carcinoma. This technique allows repeated daily treatment of the carefully defined target volume with a precision of +/- 2 mm. Total dose to the prostatic tumor, but not to the posterior rectum, has been increased by 500 to 700 rads. After 12 to 27 months of observation, no noteworthy rectal reaction has developed in a patient, easily managed urethral strictures have developed in two patients, and all but one are locally controlled.}
}

@article{Shou2005,
  title = {Quantitation of the a priori dosimetric capabilities of spatial points in inverse planning and its significant implication in defining {{IMRT}} solution space.},
  author = {Shou, Z and Yang, Y and Cotrutz, C and Levy, D and Xing, Lei},
  date = {2005-04-07},
  journaltitle = {Physics in medicine and biology},
  volume = {50},
  number = {7},
  eprint = {15798337},
  eprinttype = {pmid},
  pages = {1469--82},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/50/7/010},
  url = {http://iopscience.iop.org/0031-9155/50/7/010},
  urldate = {2014-07-29},
  abstract = {In inverse planning, the likelihood for the points in a target or sensitive structure to meet their dosimetric goals is generally heterogeneous and represents the a priori knowledge of the system once the patient and beam configuration are chosen. Because of this intrinsic heterogeneity, in some extreme cases, a region in a target may never meet the prescribed dose without seriously deteriorating the doses in other areas. Conversely, the prescription in a region may be easily met without violating the tolerance of any sensitive structure. In this work, we introduce the concept of dosimetric capability to quantify the a priori information and develop a strategy to integrate the data into the inverse planning process. An iterative algorithm is implemented to numerically compute the capability distribution on a case specific basis. A method of incorporating the capability data into inverse planning is developed by heuristically modulating the importance of the individual voxels according to the a priori capability distribution. The formalism is applied to a few specific examples to illustrate the technical details of the new inverse planning technique. Our study indicates that the dosimetric capability is a useful concept to better understand the complex inverse planning problem and an effective use of the information allows us to construct a clinically more meaningful objective function to improve IMRT dose optimization techniques.},
  langid = {english},
  keywords = {Algorithms,Body Burden,Computer Simulation,Humans,Male,Models; Biological,Prostatic Neoplasms,Prostatic Neoplasms: physiopathology,Prostatic Neoplasms: radiotherapy,Radiometry,Radiometry: methods,Radiotherapy Dosage,Radiotherapy Planning; Computer-Assisted,Radiotherapy Planning; Computer-Assisted: methods,Radiotherapy; Conformal,Radiotherapy; Conformal: methods,Relative Biological Effectiveness}
}

@article{Siddon1985,
  title = {Fast calculation of the exact radiological path for a three-dimensional {{CT}} array},
  author = {Siddon, Robert L.},
  date = {1985},
  journaltitle = {Medical Physics},
  volume = {12},
  number = {2},
  pages = {252},
  publisher = {{American Association of Physicists in Medicine}},
  issn = {00942405},
  doi = {10.1118/1.595715},
  url = {http://scitation.aip.org/content/aapm/journal/medphys/12/2/10.1118/1.595715},
  urldate = {2016-11-15},
  abstract = {Ready availability has prompted the use of computed tomography(CT) data in various applications in radiation therapy. For example, some radiation treatment planning systems now utilize CT data in heterogeneous dose calculation algorithms. In radiotherapyimaging applications, CT data are projected onto specified planes, thus producing ‘‘radiographs,’’ which are compared with simulator radiographs to assist in proper patient positioning and delineation of target volumes. All these applications share the common geometric problem of evaluating the radiological path through the CT array. Due to the complexity of the three‐dimensional geometry and the enormous amount of CT data, the exact evaluation of the radiological path has proven to be a time consuming and difficult problem. This paper identifies the inefficient aspect of the traditional exact evaluation of the radiological path as that of treating the CT data as individual voxels. Rather than individual voxels, a new exact algorithm is presented that considers the CT data as consisting of the intersection volumes of three orthogonal sets of equally spaced, parallel planes. For a three‐dimensional CT array of N 3 voxels, the new exact algorithm scales with 3N, the number of planes, rather than N 3, the number of voxels. Coded in fortran‐77 on a VAX 11/780 with a floating point option, the algorithm requires approximately 5 ms to calculate an average radiological path in a 1003 voxel array.}
}

@article{Siggel2012,
  title = {Boosting runtime-performance of photon pencil beam algorithms for radiotherapy treatment planning},
  author = {Siggel, M and Ziegenhein, P. and Nill, S. and Oelfke, U.},
  date = {2012},
  journaltitle = {Physica Medica},
  volume = {28},
  number = {4},
  eprint = {22071169},
  eprinttype = {pmid},
  pages = {273--280},
  publisher = {{Elsevier}},
  issn = {11201797},
  doi = {10.1016/j.ejmp.2011.10.004},
  abstract = {Pencil beam algorithms are still considered as standard photon dose calculation methods in Radiotherapy treatment planning for many clinical applications. Despite their established role in radiotherapy planning their performance and clinical applicability has to be continuously adapted to evolving complex treatment techniques such as adaptive radiation therapy (ART). We herewith report on a new highly efficient version of a well-established pencil beam convolution algorithm which relies purely on measured input data. A method was developed that improves raytracing efficiency by exploiting the capability of modern CPU architecture for a runtime reduction. Since most of the current desktop computers provide more than one calculation unit we used symmetric multiprocessing extensively to parallelize the workload and thus decreasing the algorithmic runtime. To maximize the advantage of code parallelization, we present two implementation strategies - one for the dose calculation in inverse planning software, and one for traditional forward planning. As a result, we could achieve on a 16-core personal computer with AMD processors a superlinear speedup factor of approx. 18 for calculating the dose distribution of typical forward IMRT treatment plans.},
  keywords = {Dose calculation,IMRT,Parallelization,Radiotherapy,Speedup},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\DL4JJ55G\\Siggel et al. - 2012 - Boosting runtime-performance of photon pencil beam algorithms for radiotherapy treatment planning.pdf}
}

@article{Simoni2020,
  title = {{{FRED}}: a fast {{Monte Carlo}} code on {{GPU}} for quality control in {{Particle Therapy}}},
  shorttitle = {{{FRED}}},
  author = {Simoni, M. De and Fischetti, M. and Gioscio, E. and Marafini, M. and Mirabelli, R. and Patera, V. and Sarti, A. and Schiavi, A. and Sciubba, A. and Traini, G.},
  date = {2020-05},
  journaltitle = {Journal of Physics: Conference Series},
  shortjournal = {J. Phys.: Conf. Ser.},
  volume = {1548},
  number = {1},
  pages = {012020},
  publisher = {{IOP Publishing}},
  issn = {1742-6596},
  doi = {10.1088/1742-6596/1548/1/012020},
  url = {https://doi.org/10.1088/1742-6596/1548/1/012020},
  urldate = {2022-05-17},
  abstract = {Charged Particle Therapy is a non-invasive technique for radio-resistant tumor treatment performed with protons or light ions, aiming to deliver a high precision treatment. Compared to conventional radiotherapy, ions allow for a higher dose deposition in the tumor region while sparing the surrounding healthy tissue. To really exploit the potential benefits of this technique, the highest possible accuracy in the calculation of dose and its spatial distribution is required in treatment planning. Commonly used Treatment Planning Software solutions adopt a simplified beam-body interaction model. An alternative is the use of Monte Carlo simulations which explicitly take into account the interaction of charged particles with actual human tissues hence providing highly accurate results. However, Monte Carlo simulations are used in a restricted number of cases due to substantial computational resources required. The code FRED has been developed to allow a fast optimization of the treatment plans in Charged Particle Therapy while profiting from the dose release accuracy of a Monte Carlo tool. Currently, the most refined module is the transport of proton beams in water. A comparison with measurements shows that the lateral dose tails are reproduced within 2\% in the field size factor test up to 20 cm. Models for the interaction of ion with the matter are currently under development in the FRED code. The status of new developments and the performance of FRED will be presented.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\A5CLT3WA\\Simoni et al. - 2020 - FRED a fast Monte Carlo code on GPU for quality c.pdf}
}

@inproceedings{Sinha2006,
  title = {Advances in {{Computation}} of the {{Maximum}} of a {{Set}} of {{Random Variables}}},
  booktitle = {7th {{International Symposium}} on {{Quality Electronic Design}} ({{ISQED}}'06)},
  author = {Sinha, Debjit and {Hai Zhou} and Shenoy, N.V.},
  date = {2006},
  pages = {306--311},
  publisher = {{IEEE}},
  issn = {19483287},
  doi = {10.1109/ISQED.2006.22},
  url = {http://ieeexplore.ieee.org/document/1613154/},
  abstract = {This paper quantifies the approximation error when results obtained by Clark (1961) are employed to compute the maximum (max) of Gaussian random variables, which is a fundamental operation in statistical timing. We show that a finite lookup table can be used to store these errors. Based on the error computations, approaches to different orderings for pairwise max operations on a set of Gaussians are proposed. Experimental results show accuracy improvements in the computation of the max of multiple Gaussians, in comparison to the traditional approach. In addition, we present an approach to compute the tightness probabilities of Gaussian random variables with dynamic runtime-accuracy tradeoff options. We replace required numerical computations for their estimations by closed form expressions based on Taylor series expansion that involve table lookup and a few fundamental arithmetic operations. Experimental results demonstrate an average speedup of 2 using our approach for computing the maximum of two Gaussians, in comparison to the traditional approach, without any accuracy penalty.},
  isbn = {0-7695-2523-7},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\L6AE7BEB\\Sinha, Hai Zhou, Shenoy - 2006 - Advances in Computation of the Maximum of a Set of Random Variables.pdf}
}

@article{Siochi1999,
  title = {Minimizing static intensity modulation delivery time using an intensity solid paradigm},
  author = {Siochi, R. Alfredo C.},
  date = {1999-02-01},
  journaltitle = {International Journal of Radiation Oncology • Biology • Physics},
  shortjournal = {Int J Radiat Oncol},
  volume = {43},
  number = {3},
  eprint = {10078655},
  eprinttype = {pmid},
  pages = {671--680},
  issn = {0360-3016},
  doi = {10.1016/S0360-3016(98)00430-1},
  url = {https://www.redjournal.org/article/S0360-3016(98)00430-1/abstract},
  urldate = {2019-10-27},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}p{$>$}Purpose: A leaf sequencing optimization algorithm that minimizes the delivery time for a static intensity modulated field is presented.{$<$}/p{$><$}p{$>$}Methods and Materials: Sets of segments are created by intensity map operations subject to leaf collision constraints and tongue and groove effects. Each set's delivery time is evaluated as a function of leaf travel, beam on time, and the verify and record (V\&R) overhead. The configuration with the minimum delivery time is chosen. As a test, optimization was done on three clinical cases of varying complexity.{$<$}/p{$><$}p{$>$}Results: Assuming 10 × 10-cm fields with an average of 17 intensity levels, the optimization technique reduced delivery times by 27\% and 45\%, when compared to rod pushing and power of two extraction, respectively. The treatment time for the optimal case with a V\&R overhead of 4 s would be 11.5 min for 9 coplanar ports. Tongue-and-groove underdosages are removed, and the worst case leakage is 2\% of the peak dose.{$<$}/p{$><$}p{$>$}Conclusion: Compared to previously reported leaf sequencing methods, the new optimization algorithm described here reduces treatment times for complex static intensity modulated fields. Additionally, leakage is minimal and no tongue-and-groove underdosage occurs.{$<$}/p{$>$}},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\ZATW5TN6\\abstract.html}
}

@book{Slater1960,
  title = {Confluent {{Hypergeometric Functions}}},
  author = {Slater, Lucy Joan},
  date = {1960},
  edition = {1},
  publisher = {{Cambridge University Press}},
  isbn = {978-0-608-30898-2},
  pagetotal = {247}
}

@book{Smart2009,
  title = {Physician {{Characteristics}} and {{Distribution}} in the {{US}}, 2010},
  author = {Smart, Derek R.},
  date = {2009-11-30},
  edition = {1},
  publisher = {{Amer Medical Assn}},
  location = {{Chicago, IL}},
  abstract = {Annual contains statistical data on trends, characteristics, distribution, professional activity by specialty and geographic region, and primary care specialties of more than 954,000 physicians. Includes doctors of osteopathy, with details on how their characteristics and populace is affecting overall physician supply. Previous edition: c2009. Softcover.},
  isbn = {978-1-60359-157-7},
  langid = {english},
  pagetotal = {488}
}

@article{Sobotta2010,
  title = {Robust optimization based upon statistical theory},
  author = {Sobotta, B. and Söhn, M. and Alber, M.},
  date = {2010-07-13},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {37},
  number = {8},
  pages = {4019--4028},
  publisher = {{American Association of Physicists in Medicine}},
  issn = {00942405},
  doi = {10.1118/1.3457333},
  url = {http://doi.wiley.com/10.1118/1.3457333},
  urldate = {2017-02-03},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\22UUD73U\\Sobotta, Söhn, Alber - 2010 - Robust optimization based upon statistical theory.pdf}
}

@article{Sobotta2012,
  title = {Accelerated evaluation of the robustness of treatment plans against geometric uncertainties by {{Gaussian}} processes},
  author = {Sobotta, B and Söhn, M and Alber, M},
  date = {2012-12-07},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {57},
  number = {23},
  pages = {8023--8039},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/57/23/8023},
  url = {http://stacks.iop.org/0031-9155/57/i=23/a=8023?key=crossref.bcc5b813db7008ce072e53460d2f79e6},
  urldate = {2016-11-01},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\SK56JRPI\\Sobotta, Söhn, Alber - 2012 - Accelerated evaluation of the robustness of treatment plans against geometric uncertainties by Gaussian pr.pdf}
}

@article{Soukup2005,
  title = {A pencil beam algorithm for intensity modulated proton therapy derived from {{Monte Carlo}} simulations},
  author = {Soukup, Martin and Fippel, Matthias and Alber, Markus},
  date = {2005-11-07},
  journaltitle = {Physics in Medicine and Biology},
  volume = {50},
  number = {21},
  pages = {5089--5104},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/50/21/010},
  url = {http://stacks.iop.org/0031-9155/50/i=21/a=010?key=crossref.d26e45f94e710de832fca244a5dcd17b},
  urldate = {2016-12-22},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\X2GIF3A7\\Soukup, Fippel, Alber - 2005 - A pencil beam algorithm for intensity modulated proton therapy derived from Monte Carlo simulations.pdf}
}

@article{Souris2016,
  title = {Fast multipurpose {{Monte Carlo}} simulation for proton therapy using multi- and many-core {{CPU}} architectures},
  author = {Souris, Kevin and Lee, John Aldo and Sterpin, Edmond},
  date = {2016},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {43},
  number = {4},
  pages = {1700--1712},
  publisher = {{Wiley}},
  issn = {2473-4209},
  doi = {10.1118/1.4943377},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.4943377},
  urldate = {2019-09-18},
  abstract = {Purpose: Accuracy in proton therapy treatment planning can be improved using Monte Carlo (MC) simulations. However the long computation time of such methods hinders their use in clinical routine. This work aims to develop a fast multipurpose Monte Carlo simulation tool for proton therapy using massively parallel central processing unit (CPU) architectures. Methods: A new Monte Carlo, called MCsquare (many-core Monte Carlo), has been designed and optimized for the last generation of Intel Xeon processors and Intel Xeon Phi coprocessors. These massively parallel architectures offer the flexibility and the computational power suitable to MC methods. The class-II condensed history algorithm of MCsquare provides a fast and yet accurate method of simulating heavy charged particles such as protons, deuterons, and alphas inside voxelized geometries. Hard ionizations, with energy losses above a user-specified threshold, are simulated individually while soft events are regrouped in a multiple scattering theory. Elastic and inelastic nuclear interactions are sampled from ICRU 63 differential cross sections, thereby allowing for the computation of prompt gamma emission profiles. MCsquare has been benchmarked with the gate/geant4 Monte Carlo application for homogeneous and heterogeneous geometries. Results: Comparisons with gate/geant4 for various geometries show deviations within 2\%–1 mm. In spite of the limited memory bandwidth of the coprocessor simulation time is below 25 s for 107 primary 200 MeV protons in average soft tissues using all Xeon Phi and CPU resources embedded in a single desktop unit. Conclusions: MCsquare exploits the flexibility of CPU architectures to provide a multipurpose MC simulation tool. Optimized code enables the use of accurate MC calculation within a reasonable computation time, adequate for clinical practice. MCsquare also simulates prompt gamma emission and can thus be used also for in vivo range verification.},
  langid = {english},
  keywords = {Collisional energy loss,Computer hardware,Databases,dose calculation,Dose-volume analysis,dosimetry,Dosimetry/exposure assessment,high performance computing,microprocessor chips,Monte Carlo algorithms,Monte Carlo methods,Monte Carlo simulation,Nuclear interactions,Nuclear structure models,proton therapy,Proton therapy,Protons,radiation therapy,Radiation therapy,Scintigraphy,Tissues,Xeon Phi},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\8DBPRIE2\\1.html}
}

@book{Squires2001,
  title = {Practical physics},
  author = {Squires, Gordon Leslie},
  date = {2001},
  edition = {4},
  publisher = {{Cambridge University Press}},
  isbn = {0-521-77045-9},
  pagetotal = {212}
}

@article{Stammer2021,
  title = {Efficient uncertainty quantification for {{Monte Carlo}} dose calculations using importance (re-)weighting},
  author = {Stammer, Pia and Burigo, Lucas and Jäkel, Oliver and Frank, Martin and Wahl, Niklas},
  date = {2021-06-22},
  journaltitle = {Physics in Medicine \& Biology},
  shortjournal = {Phys Med Biol},
  volume = {66},
  number = {20},
  eprint = {2106.11885},
  eprinttype = {arxiv},
  pages = {205003},
  doi = {10.1088/1361-6560/ac287f},
  url = {https://iopscience.iop.org/article/10.1088/1361-6560/ac287f},
  urldate = {2021-06-30},
  abstract = {The high precision and conformity of intensity-modulated particle therapy (IMPT) comes at the cost of susceptibility to treatment uncertainties in particle range and patient set-up. Dose uncertainty quantification and mitigation, which is usually based on sampled error scenarios, however becomes challenging when computing the dose with computationally expensive but accurate Monte Carlo (MC) simulations. This paper introduces an importance (re-)weighting method in MC history scoring to concurrently construct estimates for error scenarios, the expected dose and its variance from a single set of MC simulated particle histories. The approach relies on a multivariate Gaussian input and uncertainty model, which assigns probabilities to the initial phase space sample, enabling the use of different correlation models. Exploring and adapting bivariate emittance parametrizations for the beam shape, accuracy can be traded between that of the uncertainty or the nominal dose estimate. The method was implemented using the MC code TOPAS and tested for proton IMPT plan delivery in comparison to a reference scenario estimate. We achieve accurate results for set-up uncertainties (\$\textbackslash gamma\_\{3mm/3\textbackslash\%\} \textbackslash geq 99.99\textbackslash\%\$) and expectedly lower but still sufficient agreement for range uncertainties, which are approximated with uncertainty over the energy distribution (\$\textbackslash gamma\_\{3 mm/3\textbackslash\%\} \textbackslash geq 99.50\textbackslash\%\$ (\$E[\textbackslash boldsymbol\{d\}]\$), \$\textbackslash gamma\_\{3mm/3\textbackslash\%\} \textbackslash geq 91.69\textbackslash\%\$ (\$\textbackslash sigma(\textbackslash boldsymbol\{d\})\$) ). Initial experiments on a water phantom, a prostate and a liver case show that the re-weighting approach lowers the CPU time by more than an order of magnitude. Further, we show that uncertainty induced by interplay and other dynamic influences may be approximated using suitable error correlation models.},
  archiveprefix = {arXiv},
  preview = {mcuq.png},
  keywords = {Mathematical Physics,Physics - Medical Physics},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\35N2RL9V\\Stammer et al. - 2021 - Efficient uncertainty quantification for Monte Car.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\Y73L2JST\\Stammer et al. - 2021 - Efficient uncertainty quantification for Monte Car.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\IUW3NW85\\2106.html}
}

@online{Stammer2021b,
  title = {Efficient uncertainty quantification for {{Monte Carlo}} dose calculations using importance (re-)weighting},
  author = {Stammer, Pia and Burigo, Lucas and Jäkel, Oliver and Frank, Martin and Wahl, Niklas},
  date = {2021-12-15},
  url = {https://www.estro.org/About/Newsroom/Newsletter/Physics/Efficient-uncertainty-quantification-for-Monte-Car},
  urldate = {2022-03-23},
  abstract = {About ESTRO work},
  organization = {{ESTRO Physics Newsletter}},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\4TNU2S3A\\Efficient-uncertainty-quantification-for-Monte-Car.html}
}

@inproceedings{Stammer2022,
  title = {Efficient uncertainty estimates in {{Monte Carlo}} dose calculation using importance reweighting},
  booktitle = {Proceedings to the 59th {{Annual Conference}} of the {{Particle Therapy Cooperative Group}} ({{PTCOG59}} 2021 {{Online}})},
  author = {Stammer, Pia and Burigo, Lucas and Jäkel, Oliver and Frank, Martin and Wahl, Niklas},
  date = {2022},
  series = {International {{Journal}} of {{Particle Therapy}}},
  pages = {24},
  location = {{Online}},
  doi = {10.14338/IJPT-22-PTCOG59-9.3},
  eventtitle = {{{PTCOG}} 59},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\UUYGTLYI\\Stammer et al. - 2022 - Efficient uncertainty estimates in Monte Carlo dos.pdf}
}

@inproceedings{Stammer2022a,
  title = {{{PO-1728}}: {{Efficient}} modeling and quantification of time-dependent errors in {{IMPT}}},
  booktitle = {Radiotherapy and {{Oncology}}},
  author = {Stammer, Pia and Burigo, Lucas and Jäkel, Oliver and Frank, Martin and Wahl, Niklas},
  date = {2022-05-01},
  volume = {170},
  pages = {S1529-S1531},
  publisher = {{Elsevier}},
  location = {{Kopenhagen}},
  doi = {10.1016/S0167-8140(22)03692-1},
  url = {https://www.thegreenjournal.com/article/S0167-8140(22)03692-1/abstract},
  urldate = {2022-08-29},
  eventtitle = {{{ESTRO}}},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\7RK4DK92\\pdf.html}
}

@article{Stammer2023,
  title = {Multivariate error modeling and uncertainty quantification using importance (re-)weighting for {{Monte Carlo}} simulations in particle transport},
  author = {Stammer, Pia and Burigo, Lucas and Jäkel, Oliver and Frank, Martin and Wahl, Niklas},
  date = {2023-01-15},
  journaltitle = {Journal of Computational Physics},
  shortjournal = {JCP},
  number = {473},
  eprint = {2202.02379},
  eprinttype = {arxiv},
  pages = {111725},
  issn = {0021-9991},
  doi = {10.1016/j.jcp.2022.111725},
  url = {https://www.sciencedirect.com/science/article/pii/S0021999122007884},
  urldate = {2022-10-26},
  abstract = {Fast and accurate predictions of uncertainties in the computed dose are crucial for the determination of robust treatment plans in radiation therapy. This requires the solution of particle transport problems with uncertain parameters or initial conditions. Monte Carlo methods are often used to solve transport problems especially for applications which require high accuracy. In these cases, common non-intrusive solution strategies that involve repeated simulations of the problem at different points in the parameter space quickly become infeasible due to their long run-times. Intrusive methods however limit the usability in combination with proprietary simulation engines. In [61], we demonstrated the application of a new non-intrusive uncertainty quantification approach for Monte Carlo simulations in proton dose calculations with normally distributed errors on realistic patient data. In this paper, we introduce a generalized formulation and focus on a more in-depth theoretical analysis of this method concerning bias, error and convergence of the estimates. The multivariate input model of the proposed approach further supports almost arbitrary error correlation models. We demonstrate how this framework can be used to model and efficiently quantify complex auto-correlated and time-dependent errors.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Boltzmann equation,error modeling,importance sampling,Monte Carlo,radiative transport,uncertainty quantification},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\FQFDMWC7\\Stammer et al. - 2022 - Multivariate error modeling and uncertainty quanti.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\NHYRDM28\\Stammer et al. - 2022 - Multivariate error modeling and uncertainty quanti.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\B7IT5FXL\\S0021999122007884.html}
}

@article{Steitz2016,
  title = {Worst case optimization for interfractional motion mitigation in carbon ion therapy of pancreatic cancer},
  author = {Steitz, Julian and Naumann, Patrick and Ulrich, Silke and Haefner, Matthias F. and Sterzing, Florian and Oelfke, Uwe and Bangert, Mark},
  date = {2016-12-07},
  journaltitle = {Radiation Oncology},
  volume = {11},
  number = {1},
  pages = {134},
  publisher = {{BioMed Central}},
  issn = {1748-717X},
  doi = {10.1186/s13014-016-0705-8},
  url = {http://ro-journal.biomedcentral.com/articles/10.1186/s13014-016-0705-8},
  urldate = {2018-04-15},
  abstract = {The efficacy of radiation therapy treatments for pancreatic cancer is compromised by abdominal motion which limits the spatial accuracy for dose delivery - especially for particles. In this work we investigate the potential of worst case optimization for interfractional offline motion mitigation in carbon ion treatments of pancreatic cancer. We implement a worst case optimization algorithm that explicitly models the relative biological effectiveness of carbon ions during inverse planning. We perform a comparative treatment planning study for seven pancreatic cancer patients. Treatment plans that have been generated using worst case optimization are compared against (1) conventional intensity-modulated carbon ion therapy, (2) single field uniform dose carbon ion therapy, and (3) an ideal yet impractical scenario relying on daily re-planning. The dosimetric quality and robustness of the resulting treatment plans is evaluated using reconstructions of the daily delivered dose distributions on fractional control CTs. Idealized daily re-planning consistently gives the best dosimetric results with regard to both target coverage and organ at risk sparing. The absolute reduction of D 95 within the gross tumor volume during fractional dose reconstruction is most pronounced for conventional intensity-modulated carbon ion therapy. Single field uniform dose optimization exhibits no substantial reduction for six of seven patients and values for D 95 for worst case optimization fall in between. The treated volume (D{$>$}95 \% prescription dose) outside of the gross tumor volume is reduced by a factor of two by worst case optimization compared to conventional optimization and single field uniform dose optimization. Single field uniform dose optimization comes at an increased radiation exposure of normal tissues, e.g. ≈2 Gy (RBE) in the mean dose in the kidneys compared to conventional and worst case optimization and ≈4 Gy (RBE) in D 1 in the spinal cord compared to worst case optimization. Interfractional motion substantially deteriorates dose distributions for carbon ion treatments of pancreatic cancer patients. Single field uniform dose optimization mitigates the negative influence of motion on target coverage at an increased radiation exposure of normal tissue. Worst case optimization enables an exploration of the trade-off between robust target coverage and organ at risk sparing during inverse treatment planning beyond margin concepts.},
  keywords = {Cancer Research,Imaging / Radiology,Oncology,Radiotherapy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\W92AUP5E\\Steitz et al. - 2016 - Worst case optimization for interfractional motion mitigation in carbon ion therapy of pancreatic cancer.pdf}
}

@inproceedings{Straka2013,
  title = {Aspects and comparison of matrix decompositions in unscented {{Kalman}} filter},
  booktitle = {2013 {{American Control Conference}}},
  author = {Straka, Ondrej and Dunik, Jindrich and Simandl, Miroslav and Havlik, Jindrich},
  date = {2013-06},
  pages = {3075--3080},
  publisher = {{IEEE}},
  doi = {10.1109/ACC.2013.6580303},
  url = {http://ieeexplore.ieee.org/document/6580303/},
  urldate = {2018-04-03},
  isbn = {978-1-4799-0178-4},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\TNTZQVAZ\\Straka et al. - 2013 - Aspects and comparison of matrix decompositions in unscented Kalman filter.pdf}
}

@article{Sung2021,
  title = {Global {{Cancer Statistics}} 2020: {{GLOBOCAN Estimates}} of {{Incidence}} and {{Mortality Worldwide}} for 36 {{Cancers}} in 185 {{Countries}}},
  shorttitle = {Global {{Cancer Statistics}} 2020},
  author = {Sung, Hyuna and Ferlay, Jacques and Siegel, Rebecca L. and Laversanne, Mathieu and Soerjomataram, Isabelle and Jemal, Ahmedin and Bray, Freddie},
  date = {2021},
  journaltitle = {CA: A Cancer Journal for Clinicians},
  volume = {71},
  number = {3},
  pages = {209--249},
  issn = {1542-4863},
  doi = {10.3322/caac.21660},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.3322/caac.21660},
  urldate = {2021-12-15},
  abstract = {This article provides an update on the global cancer burden using the GLOBOCAN 2020 estimates of cancer incidence and mortality produced by the International Agency for Research on Cancer. Worldwide, an estimated 19.3 million new cancer cases (18.1 million excluding nonmelanoma skin cancer) and almost 10.0 million cancer deaths (9.9 million excluding nonmelanoma skin cancer) occurred in 2020. Female breast cancer has surpassed lung cancer as the most commonly diagnosed cancer, with an estimated 2.3 million new cases (11.7\%), followed by lung (11.4\%), colorectal (10.0 \%), prostate (7.3\%), and stomach (5.6\%) cancers. Lung cancer remained the leading cause of cancer death, with an estimated 1.8 million deaths (18\%), followed by colorectal (9.4\%), liver (8.3\%), stomach (7.7\%), and female breast (6.9\%) cancers. Overall incidence was from 2-fold to 3-fold higher in transitioned versus transitioning countries for both sexes, whereas mortality varied {$<$}2-fold for men and little for women. Death rates for female breast and cervical cancers, however, were considerably higher in transitioning versus transitioned countries (15.0 vs 12.8 per 100,000 and 12.4 vs 5.2 per 100,000, respectively). The global cancer burden is expected to be 28.4 million cases in 2040, a 47\% rise from 2020, with a larger increase in transitioning (64\% to 95\%) versus transitioned (32\% to 56\%) countries due to demographic changes, although this may be further exacerbated by increasing risk factors associated with globalization and a growing economy. Efforts to build a sustainable infrastructure for the dissemination of cancer prevention measures and provision of cancer care in transitioning countries is critical for global cancer control.},
  langid = {english},
  keywords = {burden,cancer,epidemiology,incidence,mortality},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.3322/caac.21660},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\HDS5KV7M\\Sung et al. - 2021 - Global Cancer Statistics 2020 GLOBOCAN Estimates .pdf;C\:\\Users\\Niklas\\Zotero\\storage\\ZY7YS8AV\\caac.html}
}

@article{Taasti2019,
  title = {A theoretical investigation of adequate range uncertainty margins in proton treatment planning to preserve tumor control probability},
  author = {Taasti, Vicki T. and Jeong, Jeho and Jackson, Andrew and Deasy, Joseph O.},
  date = {2019-10-03},
  journaltitle = {Acta Oncologica},
  shortjournal = {Acta Oncol},
  volume = {58},
  number = {10},
  pages = {1446--1450},
  issn = {0284-186X, 1651-226X},
  doi = {10.1080/0284186X.2019.1627415},
  url = {https://www.tandfonline.com/doi/full/10.1080/0284186X.2019.1627415},
  urldate = {2019-10-30},
  abstract = {Background: Proton dose distributions are sensitive to range uncertainties, resulting in margins added to ensure adequate tumor control probability (TCP). We investigated the required margin and dose shape needed to ensure adequate TCP, for representative tumor cell distributions in the clinical target volume (CTV). Material and methods: A mechanistic tumor response model, validated for lung tumors, was used to estimate TCP. The tumor cell distribution (q) was assumed to decrease exponentially in the CTV with decay parameter k toward the outer border (xCmTaVx). It was investigated if a gradual dose fall-off could reduce the dose to normal tissues outside the CTV, while achieving adequate TCP. For various values of xCmTaVx and k; we derived adequate uniform dose margins (m), coupled to linear dose fall-off regions (Dx; Dxnom ¼ Dx À 0:9 cm), that ensured TCP {$>$} TCPlimit; while delivering the least mean dose outside the CTV. To account for variabilities in patients and tumor types, variable probabilities (p) of finding tumor cells in the non-GTV part of the CTV for a given patient were also tested. Dose from a single beam or two opposing beams was simulated under the influence of a typical stopping power ratio uncertainty of 3.5\%. Results: For large k and xCmTaVx; a dose distribution with a shallower dose fall-off (Dx {$>$} 0) was advantageous, and m could be smaller than xCmTaVx: In the case of small xCmTaVx values, however, a conventional dose distribution (Dx ¼ 0) would generally perform better. For no CTV, m ¼ 0:4 cm in the case of two opposing beams, while it was 0.7 cm for a single beam, however, for two opposing beams Dx ¼ 1:2 cm (Dxnom ¼ 0:3 cm), while it was zero for a single beam. Conclusion: The details of the underlying cancer cell distribution characteristics do impact the adequate dose arrangements, and for opposing beams a non-conventional dose distribution shape is often advantageous.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\HCQSWI7W\\Taasti et al. - 2019 - A theoretical investigation of adequate range unce.pdf}
}

@article{Taasti2020,
  title = {Developments in deep learning based corrections of cone beam computed tomography to enable dose calculations for adaptive radiotherapy},
  author = {Taasti, Vicki Trier and Klages, Peter and Parodi, Katia and Muren, Ludvig Paul},
  date = {2020-07-01},
  journaltitle = {Physics and Imaging in Radiation Oncology},
  shortjournal = {Physics and Imaging in Radiation Oncology},
  volume = {15},
  pages = {77--79},
  publisher = {{Elsevier}},
  issn = {2405-6316},
  doi = {10.1016/j.phro.2020.07.012},
  url = {https://www.phiro.science/article/S2405-6316(20)30046-4/fulltext},
  urldate = {2022-08-11},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\F274ZH6X\\Taasti et al. - 2020 - Developments in deep learning based corrections of.pdf}
}

@article{Tambave2020,
  title = {Characterization of monolithic {{CMOS}} pixel sensor chip with ion beams for application in particle computed tomography},
  author = {Tambave, G. and Alme, J. and Barnaföldi, G. G. and Barthel, R. and family=Brink, given=A., prefix=van den, useprefix=true and Brons, S. and Chaar, M. and Eikeland, V. and Genov, G. and Grøttvik, O. and Pettersen, H. E. S. and Pastuovic, Z. and Huiberts, S. and Helstrup, H. and Hetland, K. F. and Mehendale, S. and Meric, I. and Malik, Q. W. and Odland, O. H. and Papp, G. and Peitzmann, T. and Piersimoni, P. and Ur Rehman, A. and Reidt, F. and Richter, M. and Röhrich, D. and Sudar, A. and Samnøy, A. T. and Seco, J. and Shafiee, H. and Skjæveland, E. V. and Sølie, J. R. and Ullaland, K. and Varga-Kofarago, M. and Volz, L. and Wagner, B. and Yang, S.},
  date = {2020-04-01},
  journaltitle = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  shortjournal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  series = {Proceedings of the {{Vienna Conference}} on {{Instrumentation}} 2019},
  volume = {958},
  pages = {162626},
  issn = {0168-9002},
  doi = {10.1016/j.nima.2019.162626},
  url = {http://www.sciencedirect.com/science/article/pii/S0168900219311258},
  urldate = {2020-03-25},
  abstract = {Particle computed tomography (pCT) is an emerging imaging modality that promises to reduce range uncertainty in particle therapy. The Bergen pCT collaboration aims to develop a novel pCT prototype based on the ALPIDE monolithic CMOS sensor. The planned prototype consist of two tracking planes forming a rear tracker and Digital Tracking Calorimeter (DTC). The DTC will be made of a 41 layer ALPIDE-aluminum sandwich structure. To enable data acquisition at clinical particle rates, a large multiplicity of particles will be measured using the highly-granular ALPIDE sensor. In this work, a first characterization of the ALPIDE sensor performance in ion beams is conducted. Particle hits in the ALPIDE sensor result in charge clusters whose size is related to the chip response and the particle energy deposit. Firstly, measurements in a 10 MeV 4He micro beam have been conducted at the SIRIUS microprobe facility of ANSTO to investigate the dependence of the cluster size on the beam position over the ALPIDE pixel. Here, a variation in cluster size depending on the impinging point of the beam was observed. Additional beam tests were conducted at the Heidelberg Ion-Beam Therapy Center (HIT) investigating the cluster size as a function of the deposited energy by protons and 4He ions in the sensitive volume of the ALPIDE. Results show the expected increase in cluster sizes with deposited energy and a clear difference in cluster sizes for protons and 4He ions. As a conclusion, the variation in cluster size with the impinging point of the beam has to be accounted for to enable accurate energy loss reconstruction with the ALPIDE. This does, however, not affect the tracking of particles through the final prototype, as for that only the center-of-mass of the cluster is relevant.},
  langid = {english},
  keywords = {Digital tracking calorimeter (DTC),Monolithic active pixel sensor (MAPS),Particle computed tomography (pCT)},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\2V4UP5VQ\\Tambave et al. - 2020 - Characterization of monolithic CMOS pixel sensor c.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\X65FQHMH\\S0168900219311258.html}
}

@article{Taylor2016,
  title = {Results {{From}} the {{Imaging}} and {{Radiation Oncology Core Houston}}’s {{Anthropomorphic Phantoms Used}} for {{Proton Therapy Clinical Trial Credentialing}}},
  author = {Taylor, Paige A. and Kry, Stephen F. and Alvarez, Paola and Keith, Tyler and Lujano, Carrie and Hernandez, Nadia and Followill, David S.},
  date = {2016-05-01},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {International Journal of Radiation Oncology*Biology*Physics},
  series = {Particle {{Therapy Special Edition}}},
  volume = {95},
  number = {1},
  pages = {242--248},
  issn = {0360-3016},
  doi = {10.1016/j.ijrobp.2016.01.061},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301616001140},
  urldate = {2020-04-03},
  abstract = {Purpose The purpose of this study was to summarize the findings of anthropomorphic proton phantom irradiations analyzed by the Imaging and Radiation Oncology Core Houston QA Center (IROC Houston). Methods and Materials A total of 103 phantoms were irradiated by proton therapy centers participating in clinical trials. The anthropomorphic phantoms simulated heterogeneous anatomy of a head, liver, lung, prostate, and spine. Treatment plans included those for scattered, uniform scanning, and pencil beam scanning beam delivery modalities using 5 different treatment planning systems. For~every phantom irradiation, point doses and planar doses were measured using thermoluminescent dosimeters (TLD) and film, respectively. Differences between measured and planned doses were studied as a function of phantom, beam delivery modality, motion, repeat attempt, treatment planning system, and date of irradiation. Results The phantom pass rate (overall, 79\%) was high for simple phantoms and lower for phantoms that introduced higher levels of difficulty, such as motion, multiple targets, or increased heterogeneity. All treatment planning systems overestimated dose to the target, compared to TLD measurements. Errors in range calculation resulted in several failed phantoms. There was no correlation between treatment planning system and pass rate. The pass rates for each individual phantom are not improving over time, but when individual institutions received feedback about failed phantom irradiations, pass rates did improve. Conclusions The proton phantom pass rates are not as high as desired and emphasize potential deficiencies in proton therapy planning and/or delivery. There are many areas for improvement with the proton phantom irradiations, such as treatment planning system dose agreement, range calculations, accounting for motion, and irradiation of multiple targets.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\9ZMCNDPM\\Taylor et al. - 2016 - Results From the Imaging and Radiation Oncology Co.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\ZDEUVARJ\\S0360301616001140.html}
}

@article{Taylor2017,
  title = {Pencil {{Beam Algorithms Are Unsuitable}} for {{Proton Dose Calculations}} in {{Lung}}},
  author = {Taylor, Paige A and Kry, Stephen F and Followill, David S},
  date = {2017-11},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {99},
  number = {3},
  pages = {750--756},
  issn = {03603016},
  doi = {10.1016/j.ijrobp.2017.06.003},
  url = {http://dx.doi.org/10.1016/j.ijrobp.2017.06.003},
  urldate = {2018-04-01},
  abstract = {Commercial analytic proton algorithms were compared with measurements and Monte Carloebased algorithms in a multi-institution phantom study. The analytic algorithms dramatically and consistently overestimated delivered dose up to 31\% in the iGTV and 46\% in the PTV. Monte Carlo algorithms and mea-surements showed consider-ably better agreement. Proton therapy centers should implement Monte Carloebased (or other more advanced) algorithms in proton therapy for thoracic malignancies. Pencil beam algorithms for proton dose calculation in lung are unacceptable. Purpose: To compare analytic and Monte Carloebased algorithms for proton dose calculations in the lung, benchmarked against anthropomorphic lung phantom mea-surements. Methods and Materials: A heterogeneous anthropomorphic moving lung phantom has been irradiated at numerous proton therapy centers. At 5 centers the treatment plan could be calculated with both an analytic and Monte Carlo algorithm. The doses calcu-lated in the treatment plans were compared with the doses delivered to the phantoms, which were measured using thermoluminescent dosimeters and film. Point doses were compared, as were planar doses using a gamma analysis. Results: The analytic algorithms overestimated the dose to the center of the target by an average of 7.2\%, whereas the Monte Carlo algorithms were within 1.6\% of the physical measurements on average. In some regions of the target volume, the analytic algorithm calculations differed from the measurement by up to 31\% in the internal gross target volume (iGTV) (46\% in the planning target volume), over-predicting the dose. All comparisons showed a region of at least 15\% dose discrepancy within the iGTV between the analytic calculation and the measured dose. The Monte Carlo algorithm recalculations showed dramatically improved agreement with the measured doses, showing mean agreement within 4\% for all cases and a maximum difference of 12\% within the iGTV. Conclusions: Analytic algorithms often do a poor job predicting proton dose in lung tumors, over-predicting the dose to the target by up to 46\%, and should not be used unless extensive validation counters the consistent results of the present study. Monte Carlo algorithms showed dramatically improved agreement with physical measure-ments and should be implemented to better reflect actual delivered dose distributions.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\856D2IEB\\Taylor, Kry, Followill - 2017 - Pencil Beam Algorithms Are Unsuitable for Proton Dose Calculations in Lung.pdf}
}

@article{tenEikelder2019,
  title = {Optimal combined proton–photon therapy schemes based on the standard {{BED}} model},
  author = {family=Eikelder, given=S C M, prefix=ten, useprefix=true and family=Hertog, given=D, prefix=den, useprefix=true and Bortfeld, T and Perkó, Z},
  date = {2019-03-12},
  journaltitle = {Physics in Medicine \& Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {64},
  number = {6},
  pages = {065011},
  issn = {1361-6560},
  doi = {10.1088/1361-6560/aafe52},
  url = {https://iopscience.iop.org/article/10.1088/1361-6560/aafe52},
  urldate = {2021-03-05},
  abstract = {This paper investigates the potential of combined proton–photon therapy schemes in radiation oncology, with a special emphasis on fractionation. Several combined modality models, with and without fractionation, are discussed, and conditions under which combined modality treatments are of added value are demonstrated analytically and numerically. The combined modality optimal fractionation problem with multiple normal tissues is formulated based on the biologically effective dose (BED) model and tested on real patient data. Results indicate that for several patients a combined modality treatment gives better results in terms of biological dose (up to14.8\% improvement) than single modality proton treatments. For several other patients, a combined modality treatment is found that offers an alternative to the optimal single modality proton treatment, being only marginally worse but using significantly fewer proton fractions, putting less pressure on the limited availability of proton slots. Overall, these results indicate that combined modality treatments can be a viable option, which is expected to become more important as proton therapy centers are spreading but the proton therapy price tag remains high.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\RKIJ5KGN\\ten Eikelder et al. - 2019 - Optimal combined proton–photon therapy schemes bas.pdf}
}

@software{TensorToolbox2015,
  title = {{{MATLAB Tensor Toolbox}}},
  author = {Bader, Brett W. and Kolda, Tamara G.},
  date = {2015},
  url = {http://www.sandia.gov/~tgkolda/TensorToolbox/},
  organization = {{Online}}
}

@book{test1,
  title = {Grundkurs {{Öffentliches Recht Staats-}} und {{Verwaltungsrecht}}},
  author = {Sodan, Helge and Ziekow, Jan},
  date = {2016},
  edition = {7},
  publisher = {{Beck}},
  isbn = {978-3-406-69459-2}
}

@article{Teugels1990,
  title = {Some representations of the multivariate {{Bernoulli}} and binomial distributions},
  author = {Teugels, Jozef L.},
  date = {1990},
  journaltitle = {Journal of Multivariate Analysis},
  volume = {32},
  number = {2},
  eprint = {20666613},
  eprinttype = {pmid},
  pages = {256--268},
  issn = {10957243},
  doi = {10.1016/0047-259X(90)90084-U},
  abstract = {Multivariate but vectorized versions for Bernoulli and binomial distributions are established using the concept of Kronecker product from matrix calculus. The multivariate Bernoulli distribution entails a parameterized model, that provides an alternative to the traditional log-linear model for binary variables. © 1990.},
  isbn = {0780376633},
  keywords = {categorical data,log-linear models,multivariate Bernoulli distribution,multivariate binomial distribution},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\6S58HIRD\\Teugels - 1990 - Some representations of the multivariate Bernoulli and binomial distributions.pdf}
}

@misc{TheMendeleySupportTeam2011,
  title = {Getting {{Started}} with {{Mendeley}}},
  author = {{The Mendeley Support Team}},
  date = {2011},
  journaltitle = {Mendeley Desktop},
  pages = {1--16},
  publisher = {{Mendeley Ltd.}},
  location = {{London}},
  url = {http://www.mendeley.com},
  abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
  keywords = {how-to,Mendeley,user manual}
}

@article{Thieke2003,
  title = {From physical dose constraints to equivalent uniform dose constraints in inverse radiotherapy planning},
  author = {Thieke, Christian and Bortfeld, Thomas and Niemierko, Andrzej and Nill, Simeon},
  date = {2003-08-21},
  journaltitle = {Medical Physics},
  volume = {30},
  number = {9},
  pages = {2332--2339},
  publisher = {{Wiley-Blackwell}},
  issn = {00942405},
  doi = {10.1118/1.1598852},
  url = {http://doi.wiley.com/10.1118/1.1598852},
  urldate = {2018-04-07},
  keywords = {Anatomy,biological organs,Cancer,Convex sets,dosimetry,Dosimetry,equivalent uniform dose,inverse planning,inverse problems,Inverse problems,iterative methods,medical computing,minimisation,Optimization,optimization constraints,Physicists,planning,projection onto convex sets,radiation therapy,Radiation therapy,Treatment strategy,tumours},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\V6DF7ZRS\\Thieke et al. - 2003 - From physical dose constraints to equivalent uniform dose constraints in inverse radiotherapy planning.pdf}
}

@article{Thieke2007,
  title = {A new concept for interactive radiotherapy planning with multicriteria optimization: first clinical evaluation},
  shorttitle = {A new concept for interactive radiotherapy planning with multicriteria optimization},
  author = {Thieke, Christian and Küfer, Karl-Heinz and Monz, Michael and Scherrer, Alexander and Alonso, Fernando and Oelfke, Uwe and Huber, Peter E. and Debus, Jürgen and Bortfeld, Thomas},
  date = {2007-11},
  journaltitle = {Radiotherapy and Oncology: Journal of the European Society for Therapeutic Radiology and Oncology},
  shortjournal = {Radiother Oncol},
  volume = {85},
  number = {2},
  eprint = {17892901},
  eprinttype = {pmid},
  pages = {292--298},
  issn = {0167-8140},
  doi = {10.1016/j.radonc.2007.06.020},
  abstract = {BACKGROUND AND PURPOSE: Currently, inverse planning for intensity-modulated radiotherapy (IMRT) can be a time-consuming trial and error process. This is because many planning objectives are inherently contradictory and cannot reach their individual optimum all at the same time. Therefore in clinical practice the potential of IMRT cannot be fully exploited for all patients. Multicriteria (multiobjective) optimization combined with interactive plan navigation is a promising approach to overcome these problems. PATIENTS AND METHODS: We developed a new inverse planning system called "Multicriteria Interactive Radiotherapy Assistant (MIRA)". The optimization result is a database of patient specific, Pareto-optimal plan proposals. The database is explored with an intuitive user interface that utilizes both a new interactive element for plan navigation and familiar dose visualizations in form of DVH and isodose projections. Two clinical test cases, one paraspinal meningioma case and one prostate case, were optimized using MIRA and compared with the clinically approved planning program KonRad. RESULTS: Generating the databases required no user interaction and took approx. 2-3h per case. The interactive exploration required only a few minutes until the best plan was identified, resulting in a significant reduction of human planning time. The achievable plan quality was comparable to KonRad with the additional benefit of having plan alternatives at hand to perform a sensitivity analysis or to decide for a different clinical compromise. CONCLUSIONS: The MIRA system provides a complete database and interactive exploration of the solution space in real time. Hence, it is ideally suited for the inherently multicriterial problem of inverse IMRT treatment planning.},
  langid = {english},
  keywords = {Aged,Female,Humans,Male,Meningioma,Prostatic Neoplasms,Radiotherapy Planning; Computer-Assisted,Radiotherapy; Intensity-Modulated}
}

@article{Thornqvist2013,
  title = {Degradation of target coverage due to inter-fraction motion during intensity-modulated proton therapy of prostate and elective targets},
  author = {Thörnqvist, Sara and Muren, Ludvig P. and Bentzen, Lise and Hysing, Liv B. and Høyer, Morten and Grau, Cai and Petersen, Jørgen B. B.},
  date = {2013-04-14},
  journaltitle = {Acta Oncologica},
  volume = {52},
  number = {3},
  pages = {521--527},
  publisher = {{Taylor \& Francis}},
  issn = {0284-186X},
  doi = {10.3109/0284186X.2012.752860},
  url = {http://www.tandfonline.com/doi/full/10.3109/0284186X.2012.752860},
  urldate = {2018-04-28},
  abstract = {AbstractInternal target and organ motion during treatment is a challenge in radiotherapy (RT) of the prostate and the involved elective targets, with residual motion being present also following image-guidance strategies. The aim of this study was to investigate organ motion-induced dose degradations for the prostate, seminal vesicle and the pelvic lymph node when treating these targets with proton therapy, using different image-guidance and delivery strategies. Material and methods. Four patients were selected from a larger series as they displayed large inter-fractional variation in bladder and rectum volume. Intensity-modulated proton therapy plans were generated using both simultaneous integrated and sequential boost delivery. For each technique, three isotropic margin expansions (in the range of 4–10 mm) were evaluated for the clinical target volume of prostate (CTV-p), seminal vesicles (CTV-sv) and lymph nodes (CTV-ln). Simulation of the dose degradations for all treatment plans were based on dose r...}
}

@article{Tian2015,
  title = {A {{GPU OpenCL}} based cross-platform {{Monte Carlo}} dose calculation engine ({{goMC}})},
  author = {Tian, Zhen and Shi, Feng and Folkerts, Michael and Qin, Nan and Jiang, Steve B. and Jia, Xun},
  date = {2015-09},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {60},
  number = {19},
  pages = {7419--7435},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/60/19/7419},
  url = {https://doi.org/10.1088/0031-9155/60/19/7419},
  urldate = {2022-05-17},
  abstract = {Monte Carlo (MC) simulation has been recognized as the most accurate dose calculation method for radiotherapy. However, the extremely long computation time impedes its clinical application. Recently, a lot of effort has been made to realize fast MC dose calculation on graphic processing units (GPUs). However, most of the GPU-based MC dose engines have been developed under NVidia’s CUDA environment. This limits the code portability to other platforms, hindering the introduction of GPU-based MC simulations to clinical practice. The objective of this paper is to develop a GPU OpenCL based cross-platform MC dose engine named goMC with coupled photon–electron simulation for external photon and electron radiotherapy in the MeV energy range. Compared to our previously developed GPU-based MC code named gDPM (Jia et al 2012 Phys. Med. Biol. 57 7783–97), goMC has two major differences. First, it was developed under the OpenCL environment for high code portability and hence could be run not only on different GPU cards but also on CPU platforms. Second, we adopted the electron transport model used in EGSnrc MC package and PENELOPE’s random hinge method in our new dose engine, instead of the dose planning method employed in gDPM. Dose distributions were calculated for a 15 MeV electron beam and a 6 MV photon beam in a homogenous water phantom, a water-bone-lung-water slab phantom and a half-slab phantom. Satisfactory agreement between the two MC dose engines goMC and gDPM was observed in all cases. The average dose differences in the regions that received a dose higher than 10\% of the maximum dose were 0.48–0.53\% for the electron beam cases and 0.15–0.17\% for the photon beam cases. In terms of efficiency, goMC was 4–16\% slower than gDPM when running on the same NVidia TITAN card for all the cases we tested, due to both the different electron transport models and the different development environments. The code portability of our new dose engine goMC was validated by successfully running it on a variety of different computing devices including an NVidia GPU card, two AMD GPU cards and an Intel CPU processor. Computational efficiency among these platforms was compared.},
  langid = {english}
}

@article{Titt2015,
  ids = {Titt2015a},
  title = {Degradation of proton depth dose distributions attributable to microstructures in lung-equivalent material.},
  author = {Titt, Uwe and Sell, Martin and Unkelbach, Jan and Bangert, Mark and Mirkovic, Dragan and Oelfke, Uwe and Mohan, Radhe},
  date = {2015},
  journaltitle = {Medical physics},
  volume = {42},
  number = {11},
  eprint = {26520732},
  eprinttype = {pmid},
  pages = {6425--32},
  issn = {0094-2405},
  doi = {10.1118/1.4932625},
  url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4608968&tool=pmcentrez&rendertype=abstract},
  abstract = {PURPOSE: The purpose of the work reported here was to investigate the influence of sub-millimeter size heterogeneities on the degradation of the distal edges of proton beams and to validate Monte Carlo (MC) methods' ability to correctly predict such degradation.\textbackslash n\textbackslash nMETHODS: A custom-designed high-resolution plastic phantom approximating highly heterogeneous, lung-like structures was employed in measurements and in Monte Carlo simulations to evaluate the degradation of proton Bragg curves penetrating heterogeneous media.\textbackslash n\textbackslash nRESULTS: Significant differences in distal falloff widths and in peak dose values were observed in the measured and the Monte Carlo simulated curves compared to pristine proton Bragg curves. Furthermore, differences between simulations of beams penetrating CT images of the phantom did not agree well with the corresponding experimental differences. The distal falloff widths in CT image-based geometries were underestimated by up to 0.2 cm in water (corresponding to 0.8-1.4 cm in lung tissue), and the peak dose values of pristine proton beams were overestimated by as much as ˜35\% compared to measured curves or depth-dose curves simulated on the basis of true geometry. The authors demonstrate that these discrepancies were caused by the limited spatial resolution of CT images that served as a basis for dose calculations and lead to underestimation of the impact of the fine structure of tissue heterogeneities. A convolution model was successfully applied to mitigate the underestimation.\textbackslash n\textbackslash nCONCLUSIONS: The results of this study justify further development of models to better represent heterogeneity effects in soft-tissue geometries, such as lung, and to correct systematic underestimation of the degradation of the distal edge of proton doses.},
  keywords = {dose degradation,lung tissue,measurements,monte carlo,Monte Carlo,proton therapy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\RZMKGZE7\\Titt et al. - 2015 - Degradation of proton depth dose distributions attributable to microstructures in lung-equivalent material.pdf}
}

@book{Tong1990,
  title = {The {{Multivariate Normal Distribution}}},
  author = {Tong, Y. L.},
  date = {1990},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4613-9655-0},
  url = {http://link.springer.com/10.1007/978-1-4613-9655-0},
  urldate = {2018-04-29},
  isbn = {978-1-4613-9657-4}
}

@article{Tsunashima2010,
  title = {The precision of respiratory-gated delivery of synchrotron-based pulsed beam proton therapy},
  author = {Tsunashima, Yoshikazu and Vedam, Sastry and Dong, Lei and Umezawa, Masumi and Balter, Peter and Mohan, Radhe},
  date = {2010-11},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {55},
  number = {24},
  pages = {7633--7647},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/55/24/016},
  url = {https://doi.org/10.1088%2F0031-9155%2F55%2F24%2F016},
  urldate = {2020-04-03},
  abstract = {A synchrotron-based proton therapy system operates in a low repetition rate pulsed beam delivery mode. Unlike cyclotron-based beam delivery, there is no guarantee that a synchrotron beam can be delivered effectively or precisely under the respiratory-gated mode. To evaluate the performance of gated synchrotron treatment, we simulated proton beam delivery in the synchrotron-based respiratory-gated mode using realistic patient breathing signals. Parameters used in the simulation were respiratory motion traces (70 traces from 24 patients), respiratory gate levels (10\%, 20\% and 30\% duty cycles at the exhalation phase) and synchrotron magnet excitation cycles (Tcyc) (fixed Tcyc mode: 2.7, 3.0–6.0 s and each patient breathing cycle, and variable Tcyc mode). The simulations were computed according to the breathing trace in which the proton beams were delivered. In the shorter fixed Tcyc (4 s) and the variable Tcyc mode, the proton beams were not consistently delivered during the end-expiration phase of the respiratory cycle. However we found that the longer and variable Tcyc operation modes delivered proton beams more precisely during irregular breathing.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\DT59KPKN\\Tsunashima et al. - 2010 - The precision of respiratory-gated delivery of syn.pdf}
}

@article{Ulrich2017,
  title = {Impact of respiratory motion on variable relative biological effectiveness in {{4D-dose}} distributions of proton therapy},
  author = {Ulrich, Silke and Wieser, Hans-Peter and Cao, Wenhua and Mohan, Radhe and Bangert, Mark},
  date = {2017-11-02},
  journaltitle = {Acta Oncologica},
  volume = {56},
  number = {11},
  pages = {1420--1427},
  publisher = {{Taylor \& Francis}},
  issn = {0284-186X},
  doi = {10.1080/0284186X.2017.1354131},
  url = {https://www.tandfonline.com/doi/full/10.1080/0284186X.2017.1354131},
  urldate = {2018-04-28},
  abstract = {AbstractBackground: Organ motion during radiation therapy with scanned protons leads to deviations between the planned and the delivered physical dose. Using a constant relative biological effectiveness (RBE) of 1.1 linearly maps these deviations into RBE-weighted dose. However, a constant value cannot account for potential nonlinear variations in RBE suggested by variable RBE models. Here, we study the impact of motion on recalculations of RBE-weighted dose distributions using a phenomenological variable RBE model.Material and methods: 4D-dose calculation including variable RBE was implemented in the open source treatment planning toolkit matRad. Four scenarios were compared for one field and two field proton treatments for a liver cancer patient assuming (α∕β)x = 2 Gy and (α∕β)x = 10 Gy: (A) the optimized static dose distribution with constant RBE, (B) a static recalculation with variable RBE, (C) a 4D-dose recalculation with constant RBE and (D) a 4D-dose recalculation with variable RBE. For (B) and (D...}
}

@article{Universit2013,
  title = {Low-{{Rank Tensor Approximation}} in post {{Hartree-Fock Methods}}},
  author = {Universit, Technischen and Benedikt, Udo and Prof, Alexander a Auer and Gemming, Sibylle},
  date = {2013},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\3ZNGUPRI\\Universit et al. - 2013 - Low-Rank Tensor Approximation in post Hartree-Fock Methods.pdf}
}

@article{Unkelbach2004,
  title = {Inclusion of organ movements in {{IMRT}} treatment planning via inverse planning based on probability distributions.},
  author = {Unkelbach, J and Oelfke, U},
  date = {2004-09-07},
  journaltitle = {Physics in medicine and biology},
  volume = {49},
  number = {17},
  eprint = {15470920},
  eprinttype = {pmid},
  pages = {4005--4029},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/49/17/013},
  url = {http://stacks.iop.org/0031-9155/49/i=17/a=013?key=crossref.247a2f1fae53199d3350a187ace37f16},
  urldate = {2016-07-25},
  abstract = {In this paper, we investigate an off-line strategy to incorporate inter-fraction organ motion in IMRT treatment planning. It was suggested that inverse planning could be based on a probability distribution of patient geometries instead of a single snap shot. However, this concept is connected to two intrinsic problems: first, this probability distribution has to be estimated from only a few images; and second, the distribution is only sparsely sampled over the treatment course due to a finite number of fractions. In the current work, we develop new concepts of inverse planning which account for these two problems.},
  isbn = {0031-9155 (Print)},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\R2CEI4PB\\Unkelbach, Oelfke - 2004 - Inclusion of organ movements in IMRT treatment planning via inverse planning based on probability distributio.pdf}
}

@article{Unkelbach2007,
  title = {Accounting for range uncertainties in the optimization of intensity modulated proton therapy.},
  author = {Unkelbach, Jan and Chan, Timothy C Y and Bortfeld, Thomas},
  date = {2007-05-21},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {52},
  number = {10},
  eprint = {17473350},
  eprinttype = {pmid},
  pages = {2755--2773},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/52/10/009},
  url = {http://stacks.iop.org/0031-9155/52/i=10/a=009},
  urldate = {2015-03-25},
  abstract = {Treatment plans optimized for intensity modulated proton therapy (IMPT) may be sensitive to range variations. The dose distribution may deteriorate substantially when the actual range of a pencil beam does not match the assumed range. We present two treatment planning concepts for IMPT which incorporate range uncertainties into the optimization. The first method is a probabilistic approach. The range of a pencil beam is assumed to be a random variable, which makes the delivered dose and the value of the objective function a random variable too. We then propose to optimize the expectation value of the objective function. The second approach is a robust formulation that applies methods developed in the field of robust linear programming. This approach optimizes the worst case dose distribution that may occur, assuming that the ranges of the pencil beams may vary within some interval. Both methods yield treatment plans that are considerably less sensitive to range variations compared to conventional treatment plans optimized without accounting for range uncertainties. In addition, both approaches--although conceptually different--yield very similar results on a qualitative level.},
  keywords = {Algorithms,Humans,Phantoms; Imaging,Protons,Radiotherapy; Intensity-Modulated},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\AS6IE7YE\\Unkelbach, Chan, Bortfeld - 2007 - Accounting for range uncertainties in the optimization of intensity modulated proton therapy.pdf}
}

@article{Unkelbach2009,
  title = {Reducing the sensitivity of {{IMPT}} treatment plans to setup errors and range uncertainties via probabilistic treatment planning.},
  author = {Unkelbach, Jan and Bortfeld, Thomas and Martin, Benjamin C. and Soukup, Martin},
  date = {2009-12-12},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {36},
  number = {2009},
  eprint = {19235384},
  eprinttype = {pmid},
  pages = {149--163},
  publisher = {{American Association of Physicists in Medicine}},
  issn = {00942405},
  doi = {10.1118/1.3021139},
  url = {http://scitation.aip.org/content/aapm/journal/medphys/36/1/10.1118/1.3021139},
  urldate = {2015-03-25},
  abstract = {Treatment plans optimized for intensity modulated proton therapy (IMPT) may be very sensitive to setup errors and range uncertainties. If these errors are not accounted for during treatment planning, the dose distribution realized in the patient may by strongly degraded compared to the planned dose distribution. The authors implemented the probabilistic approach to incorporate uncertainties directly into the optimization of an intensity modulated treatment plan. Following this approach, the dose distribution depends on a set of random variables which parameterize the uncertainty, as does the objective function used to optimize the treatment plan. The authors optimize the expected value of the objective function. They investigate IMPT treatment planning regarding range uncertainties and setup errors. They demonstrate that incorporating these uncertainties into the optimization yields qualitatively different treatment plans compared to conventional plans which do not account for uncertainty. The sensitivity of an IMPT plan depends on the dose contributions of individual beam directions. Roughly speaking, steep dose gradients in beam direction make treatment plans sensitive to range errors. Steep lateral dose gradients make plans sensitive to setup errors. More robust treatment plans are obtained by redistributing dose among different beam directions. This can be achieved by the probabilistic approach. In contrast, the safety margin approach as widely applied in photon therapy fails in IMPT and is neither suitable for handling range variations nor setup errors.},
  keywords = {impt optimization,range uncertainty,setup error},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Q33DX7DU\\Unkelbach et al. - 2009 - Reducing the sensitivity of IMPT treatment plans to setup errors and range uncertainties via probabilistic tre.pdf}
}

@article{Unkelbach2018,
  title = {Robust radiotherapy planning},
  author = {Unkelbach, Jan and Alber, Markus and Bangert, Mark and Bokrantz, Rasmus and Chan, Timothy C Y and Deasy, Joseph O and Fredriksson, Albin and Gorissen, Bram L and family=Herk, given=Marcel, prefix=van, useprefix=true and Liu, Wei and Mahmoudzadeh, Houra and Nohadani, Omid and Siebers, Jeffrey V and Witte, Marnix and Xu, Huijun},
  date = {2018-11-12},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {63},
  number = {22},
  pages = {22TR02},
  publisher = {{IOP Publishing}},
  issn = {1361-6560},
  doi = {10.1088/1361-6560/aae659},
  url = {http://stacks.iop.org/0031-9155/63/i=22/a=22TR02?key=crossref.f8f50d2ac0a867a3fa115d936f139c87},
  urldate = {2019-05-20},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\28L3IYJU\\Unkelbach et al. - 2018 - Robust radiotherapy planning.pdf}
}

@article{Unkelbach2018a,
  ids = {Unkelbach2018b,unkelbachOptimizationCombinedProton2018},
  title = {Optimization of combined proton–photon treatments},
  author = {Unkelbach, Jan and Bangert, Mark and De Amorim Bernstein, Karen and Andratschke, Nicolaus and Guckenberger, Matthias},
  date = {2018-07-01},
  journaltitle = {Radiotherapy and Oncology},
  shortjournal = {Radiother Oncol},
  volume = {128},
  number = {1},
  pages = {133--138},
  issn = {0167-8140},
  doi = {10.1016/j.radonc.2017.12.031},
  url = {http://www.sciencedirect.com/science/article/pii/S0167814018300215},
  urldate = {2019-10-25},
  abstract = {Purpose Proton treatment slots are a limited resource. Therefore, we consider combined proton–photon treatments in which most fractions are delivered with photons and only a few with protons. We demonstrate how both modalities can be combined to optimally capitalize on the proton’s ability to reduce normal tissue dose. Methods An optimal combined treatment must account for fractionation effects. We therefore perform simultaneous optimization of intensity-modulated proton (IMPT) and photon (IMRT) plans based on their cumulative biologically effective dose (BED). We demonstrate the method for a sacral chordoma patient, in whom the gross tumor volume (GTV) abuts bowel and rectum. Results In an optimal combination, proton and photon fractions deliver similar doses to bowel and rectum to protect these dose-limiting normal tissues through fractionation. However, proton fractions deliver, on average, higher doses to the GTV. Thereby, the photon dose bath is reduced. An optimized 30-fraction treatment with 10 IMPT fractions achieved more than 50\% of the integral dose reduction in the gastrointestinal tract that is possible with 30 IMPT fractions (compared to 33\% for a simple proton–photon combination in which both modalities deliver the same target dose). Conclusions A limited number of proton fractions can best be used if protons hypofractionate parts of the GTV while maintaining near-uniform fractionation in dose-limiting normal tissues.},
  langid = {english},
  keywords = {Fractionation,IMPT,IMRT,Multi-modality radiotherapy,Treatment plan optimization},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\8MCF2R7I\\Unkelbach et al. - 2018 - Optimization of combined proton–photon treatments.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\4UQ6XKVA\\S0167814018300215.html;C\:\\Users\\Niklas\\Zotero\\storage\\LH33A7HZ\\S0167814018300215.html}
}

@misc{Utrecht,
  title = {Project {{Description}} on the {{Official UMC Website}}},
  author = {Utrecht, U M C},
  url = {http://www.umcutrecht.nl/subsite/radiotherapy-research/Research-projects/mri_guided_radiotherapy/MRI-accelerator.htm}
}

@article{VandenHeuvel2018,
  title = {Using stable distributions to characterize proton pencil beams},
  author = {Van den Heuvel, Frank and George, Ben and Schreuder, Niek and Fiorini, Francesca},
  date = {2018-05},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {45},
  number = {5},
  pages = {2278--2288},
  issn = {00942405},
  doi = {10.1002/mp.12876},
  url = {http://doi.wiley.com/10.1002/mp.12876},
  urldate = {2019-10-30},
  abstract = {Purpose: To introduce and evaluate the use of stable distributions as a methodology to quantify the behavior of proton pencil beams in a medium. Methods: The proton pencil beams of a clinically commissioned proton treatment facility are replicated in a Monte Carlo simulation system (FLUKA). For each available energy, the beam deposition in water medium is characterized by the dose deposition. Using a stable distribution methodology, each beam with a nominal energy E is characterized by the lateral spread at depth z: S(z; a, c, E) and a total energy deposition ID(z, E). The parameter a describes the tailedness of the distributions, while c is used to scale the size of the function. The beams can then be described completely by a function of the variation of the parameters with depth. Results: Quantitatively, the fit of the stable distributions, compared to those implemented in some standard treatment planning systems, are equivalent for all but the highest energies (i.e., 230 MeV/u). The decrease in goodness of fit makes this methodology comparable to a double Gaussian approach. The introduction of restricted linear combinations of stable distributions also resolves that particular case. More importantly, the meta-parameterization (i.e., the description of the dose deposition by only providing the fitted parameters) allows for interpolation of nonmeasured data. In the case of the clinical commissioning data used in this paper, it was possible to only commission one out of five nominal energies to obtain a viable dataset, valid for all energies. An additional parameter b allows to describe asymmetric beam profiles as well. Conclusions: Stable distributions are intrinsically suited to describe proton pencil beams in a medium and provide a tool to quantify the propagation of proton beams in a medium. © 2018 The Authors Medical Physics published by Wiley Periodicals, Inc. on behalf of American Association of Physicists in Medicine. [https://doi.org/10.1002/mp.12876]},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\AHRLINN9\\Van den Heuvel et al. - 2018 - Using stable distributions to characterize proton .pdf}
}

@article{VanderPut2009,
  title = {Contour propagation in {{MRI-guided}} radiotherapy treatment of cervical cancer: the accuracy of rigid, non-rigid and semi-automatic registrations},
  author = {family=Put, given=R W, prefix=van der, useprefix=true and Kerkhof, E M and Raaymakers, B W and J�rgenliemk-Schulz, I M and Lagendijk, J J W},
  date = {2009},
  journaltitle = {Physics in Medicine and Biology},
  volume = {54},
  number = {23},
  pages = {7135},
  url = {http://stacks.iop.org/0031-9155/54/i=23/a=007}
}

@article{vandeWater2009,
  title = {Tumour tracking with scanned proton beams: assessing the accuracy and practicalities},
  shorttitle = {Tumour tracking with scanned proton beams},
  author = {family=Water, given=S., prefix=van de, useprefix=true and Kreuger, R. and Zenklusen, S. and Hug, E. and Lomax, A. J.},
  date = {2009-10},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {54},
  number = {21},
  pages = {6549--6563},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/54/21/007},
  url = {https://doi.org/10.1088%2F0031-9155%2F54%2F21%2F007},
  urldate = {2020-04-03},
  abstract = {The potential of tumour tracking for active spot-scanned proton therapy was assessed. Using a 4D-dose calculation and simulated target motion, a tumour tracking algorithm has been implemented and applied to a simple target volume in both homogenous and heterogeneous in silico phantoms. For tracking and retracking (a hybrid solution combining tumour tracking and rescanning), three tracking modes were analysed: ‘no tracking’ (uncorrected irradiation of a moving target), ‘perfect tracking’ (no time delays and exact knowledge of target position) and ‘imperfect tracking’ (simulated time delays or position prediction errors). For all plans, dose homogeneity in the target volume was assessed as the difference between D5 and D95 in the CTV. For the homogeneous phantom, perfect tracking could retrieve nominal dose homogeneity for all motion phases and amplitudes while severe deterioration of treatment outcomes was found for imperfect tracking. The use of retracking reduced the sensitivity to position errors significantly in the homogeneous phantom. In the heterogeneous phantoms (simulated rib proximal to target), the nominal dose homogeneity could not be obtained with perfect tracking. Adjustments in pencil beam positions could cause pencil beams to deform under the influence of the bone, resulting in loss of dose homogeneity. As retracking was not capable of reducing these effects, rescanning provided the best treatment outcomes for moving heterogeneous targets in this study.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\6JZ9HRKZ\\Water et al. - 2009 - Tumour tracking with scanned proton beams assessi.pdf}
}

@article{vandeWater2019,
  title = {Towards {{FLASH}} proton therapy: the impact of treatment planning and machine characteristics on achievable dose rates},
  shorttitle = {Towards {{FLASH}} proton therapy},
  author = {family=Water, given=Steven, prefix=van de, useprefix=true and Safai, Sairos and Schippers, Jacobus M. and Weber, Damien C. and Lomax, Antony J.},
  date = {2019-10-03},
  journaltitle = {Acta Oncologica},
  shortjournal = {Acta Oncol},
  volume = {58},
  number = {10},
  pages = {1463--1469},
  issn = {0284-186X, 1651-226X},
  doi = {10.1080/0284186X.2019.1627416},
  url = {https://www.tandfonline.com/doi/full/10.1080/0284186X.2019.1627416},
  urldate = {2019-10-30},
  abstract = {Background: This study aimed at evaluating spatially varying instantaneous dose rates for different intensity-modulated proton therapy (IMPT) planning strategies and delivery scenarios, and comparing these with FLASH dose rates ({$>$}40 Gy/s). Material and methods: In order to quantify dose rates in three-dimensions, we proposed the ‘doseaveraged dose rate’ (DADR) metric, defined for each voxel as the dose-weighted mean of the instantaneous dose rates of all spots (i.e., pencil beams). This concept was applied to four head-and-neck cases, each planned with clinical (4 fields) and various spot-reduced IMPT techniques: ‘standard’ (4 fields), ‘arc’ (120 fields) and ‘arc-shoot-through’ (120 fields; 229 MeV only). For all plans, different delivery scenarios were simulated: constant beam intensity, variable beam intensity for a clinical Varian ProBeam system, varied per energy layer or per spot, and theoretical spot-wise variable beam intensity (i.e., no monitor/safety limitations). DADR distributions were calculated assuming 2-Gy or 6-Gy fractions. Results: Spot-reduced plans contained 17–52 times fewer spots than clinical plans, with no deterioration of plan quality. For the clinical plans, the mean DADR in normal tissue for 2-Gy fractionation was 1.7 Gy/s (median over all patients) at maximum, whereas in standard spot-reduced plans it was 0.7, 4.4, 7.1, and 12.1 Gy/s, for the constant, energy-layer-wise, spot-wise, and theoretical spot-wise delivery scenarios, respectively. Similar values were observed for arc plans. Arc-shoot-through planning resulted in DADR values of 3.0, 6.0, 14.1, and 24.4 Gy/s, for the abovementioned scenarios. Hypofractionation (3Â) generally resulted in higher dose rates, up to 73.2 Gy/s for arc-shoot-through plans. The DADR was inhomogeneously distributed with highest values at beam entrance and at the Bragg peak. Conclusion: FLASH dose rates were not achieved for conventional planning and clinical spot-scanning machines. As such, increased spot-wise beam intensities, spot-reduced planning, hypofractionation and arc-shoot-through plans were required to achieve FLASH compatible dose rates.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\5LYPUQBX\\van de Water et al. - 2019 - Towards FLASH proton therapy the impact of treatm.pdf}
}

@article{vanElmpt2016,
  title = {Dual energy {{CT}} in radiotherapy: {{Current}} applications and future outlook},
  shorttitle = {Dual energy {{CT}} in radiotherapy},
  author = {family=Elmpt, given=Wouter, prefix=van, useprefix=true and Landry, Guillaume and Das, Marco and Verhaegen, Frank},
  date = {2016-04-01},
  journaltitle = {Radiotherapy and Oncology},
  shortjournal = {Radiotherapy and Oncology},
  volume = {119},
  number = {1},
  pages = {137--144},
  issn = {0167-8140},
  doi = {10.1016/j.radonc.2016.02.026},
  url = {https://www.sciencedirect.com/science/article/pii/S0167814016001146},
  urldate = {2022-11-30},
  abstract = {Dual energy CT (DECT) scanners are nowadays available in many radiology departments. For radiotherapy purposes, new strategies using DECT imaging are investigated to optimize radiation treatment for multiple steps in the radiotherapy chain. This review describes how DECT based methods can be used for electron density estimation, effective atomic number decomposition and contrast material quantification. Clinical radiotherapy related applications for improved dose calculation accuracy of brachytherapy and proton therapy, metal artifact reduction techniques and normal tissue characterization are also summarized together with future perspectives on the use of DECT for radiotherapy purposes.},
  langid = {english},
  keywords = {Brachytherapy,Dose calculation,Dual energy CT,Material decomposition,Proton therapy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\H3NTKUYA\\van Elmpt et al. - 2016 - Dual energy CT in radiotherapy Current applicatio.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\BKHM4DV8\\S0167814016001146.html}
}

@thesis{vanHaveren,
  title = {Automatic {{Configuration}} of {{Fast Automated Multi}}‐{{Objective Treatment Planning}} in {{Radiotherapy}}},
  author = {family=Haveren, given=Rens, prefix=van, useprefix=true},
  institution = {{Ridderprint}},
  langid = {english},
  pagetotal = {168},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\HDCDKTKB\\van Haveren - Automatic Configuration of Fast Automated Multi‐Ob.pdf}
}

@article{vanHerk2000,
  title = {The probability of correct target dosage: dose-population histograms for deriving treatment margins in radiotherapy},
  author = {family=Herk, given=Marcel, prefix=van, useprefix=true and Remeijer, Peter and Rasch, Coen and Lebesque, Joos V.},
  date = {2000},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {Int J Radiat Oncol Biol Phys},
  volume = {47},
  number = {4},
  pages = {1121--1135},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301600005186},
  urldate = {2014-01-15},
  abstract = {Purpose: To provide an analytical description of the effect of random and systematic geometrical deviations on the target dose in radiotherapy and to derive margin rules. Methods and Materials: The cumulative dose distribution delivered to the clinical target volume (CTV) is expressed analytically. Geometrical deviations are separated into treatment execution (random) and treatment preparation (systematic) variations. The analysis relates each possible preparation (systematic) error to the dose distribution over the CTV and allows computation of the probability distribution of, for instance, the minimum dose delivered to the CTV. Results: The probability distributions of the cumulative dose over a population of patients are called dose-population histograms in short. Large execution (random) variations lead to CTV underdosage for a large number of patients, while the same level of preparation (systematic) errors leads to a much larger underdosage for some of the patients. A single point on the histogram gives a simple “margin recipe.” For example, to ensure a minimum dose to the CTV of 95\% for 90\% of the patients, a margin between CTV and planning target volume (PTV) is required of 2.5 times the total standard deviation (SD) of preparation (systematic) errors (Σ) plus 1.64 times the total SD of execution (random) errors (σ′) combined with the penumbra width, minus 1.64 times the SD describing the penumbra width (σp). For a σp of 3.2 mm, this recipe can be simplified to 2.5 Σ + 0.7 σ′. Because this margin excludes rotational errors and shape deviations, it must be considered as a lower limit for safe radiotherapy. Conclusion: Dose-population histograms provide insight into the effects of geometrical deviations on a population of patients. Using a dose-probability based approach, simple algorithms for choosing margins were derived.},
  keywords = {Delineation variation,Margins,Organ motion,Radiotherapy,Setup error},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\V84CSPQ7\\van Herk et al. - 2000 - The probability of correct target dosage dose-population histograms for deriving treatment margins in radiother.pdf}
}

@article{vanHerk2002,
  title = {Inclusion of geometric uncertainties in treatment plan evaluation},
  author = {family=Herk, given=Marcel, prefix=van, useprefix=true and Remeijer, Peter and Lebesque, Joos V},
  date = {2002-04-01},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {52},
  number = {5},
  eprint = {11955756},
  eprinttype = {pmid},
  pages = {1407--1422},
  issn = {0360-3016},
  url = {http://www.sciencedirect.com/science/article/pii/S036030160102805X},
  urldate = {2014-01-15},
  abstract = {Purpose: To correctly evaluate realistic treatment plans in terms of absorbed dose to the clinical target volume (CTV), equivalent uniform dose (EUD), and tumor control probability (TCP) in the presence of execution (random) and preparation (systematic) geometric errors. Materials and Methods: The dose matrix is blurred with all execution errors to estimate the total dose distribution of all fractions. To include preparation errors, the CTV is randomly displaced (and optionally rotated) many times with respect to its planned position while computing the dose, EUD, and TCP for the CTV using the blurred dose matrix. Probability distributions of these parameters are computed by combining the results with the probability of each particular preparation error. We verified the method by comparing it with an analytic solution. Next, idealized and realistic prostate plans were tested with varying margins and varying execution and preparation error levels. Results: Probability levels for the minimum dose, computed with the new method, are within 1\% of the analytic solution. The impact of rotations depends strongly on the CTV shape. A margin of 10 mm between the CTV and planning target volume is adequate for three-field prostate treatments given the accuracy level in our department; i.e., the TCP in a population of patients, TCPpop, is reduced by less than 1\% due to geometric errors. When reducing the margin to 6 mm, the dose must be increased from 80 to 87 Gy to maintain the same TCPpop. Only in regions with a high-dose gradient does such a margin reduction lead to a decrease in normal tissue dose for the same TCPpop. Based on a rough correspondence of 84\% minimum dose with 98\% EUD, a margin recipe was defined. To give 90\% of patients at least 98\% EUD, the planning target volume margin must be approximately 2.5 Σ + 0.7 σ − 3 mm, where Σ and σ are the combined standard deviations of the preparation and execution errors. This recipe corresponds accurately with 1\% TCPpop loss for prostate plans with clinically reasonable values of Σ and σ. Conclusion: The new method computes in a few minutes the influence of geometric errors on the statistics of target dose and TCPpop in clinical treatment plans. Too small margins lead to a significant loss of TCPpop that is difficult to compensate for by dose escalation.},
  keywords = {Algorithms,Clinical target volume,Conformal,Conformal: methods,Equivalent uniform dose,Geometric uncertainties,Humans,Male,Margins,Physical Phenomena,Physics,Prostatic Neoplasms,Prostatic Neoplasms: radiotherapy,Radiotherapy,Radiotherapy Dosage,Tumor control probability},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\V5DIDPFP\\van Herk, Remeijer, Lebesque - 2002 - Inclusion of geometric uncertainties in treatment plan evaluation.pdf}
}

@article{VanHerk2003,
  title = {Biologic and physical fractionation effects of random geometric errors},
  author = {Van Herk, Marcel and Witte, Marnix and Van Der Geer, Joris and Schneider, Christoph and Lebesque, Joos V.},
  date = {2003},
  journaltitle = {International Journal of Radiation Oncology Biology Physics},
  volume = {57},
  number = {5},
  eprint = {14630286},
  eprinttype = {pmid},
  pages = {1460--1471},
  issn = {03603016},
  doi = {10.1016/j.ijrobp.2003.08.026},
  abstract = {Purpose: We are developing a system to model the effect of random and systematic geometric errors on radiotherapy delivery. The purpose of this study was to investigate biologic and physical fractionation effects of random geometric errors and respiration motion and compare the resulting dose distributions with Gaussian blurring of the planned dose. Methods and Materials: A hypothetical dose distribution with Gaussian penumbra was used. Random errors drawn from a normal distribution, optionally combined with simulated respiration motion (in the cranio-caudal direction), were used to displace the dose distribution for N simulated fractions. To simulate biologic effects of fractionation, the physical dose was converted to a biologically effective dose using the linear-quadratic model (including repopulation), then summed and converted back to physical dose for comparison. Differences between dose distributions were quantified in terms of the distance between selected isodose levels. Results: A limited number of fractions led to an uncertainty in the position of isodose levels in the total dose with as standard deviation (SD) the SD of the random error divided by √N. Due to biologic fractionation effects, the total dose distribution became slightly wider: 0.4 mm for α/β = 1 Gy and a random error SD of 3 mm. The widening increased with random error and reduced with increasing α/β but does not depend on the number of fractions or on repopulation. Respiration motion caused an asymmetric deviation in the shape of the total dose distribution, but no additional dose widening was seen from the biologic effect of fractionation. With a random error SD of 3 mm and respiration amplitude, A, of 1 cm or less (SD {$<$} 0.36 cm), the asymmetry was negligible. For larger respiration amplitudes (combined with the same random error), the shift of the 95\% isodose level was about 0.25*A caudally, and 0.45*A cranially. Conclusions: Gaussian blurring with a combined SD of organ motion, setup error, and respiration motion is a valid approximation for the effect of purely random errors in fractionated radiotherapy. For respiration motion in excess of 1 cm in amplitude, isodose lines shift in a distinctly asymmetric fashion and asymmetric margins need to be used. © 2003 Elsevier Inc.},
  isbn = {0360-3016 (Print)},
  keywords = {Biologic fractionation effects,Random errors,Respiration},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\4V8TF7K2\\Van Herk et al. - 2003 - Biologic and physical fractionation effects of random geometric errors.pdf}
}

@article{vanHerk2004,
  title = {Errors and margins in radiotherapy},
  author = {family=Herk, given=Marcel, prefix=van, useprefix=true},
  date = {2004-01},
  journaltitle = {Seminars in Radiation Oncology},
  shortjournal = {Semin Radiat Oncol},
  volume = {14},
  number = {1},
  pages = {52--64},
  issn = {10534296},
  doi = {10.1053/j.semradonc.2003.10.003},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S1053429603000845},
  urldate = {2017-01-30},
  abstract = {Clinical radiotherapy procedures aim at high accuracy. However, there are many error sources that act during treatment preparation and execution that limit the accuracy. As a consequence, a safety margin is required to ensure that the planned dose is actually delivered to the target for (almost) all patients. Before treatment planning, a planning computed tomography scan is made. In particular, motion of skin with respect to the internal anatomy limits the reproducibility of this step, introducing a systematic setup error. The second important error source is organ motion. The tumor is imaged in an arbitrary position, leading to a systematic organ motion error. The image may also be distorted because of the interference of the scanning process and organ motion. A further systematic error introduced during treatment planning is caused by the delineation process. During treatment, the most important errors are setup error and organ motion leading to day-to-day variations. There are many ways to define the margins required for these errors. In this article, an overview is given of errors in radiotherapy and margin recipes, based on physical and biological considerations. Respiration motion is treated separately.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\UADP668T\\van Herk - 2004 - Errors and margins in radiotherapy.pdf}
}

@article{vanLeeuwen2018,
  title = {The alfa and beta of tumours: a review of parameters of the linear-quadratic model, derived from clinical radiotherapy studies},
  shorttitle = {The alfa and beta of tumours},
  author = {family=Leeuwen, given=C. M., prefix=van, useprefix=true and Oei, A. L. and Crezee, J. and Bel, A. and Franken, N. A. P. and Stalpers, L. J. A. and Kok, H. P.},
  date = {2018-12},
  journaltitle = {Radiation Oncology},
  shortjournal = {Radiat Oncol},
  volume = {13},
  number = {1},
  pages = {96},
  issn = {1748-717X},
  doi = {10.1186/s13014-018-1040-z},
  url = {https://ro-journal.biomedcentral.com/articles/10.1186/s13014-018-1040-z},
  urldate = {2020-11-20},
  abstract = {Background: Prediction of radiobiological response is a major challenge in radiotherapy. Of several radiobiological models, the linear-quadratic (LQ) model has been best validated by experimental and clinical data. Clinically, the LQ model is mainly used to estimate equivalent radiotherapy schedules (e.g. calculate the equivalent dose in 2 Gy fractions, EQD2), but increasingly also to predict tumour control probability (TCP) and normal tissue complication probability (NTCP) using logistic models. The selection of accurate LQ parameters α, β and α/β is pivotal for a reliable estimate of radiation response. The aim of this review is to provide an overview of published values for the LQ parameters of human tumours as a guideline for radiation oncologists and radiation researchers to select appropriate radiobiological parameter values for LQ modelling in clinical radiotherapy. Methods and materials: We performed a systematic literature search and found sixty-four clinical studies reporting α, β and α/β for tumours. Tumour site, histology, stage, number of patients, type of LQ model, radiation type, TCP model, clinical endpoint and radiobiological parameter estimates were extracted. Next, we stratified by tumour site and by tumour histology. Study heterogeneity was expressed by the I2 statistic, i.e. the percentage of variance in reported values not explained by chance. Results: A large heterogeneity in LQ parameters was found within and between studies (I2 {$>$} 75\%). For the same tumour site, differences in histology partially explain differences in the LQ parameters: epithelial tumours have higher α/β values than adenocarcinomas. For tumour sites with different histologies, such as in oesophageal cancer, the α/β estimates correlate well with histology. However, many other factors contribute to the study heterogeneity of LQ parameters, e.g. tumour stage, type of LQ model, TCP model and clinical endpoint (i.e. survival, tumour control and biochemical control). Conclusions: The value of LQ parameters for tumours as published in clinical radiotherapy studies depends on many clinical and methodological factors. Therefore, for clinical use of the LQ model, LQ parameters for tumour should be selected carefully, based on tumour site, histology and the applied LQ model. To account for uncertainties in LQ parameter estimates, exploring a range of values is recommended.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Y9UYKDYH\\van Leeuwen et al. - 2018 - The alfa and beta of tumours a review of paramete.pdf}
}

@article{VantRiet1997,
  title = {A conformation number to quantify the degree of conformality in brachytherapy and external beam irradiation: application to the prostate.},
  author = {family=Riet, given=A, prefix=van't, useprefix=true and Mak, A C and Moerland, M A and Elders, L H and family=Zee, given=W, prefix=van der, useprefix=true},
  date = {1997-02-01},
  journaltitle = {International journal of radiation oncology, biology, physics},
  volume = {37},
  number = {3},
  eprint = {9112473},
  eprinttype = {pmid},
  pages = {731--6},
  issn = {0360-3016},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301696006013},
  urldate = {2013-06-24},
  abstract = {This article presents a method of quantitative assessment of the degree of conformality and its designation by a single numerical value.},
  keywords = {Brachytherapy,Computer-Assisted,Humans,Male,Prostatic Neoplasms,Prostatic Neoplasms: pathology,Prostatic Neoplasms: radiotherapy,Radiometry,Radiometry: methods,Radiotherapy Dosage,Radiotherapy Planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\4TJ5FYF4\\van't Riet et al. - 1997 - A conformation number to quantify the degree of conformality in brachytherapy and external beam irradiation a.pdf}
}

@article{Vargas-Bedoya2022,
  title = {Contour {{Propagation}} for {{Radiotherapy Treatment Planning Using Nonrigid Registration}} and {{Parameter Optimization}}: {{Case Studies}} in {{Liver}} and {{Breast Cancer}}},
  shorttitle = {Contour {{Propagation}} for {{Radiotherapy Treatment Planning Using Nonrigid Registration}} and {{Parameter Optimization}}},
  author = {Vargas-Bedoya, Eliseo and Rivera, Juan Carlos and Puerta, Maria Eugenia and Angulo, Aurelio and Wahl, Niklas and Cabal, Gonzalo},
  date = {2022-08-26},
  journaltitle = {Applied Sciences},
  shortjournal = {Appl. Sci.},
  volume = {12},
  number = {17},
  pages = {8523},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2076-3417},
  doi = {10.3390/app12178523},
  url = {https://www.mdpi.com/2076-3417/12/17/8523},
  urldate = {2022-08-26},
  abstract = {Radiotherapy treatments are carried out using computerized axial tomography. In radiation therapy planning, the radiation oncologist must do a manual segmentation of volumes of interest to delineate the organs that should be irradiated. This way of carrying out the process generates long execution times and introduces a subjective component. In this study, a contour-propagation algorithm is formulated to automate the segmentation, based on elastic registration or nonrigid demon registration. A heuristic algorithm to find the parameters that optimize the registration is also proposed. The parameters found along with the contour-propagation algorithm are able to estimate contours of scans with Dice similarity coefficients (DSC) greater than 0.92 and maintain stability with B-spline registration, which takes in the parameters found as input. The study allows for validating the results using the correlation coefficient (CC) to compare the similarity between the voxels’ gray-scale intensity of the estimated tomography and the original tomography, obtaining values greater than 0.96. These values were validated under medical criteria and applied to liver and breast CT scans, indicating good performance for radiation therapy planning.},
  issue = {17},
  langid = {english},
  keywords = {demons,heuristic methods,image registration,nonrigid registration},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\B6LJ5G67\\Vargas-Bedoya et al. - 2022 - Contour Propagation for Radiotherapy Treatment Pla.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\5UD6C7XK\\8523.html}
}

@article{Vayanos2012,
  title = {A constraint sampling approach for multi-stage robust optimization},
  author = {Vayanos, Phebe and Kuhn, Daniel and Rustem, Berç},
  date = {2012},
  journaltitle = {Automatica},
  volume = {48},
  number = {3},
  pages = {459--471},
  issn = {00051098},
  doi = {10.1016/j.automatica.2011.12.002},
  abstract = {We propose a tractable approximation scheme for convex (not necessarily linear) multi-stage robust optimization problems. We approximate the adaptive decisions by finite linear combinations of prescribed basis functions and demonstrate how one can optimize over these decision rules at low computational cost through constraint randomization. We obtain a-priori probabilistic guarantees on the feasibility properties of the optimal decision rule by applying existing constraint sampling techniques to the semi-infinite problem arising from the decision rule approximation. We demonstrate that for a suitable choice of basis functions, the approximation converges as the size of the basis and the number of sampled constraints tend to infinity. The approach yields an algorithm parameterized in the basis size, the probability of constraint violation and the confidence that this probability will not be exceeded. These three parameters serve to tune the trade-off between optimality and feasibility of the decision rules and the computational cost of the algorithm. We assess the convergence and scalability properties of our approach in the context of two inventory management problems. © 2012 Elsevier Ltd. All rights reserved.},
  keywords = {Decision rules,Multi-stage robust optimization,Scenario approximation,Violation probability},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\VC2RM5IV\\Vayanos, Kuhn, Rustem - 2012 - A constraint sampling approach for multi-stage robust optimization.pdf}
}

@article{Veiga2014,
  title = {Toward adaptive radiotherapy for head and neck patients: {{Feasibility}} study on using {{CT-to-CBCT}} deformable registration for “dose of the day” calculations},
  shorttitle = {Toward adaptive radiotherapy for head and neck patients},
  author = {Veiga, Catarina and McClelland, Jamie and Moinuddin, Syed and Lourenço, Ana and Ricketts, Kate and Annkah, James and Modat, Marc and Ourselin, Sébastien and D'Souza, Derek and Royle, Gary},
  date = {2014},
  journaltitle = {Medical Physics},
  volume = {41},
  number = {3},
  pages = {031703},
  issn = {2473-4209},
  doi = {10.1118/1.4864240},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1118/1.4864240},
  urldate = {2022-08-11},
  abstract = {Purpose: The aim of this study was to evaluate the appropriateness of using computed tomography (CT) to cone-beam CT (CBCT) deformable image registration (DIR) for the application of calculating the “dose of the day” received by a head and neck patient. Methods: NiftyReg is an open-source registration package implemented in our institution. The affine registration uses a Block Matching-based approach, while the deformable registration is a GPU implementation of the popular B-spline Free Form Deformation algorithm. Two independent tests were performed to assess the suitability of our registrations methodology for “dose of the day” calculations in a deformed CT. A geometric evaluation was performed to assess the ability of the DIR method to map identical structures between the CT and CBCT datasets. Features delineated in the planning CT were warped and compared with features manually drawn on the CBCT. The authors computed the dice similarity coefficient (DSC), distance transformation, and centre of mass distance between features. A dosimetric evaluation was performed to evaluate the clinical significance of the registrations errors in the application proposed and to identify the limitations of the approximations used. Dose calculations for the same intensity-modulated radiation therapy plan on the deformed CT and replan CT were compared. Dose distributions were compared in terms of dose differences (DD), gamma analysis, target coverage, and dose volume histograms (DVHs). Doses calculated in a rigidly aligned CT and directly in an extended CBCT were also evaluated. Results: A mean value of 0.850 in DSC was achieved in overlap between manually delineated and warped features, with the distance between surfaces being less than 2 mm on over 90\% of the pixels. Deformable registration was clearly superior to rigid registration in mapping identical structures between the two datasets. The dose recalculated in the deformed CT is a good match to the dose calculated on a replan CT. The DD is smaller than 2\% of the prescribed dose on 90\% of the bodyˈs voxels and it passes a 2\% and 2 mm gamma-test on over 95\% of the voxels. Target coverage similarity was assessed in terms of the 95\%-isodose volumes. A mean value of 0.962 was obtained for the DSC, while the distance between surfaces is less than 2 mm in 95.4\% of the pixels. The method proposed provided adequate dose estimation, closer to the gold standard than the other two approaches. Differences in DVH curves were mainly due to differences in the OARs definition (manual vs warped) and not due to differences in dose estimation (dose calculated in replan CT vs dose calculated in deformed CT). Conclusions: Deforming a planning CT to match a daily CBCT provides the tools needed for the calculation of the “dose of the day” without the need to acquire a new CT. The initial clinical application of our method will be weekly offline calculations of the “dose of the day,” and use this information to inform adaptive radiotherapy (ART). The work here presented is a first step into a full implementation of a “dose-driven” online ART.},
  langid = {english},
  keywords = {adaptive radiotherapy,Algebraic structures and number theory,Anatomy,Calibration,Computed tomography,Computerised tomographs,computerised tomography,Cone beam computed tomography,cone-beam CT,deformable image registration,Digital computing or data processing equipment or methods,Dose-volume analysis,dosimetry,Dosimetry,Dosimetry/exposure assessment,e.g. pipelining,graphics processing units,head and neck cancer,Image data processing or generation,image registration,in general,including brachytherapy,Intensity modulated radiation therapy,medical image processing,Medical image quality,Medical imaging,Processor architectures,Processor configuration,radiation therapy,Radiation therapy,Registration,Scintigraphy,specially adapted for specific applications,splines (mathematics),Therapeutic applications,Therapeutics},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1118/1.4864240},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\BCCMFHJG\\Veiga et al. - 2014 - Toward adaptive radiotherapy for head and neck pat.pdf}
}

@article{Veiga2016,
  ids = {Veiga2016a},
  title = {First {{Clinical Investigation}} of {{Cone Beam Computed Tomography}} and {{Deformable Registration}} for {{Adaptive Proton Therapy}} for {{Lung Cancer}}.},
  author = {Veiga, Catarina and Janssens, Guillaume and Teng, Ching-Ling and Baudier, Thomas and Hotoiu, Lucian and McClelland, Jamie R and Royle, Gary and Lin, Liyong and Yin, Lingshu and Metz, James and Solberg, Timothy D and Tochner, Zelig and Simone, Charles B and McDonough, James and Teo, Boon-Keng Kevin},
  date = {2016-05-01},
  journaltitle = {International journal of radiation oncology, biology, physics},
  volume = {95},
  number = {1},
  eprint = {27084664},
  eprinttype = {pmid},
  pages = {549--59},
  publisher = {{Elsevier}},
  issn = {1879-355X},
  doi = {10.1016/j.ijrobp.2016.01.055},
  abstract = {PURPOSE An adaptive proton therapy workflow using cone beam computed tomography (CBCT) is proposed. It consists of an online evaluation of a fast range-corrected dose distribution based on a virtual CT (vCT) scan. This can be followed by more accurate offline dose recalculation on the vCT scan, which can trigger a rescan CT (rCT) for replanning. METHODS AND MATERIALS The workflow was tested retrospectively for 20 consecutive lung cancer patients. A diffeomorphic Morphon algorithm was used to generate the lung vCT by deforming the average planning CT onto the CBCT scan. An additional correction step was applied to account for anatomic modifications that cannot be modeled by deformation alone. A set of clinical indicators for replanning were generated according to the water equivalent thickness (WET) and dose statistics and compared with those obtained on the rCT scan. The fast dose approximation consisted of warping the initial planned dose onto the vCT scan according to the changes in WET. The potential under- and over-ranges were assessed as a variation in WET at the target's distal surface. RESULTS The range-corrected dose from the vCT scan reproduced clinical indicators similar to those of the rCT scan. The workflow performed well under different clinical scenarios, including atelectasis, lung reinflation, and different types of tumor response. Between the vCT and rCT scans, we found a difference in the measured 95\% percentile of the over-range distribution of 3.4 ± 2.7 mm. The limitations of the technique consisted of inherent uncertainties in deformable registration and the drawbacks of CBCT imaging. The correction step was adequate when gross errors occurred but could not recover subtle anatomic or density changes in tumors with complex topology. CONCLUSIONS A proton therapy workflow based on CBCT provided clinical indicators similar to those using rCT for patients with lung cancer with considerable anatomic changes.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\S3QINU32\\Veiga et al. - 2016 - First Clinical Investigation of Cone Beam Computed Tomography and Deformable Registration for Adaptive Proton Ther.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\YFFJJMA5\\Veiga et al. - 2016 - First Clinical Investigation of Cone Beam Computed Tomography and Deformable Registration for Adaptive Proton Ther.pdf}
}

@article{Vermeesch2005,
  title = {Statistical uncertainty associated with histograms in the earth sciences},
  author = {Vermeesch, Pieter},
  date = {2005},
  journaltitle = {Journal of Geophysical Research B: Solid Earth},
  volume = {110},
  number = {2},
  pages = {1--15},
  issn = {01480227},
  doi = {10.1029/2004JB003479},
  abstract = {[1] Two types of quantitative information can be distinguished in the Earth sciences: categorical data (e. g., mineral type, fossil name) and continuous data (e. g., apparent age, strike, dip). Many branches of the Earth sciences study populations of such data by collecting a random sample and binning it into a histogram. Histograms of categorical data follow multinomial distributions. All possible outcomes of a multinomial distribution with M categories must plot on a (M-1) simplex Delta(M-1) because they are subject to a constant sum constraint. Confidence regions for such multinomial distributions can be computed using Bayesian statistics. The conjugate prior/posterior to the multinomial distribution is the Dirichlet distribution. A 100(1-alpha)\% confidence interval for the unknown multinomial population given an observed sample histogram is a polygon on Delta(M-1) containing 100(1-alpha)\% of its Dirichlet posterior. The projection of this polygon onto the sides of the simplex yields M confidence intervals for the M bin counts. These confidence intervals are "simultaneous'' in the sense that they form a band completely containing the 100(1-alpha)\% most likely multinomial populations. As opposed to categorical variables, adjacent bins of histograms containing continuous variables are not mutually independent. If this "smoothness'' of the unknown population is not taken into account, the Bayesian confidence bands described above will be overly conservative. This problem can be solved by introducing an ad hoc prior of "smoothing weights'' w = e(-sr), where r is the integrated squared second derivative of the histogram and s is a "smoothing parameter".},
  isbn = {0148-0227},
  keywords = {http://dx.doi.org/10.1029/2004JB003479; doi:10.102},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\9ZTL28PG\\Vermeesch - 2005 - Statistical uncertainty associated with histograms in the earth sciences.pdf}
}

@misc{Viewray,
  title = {Official {{Viewray Website}}},
  author = {{Viewray}},
  url = {http://www.viewray.com}
}

@article{Viswanathan2010,
  title = {Radiation dose-volume effects of the urinary bladder.},
  author = {Viswanathan, Akila N and Yorke, Ellen D and Marks, Lawrence B and Eifel, Patricia J and Shipley, William U},
  date = {2010-03-01},
  journaltitle = {International journal of radiation oncology, biology, physics},
  volume = {76},
  eprint = {20171505},
  eprinttype = {pmid},
  pages = {S116-22},
  issn = {1879-355X},
  doi = {10.1016/j.ijrobp.2009.02.090},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301609032854},
  urldate = {2014-02-21},
  abstract = {An in-depth overview of the normal-tissue radiation tolerance of the urinary bladder is presented. The most informative studies consider whole-organ irradiation. The data on partial-organ/nonuniform irradiation are suspect because the bladder motion is not accounted for, and many studies lack long enough follow-up data. Future studies are needed.},
  issue = {3 Suppl},
  keywords = {Female,Forecasting,Humans,Hysterectomy,Hysterectomy: adverse effects,Male,Models; Biological,Movement,Prostatectomy,Prostatectomy: adverse effects,Prostatic Neoplasms,Prostatic Neoplasms: radiotherapy,Radiation Injuries,Radiation Injuries: complications,Radiation Tolerance,Radiotherapy Dosage,Urinary Bladder,Urinary Bladder Neoplasms,Urinary Bladder Neoplasms: radiotherapy,Urinary Bladder: radiation effects,Urinary Bladder: radiography,Uterine Cervical Neoplasms,Uterine Cervical Neoplasms: radiotherapy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\BJX3TC5K\\Viswanathan et al. - 2010 - Radiation dose-volume effects of the urinary bladder.pdf}
}

@article{Visweswariah2006,
  title = {First-order incremental block-based statistical timing analysis},
  author = {Visweswariah, Chandramouli and Ravindran, Kaushik and Kalafala, Kerim and Walker, Steven G and Narayan, Sambasivan and Beece, Daniel K and Piaget, Jeff and Venkateswaran, Natesan and Hemmett, Jeffrey G},
  date = {2006},
  journaltitle = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  volume = {25},
  number = {10},
  pages = {2170--2180},
  issn = {0278-0070},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\R8YU9H8H\\Visweswariah et al. - 2006 - First-order incremental block-based statistical timing analysis.pdf}
}

@article{Volz2018,
  title = {The impact of secondary fragments on the image quality of helium ion imaging},
  author = {Volz, Lennart and Piersimoni, Pierluigi and Bashkirov, Vladimir A and Brons, Stephan and Collins-Fekete, Charles-Antoine and Johnson, Robert P and Schulte, Reinhard W and Seco, Joao},
  date = {2018-10-02},
  journaltitle = {Physics in Medicine \& Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {63},
  number = {19},
  pages = {195016},
  issn = {1361-6560},
  doi = {10.1088/1361-6560/aadf25},
  url = {http://stacks.iop.org/0031-9155/63/i=19/a=195016?key=crossref.97c973c4942dc76f6137118fcd32fd5b},
  urldate = {2020-03-25},
  abstract = {Single-event ion imaging enables the direct reconstruction of the relative stopping power (RSP) information required for ion-beam therapy. Helium ions were recently hypothesized to be the optimal species for such technique. The purpose of this work is to investigate the effect of secondary fragments on the image quality of helium CT (HeCT) and to assess the performance of a prototype proton CT (pCT) scanner when operated with helium beams in Monte Carlo simulations and experiment.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\4K7Q3H8Q\\Volz et al. - 2018 - The impact of secondary fragments on the image qua.pdf}
}

@article{Volz2019,
  title = {Improving single-event proton {{CT}} by removing nuclear interaction events within the energy/range detector},
  author = {Volz, Lennart and Piersimoni, Pierluigi and Johnson, Robert P. and Bashkirov, Vladimir A. and Schulte, Reinhard W. and Seco, Joao},
  date = {2019-08},
  journaltitle = {Physics in Medicine \& Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {64},
  number = {15},
  pages = {15NT01},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/ab2671},
  url = {https://doi.org/10.1088%2F1361-6560%2Fab2671},
  urldate = {2020-03-25},
  abstract = {Data filtering is crucial for accurate relative stopping power (RSP) reconstruction in proton CT (pCT). In this work, we assess different filters and their performance for the US pCT collaboration prototype pCT system in Monte Carlo (MC) simulations. The potential of using the recently proposed -E filter for removing nuclear interactions that occurred in the energy/range detector of the pCT system is investigated. Full pCT scans were acquired with the TOPAS MC simulated version of the prototype scanner that comprises two tracking detectors and a five stage energy/range detector. An ideal water cylinder and a water cylinder with five tissue inserts were investigated. Before image reconstruction, a WEPL filter was applied as the only filter, or in addition to filters acting on the energy deposit in each of the energy detector stages, as done currently with the prototype. The potential of the -E filter that was recently proposed for helium imaging was assessed. The results were compared to simulations for which nuclear interactions were disabled representing ground truth. The WEPL filter alone was not sufficient to filter out all nuclear interaction events and systematic fluctuations in the form of ring artifacts were present in the pCT reconstructed images. Applying energy filters currently used with the device prior to the WEPL filter only slightly improved the image quality. A WEPL filter improved the mean RSP accuracy, but could not fully remove the systematic fluctuations. The -E filter in addition to the current reconstruction procedure efficiently removed the systematic fluctuations and the achieved RSP accuracy closely matched the simulation without nuclear interactions. This study demonstrates the dependence of the accuracy of the usual WEPL filter on uncertainties arising within the energy detector. By enabling to remove such uncertainties, the -E method proved to yield some potential for improving the accuracy of pCT.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\6JTD2QXG\\Volz et al. - 2019 - Improving single-event proton CT by removing nucle.pdf}
}

@article{Volz2020,
  title = {Experimental exploration of a mixed helium/carbon beam for online treatment monitoring in carbon ion beam therapy},
  author = {Volz, L. and Kelleter, L. and Brons, S. and Burigo, L. and Graeff, C. and Niebuhr, N. I. and Radogna, R. and Scheloske, S. and Schömers, C. and Jolly, S. and Seco, J.},
  date = {2020-02},
  journaltitle = {Physics in Medicine \& Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {65},
  number = {5},
  pages = {055002},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/ab6e52},
  url = {https://doi.org/10.1088%2F1361-6560%2Fab6e52},
  urldate = {2020-03-25},
  abstract = {Recently, it has been proposed that a mixed helium/carbon beam could be used for online monitoring in carbon ion beam therapy. Fully stripped, the two ion species exhibit approximately the same mass/charge ratio and hence could potentially be accelerated simultaneously in a synchrotron to the same energy per nucleon. At the same energy per nucleon, helium ions have about three times the range of carbon ions, which could allow for simultaneous use of the carbon ion beam for treatment and the helium ion beam for imaging. In this work, measurements and simulations of PMMA phantoms as well as anthropomorphic phantoms irradiated sequentially with a helium ion and a carbon ion beam at equal energy per nucleon are presented. The range of the primary helium ion beam and the fragment tail of the carbon ion beam exiting the phantoms were detected using a novel range telescope made of thin plastic scintillator sheets read out by a flat-panel CMOS sensor. A 10:1 carbon to helium mixing ratio is used, generating a helium signal well above the carbon fragment background while adding little to the dose delivered to the patient. The range modulation of a narrow air gap of 1 mm thickness in the PMMA phantom that affects less than a quarter of the particles in a pencil beam were detected, demonstrating the achievable relative sensitivity of the presented method. Using two anthropomorphic pelvis phantoms it is shown that small rotations of the phantom as well as simulated bowel gas movements cause detectable changes in the helium/carbon beam exiting the phantom. The future prospects and limitations of the helium/carbon mixing as well as its technical feasibility are discussed.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\W7UX89FB\\Volz et al. - 2020 - Experimental exploration of a mixed heliumcarbon .pdf}
}

@article{Wachter2006,
  title = {On the implementation of an interior-point filter line-search algorithm for large-scale nonlinear programming},
  author = {Wächter, Andreas and Biegler, Lorenz T.},
  date = {2006-03-28},
  journaltitle = {Mathematical Programming},
  shortjournal = {Math Program},
  volume = {106},
  number = {1},
  pages = {25--57},
  publisher = {{Springer-Verlag}},
  issn = {0025-5610},
  doi = {10.1007/s10107-004-0559-y},
  url = {http://link.springer.com/10.1007/s10107-004-0559-y},
  urldate = {2016-11-22},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\R3KYJZMN\\Wächter, Biegler - 2006 - On the implementation of an interior-point filter line-search algorithm for large-scale nonlinear programming.pdf}
}

@inproceedings{Wahl2015,
  title = {Robust {{Planning}} for {{Intensity-modulated Proton Therapy}} using {{Analytical Probabilistic Modeling}}},
  booktitle = {International {{Journal}} of {{Particle Therapy}}},
  author = {Wahl, Niklas and Kamerling, Cornelis Philippus and Heinrich, Hendrik and Hennig, Philipp and Bangert, Mark},
  date = {2015},
  volume = {2},
  number = {1},
  pages = {314f},
  location = {{San Diego}},
  issn = {2331-5180},
  doi = {10.14338/IJPT.15-PTCOG-NA.1},
  url = {http://theijpt.org/doi/10.14338/IJPT.15-PTCOG-NA.1},
  eventtitle = {{{PTCOG}} \& {{PTCOG-NA}}},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\59LQBN9V\\Wahl et al. - 2015 - Robust Planning for Intensity-modulated Proton Therapy using Analytical Probabilistic Modeling.pdf}
}

@book{Wahl2015Book,
  title = {Tutorium {{Physik}} fürs {{Nebenfach}}},
  author = {Kommer, Christoph and Tugendhat, Tim and Wahl, Niklas},
  date = {2015},
  edition = {1},
  publisher = {{Springer Spektrum}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-47244-6},
  url = {http://link.springer.com/10.1007/978-3-662-47244-6},
  isbn = {978-3-662-47243-9}
}

@article{Wahl2016,
  title = {Physically constrained voxel-based penalty adaptation for ultra-fast {{IMRT}} planning},
  author = {Wahl, Niklas and Bangert, Mark and Kamerling, Cornelis P and Ziegenhein, Peter and Bol, Gijsbert H and Raaymakers, Bas W and Oelfke, Uwe},
  date = {2016},
  journaltitle = {Journal of Applied Clinical Medical Physics},
  shortjournal = {JACMP},
  volume = {17},
  number = {4},
  pages = {172--189},
  issn = {15269914},
  doi = {10.1120/jacmp.v17i4.6117},
  keywords = {adaptive radiation therapy,dose optimization,importance factors,imrt,inverse planning,matRadGrant},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\SZFBGIPM\\Wahl et al. - 2016 - Physically constrained voxel-based penalty adaptation for ultra-fast IMRT planning.pdf}
}

@unpublished{Wahl2016b,
  type = {Oral Presentation},
  title = {Probabilistic proton treatment planning using accelerated analytical probabilistic modelling},
  author = {Wahl, Niklas and Hennig, Philipp and Bangert, Mark},
  date = {2016},
  eventtitle = {18th {{ICCR}}},
  venue = {{London}},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\UYP8E7IV\\Wahl, Hennig, Bangert - 2016 - Probabilistic proton treatment planning using accelerated analytical probabilistic modelling.pdf}
}

@article{Wahl2017a,
  title = {Efficiency of analytical and sampling-based uncertainty propagation in intensity-modulated proton therapy},
  author = {Wahl, Niklas and Hennig, Philipp and Wieser, Hans-Peter and Bangert, Mark},
  date = {2017-06-26},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {62},
  number = {14},
  eprint = {WahlN_APMEfficiency_2017_acceptedPreprint.pdf},
  eprinttype = {preprint},
  pages = {5790--5807},
  issn = {1361-6560},
  doi = {10.1088/1361-6560/aa6ec5},
  url = {http://stacks.iop.org/0031-9155/62/i=14/a=5790?key=crossref.cba9093365b6707443b63a0770bf9fee},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\FJMELLAU\\Wahl et al. - 2017 - Efficiency of analytical and sampling-based uncertainty propagation in intensity-modulated proton therapy.pdf}
}

@article{Wahl2018,
  title = {Analytical incorporation of fractionation effects in probabilistic treatment planning for intensity-modulated proton therapy},
  author = {Wahl, Niklas and Hennig, Philipp and Wieser, Hans-Peter and Bangert, Mark},
  date = {2018-04-27},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {45},
  number = {4},
  eprint = {WahlN_APMFractionation_2018_acceptedPreprint.pdf},
  eprinttype = {preprint},
  pages = {1317--1328},
  issn = {00942405},
  doi = {10.1002/mp.12775},
  url = {http://doi.wiley.com/10.1002/mp.12775},
  keywords = {matRadGrant},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\F2MXWIMI\\Wahl et al. - 2018 - Analytical incorporation of fractionation effects in probabilistic treatment planning for intensity-modulated proto.pdf}
}

@thesis{Wahl2018a,
  type = {phdthesis},
  title = {Analytical {{Models}} for {{Probabilistic Inverse Treatment Planning}} in {{Intensity-modulated Proton Therapy}}},
  author = {Wahl, Niklas},
  date = {2018},
  institution = {{Ruprecht-Karls Universität Heidelberg}},
  location = {{Heidelberg}},
  doi = {10.11588/heidok.00025127},
  url = {http://archiv.ub.uni-heidelberg.de/volltextserver/25127/},
  urldate = {2018-08-22},
  abstract = {The sensitivity of intensity-modulated proton therapy to uncertainties requires case-specific uncertainty assessment and mitigation. As an alternative to scenario-based methods, this thesis describes the implementation, application and conceptual extension of the Analytical Probabilistic Modeling (APM) framework introduced by Bangert, Hennig, and Oelfke (2013). APM represents moments of the probability distribution over dose in closed-form, providing a probabilistic analog to nominal pencil-beam dose calculation subject to range and setup uncertainties that further enables probabilistic optimization. First, APM was implemented in MITKrad, a treatment planning plugin for MITK built completely from scratch. APM’s computations were validated against sample statistics, showing nearly perfect agreement. Run-times within minutes could be realized for uncertainty assessment and probabilistic optimization on patient data. Reformulation of APM enabled linear separation of the computations into random and systematic uncertainty components. Uncertainty over the full fractionation spectrum could then be modeled and optimized with a single pre-computation. It could be shown that fractionation is exploited in optimization with APM for additional organ at risk sparing. APM was then extended to propagation of uncertainties from dose to clinically relevant plan quality metrics. Expectation and variance could be modeled accurately for organ mean dose and dose-volume histograms. However, approximations for equivalent uniform dose and minimum and maximum dose values did not provide reliable results. Finally, the closed-form plan metrics were used to conceptualize constrained probabilistic optimization. Besides novel probabilistic objectives, confidence constraints could be established. Due to increased computational complexity of the new models, the proof-of-concept was provided through evaluations on a one-dimensional prototype anatomy. In conclusion, the herein extended APM framework is able to provide probabilistic analogs to established nominal concepts of dose calculation, plan quality metrics, and constrained optimization. If computational hurdles can be overcome in the future, clinical application would be within reach.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\5MNHQ94D\\Unknown - 2018 - Put forward by M . Sc . Niklas Wahl Born in Heidelberg Oral Examina on 11 . 07 . 2018.pdf}
}

@inproceedings{Wahl2018b,
  ids = {Wahl2018d},
  title = {{{PO-0909}}: {{Analytical}} probabilistic models for dose quality metrics and optimization objectives},
  shorttitle = {Analytical probabilistic models for dose quality metrics and optimization objectives},
  booktitle = {Radiotherapy and {{Oncology}}},
  author = {Wahl, Niklas and Hennig, Philipp and Wieser, Hans-Peter and Bangert, Mark},
  date = {2018-04-01},
  volume = {127},
  pages = {S486-S487},
  location = {{Barcelona}},
  doi = {10.1016/S0167-8140(18)31219-2},
  url = {https://www.thegreenjournal.com/article/S0167-8140(18)31219-2/abstract},
  eventtitle = {{{ESTRO}}},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\D6TN79XE\\Wahl et al. - 2018 - PO-0909 Analytical probabilistic models for dose .pdf;C\:\\Users\\Niklas\\Zotero\\storage\\2KV6BD49\\fulltext.html}
}

@inproceedings{Wahl2018c,
  ids = {Wahl2018d},
  title = {{{EP-1898}}: {{Smooth}} animations of the probabilistic analog to worst-case dose distributions},
  shorttitle = {Smooth animations of the probabilistic analog to worst-case dose distributions},
  booktitle = {Radiotherapy and {{Oncology}}},
  author = {Wahl, Niklas and Hennig, Philipp and Wieser, Hans-Peter and Bangert, Mark},
  date = {2018-04},
  volume = {127},
  pages = {S1028-S1029},
  location = {{Barcelona}},
  doi = {10.1016/S0167-8140(18)32207-2},
  url = {https://www.thegreenjournal.com/article/S0167-8140(18)32207-2/abstract},
  eventtitle = {{{ESTRO}}},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\PUCDJ33Q\\Wahl et al. - 2018 - EP-1898 Smooth animations of the probabilistic an.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\AT7CJ4GA\\fulltext.html}
}

@unpublished{Wahl2019,
  type = {Oral Presentation},
  title = {Development report for the open source dose calculation and optimization toolkit {{matRad}}},
  author = {Wahl, Niklas and Doerner, Edgardo and Burigo, Lucas Noberto and Ramirez, Daniel and Neishabouri, Ahmad and Bennan, Amit Ben Antony and Wieser, Hans-Peter and Bangert, Mark},
  date = {2019},
  eventtitle = {19th {{ICCR}}},
  venue = {{Montréal}}
}

@unpublished{Wahl2019a,
  type = {Oral Presentation},
  title = {Confidence constraints for probabilistic radiotherapy treatment planning},
  author = {Wahl, Niklas and Hennig, Philipp and Wieser, Hans-Peter and Bangert, Mark},
  date = {2019},
  eventtitle = {19th {{ICCR}}},
  venue = {{Montréal}}
}

@article{Wahl2020,
  title = {Analytical probabilistic modeling of dose-volume histograms},
  author = {Wahl, Niklas and Hennig, Philipp and Wieser, Hans-Peter and Bangert, Mark},
  date = {2020-09-06},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {47},
  number = {10},
  eprint = {2001.04884},
  eprinttype = {arxiv},
  pages = {5260--5273},
  issn = {2473-4209},
  doi = {10.1002/mp.14414},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.14414},
  urldate = {2020-08-03},
  abstract = {Purpose Radiotherapy, especially with charged particles, is sensitive to executional and preparational uncertainties that propagate to uncertainty in dose and plan quality indicators, e. g., dose-volume histograms (DVHs). Current approaches to quantify and mitigate such uncertainties rely on explicitly computed error scenarios and are thus subject to statistical uncertainty and limitations regarding the underlying uncertainty model. Here we present an alternative, analytical method to approximate moments, in particular expectation value and (co)variance, of the probability distribution of DVH-points, and evaluate its accuracy on patient data. Methods We use Analytical Probabilistic Modeling (APM) to derive moments of the probability distribution over individual DVH-points based on the probability distribution over dose. By using the computed moments to parameterize distinct probability distributions over DVH-points (here normal or beta distributions), not only the moments but also percentiles, i. e., α-DVHs, are computed. The model is subsequently evaluated on three patient cases (intracranial, paraspinal, prostate) in 30- and singlefraction scenarios by assuming the dose to follow a multivariate normal distribution, whose moments are computed in closed-form with APM. The results are compared to a benchmark based on discrete random sampling. Results The evaluation of the new probabilistic model on the three patient cases against a sampling benchmark proves its correctness under perfect assumptions as well as good agreement in realistic conditions. More precisely, ca. 90\% of all computed expected DVH-points and their standard deviations agree within 1\% volume with their empirical counterpart from sampling computations, for both fractionated and single fraction treatments. When computing α-DVHs, the assumption of a beta distribution achieved better agreement with empirical percentiles than the assumption of a normal distribution: While in both cases probabilities locally showed large deviations (up to ±0.2), the respective α -DVHs for α = 0:05; 0:5; 0:95 only showed small deviations in respective volume (up to ±5\% volume for a normal distribution, and up to 2\% for a beta distribution). A previously published model from literature, which was included for comparison, exhibited substantially larger deviations. Conclusions With APM we could derive a mathematically exact description of moments of probability distributions over DVH-points given a probability distribution over dose. The model generalizes previous attempts and performs well for both choices of probability distributions, i. e., normal or beta distributions, over DVH-points.},
  archiveprefix = {arXiv},
  langid = {english},
  preview = {dvh\_anim.gif},
  keywords = {Physics - Medical Physics},
  annotation = {\_eprint: https://aapm.onlinelibrary.wiley.com/doi/pdf/10.1002/mp.14414},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\83IVWLPY\\Wahl et al. - Analytical probabilistic modeling of dose-volume h.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\WUUJ92ZC\\Wahl et al. - 2020 - Analytical probabilistic modeling of dose-volume h.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\R8UEQDZ3\\mp.html}
}

@inproceedings{Wahl2020a,
  title = {{{PO-1377}}: {{Monte Carlo}} vs. pencil-beam dose calculation for uncertainty estimation in proton therapy},
  shorttitle = {Monte {{Carlo}} vs. pencil-beam dose calculation for uncertainty estimation in proton therapy},
  booktitle = {Radiotherapy and {{Oncology}}},
  author = {Wahl, Niklas and Wieser, Hans-Peter and Burigo, Lucas and Bangert, Mark},
  date = {2020-11-01},
  volume = {152},
  pages = {S731},
  location = {{Online}},
  doi = {10.1016/S0167-8140(21)01395-5},
  url = {https://www.sciencedirect.com/science/article/pii/S0167814021013955},
  urldate = {2021-02-12},
  eventtitle = {{{ESTRO}}},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\KFAFPMCV\\S0167814021013955.html}
}

@unpublished{Wahl2022,
  type = {Oral Presentation},
  title = {Scenario-free probabilistic proton dose optimization using expected dose influence and total variance},
  author = {Wahl, Niklas and Wieser, Hans-Peter},
  date = {2022-07-01},
  eventtitle = {{{PTCOG}} 60},
  venue = {{Miami}}
}

@article{Wang1999,
  title = {Photon dose calculation based on electron multiple-scattering theory: {{Primary}} dose deposition kernels},
  author = {Wang, Lu and Jette, David},
  date = {1999-08-01},
  journaltitle = {Medical Physics},
  volume = {26},
  number = {8},
  pages = {1454},
  publisher = {{American Association of Physicists in Medicine}},
  issn = {00942405},
  doi = {10.1118/1.598677},
  url = {http://scitation.aip.org/content/aapm/journal/medphys/26/8/10.1118/1.598677},
  urldate = {2014-02-10},
  abstract = {The transport of the secondary electrons resulting from high-energy photoninteractions is essential to energy redistribution and deposition. In order to develop an accurate dose-calculation algorithm for high-energy photons, which can predict the dose distribution in inhomogeneous media and at the beam edges, we have investigated the feasibility of applying electron transport theory [Jette, Med. Phys. 15, 123 (1988)] to photon dose calculation. In particular, the transport of and energy deposition by Compton electron and electrons and positrons resulting from pair production were studied. The primary photons are treated as the source of the secondary electrons and positrons, which are transported through the irradiated medium using Gaussian multiple-scattering theory [Jette, Med. Phys. 15, 123 (1988)]. The initial angular and kinetic energy distribution(s) of the secondary electrons (and positrons) emanating from the photoninteractions are incorporated into the transport. Due to different mechanisms of creation and cross-section functions, the transport of and the energy deposition by the electrons released in these two processes are studied and modeled separately based on first principles. In this article, we focus on determining the dose distribution for an individual interaction site. We define the Compton dose deposition kernel (CDK) or the pair-production dose deposition kernel (PDK) as the dose distribution relative to the point of interaction, per unit interaction density, for a monoenergetic photon beam in an infinite homogeneous medium of unit density. The validity of this analytic modeling of dose deposition was evaluated through EGS4 Monte Carlo simulation. Quantitative agreement between these two calculations of the dose distribution and the average energy deposited per interaction was achieved. Our results demonstrate the applicability of the electron dose-calculation method to photon dose calculation.}
}

@article{Wang2019,
  title = {Artificial {{Intelligence}} in {{Radiotherapy Treatment Planning}}: {{Present}} and {{Future}}},
  shorttitle = {Artificial {{Intelligence}} in {{Radiotherapy Treatment Planning}}},
  author = {Wang, Chunhao and Zhu, Xiaofeng and Hong, Julian C. and Zheng, Dandan},
  date = {2019-01},
  journaltitle = {Technology in Cancer Research \& Treatment},
  shortjournal = {Technol Cancer Res Treat},
  volume = {18},
  pages = {1--11},
  issn = {1533-0346, 1533-0338},
  doi = {10.1177/1533033819873922},
  url = {http://journals.sagepub.com/doi/10.1177/1533033819873922},
  urldate = {2019-10-30},
  abstract = {Treatment planning is an essential step of the radiotherapy workflow. It has become more sophisticated over the past couple of decades with the help of computer science, enabling planners to design highly complex radiotherapy plans to minimize the normal tissue damage while persevering sufficient tumor control. As a result, treatment planning has become more labor intensive, requiring hours or even days of planner effort to optimize an individual patient case in a trial-and-error fashion. More recently, artificial intelligence has been utilized to automate and improve various aspects of medical science. For radiotherapy treatment planning, many algorithms have been developed to better support planners. These algorithms focus on automating the planning process and/or optimizing dosimetric trade-offs, and they have already made great impact on improving treatment planning efficiency and plan quality consistency. In this review, the smart planning tools in current clinical use are summarized in 3 main categories: automated rule implementation and reasoning, modeling of prior knowledge in clinical practice, and multicriteria optimization. Novel artificial intelligence–based treatment planning applications, such as deep learning–based algorithms and emerging research directions, are also reviewed. Finally, the challenges of artificial intelligence–based treatment planning are discussed for future works.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\WKTZ3FSI\\Wang et al. - 2019 - Artificial Intelligence in Radiotherapy Treatment .pdf}
}

@article{Wannenmacher2006,
  title = {Strahlentherapie},
  author = {Wannenmacher, M and Debus, J and Wenz, F},
  date = {2006},
  url = {http://books.google.de/books?hl=de&lr=&id=ejstqjhkOAAC&oi=fnd&pg=PA2&dq=Michael+Wannenmacher,+J%C3%BCrgen+Debus,+Frederik+Wenz,+Strahlentherapie&ots=2ycqIcGGqU&sig=83R-FNJvLOQKRc3cDZFrVtreG_4},
  urldate = {2014-02-17}
}

@article{Webb1993,
  title = {A model for calculating tumour control probability in radiotherapy including the effects of inhomogeneous distributions of dose and clonogenic cell density},
  author = {Webb, S. and Nahum, A. E.},
  date = {1993-06},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {38},
  number = {6},
  pages = {653--666},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/38/6/001},
  url = {https://doi.org/10.1088/0031-9155/38/6/001},
  urldate = {2021-04-05},
  abstract = {Most calculations of the biological effect of radiation on tumours assume that the clonogenic cell density is uniform even if account is taken of non-uniform dose distribution. In practice tumours will almost certainly have a non-uniform clonogenic cell density. The paper extends one particular model of tumour control probability (TCP) to incorporate a variable clonogenic cell density while at the same time assuming a constant 2 Gy fraction size and a uniform radiosensitivity throughout the treatment. Since there are virtually no in vivo data on the variation of density the authors consider some model situations. One clear conclusion is that a large reduction in clonogenic cell density at the edges of a tumour would permit only a very modest decrease in dose if the TCP is not to be reduced. In general the effect on TCP is a complicated function of the variation in both dose and clonogenic cell density. The authors give the equations which enable both to be included.},
  langid = {english}
}

@article{Webb2003,
  title = {The physical basis of {{IMRT}} and inverse planning},
  author = {Webb, S},
  date = {2003-10-01},
  journaltitle = {British Journal of Radiology},
  volume = {76},
  number = {910},
  pages = {678--689},
  issn = {0007-1285},
  doi = {10.1259/bjr/65676879},
  url = {http://bjr.birjournals.org/cgi/doi/10.1259/bjr/65676879},
  urldate = {2014-01-28},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\EGUC7QQF\\Webb - 2003 - The physical basis of IMRT and inverse planning.pdf}
}

@article{Wheldon1998,
  title = {The linear-quadratic transformation of dose–volume histograms in fractionated radiotherapy},
  author = {Wheldon, Thomas E. and Deehan, Charles and Wheldon, Elizabeth G. and Barrett, Ann},
  date = {1998-03},
  journaltitle = {Radiotherapy and Oncology},
  shortjournal = {Radiother Oncol},
  volume = {46},
  number = {3},
  pages = {285--295},
  issn = {01678140},
  doi = {10.1016/S0167-8140(97)00162-X},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S016781409700162X},
  urldate = {2019-09-23},
  abstract = {Background and purpose: Dose–volume histograms (DVHs) are often used in radiotherapy to provide representations of treatment dose distributions. DVHs are computed from physical dose and do not include radiobiological factors; therefore, the same DVH will be computed for a treatment plan whatever fractionation regimen is used. However, dose heterogeneity resulting from variation of daily treatment dose within the volume will have biological effects due to spatial heterogeneity of fraction size as well as total dose. The purpose of the paper is to present a radiobiological (LQ) transformation of the physical dose distribution which incorporates fraction size effects and may be better suited to the prediction of biological effects. Methods: An analytic formula is derived for the linear-quadratic transformation of a normal distribution of dose to give the corresponding distribution of biologically equivalent dose given as 2 Gy fractions. This allows LQ-transformed DVHs to be computed from physical DVHs. The resultant LQ-DVH depends on the assumed value of the relevant a/b ratio. It is a modified dose distribution (corrected for spatial heterogeneity of fraction size) but does not incorporate time factors or volume effects. Results: The analysis shows that the LQ-transformed distribution is always broader than the distribution of physical dose. Radiobiological ‘hot spots’ and ‘cold spots’ are further from the mean than physical distributions would indicate. The difference between conventional DVHs and LQ-transformed DVHs is dependent on the fractionation regimen used. LQ-DVHs for a single dose distribution (treatment plan) can be computed for different fractionation regimens with some simplifying assumptions (e.g. no time-factor-dependence of late effects). Regimens calculated to be radiobiologically equivalent at a single point nevertheless result in non-equivalent LQ-DVHs when spatial variation of daily treatment dose is included. The difference is especially important for tumour sites (such as breast and head and neck) for which considerable dose heterogeneity may occur and for which different treatment regimens are in use. Conclusions: LQ-DVHs should be computed in parallel with conventional DVHs and used in the evaluation of treatment plans and fractionation regimens and in the analysis of high-dose side-effects in patients. © 1998 Elsevier Science Ireland Ltd.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\ZCAGJMT7\\Wheldon et al. - 1998 - The linear-quadratic transformation of dose–volume.pdf}
}

@online{WHO2018,
  type = {Press Release},
  title = {Latest global cancer data: {{Cancer}} burden rises to 18.1 million new cases and 9.6 million cancer deaths in 2018},
  shorttitle = {Latest global cancer data},
  author = {{WHO}},
  date = {2018-09-12},
  url = {https://www.who.int/cancer/PRGlobocanFinal.pdf},
  urldate = {2019-11-05},
  organization = {{WHO}},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\TLSBRIHV\\PRGlobocanFinal.pdf}
}

@unpublished{Wieser2016,
  type = {Oral Presentation},
  title = {Analytical probabilistic modeling of range and setup uncertainties in carbon ion therapy planning},
  author = {Wieser, Hans-Peter and Wahl, Niklas and Hennig, Philipp and Bangert, Mark},
  date = {2016},
  eventtitle = {18th {{ICCR}}},
  venue = {{London}}
}

@article{Wieser2017,
  title = {Development of the open-source dose calculation and optimization toolkit {{matRad}}},
  author = {Wieser, Hans-Peter and Cisternas, Eduardo and Wahl, Niklas and Ulrich, Silke and Stadler, Alexander and Mescher, Henning and Müller, Lucas-Raphael and Klinge, Thomas and Gabrys, Hubert and Burigo, Lucas and Mairani, Andrea and Ecker, Swantje and Ackermann, Benjamin and Ellerbrock, Malte and Parodi, Katia and Jäkel, Oliver and Bangert, Mark},
  date = {2017},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {44},
  number = {6},
  eprint = {28370020},
  eprinttype = {pmid},
  pages = {2556--2568},
  publisher = {{Wiley}},
  issn = {2473-4209},
  doi = {10.1002/mp.12251},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.12251},
  urldate = {2019-08-13},
  abstract = {Purpose We report on the development of the open-source cross-platform radiation treatment planning toolkit matRad and its comparison against validated treatment planning systems. The toolkit enables three-dimensional intensity-modulated radiation therapy treatment planning for photons, scanned protons and scanned carbon ions. Methods matRad is entirely written in Matlab and is freely available online. It re-implements well-established algorithms employing a modular and sequential software design to model the entire treatment planning workflow. It comprises core functionalities to import DICOM data, to calculate and optimize dose as well as a graphical user interface for visualization. matRad dose calculation algorithms (for carbon ions this also includes the computation of the relative biological effect) are compared against dose calculation results originating from clinically approved treatment planning systems. Results We observe three-dimensional γ-analysis pass rates ≥ 99.67\% for all three radiation modalities utilizing a distance to agreement of 2 mm and a dose difference criterion of 2\%. The computational efficiency of matRad is evaluated in a treatment planning study considering three different treatment scenarios for every radiation modality. For photons, we measure total run times of 145 s–1260 s for dose calculation and fluence optimization combined considering 4–72 beam orientations and 2608–13597 beamlets. For charged particles, we measure total run times of 63 s–993 s for dose calculation and fluence optimization combined considering 9963–45574 pencil beams. Using a CT and dose grid resolution of 0.3 cm3 requires a memory consumption of 1.59 GB–9.07 GB and 0.29 GB–17.94 GB for photons and charged particles, respectively. Conclusion The dosimetric accuracy, computational performance and open-source character of matRad encourages a future application of matRad for both educational and research purposes.},
  isbn = {4955139574},
  langid = {english},
  preview = {matrad\_hat.svg},
  selected = {true},
  keywords = {DICOM,dose calculation,inverse planning,matRadGrant,optimization,radiation therapy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\D2L5K3WM\\Wieser et al. - 2017 - Development of the open-source dose calculation and optimization toolkit matRad(2).pdf;C\:\\Users\\Niklas\\Zotero\\storage\\N9TKMPVD\\Wieser et al. - 2017 - Development of the open-source dose calculation and optimization toolkit matRad(2).pdf;C\:\\Users\\Niklas\\Zotero\\storage\\QRX7A56P\\Wieser et al. - 2017 - Development of the open-source dose calculation an.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\LPILBTA8\\mp.html}
}

@article{Wieser2017b,
  title = {Analytical probabilistic modeling of {{RBE-weighted}} dose for ion therapy},
  author = {Wieser, Hans-Peter and Hennig, Philipp and Wahl, Niklas and Bangert, Mark},
  date = {2017-10-05},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {62},
  number = {23},
  eprint = {WieserHP_APMBio_2017_acceptedPreprint.pdf},
  eprinttype = {preprint},
  pages = {8959--8982},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/aa915d},
  url = {http://iopscience.iop.org/article/10.1088/1361-6560/aa915d},
  urldate = {2017-10-05},
  keywords = {matRadGrant},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Y2RUMY4N\\Wieser et al. - 2017 - Analytical probabilistic modeling of RBE-weighted dose for ion therapy(2).pdf}
}

@inproceedings{Wieser2018,
  title = {Simultaneous consideration of biological and physical uncertainties in robust ion therapy planning},
  booktitle = {{{ESTRO}} 37 {{Abstract Book}}},
  author = {Wieser, Hans-Peter and Wahl, Niklas and Hennig, Philipp and Bangert, Mark},
  date = {2018},
  pages = {S44--S45},
  publisher = {{ELSEVIER}},
  location = {{Barcelona}}
}

@article{Wieser2018a,
  ids = {Wieser2018c},
  title = {{{matRad}} - an open-source treatment planning toolkit for educational purposes},
  author = {Wieser, Hans-Peter and Wahl, Niklas and Gabryś, Hubert S. and Müller, Lucas-Raphael and Pezzano, Giuseppe and Winter, Johanna and Ulrich, Silke and Burigo, Lucas Noberto and Jäkel, Oliver and Bangert, Mark},
  date = {2018},
  journaltitle = {Medical Physics International Journal},
  volume = {6},
  number = {1},
  pages = {119--127},
  issn = {2306-4609},
  url = {http://www.mpijournal.org/pdf/2018-01/MPI-2018-01-p119.pdf},
  abstract = {We present educational aspects of matRad –an open-source treatment planning toolkit for threedimensional intensity-modulated radiotherapy treatment planning supporting photons, scanned protons and scanned carbon ions. matRad is publicly available for download on GitHub and does not require payable software-products to run or to change its source code. This manuscript helps new users to get familiar with the basic concept, the matRad GitHub environment, and potential applications. Specifically we discuss seven novel workflow examples that illustrate usage of matRad’s code base and we introduce three practical treatment planning examples from a planner's point of view. The workflow examples and the treatment planning tutorial are available in the form of Matlab scripts and documented with pdf files and wiki pages, respectively. They are intended as both learning and teaching material, e.g., in a classroom setting. The provided examples range from simple to complex treatment planning scenarios and can all be executed in a couple of minutes on a standard desktop computer.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\JXP4WXPV\\2018 - MEDICAL PHYSICS INTERNATIONAL.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\YV99642P\\Wieser et al. - 2018 - MATRAD-AN OPEN-SOURCE TREATMENT PLANNING TOOLKIT F.pdf}
}

@inproceedings{Wieser2018b,
  title = {{{OC-0088}}: {{Simultaneous}} consideration of biologyical and physical uncertainties in robust ion therapy planning},
  shorttitle = {Simultaneous consideration of biologyical and physical uncertainties in robust ion therapy planning},
  booktitle = {Radiotherapy and {{Oncology}}},
  author = {Wieser, Hans-Peter and Wahl, Niklas and Hennig, Philipp and Bangert, Mark},
  date = {2018-04-01},
  volume = {127},
  pages = {S46-S47},
  location = {{Barcelona}},
  doi = {10.1016/S0167-8140(18)30398-0},
  url = {https://www.thegreenjournal.com/article/S0167-8140(18)30398-0/abstract},
  urldate = {2019-11-25},
  eventtitle = {{{ESTRO}}},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\9MHB6VIN\\Wieser et al. - 2018 - OC-0088 Simultaneous consideration of biologyical.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\28S2RBSV\\fulltext.html}
}

@inproceedings{Wieser2019,
  title = {Impact of {{Gaussian}} uncertainty assumptions for probabilistic optimization considering range errors},
  booktitle = {19th {{International Conference}} on the {{Use}} of {{Computers}} in {{Radiation Therapy}} ({{ICCR}})},
  author = {Wieser, Hans-Peter and Karger, Christian P. and Wahl, Niklas and Bangert, Mark},
  date = {2019}
}

@inproceedings{Wieser2019a,
  title = {Closed-form modeling of biological uncertainties in carbon ion therapy},
  booktitle = {19th {{International Conference}} on the {{Use}} of {{Computers}} in {{Radiation Therapy}} ({{ICCR}})},
  author = {Wieser, Hans-Peter and Hennig, Philipp and Wahl, Niklas and Bangert, Mark},
  date = {2019}
}

@article{Wieser2020,
  title = {Impact of {{Gaussian}} uncertainty assumptions on probabilistic optimization in particle therapy},
  author = {Wieser, Hans-Peter and Karger, Christian P. and Wahl, Niklas and Bangert, Mark},
  date = {2020-07},
  journaltitle = {Physics in Medicine \& Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {65},
  number = {14},
  eprint = {WieserHP_GaussianUncertainties_2020_acceptedPreprint.pdf},
  eprinttype = {preprint},
  pages = {145007},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/ab8d77},
  url = {https://doi.org/10.1088%2F1361-6560%2Fab8d77},
  urldate = {2020-07-22},
  abstract = {Range and setup uncertainties in charged particle therapy may induce a discrepancy between the planned and the delivered dose. Countermeasures based on probabilistic (stochastic) optimization usually assume a Gaussian probability density to model the underlying range and setup error. While this standard assumption is generally taken for granted, this study explicitly investigates the dosimetric consequences if the actual range and setup errors obey a different probability density function (PDF) over the course of treatment to the one used during the probabilistic treatment plan optimization. Discrete random sampling was performed for conventionally and probabilistically optimized proton and carbon ion treatment plans utilizing various PDFs that modeled the setup and range error. This method allowed us to assess the treatment plan robustness against different PDFs of conventional and probabilistic plans, which both explicitly assume Gaussian uncertainties. The induced uncertainty in dose was quantified by estimating the expectation value and standard deviation of the RBE-weighted dose for each PDF on the basis of 2500-5000 random dose samples. Probabilistic dose metrics and standard deviation volume histograms were computed to quantify treatment plan robustness of both optimization approaches. It was shown that the classical planning target volume margin extension concept did not compensate the influence of range and setup errors and consequently resulted in a non-negligible average standard deviation in dose of 7.3\% throughout the clinical target volume (CTV). In contrast, probabilistic optimization on normally distributed errors yielded treatment plans that not only entailed a lower standard deviation against normally distributed errors accounted for during optimization, but also lower standard deviations for other symmetric PDFs. It was shown that the impact of an incorrect probability distribution assumption is of lower importance after probabilistic optimization as the average uncertainty in the CTV drops to 3.9\%. Probabilistic optimization is an effective tool to create robust particle treatment plans. Normally distributed range and setup error assumptions for probabilistic optimization are a reasonable first approximation and yield treatment plans that are also robust against other PDFs.},
  langid = {english}
}

@inproceedings{Wild2013,
  title = {Gradient based direct aperture optimization for radiation therapy treatment planning},
  author = {Wild, Esther and Bangert, Mark and Ulrich, Silke and Nill, Simeon and Oelfke, Uwe},
  date = {2013},
  publisher = {{INFORMS healthcare}},
  location = {{Chicago}}
}

@thesis{Wild2013b,
  type = {mathesis},
  title = {Efficient {{Gradient}} based {{Direct Aperture Optimization}} for {{IMRT}} and {{IMAT}}},
  author = {Wild, Esther},
  date = {2013},
  institution = {{University of Heidelberg}}
}

@article{Wild2015,
  title = {Noncoplanar {{VMAT}} for nasopharyngeal tumors: {{Plan}} quality versus treatment time},
  shorttitle = {Noncoplanar {{VMAT}} for nasopharyngeal tumors},
  author = {Wild, Esther and Bangert, Mark and Nill, Simeon and Oelfke, Uwe},
  date = {2015},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {42},
  number = {5},
  pages = {2157--2168},
  issn = {2473-4209},
  doi = {10.1118/1.4914863},
  url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.4914863},
  urldate = {2019-10-27},
  abstract = {Purpose: The authors investigated the potential of optimized noncoplanar irradiation trajectories for volumetric modulated arc therapy (VMAT) treatments of nasopharyngeal patients and studied the trade-off between treatment plan quality and delivery time in radiation therapy. Methods: For three nasopharyngeal patients, the authors generated treatment plans for nine different delivery scenarios using dedicated optimization methods. They compared these scenarios according to dose characteristics, number of beam directions, and estimated delivery times. In particular, the authors generated the following treatment plans: (1) a 4π plan, which is a not sequenced, fluence optimized plan that uses beam directions from approximately 1400 noncoplanar directions and marks a theoretical upper limit of the treatment plan quality, (2) a coplanar 2π plan with 72 coplanar beam directions as pendant to the noncoplanar 4π plan, (3) a coplanar VMAT plan, (4) a coplanar step and shoot (SnS) plan, (5) a beam angle optimized (BAO) coplanar SnS IMRT plan, (6) a noncoplanar BAO SnS plan, (7) a VMAT plan with rotated treatment couch, (8) a noncoplanar VMAT plan with an optimized great circle around the patient, and (9) a noncoplanar BAO VMAT plan with an arbitrary trajectory around the patient. Results: VMAT using optimized noncoplanar irradiation trajectories reduced the mean and maximum doses in organs at risk compared to coplanar VMAT plans by 19\% on average while the target coverage remains constant. A coplanar BAO SnS plan was superior to coplanar SnS or VMAT; however, noncoplanar plans like a noncoplanar BAO SnS plan or noncoplanar VMAT yielded a better plan quality than the best coplanar 2π plan. The treatment plan quality of VMAT plans depended on the length of the trajectory. The delivery times of noncoplanar VMAT plans were estimated to be 6.5 min in average; 1.6 min longer than a coplanar plan but on average 2.8 min faster than a noncoplanar SnS plan with comparable treatment plan quality. Conclusions: The authors’ study reconfirms the dosimetric benefits of noncoplanar irradiation of nasopharyngeal tumors. Both SnS using optimized noncoplanar beam ensembles and VMAT using an optimized, arbitrary, noncoplanar trajectory enabled dose reductions in organs at risk compared to coplanar SnS and VMAT. Using great circles or simple couch rotations to implement noncoplanar VMAT, however, was not sufficient to yield meaningful improvements in treatment plan quality. The authors estimate that noncoplanar VMAT using arbitrary optimized irradiation trajectories comes at an increased delivery time compared to coplanar VMAT yet at a decreased delivery time compared to noncoplanar SnS IMRT.},
  langid = {english},
  keywords = {beam angle optimization,Dose-volume analysis,dosimetry,intensity-modulated arc therapy,optimisation,radiation therapy,Radiation therapy,rotation therapy,Scintigraphy,treatment planning,tumours},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\Z3YX5ZM6\\1.html}
}

@book{Wild2020,
  title = {World {{Cancer Report}}: {{Cancer Research}} for {{Cancer Prevention}}},
  shorttitle = {World {{Cancer Report}}},
  author = {Wild, CP and {E Weiderpass} and {BW Stewart}},
  date = {2020},
  publisher = {{WHO}},
  url = {https://publications.iarc.fr/Non-Series-Publications/World-Cancer-Reports/World-Cancer-Report-Cancer-Research-For-Cancer-Prevention-2020},
  urldate = {2020-07-06},
  isbn = {978-92-832-0448-0},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\34W4QABU\\586.html}
}

@article{Wilkens2006,
  title = {Fast multifield optimization of the biological effect in ion therapy},
  author = {Wilkens, Jan J. and Oelfke, Uwe},
  date = {2006-06},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {51},
  number = {12},
  pages = {3127--3140},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/51/12/009},
  url = {https://doi.org/10.1088%2F0031-9155%2F51%2F12%2F009},
  urldate = {2019-10-27},
  abstract = {In this paper, we present a new technique for simultaneous multifield optimization of the biological effect (i.e. relative biological effectiveness times dose) for intensity modulated radiotherapy with ion beams. It offers complete inverse treatment planning by taking into account planning constraints for the target volume as well as for organs at risk. The approach is based on the mixed irradiation formalism of the linear-quadratic model from radiobiology. We employ a novel objective function to directly optimize the biological effect rather than the physical dose. The required biological input data are reduced to a minimum and are completely independent from the optimization itself. They can be derived from any radiobiological model or even from directly measured data. The new optimization method was fully integrated into our inverse treatment planning tool KonRad. Comparisons with the TRiP98 treatment planning code were done for simple spread-out Bragg peaks as well as for three-dimensional treatment plans, where all fields were optimized separately. While the agreement between both planning systems was very good, the calculation time was substantially reduced in KonRad. By enabling the multifield optimization, the quality of the treatment plans and the sparing of healthy tissues can be clearly improved.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\RWTMABBG\\Wilkens und Oelfke - 2006 - Fast multifield optimization of the biological eff.pdf}
}

@article{Wilson2020,
  title = {Ultra-{{High Dose Rate}} ({{FLASH}}) {{Radiotherapy}}: {{Silver Bullet}} or {{Fool}}'s {{Gold}}?},
  shorttitle = {Ultra-{{High Dose Rate}} ({{FLASH}}) {{Radiotherapy}}},
  author = {Wilson, Joseph D. and Hammond, Ester M. and Higgins, Geoff S. and Petersson, Kristoffer},
  date = {2020},
  journaltitle = {Frontiers in Oncology},
  shortjournal = {Front. Oncol.},
  volume = {9},
  publisher = {{Frontiers}},
  issn = {2234-943X},
  doi = {10.3389/fonc.2019.01563},
  url = {https://www.frontiersin.org/articles/10.3389/fonc.2019.01563/full},
  urldate = {2021-03-16},
  abstract = {Radiotherapy is a cornerstone of both curative and palliative cancer care. However, radiotherapy is severely limited by radiation-induced toxicities. If these toxicities could be reduced, a greater dose of radiation could be given therefore facilitating a better tumour response. Initial pre-clinical studies have shown that irradiation at dose rates far exceeding those currently used in clinical contexts reduce radiation-induced toxicities whilst maintaining an equivalent tumour response. This is known as the FLASH effect. To date, a single patient has been subjected to FLASH radiotherapy for the treatment of subcutaneous T-cell lymphoma resulting in complete response and minimal toxicities. The mechanism responsible for reduced tissue toxicity following FLASH radiotherapy is yet to be elucidated, but hypotheses so far proposed include acute oxygen depletion within the irradiated tissue, and modulation of the immune response. This review examines the tissue response to FLASH radiotherapy, critically evaluates the evidence supporting hypotheses surrounding the biological basis of the FLASH effect, and considers the potential for FLASH radiotherapy to be translated into clinical contexts.},
  langid = {english},
  keywords = {flash,hypoxia,immune,Normal tissue toxicity,Radiotherapy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\RNK5ZKUS\\Wilson et al. - 2020 - Ultra-High Dose Rate (FLASH) Radiotherapy Silver .pdf}
}

@article{Winkel2019,
  title = {Adaptive radiotherapy: {{The Elekta Unity MR-linac}} concept},
  shorttitle = {Adaptive radiotherapy},
  author = {Winkel, Dennis and Bol, Gijsbert H. and Kroon, Petra S. and family=Asselen, given=Bram, prefix=van, useprefix=true and Hackett, Sara S. and Werensteijn-Honingh, Anita M. and Intven, Martijn P. W. and Eppinga, Wietse S. C. and Tijssen, Rob H. N. and Kerkmeijer, Linda G. W. and family=Boer, given=Hans C. J., prefix=de, useprefix=true and Mook, Stella and Meijer, Gert J. and Hes, Jochem and Willemsen-Bosman, Mirjam and family=Groot-van Breugel, given=Eline N., prefix=de, useprefix=true and Jürgenliemk-Schulz, Ina M. and Raaymakers, Bas W.},
  date = {2019-09-01},
  journaltitle = {Clinical and Translational Radiation Oncology},
  shortjournal = {Clinical and Translational Radiation Oncology},
  volume = {18},
  pages = {54--59},
  issn = {2405-6308},
  doi = {10.1016/j.ctro.2019.04.001},
  url = {https://www.sciencedirect.com/science/article/pii/S2405630819300631},
  urldate = {2022-08-11},
  abstract = {Background and purpose The promise of the MR-linac is that one can visualize all anatomical changes during the course of radiotherapy and hence adapt the treatment plan in order to always have the optimal treatment. Yet, there is a trade-off to be made between the time spent for adapting the treatment plan against the dosimetric gain. In this work, the various daily plan adaptation methods will be presented and applied on a variety of tumour sites. The aim is to provide an insight in the behavior of the state-of-the-art 1.5\,T MRI guided on-line adaptive radiotherapy methods. Materials and methods To explore the different available plan adaptation workflows and methods, we have simulated online plan adaptation for five cases with varying levels of inter-fraction motion, regions of interest and target sizes: prostate, rectum, esophagus and lymph node oligometastases (single and multiple target). The plans were evaluated based on the clinical dose constraints and the optimization time was measured. Results The time needed for plan adaptation ranged between 17 and 485\,s. More advanced plan adaptation methods generally resulted in more plans that met the clinical dose criteria. Violations were often caused by insufficient PTV coverage or, for the multiple lymph node case, a too high dose to OAR in the vicinity of the PTV. With full online replanning it was possible to create plans that met all clinical dose constraints for all cases. Conclusion Daily full online replanning is the most robust adaptive planning method for Unity. It is feasible for specific sites in clinically acceptable times. Faster methods are available, but before applying these, the specific use cases should be explored dosimetrically.},
  langid = {english},
  keywords = {Adaptive radiotherapy,MR-linac,MRI-guided radiotherapy,Online plan adaptation,Radiotherapy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\IZN8DGDW\\Winkel et al. - 2019 - Adaptive radiotherapy The Elekta Unity MR-linac c.pdf}
}

@article{Winkelbauer2012,
  title = {Moments and {{Absolute Moments}} of the {{Normal Distribution}}},
  author = {Winkelbauer, Andreas},
  date = {2012-09-19},
  journaltitle = {arXiv},
  volume = {1209.4340v},
  number = {2},
  eprint = {1209.4340},
  eprinttype = {arxiv},
  pages = {1--3},
  url = {http://arxiv.org/abs/1209.4340},
  abstract = {We present formulas for the (raw and central) moments and absolute moments of the normal distribution. We note that these results are not new, yet many textbooks miss out on at least some of them. Hence, we believe that it is worthwhile to collect these formulas and their derivations in these notes.},
  archiveprefix = {arXiv},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\R7PQIFAU\\Winkelbauer - 2012 - Moments and Absolute Moments of the Normal Distribution.pdf}
}

@article{Winter2020,
  title = {Analytical modeling of depth-dose degradation in heterogeneous lung tissue for intensity-modulated proton therapy planning},
  author = {Winter, Johanna and Ellerbrock, Malte and Jäkel, Oliver and Greilich, Steffen and Bangert, Mark},
  date = {2020-04-01},
  journaltitle = {Physics and Imaging in Radiation Oncology},
  shortjournal = {Physics and Imaging in Radiation Oncology},
  volume = {14},
  pages = {32--38},
  issn = {2405-6316},
  doi = {10.1016/j.phro.2020.05.001},
  url = {https://www.sciencedirect.com/science/article/pii/S2405631620300142},
  urldate = {2021-12-15},
  abstract = {Background and purpose Proton therapy may be promising for treating non-small-cell lung cancer due to lower doses to the lung and heart, as compared to photon therapy. A reported challenge is degradation, i.e., a smoothing of the depth-dose distribution due to heterogeneous lung tissue. For pencil beams, this causes a distal falloff widening and a peak-to-plateau ratio decrease, not considered in clinical treatment planning systems. Materials and methods We present a degradation model implemented into an analytical dose calculation, fully integrated into a treatment planning workflow. Degradation effects were investigated on target dose, distal dose falloffs, and mean lung dose for ten patient cases with varying anatomical characteristics. Results For patients with pronounced range straggling (in our study large tumors, or lesions close to the mediastinum), degradation effects were restricted to a maximum decrease in target coverage (D95 of the planning target volume) of 1.4\%. The median broadening of the distal 80–20\% dose falloffs was 0.5~mm at the maximum. For small target volumes deep inside lung tissue, however, the target underdose increased considerably by up to 26\%. The mean lung dose was not negatively affected by degradation in any of the investigated cases. Conclusion For most cases, dose degradation due to heterogeneous lung tissue did not yield critical organ at risk overdosing or overall target underdosing. However, for small and deep-seated tumors which can only be reached by penetrating lung tissue, we have seen substantial local underdose, which deserves further investigation, also considering other prevalent sources of uncertainty.},
  langid = {english},
  keywords = {Bragg peak degradation,Depth-dose degradation,Heterogeneous lung tissue,Non-small-cell lung carcinoma,Proton therapy,Radiotherapy planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\7NC697A3\\Winter et al. - 2020 - Analytical modeling of depth-dose degradation in h.pdf}
}

@article{Wolthaus2008,
  title = {Comparison of {{Different Strategies}} to {{Use Four-Dimensional Computed Tomography}} in {{Treatment Planning}} for {{Lung Cancer Patients}}},
  author = {Wolthaus, Jochem W H and Sonke, Jan-Jakob and family=Herk, given=Marcel, prefix=van, useprefix=true and Belderbos, Jos� S A and Rossi, Maddalena M G and Lebesque, Joos V and Damen, Eug�ne M F},
  date = {2008},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {70},
  number = {4},
  pages = {1229--1238},
  doi = {10.1016/j.ijrobp.2007.11.042},
  url = {http://www.sciencedirect.com/science/article/pii/S0360301607045920},
  keywords = {Computed tomography}
}

@article{Woodard1986,
  title = {The composition of body tissues},
  author = {Woodard, H Q},
  date = {1986},
  volume = {59},
  number = {708},
  pages = {10},
  abstract = {A reassessment of the composition data given by ICRP (1975) has been completed, augmented with results from appropriate recent studies. The water, lipid, protein, carbohydrate and ash contents, together with elemental compositions, mass and electron densities are given here for 56 body tissues. Seven tissues (adipose tissue, heart, kidney, liver, mammary gland, muscle—skeletal and skin) had sufficient measured data to enable the spread in the results to be evaluated. All the compositions presented apply to healthy, adult humans, except for some new material on the bones of children.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\ARNQQEBB\\Woodard - 1986 - The composition of body tissues.pdf}
}

@article{Worthy2009,
  title = {Parameter optimization in {{HN-IMRT}} for {{Elekta}} linacs},
  author = {Worthy, Danielle and Wu, Qiuwen},
  date = {2009-04-28},
  journaltitle = {Journal of Applied Clinical Medical Physics; Vol 10, No 2 (2009)},
  url = {http://www.jacmp.org/index.php/jacmp/article/view/2951/1594},
  abstract = {Normal 0 Normal 0 Planning and delivery in HN-IMRT has been challenging for Elekta linacs because of numerous machine limitations. Direct aperture optimization (DAO) algorithms have had success in simplifying the planning process and improving plan quality. Commercial adaptations of DAO allow for widespread use in many clinics, however clinical validation of these methods is still needed. In this work we evaluated Pinnacle 3 commercial software for HN-IMRT on Elekta linacs. The purpose was to find a set of planning parameters that are applicable to most patients and optimal in terms of plan quality, delivery efficiency and dosimetric accuracy. Four types of plans were created for each of 12 patients: ideal fluence optimization (FO), conventional two-step optimization (TS), segment weight optimization (SW) and direct machine parameter optimization (DMPO). Maximum number of segments (NS) and minimum segment area (MSA) were varied in DMPO. Results showed DMPO plans have the best optimization scores, dosimetric indices and the most consistent IMRT output among patients. At larger NS ( ? 80), plan quality decreases with increasing MSA as expected, except for MSA 2 , suggesting presence of local minima in DMPO. Segment area and MUs can vary significantly between optimization methods and parameter settings, however, the quantity ‘integral MU’ remains constant. Irradiation time is linearly proportional to total plan segments, weakly dependent on MUs and independent of MSA. Dosimetric accuracy is independent of DMPO parameters. The superior quality of DMPO makes it the choice for HN-IMRT on Elekta linacs and its consistency allows development of ‘class solutions’. However, planners should be aware of the local minima issue when pushing parameters to the limit such as NS 2 . The optimal set of parameters should be chosen to balance plan quality and delivery efficiency based on a systematic evaluation of the planning technique and system constraints.},
  keywords = {delivery efficiency,DMPO,dosimetric accuracy,head-and-neck,IMRT}
}

@article{Wu2000,
  title = {Algorithms and functionality of an intensity modulated radiotherapy optimization system.},
  author = {Wu, Q and Mohan, R},
  date = {2000},
  journaltitle = {Medical physics},
  volume = {27},
  number = {4},
  eprint = {10798692},
  eprinttype = {pmid},
  pages = {701--711},
  issn = {00942405},
  doi = {10.1118/1.598932},
  abstract = {The main purpose of this paper is to describe formalisms, algorithms, and certain unique features of a system for optimization of intensity modulated radiotherapy (IMRT). The system is coupled to a commercial treatment planning system with an accurate dose calculation engine based on the kernel superposition algorithm. The system was designed for use for research as well as for routine clinical practice. It employs dose- and dose-volume-based objective functions. The system can optimize IMRT plans with multiple target volumes simultaneously. Each target volume may be assigned a different prescription dose with constraints on either underdosing, or overdosing, or both. For organs at risk more than one constraint may be applied. This feature allows simultaneous treatment of primary, regional disease and electively treated nodes. The system allows specification of constraints on logical combinations of anatomic structures, such as a region of overlap between the prostate planning target volume and rectum or the volume of lung excluding the tumor. The optimization may also be performed on plans which, in addition to intensity-modulated beams, include other modalities such as non-IMRT photon and electron beams and brachytherapy sources. The various features of the system are illustrated with one phantom example and two clinical examples: a brain stereotactic radiosurgery case and a nasopharynx case. In the cylindrical phantom example, the use of the system for overlap regions is demonstrated. The brain stereotactic radiosurgery example shows the improvement of IMRT plans over the conventional arcs based plan and the three-dimensional conformal plan with multiple fixed gantry angles and demonstrates the application of our system to cases where small grid sizes are important. The nasopharynx example shows the potential of IMRT to simultaneously treat large and boost fields. It also illustrates the power of IMRT to protect normal anatomic structures for highly complex situations and the efficiency in planning and delivery achievable with IMRT. The overall IMRT planning time is typically less than 2 h on a Sun Ultrasparc workstation, most of which is spent in repeated computation of dose distributions.},
  keywords = {3d treatment planning,intensity modulated radiotherapy,optimization},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\3R4T5U9F\\Wu, Mohan - 2000 - Algorithms and functionality of an intensity modulated radiotherapy optimization system.pdf}
}

@article{Wu2002,
  ids = {Wu2002a},
  title = {Optimization of intensity-modulated radiotherapy plans based on the equivalent uniform dose},
  author = {Wu, Qiuwen and Mohan, Radhe and Niemierko, Andrzej and Schmidt-Ullrich, Rupert},
  date = {2002-01-01},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {52},
  number = {1},
  eprint = {11777642},
  eprinttype = {pmid},
  pages = {224--235},
  publisher = {{Elsevier}},
  issn = {03603016},
  doi = {10.1016/S0360-3016(01)02585-8},
  abstract = {PURPOSE The equivalent uniform dose (EUD) for tumors is defined as the biologically equivalent dose that, if given uniformly, will lead to the same cell kill in the tumor volume as the actual nonuniform dose distribution. Recently, a new formulation of EUD was introduced that applies to normal tissues as well. EUD can be a useful end point in evaluating treatment plans with nonuniform dose distributions for three-dimensional conformal radiotherapy and intensity-modulated radiotherapy. In this study, we introduce an objective function based on the EUD and investigate the feasibility and usefulness of using it for intensity-modulated radiotherapy optimization. METHODS AND MATERIALS We applied the EUD-based optimization to obtain intensity-modulated radiotherapy plans for prostate and head-and-neck cancer patients and compared them with the corresponding plans optimized with dose-volume-based criteria. RESULTS We found that, for the same or better target coverage, EUD-based optimization is capable of improving the sparing of critical structures beyond the specified requirements. We also found that, in the absence of constraints on the maximal target dose, the target dose distributions are more inhomogeneous, with significant hot spots within the target volume. This is an obvious consequence of unrestricted maximization target cell kill and, although this may be considered beneficial for some cases, it is generally not desirable. To minimize the magnitude of hot spots, we applied dose inhomogeneity constraints to the target by treating it as a "virtual" normal structure as well. This led to much-improved target dose homogeneity, with a small, but expected, degradation in normal structure sparing. We also found that, in principle, the dose-volume objective function may be able to arrive at similar optimum dose distributions by using multiple dose-volume constraints for each anatomic structure and with considerably greater trial-and-error to adjust a large number of objective function parameters. CONCLUSION The general inference drawn from our investigation is that the EUD-based objective function has the advantages that it needs only a small number of parameters and allows exploration of a much larger universe of solutions, making it easier for the optimization system to balance competing requirements in search of a better solution.},
  keywords = {Biologic models,Equivalent uniform dose,IMRT,Intensity-modulated radiotherapy,Optimization},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\VKEE6HKK\\Wu et al. - 2002 - Optimization of intensity-modulated radiotherapy p.pdf}
}

@article{Wu2003,
  title = {Treatment plan modification using voxel-based weighting factors/dose prescription.},
  author = {Wu, Chuan and Olivera, Gustavo H and Jeraj, Robert and Keller, Harry and Mackie, Thomas R},
  date = {2003-08-07},
  journaltitle = {Physics in medicine and biology},
  volume = {48},
  number = {15},
  eprint = {12953910},
  eprinttype = {pmid},
  pages = {2479--91},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/48/15/315},
  url = {http://iopscience.iop.org/0031-9155/48/15/315},
  urldate = {2013-06-24},
  abstract = {Under various clinical situations, it is desirable to modify the original treatment plan to better suit the clinical goals. In this work, a method to help physicians modify treatment plans based on their clinical preferences is proposed. The method uses a weighted quadratic dose objective function. The commonly used organ-/ROI-based weighting factors are expanded to a set of voxel-based weighting factors in order to obtain greater flexibility in treatment plan modification. Two different but equivalent modification schemes based on Rustem's quadratic programming algorithms--modification of a weighting matrix and modification of prescribed doses--are presented. Case studies demonstrated the effectiveness of the two methods with regard to their capability to fine-tune treatment plans.},
  keywords = {Algorithms,Computer-Assisted,Computer-Assisted: methods,Conformal,Conformal: methods,Dose Fractionation,Expert Systems,Humans,Nasopharyngeal Neoplasms,Nasopharyngeal Neoplasms: radiotherapy,Quality Control,Radiometry,Radiometry: methods,Radiotherapy,Radiotherapy Dosage,Radiotherapy Planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\DV8QWCAN\\Wu et al. - 2003 - Treatment plan modification using voxel-based weighting factorsdose prescription.pdf}
}

@software{XCOM,
  title = {{{XCOM}}: {{Photon Cross Section Database}}},
  shorttitle = {{{NIST XCOM}}},
  author = {Berger, M.J. and Hubbell, J.H. and Seltzer, S.M. and Chang, J. and Coursey, J.S. and Sukumar, R. and Zucker, D.S. and Olsen, K.},
  date = {2010},
  url = {http://physics.nist.gov/xcom}
}

@article{Xhaferllari2013,
  title = {Automated {{IMRT}} planning with regional optimization using planning scripts.},
  author = {Xhaferllari, Ilma and Wong, Eugene and Bzdusek, Karl and Lock, Michael and Chen, Jeff},
  date = {2013-01},
  journaltitle = {Journal of applied clinical medical physics / American College of Medical Physics},
  volume = {14},
  number = {1},
  eprint = {23318393},
  eprinttype = {pmid},
  pages = {4052},
  issn = {1526-9914},
  abstract = {Intensity-modulated radiation therapy (IMRT) has become a standard technique in radiation therapy for treating different types of cancers. Various class solutions have been developed for simple cases (e.g., localized prostate, whole breast) to generate IMRT plans efficiently. However, for more complex cases (e.g., head and neck, pelvic nodes), it can be time-consuming for a planner to generate optimized IMRT plans. To generate optimal plans in these more complex cases which generally have multiple target volumes and organs at risk, it is often required to have additional IMRT optimization structures such as dose limiting ring structures, adjust beam geometry, select inverse planning objectives and associated weights, and additional IMRT objectives to reduce cold and hot spots in the dose distribution. These parameters are generally manually adjusted with a repeated trial and error approach during the optimization process. To improve IMRT planning efficiency in these more complex cases, an iterative method that incorporates some of these adjustment processes automatically in a planning script is designed, implemented, and validated. In particular, regional optimization has been implemented in an iterative way to reduce various hot or cold spots during the optimization process that begins with defining and automatic segmentation of hot and cold spots, introducing new objectives and their relative weights into inverse planning, and turn this into an iterative process with termination criteria. The method has been applied to three clinical sites: prostate with pelvic nodes, head and neck, and anal canal cancers, and has shown to reduce IMRT planning time significantly for clinical applications with improved plan quality. The IMRT planning scripts have been used for more than 500 clinical cases.},
  keywords = {Algorithms,Humans,Neoplasms,Neoplasms: radiotherapy,Radiometry,Radiometry: methods,Radiotherapy Dosage,Radiotherapy Planning; Computer-Assisted,Radiotherapy Planning; Computer-Assisted: methods,Radiotherapy; Conformal,Radiotherapy; Conformal: methods},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\9ABUUWNG\\Xhaferllari et al. - 2013 - Automated IMRT planning with regional optimization using planning scripts.pdf}
}

@article{Xia1998,
  title = {Multileaf collimator leaf sequencing algorithm for intensity modulated beams with multiple static segments},
  author = {Xia, Ping and Verhey, Lynn J.},
  date = {1998},
  journaltitle = {Medical Physics},
  shortjournal = {Med Phys},
  volume = {25},
  number = {8},
  pages = {1424},
  issn = {00942405},
  doi = {10.1118/1.598315},
  url = {http://scitation.aip.org/content/aapm/journal/medphys/25/8/10.1118/1.598315},
  urldate = {2014-03-02}
}

@article{Xing1999a,
  title = {Optimization of importance factors in inverse planning},
  author = {Xing, L and Li, JG G and Donaldson, S and Le, Q T and Boyer, A L},
  date = {1999},
  journaltitle = {Physics in medicine and …},
  volume = {2525},
  number = {10},
  eprint = {10533926},
  eprinttype = {pmid},
  pages = {2525--2536},
  publisher = {{Department of Radiation Oncology, Stanford University School of Medicine, CA 94305-5304, USA. lei@reyes.stanford.edu}},
  url = {http://iopscience.iop.org/0031-9155/44/10/311},
  urldate = {2014-01-20},
  abstract = {Inverse treatment planning starts with a treatment objective and obtains the solution by optimizing an objective function. The clinical objectives are usually multifaceted and potentially incompatible with one another. A set of importance factors is often incorporated in the objective function to parametrize trade-off strategies and to prioritize the dose conformality in different anatomical structures. Whereas the general formalism remains the same, different sets of importance factors characterize plans of obviously different flavour and thus critically determine the final plan. Up to now, the determination of these parameters has been a 'guessing' game based on empirical knowledge because the final dose distribution depends on the parameters in a complex and implicit way. The influence of these parameters is not known until the plan optimization is completed. In order to compromise properly the conflicting requirements of the target and sensitive structures, the parameters are usually adjusted through a trial-and-error process. In this paper, a method to estimate these parameters computationally is proposed and an iterative computer algorithm is described to determine these parameters numerically. The treatment plan selection is done in two steps. First, a set of importance factors are chosen and the corresponding beam parameters (e.g. beam profiles) are optimized under the guidance of a quadratic objective function using an iterative algorithm reported earlier. The 'optimal' plan is then evaluated by an additional scoring function. The importance factors in the objective function are accordingly adjusted to improve the ranking of the plan. For every change in the importance factors, the beam parameters need to be re-optimized. This process continues in an iterative fashion until the scoring function is saturated. The algorithm was applied to two clinical cases and the results demonstrated that it has the potential to improve significantly the existing method of inverse planning. It was noticed that near the final solution the plan became insensitive to small variations of the importance factors.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\GY78UCXD\\Xing et al. - 1999 - Optimization of importance factors in inverse planning.pdf}
}

@article{Xing1999b,
  title = {Estimation theory and model parameter selection for therapeutic treatment plan optimization},
  author = {Xing, L. and Li, J. G. and Pugachev, A. and Le, Q. T. and Boyer, a. L.},
  date = {1999},
  journaltitle = {Medical Physics},
  volume = {26},
  number = {11},
  pages = {2348},
  issn = {00942405},
  doi = {10.1118/1.598749},
  url = {http://link.aip.org/link/MPHYA6/v26/i11/p2348/s1&Agg=doi},
  urldate = {2014-01-20},
  keywords = {intensity modulation,inverse,optimization,statistical analysis,treatment planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\NQT5H8DU\\Xing et al. - 1999 - Estimation theory and model parameter selection for therapeutic treatment plan optimization.pdf}
}

@article{Yang2004,
  title = {Inverse treatment planning with adaptively evolving voxel-dependent penalty scheme},
  author = {Yang, Yong and Xing, Lei},
  date = {2004-09-21},
  journaltitle = {Medical Physics},
  volume = {31},
  number = {10},
  pages = {2839},
  publisher = {{American Association of Physicists in Medicine}},
  issn = {00942405},
  doi = {10.1118/1.1799311},
  url = {http://scitation.aip.org/content/aapm/journal/medphys/31/10/10.1118/1.1799311},
  urldate = {2014-07-29},
  abstract = {In current inverse planning algorithms it is common to treat all voxels within a target or sensitive structure equally and use structure specific prescriptions and weighting factors as system parameters. In reality, the voxels within a structure are not identical in complying with their dosimetric goals and there exists strong intrastructural competition. Inverse planning objective function should not only balance the competing objectives of different structures but also that of the individual voxels in various structures. In this work we propose to model the intrastructural tradeoff through the modulation of voxel-dependent importance factors and deal with the challenging problem of how to obtain a sensible set of importance factors with a manageable amount of computing. Instead of letting the values of voxel-dependent importance to vary freely during the search process, an adaptive algorithm, in which the importance factors were tied to the local radiation doses through a heuristically constructed relation, was developed. It is shown that the approach is quite general and the EUD-based optimization is a special case of the proposed framework. The new planning tool was applied to study a hypothetical phantom case and a prostate case. Comparison of the results with that obtained using conventional inverse planning technique with structure specific importance factors indicated that the dose distributions from the conventional inverse planning are at best suboptimal and can be significantly improved with the help of the proposed nonuniform penalty scheme.}
}

@article{Yang2007,
  title = {Evaluation of on-board {{kV}} cone beam {{CT}} ({{CBCT}})-based dose calculation},
  author = {Yang, Yong and Schreibmann, Eduard and Li, Tianfang and Wang, Chuang and Xing, Lei},
  date = {2007-01},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {52},
  number = {3},
  pages = {685--705},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/52/3/011},
  url = {https://doi.org/10.1088/0031-9155/52/3/011},
  urldate = {2022-08-15},
  abstract = {On-board CBCT images are used to generate patient geometric models to assist patient setup. The image data can also, potentially, be used for dose reconstruction in combination with the fluence maps from treatment plan. Here we evaluate the achievable accuracy in using a kV CBCT for dose calculation. Relative electron density as a function of HU was obtained for both planning CT (pCT) and CBCT using a Catphan-600 calibration phantom. The CBCT calibration stability was monitored weekly for 8 consecutive weeks. A clinical treatment planning system was employed for pCT- and CBCT-based dose calculations and subsequent comparisons. Phantom and patient studies were carried out. In the former study, both Catphan-600 and pelvic phantoms were employed to evaluate the dosimetric performance of the full-fan and half-fan scanning modes. To evaluate the dosimetric influence of motion artefacts commonly seen in CBCT images, the Catphan-600 phantom was scanned with and without cyclic motion using the pCT and CBCT scanners. The doses computed based on the four sets of CT images (pCT and CBCT with/without motion) were compared quantitatively. The patient studies included a lung case and three prostate cases. The lung case was employed to further assess the adverse effect of intra-scan organ motion. Unlike the phantom study, the pCT of a patient is generally acquired at the time of simulation and the anatomy may be different from that of CBCT acquired at the time of treatment delivery because of organ deformation. To tackle the problem, we introduced a set of modified CBCT images (mCBCT) for each patient, which possesses the geometric information of the CBCT but the electronic density distribution mapped from the pCT with the help of a BSpline deformable image registration software. In the patient study, the dose computed with the mCBCT was used as a surrogate of the ‘ground truth’. We found that the CBCT electron density calibration curve differs moderately from that of pCT. No significant fluctuation was observed in the calibration over the period of 8 weeks. For the static phantom, the doses computed based on pCT and CBCT agreed to within 1\%. A notable difference in CBCT- and pCT-based dose distributions was found for the motion phantom due to the motion artefacts which appeared in the CBCT images (the maximum discrepancy was found to be ∼3.0\% in the high dose region). The motion artefacts-induced dosimetric inaccuracy was also observed in the lung patient study. For the prostate cases, the mCBCT- and CBCT-based dose calculations yielded very close results ({$<$}2\%). Coupled with the phantom data, it is concluded that the CBCT can be employed directly for dose calculation for a disease site such as the prostate, where there is little motion artefact. In the prostate case study, we also noted a large discrepancy between the original treatment plan and the CBCT (or mCBCT)-based calculation, suggesting the importance of inter-fractional organ movement and the need for adaptive therapy to compensate for the anatomical changes in the future.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\SR4L277Q\\Yang et al. - 2007 - Evaluation of on-board kV cone beam CT (CBCT)-base.pdf}
}

@article{Yang2017,
  title = {Superiorization-based multi-energy {{CT}} image reconstruction},
  author = {Yang, Q. and Cong, W. and Wang, G.},
  date = {2017-03},
  journaltitle = {Inverse Problems},
  shortjournal = {Inverse Problems},
  volume = {33},
  number = {4},
  pages = {044014},
  publisher = {{IOP Publishing}},
  issn = {0266-5611},
  doi = {10.1088/1361-6420/aa5e0a},
  url = {https://doi.org/10.1088/1361-6420/aa5e0a},
  urldate = {2022-06-17},
  abstract = {The recently-developed superiorization approach is efficient and robust for solving various constrained optimization problems. This methodology can be applied to multi-energy CT image reconstruction with the regularization in terms of the prior rank, intensity and sparsity model (PRISM). In this paper, we propose a superiorized version of the simultaneous algebraic reconstruction technique (SART) based on the PRISM model. Then, we compare the proposed superiorized algorithm with the Split-Bregman algorithm in numerical experiments. The results show that both the Superiorized-SART and the Split-Bregman algorithms generate good results with weak noise and reduced artefacts.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\8CKMNE3U\\Yang et al. - 2017 - Superiorization-based multi-energy CT image recons.pdf}
}

@article{Yao2016,
  title = {A correction scheme for a simplified analytical random walk model algorithm of proton dose calculation in distal {{Bragg}} peak regions},
  author = {Yao, Weiguang and Merchant, Thomas E and Farr, Jonathan B},
  date = {2016-10-21},
  journaltitle = {Physics in Medicine and Biology},
  volume = {61},
  number = {20},
  pages = {7397--7411},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/61/20/7397},
  url = {http://stacks.iop.org/0031-9155/61/i=20/a=7397?key=crossref.49de0324110e6390360ceca8caa8ff96},
  urldate = {2016-11-17},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\GMVREUK6\\Yao, Merchant, Farr - 2016 - A correction scheme for a simplified analytical random walk model algorithm of proton dose calculation in d.pdf}
}

@article{Yoo2002,
  title = {Engineering and {{Algorithm Design}} for an {{Image Processing API}}: {{A Technical Report}} on {{ITK}} -the {{Insight Toolkit}}},
  author = {Yoo, Terry S and Ackerman, Michael J and Lorensen, William E and Schroeder, Will and Chalana, Vikram and Aylward, Stephen and Metaxas, Dimitris and Whitaker, Ross},
  date = {2002},
  journaltitle = {Studies in Health Technology and Informatics},
  volume = {85},
  pages = {586--592},
  publisher = {{IOS Press}},
  abstract = {We present the detailed planning and execution of the Insight Toolkit (ITK), an application programmers interface (API) for the segmentation and registration of medical image data. This public resource has been developed through the NLM Visible Human Project, and is in beta test as an open-source software offering under cost-free licensing. The toolkit concentrates on 3D medical data segmentation and registration algorithms, multimodal and multiresolution capabilities, and portable platform independent support for Windows, Linux/Unix systems. This toolkit was built using current practices in software engineering. Specifically, we embraced the concept of generic programming during the development of these tools, working extensively with C++ templates and the freedom and flexibility they allow. Additional software development tools for distributed consortium-based code development have been created and are available from the project. In this paper, we discuss our assumptions, design decisions, and some of the lessons we have learned.},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\2BGL2YUZ\\Yoo et al. - 2002 - Engineering and Algorithm Design for an Image Processing API A Technical Report on ITK -the Insight Toolkit.pdf}
}

@article{Yoo2006,
  title = {Dosimetric feasibility of cone-beam {{CT-based}} treatment planning compared to {{CT-based}} treatment planning},
  author = {Yoo, Sua and Yin, Fang-Fang},
  date = {2006-12-01},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {66},
  number = {5},
  pages = {1553--1561},
  issn = {0360-3016},
  doi = {10.1016/j.ijrobp.2006.08.031},
  url = {https://www.sciencedirect.com/science/article/pii/S0360301606027945},
  urldate = {2022-08-15},
  abstract = {Purpose: Cone-beam computed tomography (CBCT) images are currently used for positioning verification. However, it is yet unknown whether CBCT could be used in dose calculation for replanning in adaptive radiation therapy. This study investigates the dosimetric feasibility of CBCT-based treatment planning. Methods and Materials: Hounsfield unit (HU) values and profiles of Catphan, homogeneous/inhomogeneous phantoms, and various tissue regions of patients in CBCT images were compared to those in CT. The dosimetric consequence of the HU variation was investigated by comparing CBCT-based treatment plans to conventional CT-based plans for both phantoms and patients. Results: The maximum HU difference between CBCT and CT of Catphan was 34 HU in the Teflon. The differences in other materials were less than 10 HU. The profiles for the homogeneous phantoms in CBCT displayed reduced HU values up to 150 HU in the peripheral regions compared to those in CT. The scatter and artifacts in CBCT became severe surrounding inhomogeneous tissues with reduced HU values up to 200 HU. The MU/cGy differences were less than 1\% for most phantom cases. The isodose distributions between CBCT-based and CT-based plans agreed very well. However, the discrepancy was larger when CBCT was scanned without a bowtie filter than with bowtie filter. Also, up to 3\% dosimetric error was observed in the plans for the inhomogeneous phantom. In the patient studies, the discrepancies of isodose lines between CT-based and CBCT-based plans, both 3D and IMRT, were less than 2 mm. Again, larger discrepancy occurred for the lung cancer patients. Conclusion: This study demonstrated the feasibility of CBCT-based treatment planning. CBCT-based treatment plans were dosimetrically comparable to CT-based treatment plans. Dosimetric data in the inhomogeneous tissue regions should be carefully validated.},
  langid = {english},
  keywords = {Cone-beam CT,HU values,Treatment planning},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\AQFX56MH\\Yoo und Yin - 2006 - Dosimetric feasibility of cone-beam CT-based treat.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\XN7F3S5D\\S0360301606027945.html}
}

@article{Yoon2007,
  title = {A new homogeneity index based on statistical analysis of the dose-volume histogram.},
  author = {Yoon, Myonggeun and Park, Sung Yong and Shin, Dongho and Lee, Se Byeong and Pyo, Hong Ryull and Kim, Dae Yong and Cho, Kwan Ho},
  date = {2007-01},
  journaltitle = {Journal of applied clinical medical physics / American College of Medical Physics},
  volume = {8},
  number = {2},
  eprint = {17592460},
  eprinttype = {pmid},
  pages = {9--17},
  issn = {1526-9914},
  url = {http://www.jacmp.org/index.php/jacmp/article/viewArticle/2390},
  urldate = {2013-06-24},
  abstract = {The goal of the present study was to develop a new dose-volume histogram (DVH)- based homogeneity index for effectively evaluating the dose homogeneity of intensity-modulated radiotherapy plans. The new index, called the sigma-index ("S-index") is defined as the standard deviation of the normalized differential DVH curve. In a study of 16 patients with brain tumors at our institution, the S-index was found to vary from 0.80 to 3.15. Our results showed that the S-index provides a more reliable and accurate measure of dose homogeneity than that given by conventional methods. A guideline for evaluating the dose homogeneity of treatment plans based on the S-index and its relation to equivalent uniform dose is discussed.},
  keywords = {Biological,Computer Simulation,Computer-Assisted,Computer-Assisted: methods,Conformal,Conformal: methods,Data Interpretation,Humans,Models,Radiometry,Radiometry: methods,Radiotherapy,Radiotherapy Dosage,Radiotherapy Planning,Reproducibility of Results,Sensitivity and Specificity,Statistical},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\3NQQ2BQA\\Yoon et al. - 2007 - A new homogeneity index based on statistical analysis of the dose-volume histogram.pdf}
}

@article{Yuan2013,
  title = {Feasibility study of in vivo {{MRI}} based dosimetric verification of proton end-of-range for liver cancer patients},
  author = {Yuan, Yading and Andronesi, Ovidiu C. and Bortfeld, Thomas R. and Richter, Christian and Wolf, Russell and Guimaraes, Alexander R. and Hong, Theodore S. and Seco, Joao},
  date = {2013-03-01},
  journaltitle = {Radiotherapy and Oncology},
  shortjournal = {Radiotherapy and Oncology},
  volume = {106},
  number = {3},
  pages = {378--382},
  issn = {0167-8140},
  doi = {10.1016/j.radonc.2013.01.016},
  url = {http://www.sciencedirect.com/science/article/pii/S0167814013000455},
  urldate = {2020-04-03},
  abstract = {Purpose To investigate the feasibility of using MRI to verify proton beam distal range for liver tumor treatment in a retrospective study. Methods and materials Because the follow-up hepatocyte-specific functional MR imaging can detect the radiobiological change of liver tissue after radiation, we firstly registered the contrast-enhanced MR images to the planning CT images from 5 liver patients, then overlaid the prescribed dose distribution on the MR images. Since dose calculation is most accurate at the penumbra dose region, we correlated the MR signal intensity (SI) to the radiation dose at the superior/inferior penumbra region. This dose–SI correlation was finally employed on registered MR images to estimate the proton end-of-range. Results Statistically significant correlations between radiation dose and MR SI were observed in superior/inferior penumbra regions, with correlation coefficient ranging from 0.93 to 0.99. By applying the dose-SI correlation to the distal region of each proton beam, the mean difference between MR-estimated and the planned dose range was −2.18±4.89mm for anterior–posterior beams and −3.90±5.87mm for lateral beams. Conclusions This feasibility study proved the principle that proton dose range can be verified in vivo by follow-up MR images after proton liver treatment.},
  langid = {english},
  keywords = {Distal proton range verification,dosimetry,Liver tumor,Magnetic resonance imaging,Proton therapy,Radiation effects on liver},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\3ESJYI7E\\Yuan et al. - 2013 - Feasibility study of in vivo MRI based dosimetric .pdf;C\:\\Users\\Niklas\\Zotero\\storage\\XCM676B5\\S0167814013000455.html}
}

@article{Yun2012,
  title = {An artificial neural network ({{ANN}})-based lung-tumor motion predictor for intrafractional {{MR}} tumor tracking.},
  author = {Yun, Jihyun and Mackenzie, Marc and Rathee, Satyapal and Robinson, Don and Fallone, B G},
  date = {2012-07},
  journaltitle = {Med Phys},
  volume = {39},
  number = {7},
  pages = {4423--4433},
  doi = {10.1118/1.4730294},
  url = {http://dx.doi.org/10.1118/1.4730294},
  abstract = {To address practical issues of implementing artificial neural networks (ANN) for lung-tumor motion prediction in MRI-based intrafractional lung-tumor tracking.A feedforward four-layered ANN structure is used to predict future tumor positions. A back-propagation algorithm is used for ANN learning. Adaptive learning is incorporated by continuously updating weights and learning rate during prediction. An ANN training scheme specific for MRI-based tracking is developed. A multiple-ANN structure is developed to reduce tracking failures caused by the lower imaging rates of MRI. We used particle swarm optimization to optimize the ANN structure and initial weights (IW) for each patient and treatment fraction. Prediction accuracy is evaluated using the 1D superior-inferior lung-tumor motions of 29 lung cancer patients for system delays of 120-520 ms, in increments of 80 ms. The result}
}

@article{Yun2012a,
  title = {Evaluation of a lung tumor autocontouring algorithm for intrafractional tumor tracking using low-field {{MRI}}: a phantom study.},
  author = {Yun, Jihyun and Yip, Eugene and Wachowicz, Keith and Rathee, Satyapal and Mackenzie, Marc and Robinson, Don and Fallone, B G},
  date = {2012},
  journaltitle = {Med Phys},
  volume = {39},
  number = {3},
  pages = {1481--1494},
  doi = {10.1118/1.3685578},
  url = {http://dx.doi.org/10.1118/1.3685578},
  abstract = {The first aim of this study is to investigate the feasibility of online autocontouring of tumor in low field MR images (0.2 and 0.5?T) by means of a phantom and simulation study for tumor-tracking in linac-MR systems. The second aim of this study is to develop an MR compatible, lung tumor motion phantom.An autocontouring algorithm was developed to determine both the position and shape of a lung tumor from each intra fractional MR image. To initiate the algorithm, an expert user contours the tumor and its maximum anticipated range of motion (herein termed the Background) using pretreatment scan data. During treatment, the algorithm processes each intrafractional MR image and automatically contours the tumor. To evaluate this algorithm, the authors built a phantom that replicates the low field contrast parameters (proton density, T(1), T(2)) of lung tumors and healthy lung parenchyma. This phantom allows simulation of MR images with the expected lung tumor CNR at 0.2 and 0.5?T by using a single 3?T scanner. Dynamic bSSFP images (approximately 4 images per second) are acquired while the phantom undergoes a series of preprogrammed motions based on patient lung tumor motion data. These images are autocontoured off-line using our algorithm. The fidelity of autocontouring is assessed by comparing autocontoured tumor shape and its centroid position to the actual tumor shape and its position.The algorithm successfully contoured the shape of a moving tumor model from dynamic MR images acquired every 275?ms. Dice's coefficients of {$>$}?0.96 and {$>$}?0.93 are achieved in 0.5 and 0.2?T equivalent images, respectively. Also, the algorithm tracked tumor position during dynamic studies, with root mean squared error (RMSE) values of}
}

@article{Zaider1999,
  title = {Practical considerations in using calculated healthy-tissue complication probabilities for treatment-plan optimization},
  author = {Zaider, M. and Amols, H. I.},
  date = {1999-05-01},
  journaltitle = {International Journal of Radiation Oncology*Biology*Physics},
  shortjournal = {International Journal of Radiation Oncology*Biology*Physics},
  volume = {44},
  number = {2},
  pages = {439--447},
  issn = {0360-3016},
  doi = {10.1016/S0360-3016(99)00014-0},
  url = {https://www.sciencedirect.com/science/article/pii/S0360301699000140},
  urldate = {2021-04-05},
  abstract = {Purpose: Healthy and neoplastic tissues are generally exposed nonuniformly to ionizing radiation. It is thus useful to develop algorithms that predict the probability of tumor control or normal tissue complication probability (NTCP) for any given spatial pattern of dose delivery. The questions addressed here concern: (a) the sensitivity of the NTCP predictions to the actual model used for extrapolation from uniform irradiation (where some clinical data exist) to nonuniform exposures, (b) its dependence on tissue type, and (c) consequences for treatment-plan optimization. Methods and Materials: Two (of several possible) NTCP formulations are used here: the Lyman model and a binomial equation. The effective volume-reduction scheme of Kutcher and Burman is used to obtain the NTCP for an arbitrary distribution of dose. NTCP was calculated for seven organs by postulating a dose distribution of maximum nonuniformity. Results: Both models fit available NTCP data well, but have very different extrapolations for exposures of small tissue volumes and very low values of NTCP (e.g., {$<$} 5\%) where no data exist. Organs with pronounced volume effects (lung, kidneys) show substantial NTCP differences between the two models. Even in organs where the volume effect is small (e.g., spinal cord, brain), differences in NTCP due to the model selected may still have serious clinical consequences, as an actual example (for the spinal cord) indicates. Conclusions: NTCP calculations based on extrapolations to volume fractions and/or NTCP levels for which reliable data do not exist depend on the model used to fit the data and the degree of dose nonuniformity. If NTCP is to be used in treatment-plan optimization, the prudent approach is to design plans that reproduce the conditions under which available dose-volume data were taken (e.g., uniform dose distributions).},
  langid = {english},
  keywords = {NTCP,TCP,Treatment plan optimization}
}

@article{Zarepisheh2012,
  title = {A {{Multi-Criteria Framework}} with {{Voxel-Dependent Parameters}} for {{Radiotherapy Treatment Plan Optimization}}},
  author = {Zarepisheh, M and Uribe-Sanchez, AF and Li, N},
  date = {2012},
  journaltitle = {arXiv preprint arXiv: …},
  url = {http://arxiv.org/abs/1210.7006},
  urldate = {2014-01-20}
}

@article{Zarepisheh2014,
  title = {A multicriteria framework with voxel-dependent parameters for radiotherapy treatment plan optimization.},
  author = {Zarepisheh, Masoud and Uribe-Sanchez, Andres F and Li, Nan and Jia, Xun and Jiang, Steve B},
  date = {2014-04-19},
  journaltitle = {Medical physics},
  volume = {41},
  number = {4},
  eprint = {24694125},
  eprinttype = {pmid},
  pages = {041705},
  publisher = {{American Association of Physicists in Medicine}},
  issn = {0094-2405},
  doi = {10.1118/1.4866886},
  url = {http://scitation.aip.org/content/aapm/journal/medphys/41/4/10.1118/1.4866886},
  urldate = {2014-05-07},
  abstract = {PURPOSE: To establish a new mathematical framework for radiotherapy treatment optimization with voxel-dependent optimization parameters. METHODS: In the treatment plan optimization problem for radiotherapy, a clinically acceptable plan is usually generated by an optimization process with weighting factors or reference doses adjusted for a set of the objective functions associated to the organs. Recent discoveries indicate that adjusting parameters associated with each voxel may lead to better plan quality. However, it is still unclear regarding the mathematical reasons behind it. Furthermore, questions about the objective function selection and parameter adjustment to assure Pareto optimality as well as the relationship between the optimal solutions obtained from the organ-based and voxel-based models remain unanswered. To answer these questions, the authors establish in this work a new mathematical framework equipped with two theorems. RESULTS: The new framework clarifies the different consequences of adjusting organ-dependent and voxel-dependent parameters for the treatment plan optimization of radiation therapy, as well as the impact of using different objective functions on plan qualities and Pareto surfaces. The main discoveries are threefold: (1) While in the organ-based model the selection of the objective function has an impact on the quality of the optimized plans, this is no longer an issue for the voxel-based model since the Pareto surface is independent of the objective function selection and the entire Pareto surface could be generated as long as the objective function satisfies certain mathematical conditions; (2) All Pareto solutions generated by the organ-based model with different objective functions are parts of a unique Pareto surface generated by the voxel-based model with any appropriate objective function; (3) A much larger Pareto surface is explored by adjusting voxel-dependent parameters than by adjusting organ-dependent parameters, possibly allowing for the generation of plans with better trade-offs among different clinical objectives. CONCLUSIONS: The authors have developed a mathematical framework for radiotherapy treatment optimization using voxel-based parameters. The authors can improve the plan quality by adjusting voxel-based weighting factors and exploring the unique and large Pareto surface which include all the Pareto surfaces that can be generated by organ-based model using different objective functions.},
  keywords = {intensity modulation,optimization,pareto surface,treatment planning,voxel-dependent}
}

@article{Zarepisheh2014a,
  title = {A {{DVH-guided IMRT}} optimization algorithm for automatic treatment planning and adaptive radiotherapy replanning.},
  author = {Zarepisheh, Masoud and Long, Troy and Li, Nan and Tian, Zhen and Romeijn, H Edwin and Jia, Xun and Jiang, Steve B},
  date = {2014-06-15},
  journaltitle = {Medical physics},
  volume = {41},
  number = {6},
  eprint = {24877806},
  eprinttype = {pmid},
  pages = {061711},
  publisher = {{American Association of Physicists in Medicine}},
  issn = {0094-2405},
  doi = {10.1118/1.4875700},
  url = {http://scitation.aip.org/content/aapm/journal/medphys/41/6/10.1118/1.4875700},
  urldate = {2014-08-07},
  abstract = {PURPOSE: To develop a novel algorithm that incorporates prior treatment knowledge into intensity modulated radiation therapy optimization to facilitate automatic treatment planning and adaptive radiotherapy (ART) replanning. METHODS: The algorithm automatically creates a treatment plan guided by the DVH curves of a reference plan that contains information on the clinician-approved dose-volume trade-offs among different targets/organs and among different portions of a DVH curve for an organ. In ART, the reference plan is the initial plan for the same patient, while for automatic treatment planning the reference plan is selected from a library of clinically approved and delivered plans of previously treated patients with similar medical conditions and geometry. The proposed algorithm employs a voxel-based optimization model and navigates the large voxel-based Pareto surface. The voxel weights are iteratively adjusted to approach a plan that is similar to the reference plan in terms of the DVHs. If the reference plan is feasible but not Pareto optimal, the algorithm generates a Pareto optimal plan with the DVHs better than the reference ones. If the reference plan is too restricting for the new geometry, the algorithm generates a Pareto plan with DVHs close to the reference ones. In both cases, the new plans have similar DVH trade-offs as the reference plans. RESULTS: The algorithm was tested using three patient cases and found to be able to automatically adjust the voxel-weighting factors in order to generate a Pareto plan with similar DVH trade-offs as the reference plan. The algorithm has also been implemented on a GPU for high efficiency. CONCLUSIONS: A novel prior-knowledge-based optimization algorithm has been developed that automatically adjust the voxel weights and generate a clinical optimal plan at high efficiency. It is found that the new algorithm can significantly improve the plan quality and planning efficiency in ART replanning and automatic treatment planning.}
}

@article{Zenklusen2010,
  title = {A study on repainting strategies for treating moderately moving targets with proton pencil beam scanning at the new {{Gantry}} 2 at {{PSI}}},
  author = {Zenklusen, S. M. and Pedroni, E. and Meer, D.},
  date = {2010-08},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {55},
  number = {17},
  pages = {5103--5121},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/55/17/014},
  url = {https://doi.org/10.1088%2F0031-9155%2F55%2F17%2F014},
  urldate = {2020-04-03},
  abstract = {Treating moving targets using a scanning gantry for proton therapy is a promising but very challenging, not yet clinically demonstrated treatment modality. The interference of organ motion with the sequence of the beam delivery produces uncontrolled dose inhomogeneities within the target. One promising approach to overcome this difficulty is to increase the speed of scanning in order to apply the dose repeatedly (so-called repainting). To obtain sufficiently high scanning speeds a new, technologically improved gantry—Gantry 2—has been designed and is currently under construction at PSI. As there are many possible repainting strategies, the way repainting will be implemented on Gantry 2 will depend on the result of a careful analysis of the various treatment delivery strategies available. To achieve this aim, and prior to the start of experimental work with Gantry 2, simulations of dose distribution errors due to organ motion under various beam delivery strategies were investigated. The effects of motion on the dose distribution were studied for moderate motion amplitudes (5 mm) for spherical target volumes in a homogeneous medium and with homogeneous dose. In total over 200 000 dose distributions have been simulated and analyzed and selected results are discussed. From the obtained results we are confident to be able to treat moderately moving targets on Gantry 2 using repainted pencil-beam spot scanning. Continuous line scanning seems to be the most elegant solution; it provides higher repainting rates and produces superior results but is probably more difficult to realize. For larger motion amplitudes, continuous line scanning still shows good results, but we plan anyways to use a gating system for these cases, not only to reduce the inhomogeneity within the target volume but also to reduce safety margins.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\NKNSC8BY\\Zenklusen et al. - 2010 - A study on repainting strategies for treating mode.pdf}
}

@article{Zhang2014,
  title = {Online image guided tumour tracking with scanned proton beams: a comprehensive simulation study},
  shorttitle = {Online image guided tumour tracking with scanned proton beams},
  author = {Zhang, Ye and Knopf, A and Tanner, C and Lomax, A J},
  date = {2014-12-21},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys. Med. Biol.},
  volume = {59},
  number = {24},
  pages = {7793--7817},
  issn = {0031-9155, 1361-6560},
  doi = {10.1088/0031-9155/59/24/7793},
  url = {http://stacks.iop.org/0031-9155/59/i=24/a=7793?key=crossref.924615ff0ee69315d06b0453d215c9de},
  urldate = {2020-04-03},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\552AKPUY\\Zhang et al. - 2014 - Online image guided tumour tracking with scanned p.pdf}
}

@article{Zheng2016,
  title = {An end-to-end assessment of range uncertainty in proton therapy using animal tissues},
  author = {Zheng, Yuanshui and Kang, Yixiu and Zeidan, Omar and Schreuder, Niek},
  date = {2016-11-21},
  journaltitle = {Physics in Medicine and Biology},
  volume = {61},
  number = {22},
  pages = {8010--8024},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/61/22/8010},
  url = {http://stacks.iop.org/0031-9155/61/i=22/a=8010?key=crossref.0940a6fed09a42218139d5e1754cc871},
  urldate = {2016-11-17},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\564BNX8Y\\Zheng et al. - 2016 - An end-to-end assessment of range uncertainty in proton therapy using animal tissues.pdf}
}

@article{Zhong2017,
  title = {Adaptive radiotherapy for {{NSCLC}} patients: utilizing the principle of energy conservation to evaluate dose mapping operations},
  shorttitle = {Adaptive radiotherapy for {{NSCLC}} patients},
  author = {Zhong, Hualiang and Chetty, Indrin J.},
  date = {2017-06-07},
  journaltitle = {Physics in medicine and biology},
  shortjournal = {Phys Med Biol},
  volume = {62},
  number = {11},
  eprint = {28475493},
  eprinttype = {pmid},
  pages = {4333--4345},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/aa54a5},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5726231/},
  urldate = {2022-08-11},
  abstract = {Tumor regression during the course of fractionated radiotherapy confounds the ability to accurately estimate the total dose delivered to tumor targets. Here we present a new criterion to improve the accuracy of image intensity-based dose mapping operations for adaptive radiotherapy for patients with non-small cell lung cancer (NSCLC). Six NSCLC patients were retrospectively investigated in this study. An image intensity-based B-spline registration algorithm was used for deformable image registration (DIR) of weekly CBCT images to a reference image. The resultant displacement vector fields were employed to map the doses calculated on weekly images to the reference image. The concept of energy conservation was introduced as a criterion to evaluate the accuracy of the dose mapping operations. A finite element method (FEM)-based mechanical model was implemented to improve the performance of the B-Spline-based registration algorithm in regions involving tumor regression. For the six patients, deformed tumor volumes changed by 21.2±15.0\% and 4.1±3.7\% on average for the B-Spline and the FEM-based registrations performed from fraction 1 to fraction 21, respectively. The energy deposited in the gross tumor volume (GTV) was 0.66 Joules (J) per fraction on average. The energy derived from the fractional dose reconstructed by the B-spline and FEM-based DIR algorithms in the deformed GTV’s was 0.51 J and 0.64 J, respectively. Based on landmark comparisons for the 6 patients, mean error for the FEM-based DIR algorithm was 2.5±1.9 mm. The cross-correlation coefficient between the landmark-measured displacement error and the loss of radiation energy was −0.16 for the FEM-based algorithm. To avoid uncertainties in measuring distorted landmarks, the B-Spline-based registrations were compared to the FEM registrations, and their displacement differences equal 4.2±4.7 mm on average. The displacement differences were correlated to their relative loss of radiation energy with a cross-correlation coefficient equal to 0.68. Based on the principle of energy conservation, the FEM-based mechanical model has a better performance than the B-Spline-based DIR algorithm. It is recommended that the principle of energy conservation be incorporated into a comprehensive QA protocol for adaptive radiotherapy.},
  pmcid = {PMC5726231},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\RDJZ2GTI\\Zhong und Chetty - 2017 - Adaptive radiotherapy for NSCLC patients utilizin.pdf}
}

@article{Zhu2014,
  title = {A single-field integrated boost treatment planning technique for spot scanning proton therapy.},
  author = {Zhu, Xiaorong Ronald and Poenisch, Falk and Li, Heng and Zhang, Xiaodong and Sahoo, Narayan and Wu, Richard Y and Li, Xiaoqiang and Lee, Andrew K and Chang, Eric L and Choi, Seungtaek and Pugh, Thomas and Frank, Steven J and Gillin, Michael T and Mahajan, Anita and Grosshans, David R},
  date = {2014},
  journaltitle = {Radiation Oncology},
  volume = {9},
  eprint = {25212571},
  eprinttype = {pmid},
  pages = {202},
  issn = {1748-717X},
  doi = {10.1186/1748-717X-9-202},
  url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4262206&tool=pmcentrez&rendertype=abstract},
  abstract = {PURPOSE: Intensity modulated proton therapy (IMPT) plans are normally generated utilizing multiple field optimization (MFO) techniques. Similar to photon based IMRT, MFO allows for the utilization of a simultaneous integrated boost in which multiple target volumes are treated to discrete doses simultaneously, potentially improving plan quality and streamlining quality assurance and treatment delivery. However, MFO may render plans more sensitive to the physical uncertainties inherent to particle therapy. Here we present clinical examples of a single-field integrated boost (SFIB) technique for spot scanning proton therapy based on single field optimization (SFO) treatment-planning techniques. METHODS AND MATERIALS: We designed plans of each type for illustrative patients with central nervous system (brain and spine), prostate and head and neck malignancies. SFIB and IMPT plans were constructed to deliver multiple prescription dose levels to multiple targets using SFO or MFO, respectively. Dose and fractionation schemes were based on the current clinical practice using X-ray IMRT in our clinic. For inverse planning, dose constraints were employed to achieve the desired target coverage and normal tissue sparing. Conformality and inhomogeneity indices were calculated to quantify plan quality. We also compared the worst-case robustness of the SFIB, sequential boost SFUD, and IMPT plans. RESULTS: The SFIB technique produced more conformal dose distributions than plans generated by sequential boost using a SFUD technique (conformality index for prescription isodose levels; 0.585 ± 0.30 vs. 0.435 ± 0.24, SFIB vs. SFUD respectively, Wilcoxon matched-pair signed rank test, p {$<$} 0.01). There was no difference in the conformality index between SFIB and IMPT plans (0.638 ± 0.27 vs. 0.633 ± 0.26, SFIB vs. IMPT, respectively). Heterogeneity between techniques was not significantly different. With respect to clinical metrics, SFIB plans proved more robust than the corresponding IMPT plans. CONCLUSIONS: SFIB technique for scanning beam proton therapy (SSPT) is now routinely employed in our clinic. The SFIB technique is a natural application of SFO and offers several advantages over SFUD, including more conformal plans, seamless treatment delivery and more efficient planning and QA. SFIB may be more robust than IMPT and has been the treatment planning technique of choice for some patients.},
  keywords = {Acinar Cell,Acinar Cell: radiotherapy,Adenocarcinoma,Adenocarcinoma: radiotherapy,Adult,Brain Neoplasms,Brain Neoplasms: radiotherapy,Carcinoma,Child,Computer-Assisted,Computer-Assisted: methods,Ependymoma,Ependymoma: radiotherapy,Glioma,Glioma: radiotherapy,Humans,Intensity-Modulated,Intensity-Modulated: methods,Male,Neoplasms,Neoplasms: radiotherapy,Parotid Neoplasms,Parotid Neoplasms: radiotherapy,Prostatic Neoplasms,Prostatic Neoplasms: radiotherapy,Proton Therapy,Proton Therapy: methods,Radiotherapy,Radiotherapy Planning,Spinal Cord Neoplasms,Spinal Cord Neoplasms: radiotherapy},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\M5PQVMBF\\Zhu et al. - 2014 - A single-field integrated boost treatment planning technique for spot scanning proton therapy.pdf}
}

@article{Ziegenhein2008,
  title = {Speed optimized influence matrix processing in inverse treatment planning tools.},
  author = {Ziegenhein, Peter and Wilkens, Jan J and Nill, Simeon and Ludwig, Thomas and Oelfke, Uwe},
  date = {2008},
  journaltitle = {Physics in medicine and biology},
  volume = {53},
  eprint = {18401066},
  eprinttype = {pmid},
  pages = {N157-N164},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/53/9/N02},
  abstract = {An optimal plan in modern treatment planning tools is found through the use of an iterative optimization algorithm, which deals with a high amount of patient-related data and number of treatment parameters to be optimized. Thus, calculating a good plan is a very time-consuming process which limits the application for patients in clinics and for research activities aiming for more accuracy. A common technique to handle the vast amount of radiation dose data is the concept of the influence matrix (DIJ), which stores the dose contribution of each bixel to the patient in the main memory of the computer. This study revealed that a bottleneck for the optimization time arises from the data transfer of the dose data between the memory and the CPU. In this note, we introduce a new method which speeds up the data transportation from stored dose data to the CPU. As an example we used the DIJ approach as is implemented in our treatment planning tool KonRad, developed at the German Cancer Research Center (DKFZ) in Heidelberg. A data cycle reordering method is proposed to take the advantage of modern memory hardware. This induces a minimal eviction policy which results in a memory behaviour exhibiting a 2.6 times faster algorithm compared to the naive implementation. Although our method is described for the DIJ approach implemented in KonRad, we believe that any other planning tool which uses a similar approach to store the dose data will also benefit from the described methods.}
}

@article{Ziegenhein2013,
  title = {Performance-optimized clinical {{IMRT}} planning on modern {{CPUs}}.},
  author = {Ziegenhein, Peter and Kamerling, Cornelis Ph and Bangert, Mark and Kunkel, Julian and Oelfke, Uwe},
  date = {2013-06-07},
  journaltitle = {Physics in medicine and biology},
  shortjournal = {Phys Med Biol},
  volume = {58},
  number = {11},
  eprint = {23656861},
  eprinttype = {pmid},
  pages = {3705--15},
  issn = {1361-6560},
  doi = {10.1088/0031-9155/58/11/3705},
  abstract = {Intensity modulated treatment plan optimization is a computationally expensive task. The feasibility of advanced applications in intensity modulated radiation therapy as every day treatment planning, frequent re-planning for adaptive radiation therapy and large-scale planning research severely depends on the runtime of the plan optimization implementation. Modern computational systems are built as parallel architectures to yield high performance. The use of GPUs, as one class of parallel systems, has become very popular in the field of medical physics. In contrast we utilize the multi-core central processing unit (CPU), which is the heart of every modern computer and does not have to be purchased additionally. In this work we present an ultra-fast, high precision implementation of the inverse plan optimization problem using a quasi-Newton method on pre-calculated dose influence data sets. We redefined the classical optimization algorithm to achieve a minimal runtime and high scalability on CPUs. Using the proposed methods in this work, a total plan optimization process can be carried out in only a few seconds on a low-cost CPU-based desktop computer at clinical resolution and quality. We have shown that our implementation uses the CPU hardware resources efficiently with runtimes comparable to GPU implementations, at lower costs.},
  keywords = {matRadGrant},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\CN8FAS4E\\Ziegenhein et al. - 2013 - Performance-optimized clinical IMRT planning on mo.pdf}
}

@thesis{Ziegenhein2013b,
  title = {Realizing a new paradigm in radiation therapy treatment planning},
  author = {Ziegenhein, Peter},
  date = {2013},
  institution = {{University of Heidelberg}},
  url = {http://archiv.ub.uni-heidelberg.de/volltextserver/15403/},
  langid = {english}
}

@article{Ziegenhein2016,
  title = {Interactive dose shaping part 1: a new paradigm for {{IMRT}} treatment planning},
  shorttitle = {Interactive dose shaping part 1},
  author = {Ziegenhein, Peter and Ph Kamerling, Cornelis and Oelfke, Uwe},
  date = {2016-03-21},
  journaltitle = {Physics in Medicine and Biology},
  shortjournal = {Phys Med Biol},
  volume = {61},
  number = {6},
  eprint = {26948145},
  eprinttype = {pmid},
  pages = {2457--2470},
  issn = {0031-9155},
  doi = {10.1088/0031-9155/61/6/2457},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5390946/},
  urldate = {2019-10-25},
  abstract = {In this work we present a novel treatment planning technique called interactive dose shaping (IDS) to be employed for the optimization of intensity modulated radiation therapy (IMRT). IDS does not rely on a Newton-based optimization algorithm which is driven by an objective function formed of dose volume constraints on pre-segmented volumes of interest (VOIs). Our new planning technique allows for direct, interactive adaptation of localized planning features. This is realized by a dose modification and recovery (DMR) planning engine which implements a two-step approach: firstly, the desired localized plan adaptation is imposed on the current plan (modification) while secondly inevitable, undesired disturbances of the dose pattern elsewhere are compensated for automatically by the recovery module. Together with an ultra-fast dose update calculation method the DMR engine has been implemented in a newly designed 3D therapy planning system Dynaplan enabling true real-time interactive therapy planning. Here we present the underlying strategy and algorithms of the DMR based planning concept. The functionality of the IDS planning approach is demonstrated for a phantom geometry of clinical resolution and size.},
  pmcid = {PMC5390946},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\85RQNGWX\\Ziegenhein et al. - 2016 - Interactive dose shaping part 1 a new paradigm fo.pdf}
}

@article{Ziegenhein2017,
  title = {Towards real-time photon {{Monte Carlo}} dose calculation in the cloud},
  author = {Ziegenhein, Peter and Kozin, Igor N and Kamerling, Cornelis Ph and Oelfke, Uwe},
  date = {2017-06-07},
  journaltitle = {Physics in Medicine and Biology},
  volume = {62},
  number = {11},
  pages = {4375--4389},
  publisher = {{IOP Publishing}},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/aa5d4e},
  url = {http://stacks.iop.org/0031-9155/62/i=11/a=4375?key=crossref.421bf0b1b7ecd9935931cafeac5fc43d},
  urldate = {2018-04-25},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\AZA3T68S\\Ziegenhein et al. - 2017 - Towards real-time photon Monte Carlo dose calculation in the cloud.pdf}
}

@book{zotero-1652,
  title = {Nonlinear {{Programming}}: {{Theory}} and {{Algorithms}}, 3rd {{Edition}} | {{Wiley}}},
  shorttitle = {Nonlinear {{Programming}}},
  url = {https://www.wiley.com/en-ag/Nonlinear+Programming%3A+Theory+and+Algorithms%2C+3rd+Edition-p-9780471486008},
  urldate = {2021-12-01},
  abstract = {COMPREHENSIVE COVERAGE OF NONLINEAR PROGRAMMING THEORY AND ALGORITHMS, THOROUGHLY REVISED AND EXPANDED Nonlinear Programming: Theory and Algorithms—now in an extensively updated Third Edition—addresses the problem of optimizing an objective function in the presence of equality and inequality constraints. Many realistic problems cannot be adequately represented as a linear program owing to the nature of the nonlinearity of the objective function and/or the nonlinearity of any constraints. The Third Edition begins with a general introduction to nonlinear programming with illustrative examples and guidelines for model construction. Concentration on the three major parts of nonlinear programming is provided: Convex analysis with discussion of topological properties of convex sets, separation and support of convex sets, polyhedral sets, extreme points and extreme directions of polyhedral sets, and linear programming Optimality conditions and duality with coverage of the nature, interpretation, and value of the classical Fritz John (FJ) and the Karush-Kuhn-Tucker (KKT) optimality conditions; the interrelationships between various proposed constraint qualifications; and Lagrangian duality and saddle point optimality conditions Algorithms and their convergence, with a presentation of algorithms for solving both unconstrained and constrained nonlinear programming problems Important features of the Third Edition include: New topics such as second interior point methods, nonconvex optimization, nondifferentiable optimization, and more Updated discussion and new applications in each chapter Detailed numerical examples and graphical illustrations Essential coverage of modeling and formulating nonlinear programs Simple numerical problems Advanced theoretical exercises The book is a solid reference for professionals as well as a useful text for students in the fields of operations research, management science, industrial engineering, applied mathematics, and also in engineering disciplines that deal with analytical optimization techniques. The logical and self-contained format uniquely covers nonlinear programming techniques with a great depth of information and an abundance of valuable examples and illustrations that showcase the most current advances in nonlinear problems.},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\AS8KGL6K\\Nonlinear+Programming+Theory+and+Algorithms,+3rd+Edition-p-9780471486008.html}
}

@online{zotero-20,
  title = {Parameters for the {{Lyman Kutcher Burman}} ({{LKB}}) model of {{Normal Tissue Complication Probability}} ({{NTCP}}) for specific rectal complications observed in clinical practise | {{Elsevier Enhanced Reader}}},
  doi = {10.1016/j.radonc.2011.10.022},
  url = {https://reader.elsevier.com/reader/sd/pii/S0167814011006396?token=E5C87E81BBC6B736C46749935DB6AAC9DF4A3FA64F1FDAFC6F6B260D41E9654E76111561E2FC18DBDCC136D1F994E0F6},
  urldate = {2019-08-14},
  langid = {english},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\LPVFEJMY\\Parameters for the Lyman Kutcher Burman (LKB) mode.pdf;C\:\\Users\\Niklas\\Zotero\\storage\\NCI7EIKY\\S0167814011006396.html}
}

@misc{zotero-204,
  title = {login @ www.sciencedirect.com.ubproxy.ub.uni-heidelberg.de}
}

@online{zotero-294,
  ids = {zotero-293},
  title = {Incorporating the {{Local Biological Effect}} of {{Dose Per Fraction}} in {{IMRT Inverse Optimization}} | {{SpringerLink}}},
  url = {https://link.springer.com/chapter/10.1007/978-981-10-9023-3_74},
  urldate = {2019-10-30},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\GX86MBWV\\978-981-10-9023-3_74.html;C\:\\Users\\Niklas\\Zotero\\storage\\UTHDJ8JD\\978-981-10-9023-3_74.html}
}

@online{zotero-295,
  title = {Minimum-{{MU}} and sparse-energy-layer ({{MMSEL}}) constrained inverse optimization method for efficiently deliverable {{PBS}} plans - {{IOPscience}}},
  url = {https://iopscience.iop.org/article/10.1088/1361-6560/ab4529/meta},
  urldate = {2019-10-30},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\DFHFN97T\\meta.html}
}

@online{zotero-297,
  ids = {zotero-296},
  title = {Automatic treatment planning based on three‐dimensional dose distribution predicted from deep learning technique - {{Fan}} - 2019 - {{Medical Physics}} - {{Wiley Online Library}}},
  url = {https://aapm.onlinelibrary.wiley.com/doi/full/10.1002/mp.13271},
  urldate = {2019-10-30},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\7N24IR23\\mp.html;C\:\\Users\\Niklas\\Zotero\\storage\\W4QYDR2C\\mp.html}
}

@online{zotero-871,
  title = {How much margin reduction is possible through gating or breath hold? - {{IOPscience}}},
  url = {https://iopscience.iop.org/article/10.1088/0031-9155/50/3/006/meta},
  urldate = {2020-03-23},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\FYG5KV9B\\How much margin reduction is possible through gati.pdf}
}

@online{zotero-875,
  title = {Motion in radiotherapy: particle therapy - {{IOPscience}}},
  url = {https://iopscience.iop.org/article/10.1088/0031-9155/56/16/R01/meta},
  urldate = {2020-03-23}
}

@online{zotero-9,
  title = {The linear-quadratic transformation of dose–volume histograms in fractionated radiotherapy - {{Radiotherapy}} and {{Oncology}}},
  url = {https://www.thegreenjournal.com/article/S0167-8140(97)00162-X/fulltext},
  urldate = {2019-09-23},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\HTHSEVDZ\\fulltext.html}
}

@online{zotero-928,
  title = {The spatial distribution of positron-emitting nuclei generated by relativistic light ion beams in organic matter - {{IOPscience}}},
  url = {https://iopscience.iop.org/article/10.1088/0031-9155/37/11/009},
  urldate = {2020-04-03},
  file = {C\:\\Users\\Niklas\\Zotero\\storage\\YGV4CUGN\\009.html}
}
